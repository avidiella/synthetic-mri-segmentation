
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-12-07 12:02:42.624446: do_dummy_2d_data_aug: False 
2025-12-07 12:02:42.743926: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-07 12:02:42.745929: The split file contains 5 splits. 
2025-12-07 12:02:42.745929: Desired fold for training: 0 
2025-12-07 12:02:42.746932: This split has 400 training and 100 validation cases. 
2025-12-07 12:03:16.604067: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [202, 202, 202], 'spacing': [1.2667700813876164, 1.2667700813876164, 1.2667700813876164], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset500_MRI', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [256, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0000001192092896, 'mean': 0.422696590423584, 'median': 0.4194243550300598, 'min': 0.0027002037968486547, 'percentile_00_5': 0.05628390982747078, 'percentile_99_5': 0.8565635681152344, 'std': 0.19347868859767914}}} 
 
2025-12-07 12:03:16.607102: unpacking dataset... 
2025-12-07 12:03:17.183792: unpacking done... 
2025-12-07 12:03:17.186795: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-12-07 12:03:17.238692:  
2025-12-07 12:03:17.238692: Epoch 0 
2025-12-07 12:03:17.238692: Current learning rate: 0.01 
2025-12-07 12:05:53.139965: train_loss 0.2196 
2025-12-07 12:05:53.142323: val_loss 0.0403 
2025-12-07 12:05:53.142323: Pseudo dice [0.4587, 0.5406, 0.1938] 
2025-12-07 12:05:53.144326: Epoch time: 155.9 s 
2025-12-07 12:05:53.144326: Yayy! New best EMA pseudo Dice: 0.3977 
2025-12-07 12:05:54.202162:  
2025-12-07 12:05:54.202162: Epoch 1 
2025-12-07 12:05:54.203249: Current learning rate: 0.00999 
2025-12-07 12:08:12.715917: train_loss -0.0151 
2025-12-07 12:08:12.715917: val_loss -0.0894 
2025-12-07 12:08:12.720767: Pseudo dice [0.5204, 0.5247, 0.4031] 
2025-12-07 12:08:12.720767: Epoch time: 138.51 s 
2025-12-07 12:08:12.722769: Yayy! New best EMA pseudo Dice: 0.4062 
2025-12-07 12:08:13.717835:  
2025-12-07 12:08:13.717835: Epoch 2 
2025-12-07 12:08:13.717835: Current learning rate: 0.00998 
2025-12-07 12:10:32.201926: train_loss -0.1272 
2025-12-07 12:10:32.201926: val_loss -0.2044 
2025-12-07 12:10:32.201926: Pseudo dice [0.5887, 0.6235, 0.4818] 
2025-12-07 12:10:32.201926: Epoch time: 138.48 s 
2025-12-07 12:10:32.201926: Yayy! New best EMA pseudo Dice: 0.422 
2025-12-07 12:10:33.311255:  
2025-12-07 12:10:33.311255: Epoch 3 
2025-12-07 12:10:33.311255: Current learning rate: 0.00997 
2025-12-07 12:12:51.732815: train_loss -0.1829 
2025-12-07 12:12:51.732815: val_loss -0.2453 
2025-12-07 12:12:51.734817: Pseudo dice [0.614, 0.6514, 0.5158] 
2025-12-07 12:12:51.734817: Epoch time: 138.42 s 
2025-12-07 12:12:51.736820: Yayy! New best EMA pseudo Dice: 0.4392 
2025-12-07 12:12:52.677979:  
2025-12-07 12:12:52.677979: Epoch 4 
2025-12-07 12:12:52.679981: Current learning rate: 0.00996 
2025-12-07 12:15:11.186821: train_loss -0.2242 
2025-12-07 12:15:11.186821: val_loss -0.2876 
2025-12-07 12:15:11.186821: Pseudo dice [0.6251, 0.6688, 0.5547] 
2025-12-07 12:15:11.186821: Epoch time: 138.51 s 
2025-12-07 12:15:11.186821: Yayy! New best EMA pseudo Dice: 0.4569 
2025-12-07 12:15:12.097795:  
2025-12-07 12:15:12.109192: Epoch 5 
2025-12-07 12:15:12.110253: Current learning rate: 0.00995 
2025-12-07 12:17:30.693334: train_loss -0.2805 
2025-12-07 12:17:30.694335: val_loss -0.3475 
2025-12-07 12:17:30.696335: Pseudo dice [0.6791, 0.7091, 0.6116] 
2025-12-07 12:17:30.697336: Epoch time: 138.6 s 
2025-12-07 12:17:30.698634: Yayy! New best EMA pseudo Dice: 0.4779 
2025-12-07 12:17:31.592087:  
2025-12-07 12:17:31.592087: Epoch 6 
2025-12-07 12:17:31.592087: Current learning rate: 0.00995 
2025-12-07 12:19:49.941831: train_loss -0.3535 
2025-12-07 12:19:49.941831: val_loss -0.4248 
2025-12-07 12:19:49.945835: Pseudo dice [0.7176, 0.7663, 0.6502] 
2025-12-07 12:19:49.945835: Epoch time: 138.35 s 
2025-12-07 12:19:49.947837: Yayy! New best EMA pseudo Dice: 0.5012 
2025-12-07 12:19:51.041833:  
2025-12-07 12:19:51.041833: Epoch 7 
2025-12-07 12:19:51.041833: Current learning rate: 0.00994 
2025-12-07 12:22:09.351999: train_loss -0.4049 
2025-12-07 12:22:09.351999: val_loss -0.461 
2025-12-07 12:22:09.354000: Pseudo dice [0.7487, 0.7912, 0.6669] 
2025-12-07 12:22:09.356002: Epoch time: 138.31 s 
2025-12-07 12:22:09.356002: Yayy! New best EMA pseudo Dice: 0.5247 
2025-12-07 12:22:10.270842:  
2025-12-07 12:22:10.270842: Epoch 8 
2025-12-07 12:22:10.271836: Current learning rate: 0.00993 
2025-12-07 12:24:28.592975: train_loss -0.4353 
2025-12-07 12:24:28.592975: val_loss -0.4571 
2025-12-07 12:24:28.594978: Pseudo dice [0.7581, 0.8073, 0.6306] 
2025-12-07 12:24:28.594978: Epoch time: 138.32 s 
2025-12-07 12:24:28.596981: Yayy! New best EMA pseudo Dice: 0.5454 
2025-12-07 12:24:29.511336:  
2025-12-07 12:24:29.511336: Epoch 9 
2025-12-07 12:24:29.511336: Current learning rate: 0.00992 
2025-12-07 12:26:47.756474: train_loss -0.4425 
2025-12-07 12:26:47.756474: val_loss -0.475 
2025-12-07 12:26:47.758476: Pseudo dice [0.7401, 0.8154, 0.6627] 
2025-12-07 12:26:47.758476: Epoch time: 138.25 s 
2025-12-07 12:26:47.760478: Yayy! New best EMA pseudo Dice: 0.5648 
2025-12-07 12:26:48.769609:  
2025-12-07 12:26:48.769609: Epoch 10 
2025-12-07 12:26:48.769609: Current learning rate: 0.00991 
2025-12-07 12:29:06.840700: train_loss -0.4845 
2025-12-07 12:29:06.842703: val_loss -0.5245 
2025-12-07 12:29:06.843822: Pseudo dice [0.7929, 0.8335, 0.6995] 
2025-12-07 12:29:06.844824: Epoch time: 138.07 s 
2025-12-07 12:29:06.844824: Yayy! New best EMA pseudo Dice: 0.5859 
2025-12-07 12:29:07.730428:  
2025-12-07 12:29:07.732430: Epoch 11 
2025-12-07 12:29:07.733517: Current learning rate: 0.0099 
2025-12-07 12:31:25.607714: train_loss -0.5058 
2025-12-07 12:31:25.607714: val_loss -0.5183 
2025-12-07 12:31:25.607714: Pseudo dice [0.7421, 0.8271, 0.7428] 
2025-12-07 12:31:25.615353: Epoch time: 137.88 s 
2025-12-07 12:31:25.615353: Yayy! New best EMA pseudo Dice: 0.6043 
2025-12-07 12:31:26.515118:  
2025-12-07 12:31:26.515118: Epoch 12 
2025-12-07 12:31:26.515118: Current learning rate: 0.00989 
2025-12-07 12:33:44.547827: train_loss -0.503 
2025-12-07 12:33:44.549829: val_loss -0.5551 
2025-12-07 12:33:44.549829: Pseudo dice [0.7826, 0.8474, 0.7459] 
2025-12-07 12:33:44.551833: Epoch time: 138.05 s 
2025-12-07 12:33:44.553840: Yayy! New best EMA pseudo Dice: 0.6231 
2025-12-07 12:33:45.812248:  
2025-12-07 12:33:45.812248: Epoch 13 
2025-12-07 12:33:45.812248: Current learning rate: 0.00988 
2025-12-07 12:36:03.736776: train_loss -0.5433 
2025-12-07 12:36:03.738779: val_loss -0.5758 
2025-12-07 12:36:03.738779: Pseudo dice [0.7995, 0.8558, 0.7635] 
2025-12-07 12:36:03.740782: Epoch time: 137.92 s 
2025-12-07 12:36:03.740782: Yayy! New best EMA pseudo Dice: 0.6414 
2025-12-07 12:36:04.655371:  
2025-12-07 12:36:04.655371: Epoch 14 
2025-12-07 12:36:04.655371: Current learning rate: 0.00987 
2025-12-07 12:38:22.670951: train_loss -0.5609 
2025-12-07 12:38:22.670951: val_loss -0.6053 
2025-12-07 12:38:22.670951: Pseudo dice [0.8259, 0.8745, 0.7606] 
2025-12-07 12:38:22.670951: Epoch time: 138.02 s 
2025-12-07 12:38:22.679574: Yayy! New best EMA pseudo Dice: 0.6593 
2025-12-07 12:38:23.561860:  
2025-12-07 12:38:23.561860: Epoch 15 
2025-12-07 12:38:23.561860: Current learning rate: 0.00986 
2025-12-07 12:40:41.843736: train_loss -0.5783 
2025-12-07 12:40:41.843736: val_loss -0.6026 
2025-12-07 12:40:41.843736: Pseudo dice [0.8147, 0.8636, 0.774] 
2025-12-07 12:40:41.859708: Epoch time: 138.28 s 
2025-12-07 12:40:41.859708: Yayy! New best EMA pseudo Dice: 0.6751 
2025-12-07 12:40:42.827409:  
2025-12-07 12:40:42.827409: Epoch 16 
2025-12-07 12:40:42.843043: Current learning rate: 0.00986 
2025-12-07 12:43:00.951350: train_loss -0.6051 
2025-12-07 12:43:00.951350: val_loss -0.6286 
2025-12-07 12:43:00.952852: Pseudo dice [0.8275, 0.8794, 0.7966] 
2025-12-07 12:43:00.954854: Epoch time: 138.12 s 
2025-12-07 12:43:00.954854: Yayy! New best EMA pseudo Dice: 0.6911 
2025-12-07 12:43:01.872051:  
2025-12-07 12:43:01.872051: Epoch 17 
2025-12-07 12:43:01.873054: Current learning rate: 0.00985 
2025-12-07 12:45:20.038627: train_loss -0.5668 
2025-12-07 12:45:20.040629: val_loss -0.5955 
2025-12-07 12:45:20.040629: Pseudo dice [0.8052, 0.865, 0.7676] 
2025-12-07 12:45:20.042631: Epoch time: 138.17 s 
2025-12-07 12:45:20.042631: Yayy! New best EMA pseudo Dice: 0.7032 
2025-12-07 12:45:20.970897:  
2025-12-07 12:45:20.971897: Epoch 18 
2025-12-07 12:45:20.973049: Current learning rate: 0.00984 
2025-12-07 12:47:39.014487: train_loss -0.586 
2025-12-07 12:47:39.016227: val_loss -0.6399 
2025-12-07 12:47:39.018230: Pseudo dice [0.8319, 0.8798, 0.7976] 
2025-12-07 12:47:39.018230: Epoch time: 138.04 s 
2025-12-07 12:47:39.020233: Yayy! New best EMA pseudo Dice: 0.7165 
2025-12-07 12:47:40.126882:  
2025-12-07 12:47:40.126882: Epoch 19 
2025-12-07 12:47:40.126882: Current learning rate: 0.00983 
2025-12-07 12:49:58.042298: train_loss -0.6258 
2025-12-07 12:49:58.042298: val_loss -0.6484 
2025-12-07 12:49:58.044300: Pseudo dice [0.8286, 0.8863, 0.8122] 
2025-12-07 12:49:58.045804: Epoch time: 137.92 s 
2025-12-07 12:49:58.047810: Yayy! New best EMA pseudo Dice: 0.7291 
2025-12-07 12:49:58.963232:  
2025-12-07 12:49:58.963232: Epoch 20 
2025-12-07 12:49:58.964236: Current learning rate: 0.00982 
2025-12-07 12:52:17.379574: train_loss -0.6257 
2025-12-07 12:52:17.379574: val_loss -0.6573 
2025-12-07 12:52:17.381579: Pseudo dice [0.832, 0.8862, 0.8171] 
2025-12-07 12:52:17.382582: Epoch time: 138.42 s 
2025-12-07 12:52:17.383585: Yayy! New best EMA pseudo Dice: 0.7407 
2025-12-07 12:52:18.296248:  
2025-12-07 12:52:18.296248: Epoch 21 
2025-12-07 12:52:18.296248: Current learning rate: 0.00981 
2025-12-07 12:54:37.452593: train_loss -0.6351 
2025-12-07 12:54:37.452593: val_loss -0.6621 
2025-12-07 12:54:37.452593: Pseudo dice [0.8363, 0.8972, 0.8063] 
2025-12-07 12:54:37.452593: Epoch time: 139.16 s 
2025-12-07 12:54:37.468580: Yayy! New best EMA pseudo Dice: 0.7513 
2025-12-07 12:54:38.344551:  
2025-12-07 12:54:38.344551: Epoch 22 
2025-12-07 12:54:38.344551: Current learning rate: 0.0098 
2025-12-07 12:56:56.899885: train_loss -0.6617 
2025-12-07 12:56:56.899885: val_loss -0.6814 
2025-12-07 12:56:56.901886: Pseudo dice [0.8482, 0.9002, 0.8436] 
2025-12-07 12:56:56.902886: Epoch time: 138.56 s 
2025-12-07 12:56:56.903886: Yayy! New best EMA pseudo Dice: 0.7626 
2025-12-07 12:56:57.956879:  
2025-12-07 12:56:57.956879: Epoch 23 
2025-12-07 12:56:57.956879: Current learning rate: 0.00979 
2025-12-07 12:59:16.344981: train_loss -0.6593 
2025-12-07 12:59:16.344981: val_loss -0.669 
2025-12-07 12:59:16.346983: Pseudo dice [0.8425, 0.8934, 0.8158] 
2025-12-07 12:59:16.346983: Epoch time: 138.39 s 
2025-12-07 12:59:16.346983: Yayy! New best EMA pseudo Dice: 0.7714 
2025-12-07 12:59:17.233570:  
2025-12-07 12:59:17.233570: Epoch 24 
2025-12-07 12:59:17.233570: Current learning rate: 0.00978 
2025-12-07 13:01:35.506209: train_loss -0.6638 
2025-12-07 13:01:35.506209: val_loss -0.697 
2025-12-07 13:01:35.508219: Pseudo dice [0.8536, 0.9118, 0.8405] 
2025-12-07 13:01:35.509218: Epoch time: 138.27 s 
2025-12-07 13:01:35.510219: Yayy! New best EMA pseudo Dice: 0.7811 
2025-12-07 13:01:36.388420:  
2025-12-07 13:01:36.388420: Epoch 25 
2025-12-07 13:01:36.388420: Current learning rate: 0.00977 
2025-12-07 13:03:54.779933: train_loss -0.6685 
2025-12-07 13:03:54.779933: val_loss -0.6985 
2025-12-07 13:03:54.782322: Pseudo dice [0.8537, 0.9031, 0.8396] 
2025-12-07 13:03:54.782322: Epoch time: 138.39 s 
2025-12-07 13:03:54.782322: Yayy! New best EMA pseudo Dice: 0.7895 
2025-12-07 13:03:55.703962:  
2025-12-07 13:03:55.704962: Epoch 26 
2025-12-07 13:03:55.706256: Current learning rate: 0.00977 
2025-12-07 13:06:14.180086: train_loss -0.6646 
2025-12-07 13:06:14.181088: val_loss -0.6694 
2025-12-07 13:06:14.183092: Pseudo dice [0.8369, 0.8871, 0.8324] 
2025-12-07 13:06:14.183092: Epoch time: 138.48 s 
2025-12-07 13:06:14.184093: Yayy! New best EMA pseudo Dice: 0.7958 
2025-12-07 13:06:15.092323:  
2025-12-07 13:06:15.092323: Epoch 27 
2025-12-07 13:06:15.092323: Current learning rate: 0.00976 
2025-12-07 13:08:33.145122: train_loss -0.6767 
2025-12-07 13:08:33.145122: val_loss -0.684 
2025-12-07 13:08:33.147125: Pseudo dice [0.8436, 0.8973, 0.8562] 
2025-12-07 13:08:33.149128: Epoch time: 138.05 s 
2025-12-07 13:08:33.151134: Yayy! New best EMA pseudo Dice: 0.8028 
2025-12-07 13:08:34.030535:  
2025-12-07 13:08:34.030535: Epoch 28 
2025-12-07 13:08:34.030535: Current learning rate: 0.00975 
2025-12-07 13:10:51.983656: train_loss -0.6823 
2025-12-07 13:10:51.983656: val_loss -0.6834 
2025-12-07 13:10:51.983656: Pseudo dice [0.8393, 0.9003, 0.8465] 
2025-12-07 13:10:51.983656: Epoch time: 137.95 s 
2025-12-07 13:10:51.983656: Yayy! New best EMA pseudo Dice: 0.8087 
2025-12-07 13:10:52.868313:  
2025-12-07 13:10:52.868313: Epoch 29 
2025-12-07 13:10:52.868313: Current learning rate: 0.00974 
2025-12-07 13:13:10.874206: train_loss -0.6954 
2025-12-07 13:13:10.874206: val_loss -0.699 
2025-12-07 13:13:10.874206: Pseudo dice [0.8432, 0.9005, 0.8688] 
2025-12-07 13:13:10.874206: Epoch time: 138.01 s 
2025-12-07 13:13:10.874206: Yayy! New best EMA pseudo Dice: 0.8149 
2025-12-07 13:13:11.932128:  
2025-12-07 13:13:11.932128: Epoch 30 
2025-12-07 13:13:11.932128: Current learning rate: 0.00973 
2025-12-07 13:15:29.999683: train_loss -0.6946 
2025-12-07 13:15:29.999683: val_loss -0.7117 
2025-12-07 13:15:29.999683: Pseudo dice [0.8577, 0.9027, 0.8537] 
2025-12-07 13:15:29.999683: Epoch time: 138.07 s 
2025-12-07 13:15:29.999683: Yayy! New best EMA pseudo Dice: 0.8206 
2025-12-07 13:15:30.888777:  
2025-12-07 13:15:30.888777: Epoch 31 
2025-12-07 13:15:30.888777: Current learning rate: 0.00972 
2025-12-07 13:17:48.909447: train_loss -0.7042 
2025-12-07 13:17:48.910448: val_loss -0.7234 
2025-12-07 13:17:48.911448: Pseudo dice [0.86, 0.9105, 0.8626] 
2025-12-07 13:17:48.912448: Epoch time: 138.02 s 
2025-12-07 13:17:48.914448: Yayy! New best EMA pseudo Dice: 0.8263 
2025-12-07 13:17:49.828179:  
2025-12-07 13:17:49.829184: Epoch 32 
2025-12-07 13:17:49.829184: Current learning rate: 0.00971 
2025-12-07 13:20:07.793944: train_loss -0.7064 
2025-12-07 13:20:07.793944: val_loss -0.7209 
2025-12-07 13:20:07.796949: Pseudo dice [0.8592, 0.9071, 0.8653] 
2025-12-07 13:20:07.798951: Epoch time: 137.97 s 
2025-12-07 13:20:07.798951: Yayy! New best EMA pseudo Dice: 0.8314 
2025-12-07 13:20:08.699880:  
2025-12-07 13:20:08.701621: Epoch 33 
2025-12-07 13:20:08.701621: Current learning rate: 0.0097 
2025-12-07 13:22:26.841862: train_loss -0.7052 
2025-12-07 13:22:26.841862: val_loss -0.7285 
2025-12-07 13:22:26.843602: Pseudo dice [0.8619, 0.9052, 0.8859] 
2025-12-07 13:22:26.843602: Epoch time: 138.14 s 
2025-12-07 13:22:26.843602: Yayy! New best EMA pseudo Dice: 0.8367 
2025-12-07 13:22:27.740093:  
2025-12-07 13:22:27.740093: Epoch 34 
2025-12-07 13:22:27.741402: Current learning rate: 0.00969 
2025-12-07 13:24:45.795722: train_loss -0.7063 
2025-12-07 13:24:45.798494: val_loss -0.7337 
2025-12-07 13:24:45.798494: Pseudo dice [0.8641, 0.9149, 0.8744] 
2025-12-07 13:24:45.800663: Epoch time: 138.06 s 
2025-12-07 13:24:45.800663: Yayy! New best EMA pseudo Dice: 0.8414 
2025-12-07 13:24:46.715203:  
2025-12-07 13:24:46.715203: Epoch 35 
2025-12-07 13:24:46.717796: Current learning rate: 0.00968 
2025-12-07 13:27:04.813298: train_loss -0.7245 
2025-12-07 13:27:04.813298: val_loss -0.7427 
2025-12-07 13:27:04.817307: Pseudo dice [0.8612, 0.9097, 0.8896] 
2025-12-07 13:27:04.819311: Epoch time: 138.1 s 
2025-12-07 13:27:04.821313: Yayy! New best EMA pseudo Dice: 0.846 
2025-12-07 13:27:05.921616:  
2025-12-07 13:27:05.921616: Epoch 36 
2025-12-07 13:27:05.921616: Current learning rate: 0.00968 
2025-12-07 13:29:24.091347: train_loss -0.7268 
2025-12-07 13:29:24.093348: val_loss -0.7458 
2025-12-07 13:29:24.093348: Pseudo dice [0.8731, 0.9194, 0.8733] 
2025-12-07 13:29:24.093348: Epoch time: 138.17 s 
2025-12-07 13:29:24.093348: Yayy! New best EMA pseudo Dice: 0.8503 
2025-12-07 13:29:24.998879:  
2025-12-07 13:29:24.999885: Epoch 37 
2025-12-07 13:29:25.000924: Current learning rate: 0.00967 
2025-12-07 13:31:43.165655: train_loss -0.7175 
2025-12-07 13:31:43.165655: val_loss -0.7488 
2025-12-07 13:31:43.165655: Pseudo dice [0.8687, 0.9196, 0.8825] 
2025-12-07 13:31:43.165655: Epoch time: 138.17 s 
2025-12-07 13:31:43.165655: Yayy! New best EMA pseudo Dice: 0.8543 
2025-12-07 13:31:44.078124:  
2025-12-07 13:31:44.078124: Epoch 38 
2025-12-07 13:31:44.078124: Current learning rate: 0.00966 
2025-12-07 13:34:02.928632: train_loss -0.7176 
2025-12-07 13:34:02.928632: val_loss -0.7436 
2025-12-07 13:34:02.930634: Pseudo dice [0.8716, 0.9153, 0.8855] 
2025-12-07 13:34:02.930634: Epoch time: 138.85 s 
2025-12-07 13:34:02.932636: Yayy! New best EMA pseudo Dice: 0.8579 
2025-12-07 13:34:03.874761:  
2025-12-07 13:34:03.874761: Epoch 39 
2025-12-07 13:34:03.874761: Current learning rate: 0.00965 
2025-12-07 13:36:22.391249: train_loss -0.708 
2025-12-07 13:36:22.391249: val_loss -0.7507 
2025-12-07 13:36:22.393255: Pseudo dice [0.8793, 0.9222, 0.8788] 
2025-12-07 13:36:22.393255: Epoch time: 138.52 s 
2025-12-07 13:36:22.394257: Yayy! New best EMA pseudo Dice: 0.8615 
2025-12-07 13:36:23.295635:  
2025-12-07 13:36:23.295635: Epoch 40 
2025-12-07 13:36:23.295635: Current learning rate: 0.00964 
2025-12-07 13:38:41.825699: train_loss -0.7291 
2025-12-07 13:38:41.826824: val_loss -0.7613 
2025-12-07 13:38:41.827859: Pseudo dice [0.8764, 0.9237, 0.889] 
2025-12-07 13:38:41.828870: Epoch time: 138.53 s 
2025-12-07 13:38:41.829872: Yayy! New best EMA pseudo Dice: 0.865 
2025-12-07 13:38:42.742896:  
2025-12-07 13:38:42.744899: Epoch 41 
2025-12-07 13:38:42.744899: Current learning rate: 0.00963 
2025-12-07 13:41:01.513389: train_loss -0.7332 
2025-12-07 13:41:01.513389: val_loss -0.7374 
2025-12-07 13:41:01.513389: Pseudo dice [0.854, 0.8996, 0.8852] 
2025-12-07 13:41:01.513389: Epoch time: 138.77 s 
2025-12-07 13:41:01.513389: Yayy! New best EMA pseudo Dice: 0.8664 
2025-12-07 13:41:02.762189:  
2025-12-07 13:41:02.762189: Epoch 42 
2025-12-07 13:41:02.762189: Current learning rate: 0.00962 
2025-12-07 13:43:21.392246: train_loss -0.7321 
2025-12-07 13:43:21.392246: val_loss -0.7654 
2025-12-07 13:43:21.396259: Pseudo dice [0.8763, 0.9273, 0.8869] 
2025-12-07 13:43:21.398261: Epoch time: 138.63 s 
2025-12-07 13:43:21.398261: Yayy! New best EMA pseudo Dice: 0.8695 
2025-12-07 13:43:22.296043:  
2025-12-07 13:43:22.296043: Epoch 43 
2025-12-07 13:43:22.296043: Current learning rate: 0.00961 
2025-12-07 13:45:40.435916: train_loss -0.7375 
2025-12-07 13:45:40.435916: val_loss -0.7605 
2025-12-07 13:45:40.439421: Pseudo dice [0.8744, 0.9184, 0.8994] 
2025-12-07 13:45:40.439421: Epoch time: 138.14 s 
2025-12-07 13:45:40.441425: Yayy! New best EMA pseudo Dice: 0.8723 
2025-12-07 13:45:41.341435:  
2025-12-07 13:45:41.343438: Epoch 44 
2025-12-07 13:45:41.343438: Current learning rate: 0.0096 
2025-12-07 13:47:59.490836: train_loss -0.7405 
2025-12-07 13:47:59.490836: val_loss -0.7674 
2025-12-07 13:47:59.490836: Pseudo dice [0.8785, 0.9207, 0.8934] 
2025-12-07 13:47:59.490836: Epoch time: 138.15 s 
2025-12-07 13:47:59.490836: Yayy! New best EMA pseudo Dice: 0.8748 
2025-12-07 13:48:00.418223:  
2025-12-07 13:48:00.418223: Epoch 45 
2025-12-07 13:48:00.420227: Current learning rate: 0.00959 
2025-12-07 13:50:18.262044: train_loss -0.7367 
2025-12-07 13:50:18.264782: val_loss -0.7574 
2025-12-07 13:50:18.265785: Pseudo dice [0.8693, 0.9164, 0.8974] 
2025-12-07 13:50:18.267915: Epoch time: 137.84 s 
2025-12-07 13:50:18.268916: Yayy! New best EMA pseudo Dice: 0.8767 
2025-12-07 13:50:19.171134:  
2025-12-07 13:50:19.171134: Epoch 46 
2025-12-07 13:50:19.173098: Current learning rate: 0.00959 
2025-12-07 13:52:37.202387: train_loss -0.7436 
2025-12-07 13:52:37.202387: val_loss -0.7717 
2025-12-07 13:52:37.202387: Pseudo dice [0.8737, 0.9235, 0.8935] 
2025-12-07 13:52:37.202387: Epoch time: 138.03 s 
2025-12-07 13:52:37.202387: Yayy! New best EMA pseudo Dice: 0.8788 
2025-12-07 13:52:38.061700:  
2025-12-07 13:52:38.061700: Epoch 47 
2025-12-07 13:52:38.077672: Current learning rate: 0.00958 
2025-12-07 13:54:56.026354: train_loss -0.7512 
2025-12-07 13:54:56.026354: val_loss -0.7578 
2025-12-07 13:54:56.026354: Pseudo dice [0.8669, 0.9171, 0.8977] 
2025-12-07 13:54:56.029906: Epoch time: 137.96 s 
2025-12-07 13:54:56.031908: Yayy! New best EMA pseudo Dice: 0.8803 
2025-12-07 13:54:57.078152:  
2025-12-07 13:54:57.078152: Epoch 48 
2025-12-07 13:54:57.078152: Current learning rate: 0.00957 
2025-12-07 13:57:15.120730: train_loss -0.7548 
2025-12-07 13:57:15.120730: val_loss -0.7752 
2025-12-07 13:57:15.122733: Pseudo dice [0.8817, 0.925, 0.8889] 
2025-12-07 13:57:15.124736: Epoch time: 138.04 s 
2025-12-07 13:57:15.124736: Yayy! New best EMA pseudo Dice: 0.8821 
2025-12-07 13:57:15.998859:  
2025-12-07 13:57:15.998859: Epoch 49 
2025-12-07 13:57:16.014501: Current learning rate: 0.00956 
2025-12-07 13:59:33.967801: train_loss -0.7621 
2025-12-07 13:59:33.967801: val_loss -0.7815 
2025-12-07 13:59:33.967801: Pseudo dice [0.882, 0.9293, 0.8922] 
2025-12-07 13:59:33.967801: Epoch time: 137.97 s 
2025-12-07 13:59:34.223984: Yayy! New best EMA pseudo Dice: 0.884 
2025-12-07 13:59:35.109556:  
2025-12-07 13:59:35.109556: Epoch 50 
2025-12-07 13:59:35.109556: Current learning rate: 0.00955 
2025-12-07 14:01:53.284263: train_loss -0.7651 
2025-12-07 14:01:53.284263: val_loss -0.7713 
2025-12-07 14:01:53.286264: Pseudo dice [0.8695, 0.9142, 0.9061] 
2025-12-07 14:01:53.288265: Epoch time: 138.17 s 
2025-12-07 14:01:53.289265: Yayy! New best EMA pseudo Dice: 0.8853 
2025-12-07 14:01:54.192549:  
2025-12-07 14:01:54.193554: Epoch 51 
2025-12-07 14:01:54.194742: Current learning rate: 0.00954 
2025-12-07 14:04:12.320916: train_loss -0.7568 
2025-12-07 14:04:12.323343: val_loss -0.7886 
2025-12-07 14:04:12.325345: Pseudo dice [0.8872, 0.9308, 0.8965] 
2025-12-07 14:04:12.325345: Epoch time: 138.13 s 
2025-12-07 14:04:12.327347: Yayy! New best EMA pseudo Dice: 0.8872 
2025-12-07 14:04:13.217274:  
2025-12-07 14:04:13.217274: Epoch 52 
2025-12-07 14:04:13.217274: Current learning rate: 0.00953 
2025-12-07 14:06:31.374332: train_loss -0.7599 
2025-12-07 14:06:31.376335: val_loss -0.7676 
2025-12-07 14:06:31.378337: Pseudo dice [0.8724, 0.9153, 0.897] 
2025-12-07 14:06:31.380339: Epoch time: 138.16 s 
2025-12-07 14:06:31.380339: Yayy! New best EMA pseudo Dice: 0.888 
2025-12-07 14:06:32.268285:  
2025-12-07 14:06:32.270287: Epoch 53 
2025-12-07 14:06:32.270287: Current learning rate: 0.00952 
2025-12-07 14:08:50.275688: train_loss -0.7644 
2025-12-07 14:08:50.277691: val_loss -0.7689 
2025-12-07 14:08:50.277691: Pseudo dice [0.867, 0.9207, 0.8894] 
2025-12-07 14:08:50.280437: Epoch time: 138.01 s 
2025-12-07 14:08:50.280437: Yayy! New best EMA pseudo Dice: 0.8884 
2025-12-07 14:08:51.337795:  
2025-12-07 14:08:51.337795: Epoch 54 
2025-12-07 14:08:51.339860: Current learning rate: 0.00951 
2025-12-07 14:11:09.496246: train_loss -0.742 
2025-12-07 14:11:09.497247: val_loss -0.7651 
2025-12-07 14:11:09.498261: Pseudo dice [0.8776, 0.92, 0.9047] 
2025-12-07 14:11:09.499264: Epoch time: 138.16 s 
2025-12-07 14:11:09.499264: Yayy! New best EMA pseudo Dice: 0.8897 
2025-12-07 14:11:10.379016:  
2025-12-07 14:11:10.379016: Epoch 55 
2025-12-07 14:11:10.381033: Current learning rate: 0.0095 
2025-12-07 14:13:28.727434: train_loss -0.7619 
2025-12-07 14:13:28.728439: val_loss -0.7768 
2025-12-07 14:13:28.729443: Pseudo dice [0.8759, 0.9226, 0.9032] 
2025-12-07 14:13:28.730887: Epoch time: 138.35 s 
2025-12-07 14:13:28.732020: Yayy! New best EMA pseudo Dice: 0.8908 
2025-12-07 14:13:29.632132:  
2025-12-07 14:13:29.634803: Epoch 56 
2025-12-07 14:13:29.634803: Current learning rate: 0.00949 
2025-12-07 14:15:47.516894: train_loss -0.7668 
2025-12-07 14:15:47.518897: val_loss -0.7955 
2025-12-07 14:15:47.522906: Pseudo dice [0.8852, 0.9302, 0.9092] 
2025-12-07 14:15:47.524910: Epoch time: 137.88 s 
2025-12-07 14:15:47.524910: Yayy! New best EMA pseudo Dice: 0.8925 
2025-12-07 14:15:48.431750:  
2025-12-07 14:15:48.431750: Epoch 57 
2025-12-07 14:15:48.431750: Current learning rate: 0.00949 
2025-12-07 14:18:06.530013: train_loss -0.7701 
2025-12-07 14:18:06.530013: val_loss -0.7885 
2025-12-07 14:18:06.533609: Pseudo dice [0.8838, 0.9245, 0.9017] 
2025-12-07 14:18:06.535612: Epoch time: 138.1 s 
2025-12-07 14:18:06.535612: Yayy! New best EMA pseudo Dice: 0.8936 
2025-12-07 14:18:07.414712:  
2025-12-07 14:18:07.416714: Epoch 58 
2025-12-07 14:18:07.416714: Current learning rate: 0.00948 
2025-12-07 14:20:25.404863: train_loss -0.7702 
2025-12-07 14:20:25.404863: val_loss -0.7962 
2025-12-07 14:20:25.411859: Pseudo dice [0.8844, 0.9327, 0.9039] 
2025-12-07 14:20:25.411859: Epoch time: 137.99 s 
2025-12-07 14:20:25.413862: Yayy! New best EMA pseudo Dice: 0.8949 
2025-12-07 14:20:26.309478:  
2025-12-07 14:20:26.309478: Epoch 59 
2025-12-07 14:20:26.311482: Current learning rate: 0.00947 
2025-12-07 14:22:44.464775: train_loss -0.7687 
2025-12-07 14:22:44.464775: val_loss -0.7907 
2025-12-07 14:22:44.466780: Pseudo dice [0.8877, 0.9297, 0.9076] 
2025-12-07 14:22:44.467783: Epoch time: 138.16 s 
2025-12-07 14:22:44.468822: Yayy! New best EMA pseudo Dice: 0.8963 
2025-12-07 14:22:45.529862:  
2025-12-07 14:22:45.529862: Epoch 60 
2025-12-07 14:22:45.529862: Current learning rate: 0.00946 
2025-12-07 14:25:03.547161: train_loss -0.7757 
2025-12-07 14:25:03.547161: val_loss -0.7721 
2025-12-07 14:25:03.563090: Pseudo dice [0.8716, 0.9133, 0.8963] 
2025-12-07 14:25:03.564569: Epoch time: 138.02 s 
2025-12-07 14:25:04.199976:  
2025-12-07 14:25:04.199976: Epoch 61 
2025-12-07 14:25:04.201984: Current learning rate: 0.00945 
2025-12-07 14:27:22.186749: train_loss -0.763 
2025-12-07 14:27:22.186749: val_loss -0.7915 
2025-12-07 14:27:22.186749: Pseudo dice [0.8848, 0.9282, 0.9078] 
2025-12-07 14:27:22.198249: Epoch time: 137.99 s 
2025-12-07 14:27:22.198249: Yayy! New best EMA pseudo Dice: 0.8971 
2025-12-07 14:27:23.119595:  
2025-12-07 14:27:23.120599: Epoch 62 
2025-12-07 14:27:23.122604: Current learning rate: 0.00944 
2025-12-07 14:29:41.109188: train_loss -0.7632 
2025-12-07 14:29:41.109188: val_loss -0.7862 
2025-12-07 14:29:41.113193: Pseudo dice [0.88, 0.9359, 0.8971] 
2025-12-07 14:29:41.113193: Epoch time: 137.99 s 
2025-12-07 14:29:41.113193: Yayy! New best EMA pseudo Dice: 0.8978 
2025-12-07 14:29:42.010019:  
2025-12-07 14:29:42.010019: Epoch 63 
2025-12-07 14:29:42.010019: Current learning rate: 0.00943 
2025-12-07 14:32:00.133271: train_loss -0.7658 
2025-12-07 14:32:00.133271: val_loss -0.7754 
2025-12-07 14:32:00.133271: Pseudo dice [0.8806, 0.9187, 0.8894] 
2025-12-07 14:32:00.133271: Epoch time: 138.12 s 
2025-12-07 14:32:00.773430:  
2025-12-07 14:32:00.773430: Epoch 64 
2025-12-07 14:32:00.775844: Current learning rate: 0.00942 
2025-12-07 14:34:18.834719: train_loss -0.77 
2025-12-07 14:34:18.836722: val_loss -0.7952 
2025-12-07 14:34:18.836722: Pseudo dice [0.883, 0.9313, 0.9046] 
2025-12-07 14:34:18.839950: Epoch time: 138.06 s 
2025-12-07 14:34:18.839950: Yayy! New best EMA pseudo Dice: 0.8985 
2025-12-07 14:34:19.749488:  
2025-12-07 14:34:19.749488: Epoch 65 
2025-12-07 14:34:19.749488: Current learning rate: 0.00941 
2025-12-07 14:36:37.855958: train_loss -0.77 
2025-12-07 14:36:37.856958: val_loss -0.8027 
2025-12-07 14:36:37.858999: Pseudo dice [0.8942, 0.9335, 0.9026] 
2025-12-07 14:36:37.860000: Epoch time: 138.12 s 
2025-12-07 14:36:37.861000: Yayy! New best EMA pseudo Dice: 0.8997 
2025-12-07 14:36:38.931678:  
2025-12-07 14:36:38.932681: Epoch 66 
2025-12-07 14:36:38.933684: Current learning rate: 0.0094 
2025-12-07 14:38:56.968285: train_loss -0.7727 
2025-12-07 14:38:56.968285: val_loss -0.7871 
2025-12-07 14:38:56.968285: Pseudo dice [0.8782, 0.9222, 0.9156] 
2025-12-07 14:38:56.968285: Epoch time: 138.04 s 
2025-12-07 14:38:56.968285: Yayy! New best EMA pseudo Dice: 0.9003 
2025-12-07 14:38:57.867096:  
2025-12-07 14:38:57.868098: Epoch 67 
2025-12-07 14:38:57.870107: Current learning rate: 0.00939 
2025-12-07 14:41:16.294418: train_loss -0.773 
2025-12-07 14:41:16.294418: val_loss -0.7866 
2025-12-07 14:41:16.296158: Pseudo dice [0.8861, 0.927, 0.9049] 
2025-12-07 14:41:16.298164: Epoch time: 138.43 s 
2025-12-07 14:41:16.300168: Yayy! New best EMA pseudo Dice: 0.9008 
2025-12-07 14:41:17.213991:  
2025-12-07 14:41:17.213991: Epoch 68 
2025-12-07 14:41:17.216001: Current learning rate: 0.00939 
2025-12-07 14:43:35.331965: train_loss -0.7749 
2025-12-07 14:43:35.332967: val_loss -0.7903 
2025-12-07 14:43:35.333970: Pseudo dice [0.8787, 0.9275, 0.8987] 
2025-12-07 14:43:35.335975: Epoch time: 138.12 s 
2025-12-07 14:43:35.336977: Yayy! New best EMA pseudo Dice: 0.9009 
2025-12-07 14:43:36.237662:  
2025-12-07 14:43:36.239664: Epoch 69 
2025-12-07 14:43:36.239664: Current learning rate: 0.00938 
2025-12-07 14:45:54.321488: train_loss -0.779 
2025-12-07 14:45:54.323490: val_loss -0.8105 
2025-12-07 14:45:54.325492: Pseudo dice [0.8885, 0.9362, 0.9259] 
2025-12-07 14:45:54.325492: Epoch time: 138.08 s 
2025-12-07 14:45:54.327494: Yayy! New best EMA pseudo Dice: 0.9025 
2025-12-07 14:45:55.405250:  
2025-12-07 14:45:55.407254: Epoch 70 
2025-12-07 14:45:55.407254: Current learning rate: 0.00937 
2025-12-07 14:48:13.466728: train_loss -0.7779 
2025-12-07 14:48:13.467728: val_loss -0.8034 
2025-12-07 14:48:13.467728: Pseudo dice [0.8929, 0.9339, 0.9079] 
2025-12-07 14:48:13.467728: Epoch time: 138.06 s 
2025-12-07 14:48:13.467728: Yayy! New best EMA pseudo Dice: 0.9034 
2025-12-07 14:48:14.372334:  
2025-12-07 14:48:14.372334: Epoch 71 
2025-12-07 14:48:14.372334: Current learning rate: 0.00936 
2025-12-07 14:50:32.549900: train_loss -0.7857 
2025-12-07 14:50:32.550900: val_loss -0.7929 
2025-12-07 14:50:32.552900: Pseudo dice [0.8838, 0.9297, 0.9097] 
2025-12-07 14:50:32.554215: Epoch time: 138.18 s 
2025-12-07 14:50:32.555215: Yayy! New best EMA pseudo Dice: 0.9038 
2025-12-07 14:50:33.647736:  
2025-12-07 14:50:33.647736: Epoch 72 
2025-12-07 14:50:33.650096: Current learning rate: 0.00935 
2025-12-07 14:52:51.641641: train_loss -0.7802 
2025-12-07 14:52:51.641641: val_loss -0.7876 
2025-12-07 14:52:51.641641: Pseudo dice [0.8753, 0.9276, 0.9093] 
2025-12-07 14:52:51.641641: Epoch time: 137.99 s 
2025-12-07 14:52:51.641641: Yayy! New best EMA pseudo Dice: 0.9039 
2025-12-07 14:52:52.662028:  
2025-12-07 14:52:52.662028: Epoch 73 
2025-12-07 14:52:52.664046: Current learning rate: 0.00934 
2025-12-07 14:55:10.733321: train_loss -0.7835 
2025-12-07 14:55:10.733321: val_loss -0.8145 
2025-12-07 14:55:10.733321: Pseudo dice [0.9013, 0.9313, 0.9134] 
2025-12-07 14:55:10.733321: Epoch time: 138.07 s 
2025-12-07 14:55:10.733321: Yayy! New best EMA pseudo Dice: 0.905 
2025-12-07 14:55:11.659639:  
2025-12-07 14:55:11.659639: Epoch 74 
2025-12-07 14:55:11.659639: Current learning rate: 0.00933 
2025-12-07 14:57:29.842820: train_loss -0.7836 
2025-12-07 14:57:29.842820: val_loss -0.8017 
2025-12-07 14:57:29.842820: Pseudo dice [0.8874, 0.9269, 0.9165] 
2025-12-07 14:57:29.842820: Epoch time: 138.19 s 
2025-12-07 14:57:29.842820: Yayy! New best EMA pseudo Dice: 0.9055 
2025-12-07 14:57:30.733202:  
2025-12-07 14:57:30.733202: Epoch 75 
2025-12-07 14:57:30.748980: Current learning rate: 0.00932 
2025-12-07 14:59:48.733162: train_loss -0.7836 
2025-12-07 14:59:48.733162: val_loss -0.8213 
2025-12-07 14:59:48.733162: Pseudo dice [0.9033, 0.9381, 0.9155] 
2025-12-07 14:59:48.738547: Epoch time: 138.0 s 
2025-12-07 14:59:48.738547: Yayy! New best EMA pseudo Dice: 0.9069 
2025-12-07 14:59:49.799754:  
2025-12-07 14:59:49.799754: Epoch 76 
2025-12-07 14:59:49.801580: Current learning rate: 0.00931 
2025-12-07 15:02:07.841862: train_loss -0.7839 
2025-12-07 15:02:07.841862: val_loss -0.8092 
2025-12-07 15:02:07.843864: Pseudo dice [0.8952, 0.9355, 0.9117] 
2025-12-07 15:02:07.843864: Epoch time: 138.04 s 
2025-12-07 15:02:07.843864: Yayy! New best EMA pseudo Dice: 0.9076 
2025-12-07 15:02:08.762301:  
2025-12-07 15:02:08.762301: Epoch 77 
2025-12-07 15:02:08.765147: Current learning rate: 0.0093 
2025-12-07 15:04:26.873888: train_loss -0.7768 
2025-12-07 15:04:26.873888: val_loss -0.7989 
2025-12-07 15:04:26.873888: Pseudo dice [0.8857, 0.9309, 0.9094] 
2025-12-07 15:04:26.873888: Epoch time: 138.11 s 
2025-12-07 15:04:26.873888: Yayy! New best EMA pseudo Dice: 0.9077 
2025-12-07 15:04:27.951750:  
2025-12-07 15:04:27.951750: Epoch 78 
2025-12-07 15:04:27.951750: Current learning rate: 0.0093 
2025-12-07 15:06:45.948339: train_loss -0.7869 
2025-12-07 15:06:45.950341: val_loss -0.7932 
2025-12-07 15:06:45.952081: Pseudo dice [0.887, 0.9312, 0.9065] 
2025-12-07 15:06:45.956087: Epoch time: 138.0 s 
2025-12-07 15:06:45.958091: Yayy! New best EMA pseudo Dice: 0.9078 
2025-12-07 15:06:47.059551:  
2025-12-07 15:06:47.059551: Epoch 79 
2025-12-07 15:06:47.061551: Current learning rate: 0.00929 
2025-12-07 15:09:05.310976: train_loss -0.7915 
2025-12-07 15:09:05.310976: val_loss -0.8168 
2025-12-07 15:09:05.310976: Pseudo dice [0.8971, 0.9438, 0.9092] 
2025-12-07 15:09:05.310976: Epoch time: 138.25 s 
2025-12-07 15:09:05.323732: Yayy! New best EMA pseudo Dice: 0.9087 
2025-12-07 15:09:06.234081:  
2025-12-07 15:09:06.234081: Epoch 80 
2025-12-07 15:09:06.234081: Current learning rate: 0.00928 
2025-12-07 15:11:25.072927: train_loss -0.7902 
2025-12-07 15:11:25.072927: val_loss -0.8031 
2025-12-07 15:11:25.074929: Pseudo dice [0.8901, 0.927, 0.9109] 
2025-12-07 15:11:25.076669: Epoch time: 138.84 s 
2025-12-07 15:11:25.078564: Yayy! New best EMA pseudo Dice: 0.9087 
2025-12-07 15:11:25.998330:  
2025-12-07 15:11:25.998330: Epoch 81 
2025-12-07 15:11:25.998330: Current learning rate: 0.00927 
2025-12-07 15:13:44.609713: train_loss -0.7953 
2025-12-07 15:13:44.609713: val_loss -0.8039 
2025-12-07 15:13:44.611716: Pseudo dice [0.8857, 0.9305, 0.9235] 
2025-12-07 15:13:44.613718: Epoch time: 138.61 s 
2025-12-07 15:13:44.615720: Yayy! New best EMA pseudo Dice: 0.9092 
2025-12-07 15:13:45.575633:  
2025-12-07 15:13:45.575633: Epoch 82 
2025-12-07 15:13:45.576768: Current learning rate: 0.00926 
2025-12-07 15:16:04.210169: train_loss -0.7891 
2025-12-07 15:16:04.210169: val_loss -0.8159 
2025-12-07 15:16:04.210169: Pseudo dice [0.8994, 0.9389, 0.9159] 
2025-12-07 15:16:04.210169: Epoch time: 138.64 s 
2025-12-07 15:16:04.210169: Yayy! New best EMA pseudo Dice: 0.9101 
2025-12-07 15:16:05.270648:  
2025-12-07 15:16:05.270648: Epoch 83 
2025-12-07 15:16:05.373798: Current learning rate: 0.00925 
2025-12-07 15:18:23.699862: train_loss -0.7844 
2025-12-07 15:18:23.699862: val_loss -0.8123 
2025-12-07 15:18:23.702919: Pseudo dice [0.896, 0.9363, 0.914] 
2025-12-07 15:18:23.703960: Epoch time: 138.43 s 
2025-12-07 15:18:23.705961: Yayy! New best EMA pseudo Dice: 0.9106 
2025-12-07 15:18:24.596686:  
2025-12-07 15:18:24.597991: Epoch 84 
2025-12-07 15:18:24.598994: Current learning rate: 0.00924 
2025-12-07 15:20:42.841209: train_loss -0.7959 
2025-12-07 15:20:42.841209: val_loss -0.8107 
2025-12-07 15:20:42.843213: Pseudo dice [0.8936, 0.9346, 0.9172] 
2025-12-07 15:20:42.843213: Epoch time: 138.24 s 
2025-12-07 15:20:42.843213: Yayy! New best EMA pseudo Dice: 0.9111 
2025-12-07 15:20:43.717208:  
2025-12-07 15:20:43.717208: Epoch 85 
2025-12-07 15:20:43.717208: Current learning rate: 0.00923 
2025-12-07 15:23:01.830331: train_loss -0.7809 
2025-12-07 15:23:01.832335: val_loss -0.8198 
2025-12-07 15:23:01.834337: Pseudo dice [0.9047, 0.9358, 0.9116] 
2025-12-07 15:23:01.834337: Epoch time: 138.11 s 
2025-12-07 15:23:01.836340: Yayy! New best EMA pseudo Dice: 0.9117 
2025-12-07 15:23:02.831616:  
2025-12-07 15:23:02.831616: Epoch 86 
2025-12-07 15:23:02.831616: Current learning rate: 0.00922 
2025-12-07 15:25:20.888710: train_loss -0.788 
2025-12-07 15:25:20.890451: val_loss -0.8091 
2025-12-07 15:25:20.892542: Pseudo dice [0.8888, 0.9323, 0.9229] 
2025-12-07 15:25:20.893543: Epoch time: 138.06 s 
2025-12-07 15:25:20.894543: Yayy! New best EMA pseudo Dice: 0.912 
2025-12-07 15:25:21.779858:  
2025-12-07 15:25:21.779858: Epoch 87 
2025-12-07 15:25:21.779858: Current learning rate: 0.00921 
2025-12-07 15:27:39.822057: train_loss -0.792 
2025-12-07 15:27:39.824059: val_loss -0.8135 
2025-12-07 15:27:39.826064: Pseudo dice [0.8935, 0.9328, 0.9186] 
2025-12-07 15:27:39.827804: Epoch time: 138.04 s 
2025-12-07 15:27:39.829807: Yayy! New best EMA pseudo Dice: 0.9123 
2025-12-07 15:27:40.729155:  
2025-12-07 15:27:40.729155: Epoch 88 
2025-12-07 15:27:40.729155: Current learning rate: 0.0092 
2025-12-07 15:29:58.702726: train_loss -0.7922 
2025-12-07 15:29:58.702726: val_loss -0.8049 
2025-12-07 15:29:58.716668: Pseudo dice [0.8953, 0.9353, 0.9104] 
2025-12-07 15:29:58.716668: Epoch time: 137.97 s 
2025-12-07 15:29:58.718410: Yayy! New best EMA pseudo Dice: 0.9124 
2025-12-07 15:29:59.877388:  
2025-12-07 15:29:59.877388: Epoch 89 
2025-12-07 15:29:59.877388: Current learning rate: 0.0092 
2025-12-07 15:32:17.845928: train_loss -0.7723 
2025-12-07 15:32:17.845928: val_loss -0.7628 
2025-12-07 15:32:17.847931: Pseudo dice [0.8638, 0.9116, 0.8958] 
2025-12-07 15:32:17.847931: Epoch time: 137.97 s 
2025-12-07 15:32:18.473625:  
2025-12-07 15:32:18.473625: Epoch 90 
2025-12-07 15:32:18.473625: Current learning rate: 0.00919 
2025-12-07 15:34:37.119003: train_loss -0.7698 
2025-12-07 15:34:37.121009: val_loss -0.8071 
2025-12-07 15:34:37.122013: Pseudo dice [0.8956, 0.9352, 0.9201] 
2025-12-07 15:34:37.123018: Epoch time: 138.65 s 
2025-12-07 15:34:37.742519:  
2025-12-07 15:34:37.742519: Epoch 91 
2025-12-07 15:34:37.742519: Current learning rate: 0.00918 
2025-12-07 15:36:56.155664: train_loss -0.7776 
2025-12-07 15:36:56.155664: val_loss -0.8155 
2025-12-07 15:36:56.157667: Pseudo dice [0.8978, 0.9313, 0.9096] 
2025-12-07 15:36:56.159669: Epoch time: 138.41 s 
2025-12-07 15:36:56.812711:  
2025-12-07 15:36:56.814675: Epoch 92 
2025-12-07 15:36:56.814675: Current learning rate: 0.00917 
2025-12-07 15:39:15.214092: train_loss -0.7966 
2025-12-07 15:39:15.216094: val_loss -0.8326 
2025-12-07 15:39:15.217835: Pseudo dice [0.9131, 0.9416, 0.9178] 
2025-12-07 15:39:15.220004: Epoch time: 138.4 s 
2025-12-07 15:39:15.843603:  
2025-12-07 15:39:15.843603: Epoch 93 
2025-12-07 15:39:15.843603: Current learning rate: 0.00916 
2025-12-07 15:41:34.076472: train_loss -0.7986 
2025-12-07 15:41:34.076472: val_loss -0.8028 
2025-12-07 15:41:34.078212: Pseudo dice [0.89, 0.9243, 0.9153] 
2025-12-07 15:41:34.078212: Epoch time: 138.23 s 
2025-12-07 15:41:34.695260:  
2025-12-07 15:41:34.697262: Epoch 94 
2025-12-07 15:41:34.697262: Current learning rate: 0.00915 
2025-12-07 15:43:53.047504: train_loss -0.7987 
2025-12-07 15:43:53.047504: val_loss -0.8202 
2025-12-07 15:43:53.049506: Pseudo dice [0.8975, 0.933, 0.9333] 
2025-12-07 15:43:53.051509: Epoch time: 138.35 s 
2025-12-07 15:43:53.053512: Yayy! New best EMA pseudo Dice: 0.9131 
2025-12-07 15:43:54.067632:  
2025-12-07 15:43:54.067632: Epoch 95 
2025-12-07 15:43:54.067632: Current learning rate: 0.00914 
2025-12-07 15:46:12.124059: train_loss -0.7989 
2025-12-07 15:46:12.126063: val_loss -0.8135 
2025-12-07 15:46:12.128068: Pseudo dice [0.8963, 0.9333, 0.9221] 
2025-12-07 15:46:12.130070: Epoch time: 138.06 s 
2025-12-07 15:46:12.132072: Yayy! New best EMA pseudo Dice: 0.9135 
2025-12-07 15:46:13.208620:  
2025-12-07 15:46:13.208620: Epoch 96 
2025-12-07 15:46:13.208620: Current learning rate: 0.00913 
2025-12-07 15:48:31.231319: train_loss -0.7992 
2025-12-07 15:48:31.233060: val_loss -0.8096 
2025-12-07 15:48:31.233060: Pseudo dice [0.8915, 0.936, 0.9051] 
2025-12-07 15:48:31.233060: Epoch time: 138.02 s 
2025-12-07 15:48:31.872406:  
2025-12-07 15:48:31.872406: Epoch 97 
2025-12-07 15:48:31.874149: Current learning rate: 0.00912 
2025-12-07 15:50:49.756040: train_loss -0.7994 
2025-12-07 15:50:49.758040: val_loss -0.8147 
2025-12-07 15:50:49.761040: Pseudo dice [0.896, 0.9368, 0.917] 
2025-12-07 15:50:49.763041: Epoch time: 137.88 s 
2025-12-07 15:50:49.764042: Yayy! New best EMA pseudo Dice: 0.9136 
2025-12-07 15:50:50.748638:  
2025-12-07 15:50:50.748638: Epoch 98 
2025-12-07 15:50:50.748638: Current learning rate: 0.00911 
2025-12-07 15:53:08.550105: train_loss -0.795 
2025-12-07 15:53:08.551105: val_loss -0.823 
2025-12-07 15:53:08.554105: Pseudo dice [0.8977, 0.9395, 0.9256] 
2025-12-07 15:53:08.555106: Epoch time: 137.8 s 
2025-12-07 15:53:08.557106: Yayy! New best EMA pseudo Dice: 0.9143 
2025-12-07 15:53:09.471509:  
2025-12-07 15:53:09.471509: Epoch 99 
2025-12-07 15:53:09.471509: Current learning rate: 0.0091 
2025-12-07 15:55:27.374797: train_loss -0.7977 
2025-12-07 15:55:27.375866: val_loss -0.8193 
2025-12-07 15:55:27.377870: Pseudo dice [0.8974, 0.9409, 0.918] 
2025-12-07 15:55:27.378870: Epoch time: 137.91 s 
2025-12-07 15:55:27.624727: Yayy! New best EMA pseudo Dice: 0.9147 
2025-12-07 15:55:28.519988:  
2025-12-07 15:55:28.519988: Epoch 100 
2025-12-07 15:55:28.519988: Current learning rate: 0.0091 
2025-12-07 15:57:46.514616: train_loss -0.7988 
2025-12-07 15:57:46.515687: val_loss -0.8197 
2025-12-07 15:57:46.517686: Pseudo dice [0.8954, 0.9328, 0.9284] 
2025-12-07 15:57:46.519687: Epoch time: 137.99 s 
2025-12-07 15:57:46.520687: Yayy! New best EMA pseudo Dice: 0.9152 
2025-12-07 15:57:47.581095:  
2025-12-07 15:57:47.582097: Epoch 101 
2025-12-07 15:57:47.584105: Current learning rate: 0.00909 
2025-12-07 16:00:05.891500: train_loss -0.7755 
2025-12-07 16:00:05.891500: val_loss -0.7492 
2025-12-07 16:00:05.908652: Pseudo dice [0.8527, 0.9113, 0.9045] 
2025-12-07 16:00:05.909656: Epoch time: 138.31 s 
2025-12-07 16:00:06.514517:  
2025-12-07 16:00:06.514517: Epoch 102 
2025-12-07 16:00:06.514517: Current learning rate: 0.00908 
2025-12-07 16:02:24.558972: train_loss -0.7171 
2025-12-07 16:02:24.558972: val_loss -0.7497 
2025-12-07 16:02:24.561977: Pseudo dice [0.8617, 0.9055, 0.8943] 
2025-12-07 16:02:24.563979: Epoch time: 138.04 s 
2025-12-07 16:02:25.186821:  
2025-12-07 16:02:25.186821: Epoch 103 
2025-12-07 16:02:25.186821: Current learning rate: 0.00907 
2025-12-07 16:04:43.179550: train_loss -0.7604 
2025-12-07 16:04:43.181552: val_loss -0.7805 
2025-12-07 16:04:43.185558: Pseudo dice [0.8799, 0.9247, 0.8995] 
2025-12-07 16:04:43.187300: Epoch time: 137.99 s 
2025-12-07 16:04:43.821460:  
2025-12-07 16:04:43.821460: Epoch 104 
2025-12-07 16:04:43.821460: Current learning rate: 0.00906 
2025-12-07 16:07:01.811475: train_loss -0.7787 
2025-12-07 16:07:01.811475: val_loss -0.8099 
2025-12-07 16:07:01.811475: Pseudo dice [0.8937, 0.9395, 0.9121] 
2025-12-07 16:07:01.816200: Epoch time: 137.99 s 
2025-12-07 16:07:02.448996:  
2025-12-07 16:07:02.448996: Epoch 105 
2025-12-07 16:07:02.451605: Current learning rate: 0.00905 
2025-12-07 16:09:20.368018: train_loss -0.7814 
2025-12-07 16:09:20.368018: val_loss -0.805 
2025-12-07 16:09:20.368018: Pseudo dice [0.8919, 0.9328, 0.9179] 
2025-12-07 16:09:20.368018: Epoch time: 137.92 s 
2025-12-07 16:09:20.983096:  
2025-12-07 16:09:20.983096: Epoch 106 
2025-12-07 16:09:20.983096: Current learning rate: 0.00904 
2025-12-07 16:11:38.946606: train_loss -0.7844 
2025-12-07 16:11:38.946606: val_loss -0.8045 
2025-12-07 16:11:38.949704: Pseudo dice [0.8915, 0.9313, 0.9177] 
2025-12-07 16:11:38.950704: Epoch time: 137.96 s 
2025-12-07 16:11:39.587979:  
2025-12-07 16:11:39.587979: Epoch 107 
2025-12-07 16:11:39.587979: Current learning rate: 0.00903 
2025-12-07 16:13:58.280770: train_loss -0.7941 
2025-12-07 16:13:58.280770: val_loss -0.8093 
2025-12-07 16:13:58.284748: Pseudo dice [0.8902, 0.9342, 0.925] 
2025-12-07 16:13:58.284748: Epoch time: 138.69 s 
2025-12-07 16:13:59.075996:  
2025-12-07 16:13:59.075996: Epoch 108 
2025-12-07 16:13:59.077999: Current learning rate: 0.00902 
2025-12-07 16:16:17.364313: train_loss -0.7948 
2025-12-07 16:16:17.364313: val_loss -0.8088 
2025-12-07 16:16:17.366314: Pseudo dice [0.8899, 0.9283, 0.9205] 
2025-12-07 16:16:17.368317: Epoch time: 138.29 s 
2025-12-07 16:16:17.999796:  
2025-12-07 16:16:17.999796: Epoch 109 
2025-12-07 16:16:17.999796: Current learning rate: 0.00901 
2025-12-07 16:18:36.327240: train_loss -0.7972 
2025-12-07 16:18:36.327240: val_loss -0.8378 
2025-12-07 16:18:36.343140: Pseudo dice [0.9119, 0.9463, 0.9225] 
2025-12-07 16:18:36.345294: Epoch time: 138.33 s 
2025-12-07 16:18:36.983928:  
2025-12-07 16:18:36.983928: Epoch 110 
2025-12-07 16:18:36.983928: Current learning rate: 0.009 
2025-12-07 16:20:55.467999: train_loss -0.7999 
2025-12-07 16:20:55.467999: val_loss -0.815 
2025-12-07 16:20:55.485145: Pseudo dice [0.8933, 0.9356, 0.9215] 
2025-12-07 16:20:55.486149: Epoch time: 138.48 s 
2025-12-07 16:20:56.092997:  
2025-12-07 16:20:56.092997: Epoch 111 
2025-12-07 16:20:56.108891: Current learning rate: 0.009 
2025-12-07 16:23:14.327790: train_loss -0.8044 
2025-12-07 16:23:14.327790: val_loss -0.8075 
2025-12-07 16:23:14.327790: Pseudo dice [0.8892, 0.9351, 0.9214] 
2025-12-07 16:23:14.327790: Epoch time: 138.23 s 
2025-12-07 16:23:14.967971:  
2025-12-07 16:23:14.967971: Epoch 112 
2025-12-07 16:23:14.967971: Current learning rate: 0.00899 
2025-12-07 16:25:33.175082: train_loss -0.7996 
2025-12-07 16:25:33.176084: val_loss -0.8305 
2025-12-07 16:25:33.178086: Pseudo dice [0.9082, 0.949, 0.9193] 
2025-12-07 16:25:33.179219: Epoch time: 138.21 s 
2025-12-07 16:25:33.796665:  
2025-12-07 16:25:33.796665: Epoch 113 
2025-12-07 16:25:33.796665: Current learning rate: 0.00898 
2025-12-07 16:27:51.807860: train_loss -0.8036 
2025-12-07 16:27:51.807860: val_loss -0.8201 
2025-12-07 16:27:51.810868: Pseudo dice [0.898, 0.9322, 0.9208] 
2025-12-07 16:27:51.810868: Epoch time: 138.01 s 
2025-12-07 16:27:52.609508:  
2025-12-07 16:27:52.609508: Epoch 114 
2025-12-07 16:27:52.609508: Current learning rate: 0.00897 
2025-12-07 16:30:10.639646: train_loss -0.7909 
2025-12-07 16:30:10.639646: val_loss -0.8089 
2025-12-07 16:30:10.639646: Pseudo dice [0.8893, 0.9352, 0.9184] 
2025-12-07 16:30:10.655335: Epoch time: 138.03 s 
2025-12-07 16:30:11.291274:  
2025-12-07 16:30:11.293277: Epoch 115 
2025-12-07 16:30:11.293277: Current learning rate: 0.00896 
2025-12-07 16:32:29.155187: train_loss -0.8004 
2025-12-07 16:32:29.155187: val_loss -0.825 
2025-12-07 16:32:29.155187: Pseudo dice [0.9033, 0.9392, 0.9234] 
2025-12-07 16:32:29.155187: Epoch time: 137.86 s 
2025-12-07 16:32:29.155187: Yayy! New best EMA pseudo Dice: 0.9156 
2025-12-07 16:32:30.061271:  
2025-12-07 16:32:30.061271: Epoch 116 
2025-12-07 16:32:30.061271: Current learning rate: 0.00895 
2025-12-07 16:34:48.156141: train_loss -0.7987 
2025-12-07 16:34:48.158144: val_loss -0.8332 
2025-12-07 16:34:48.160146: Pseudo dice [0.9103, 0.9425, 0.9241] 
2025-12-07 16:34:48.160146: Epoch time: 138.1 s 
2025-12-07 16:34:48.162148: Yayy! New best EMA pseudo Dice: 0.9166 
2025-12-07 16:34:49.068957:  
2025-12-07 16:34:49.068957: Epoch 117 
2025-12-07 16:34:49.068957: Current learning rate: 0.00894 
2025-12-07 16:37:06.967427: train_loss -0.806 
2025-12-07 16:37:06.967427: val_loss -0.828 
2025-12-07 16:37:06.969168: Pseudo dice [0.9015, 0.94, 0.9243] 
2025-12-07 16:37:06.969168: Epoch time: 137.9 s 
2025-12-07 16:37:06.969168: Yayy! New best EMA pseudo Dice: 0.9171 
2025-12-07 16:37:07.904633:  
2025-12-07 16:37:07.904633: Epoch 118 
2025-12-07 16:37:07.904633: Current learning rate: 0.00893 
2025-12-07 16:39:25.964246: train_loss -0.8013 
2025-12-07 16:39:25.965246: val_loss -0.8324 
2025-12-07 16:39:25.967246: Pseudo dice [0.9043, 0.943, 0.927] 
2025-12-07 16:39:25.969247: Epoch time: 138.06 s 
2025-12-07 16:39:25.971247: Yayy! New best EMA pseudo Dice: 0.9179 
2025-12-07 16:39:26.874269:  
2025-12-07 16:39:26.874269: Epoch 119 
2025-12-07 16:39:26.874269: Current learning rate: 0.00892 
2025-12-07 16:41:44.774969: train_loss -0.8063 
2025-12-07 16:41:44.775970: val_loss -0.8229 
2025-12-07 16:41:44.778970: Pseudo dice [0.8987, 0.933, 0.9229] 
2025-12-07 16:41:44.781009: Epoch time: 137.92 s 
2025-12-07 16:41:44.783009: Yayy! New best EMA pseudo Dice: 0.9179 
2025-12-07 16:41:45.869986:  
2025-12-07 16:41:45.869986: Epoch 120 
2025-12-07 16:41:45.872069: Current learning rate: 0.00891 
2025-12-07 16:44:04.077094: train_loss -0.8078 
2025-12-07 16:44:04.077094: val_loss -0.8139 
2025-12-07 16:44:04.077094: Pseudo dice [0.8876, 0.9318, 0.9276] 
2025-12-07 16:44:04.077094: Epoch time: 138.21 s 
2025-12-07 16:44:04.825780:  
2025-12-07 16:44:04.825780: Epoch 121 
2025-12-07 16:44:04.827784: Current learning rate: 0.0089 
2025-12-07 16:46:22.766015: train_loss -0.8088 
2025-12-07 16:46:22.766015: val_loss -0.8291 
2025-12-07 16:46:22.769016: Pseudo dice [0.9035, 0.9424, 0.922] 
2025-12-07 16:46:22.770015: Epoch time: 137.94 s 
2025-12-07 16:46:22.771016: Yayy! New best EMA pseudo Dice: 0.9182 
2025-12-07 16:46:23.655277:  
2025-12-07 16:46:23.655277: Epoch 122 
2025-12-07 16:46:23.655277: Current learning rate: 0.00889 
2025-12-07 16:48:41.561579: train_loss -0.8129 
2025-12-07 16:48:41.561579: val_loss -0.8455 
2025-12-07 16:48:41.561579: Pseudo dice [0.9133, 0.946, 0.9336] 
2025-12-07 16:48:41.561579: Epoch time: 137.91 s 
2025-12-07 16:48:41.569604: Yayy! New best EMA pseudo Dice: 0.9195 
2025-12-07 16:48:42.467548:  
2025-12-07 16:48:42.467548: Epoch 123 
2025-12-07 16:48:42.467548: Current learning rate: 0.00889 
2025-12-07 16:51:00.448020: train_loss -0.804 
2025-12-07 16:51:00.448020: val_loss -0.8282 
2025-12-07 16:51:00.448020: Pseudo dice [0.9026, 0.9379, 0.9197] 
2025-12-07 16:51:00.451008: Epoch time: 137.98 s 
2025-12-07 16:51:00.452510: Yayy! New best EMA pseudo Dice: 0.9195 
2025-12-07 16:51:01.457386:  
2025-12-07 16:51:01.457386: Epoch 124 
2025-12-07 16:51:01.462206: Current learning rate: 0.00888 
2025-12-07 16:53:19.457713: train_loss -0.8121 
2025-12-07 16:53:19.457713: val_loss -0.829 
2025-12-07 16:53:19.459715: Pseudo dice [0.9012, 0.938, 0.9278] 
2025-12-07 16:53:19.461717: Epoch time: 138.0 s 
2025-12-07 16:53:19.463719: Yayy! New best EMA pseudo Dice: 0.9198 
2025-12-07 16:53:20.359650:  
2025-12-07 16:53:20.359650: Epoch 125 
2025-12-07 16:53:20.359650: Current learning rate: 0.00887 
2025-12-07 16:55:38.324898: train_loss -0.8137 
2025-12-07 16:55:38.326901: val_loss -0.8415 
2025-12-07 16:55:38.328642: Pseudo dice [0.9095, 0.9396, 0.9289] 
2025-12-07 16:55:38.328642: Epoch time: 137.97 s 
2025-12-07 16:55:38.332147: Yayy! New best EMA pseudo Dice: 0.9204 
2025-12-07 16:55:39.406934:  
2025-12-07 16:55:39.406934: Epoch 126 
2025-12-07 16:55:39.406934: Current learning rate: 0.00886 
2025-12-07 16:57:57.317434: train_loss -0.8105 
2025-12-07 16:57:57.317434: val_loss -0.8386 
2025-12-07 16:57:57.319437: Pseudo dice [0.9063, 0.9453, 0.9321] 
2025-12-07 16:57:57.319437: Epoch time: 137.91 s 
2025-12-07 16:57:57.319437: Yayy! New best EMA pseudo Dice: 0.9212 
2025-12-07 16:57:58.311456:  
2025-12-07 16:57:58.311456: Epoch 127 
2025-12-07 16:57:58.311456: Current learning rate: 0.00885 
2025-12-07 17:00:17.405801: train_loss -0.8136 
2025-12-07 17:00:17.405801: val_loss -0.8313 
2025-12-07 17:00:17.405801: Pseudo dice [0.906, 0.9331, 0.9232] 
2025-12-07 17:00:17.421701: Epoch time: 139.09 s 
2025-12-07 17:00:18.045698:  
2025-12-07 17:00:18.045698: Epoch 128 
2025-12-07 17:00:18.045698: Current learning rate: 0.00884 
2025-12-07 17:02:36.500011: train_loss -0.8139 
2025-12-07 17:02:36.500011: val_loss -0.8176 
2025-12-07 17:02:36.515863: Pseudo dice [0.8942, 0.9302, 0.9295] 
2025-12-07 17:02:36.515863: Epoch time: 138.45 s 
2025-12-07 17:02:37.139918:  
2025-12-07 17:02:37.139918: Epoch 129 
2025-12-07 17:02:37.155756: Current learning rate: 0.00883 
2025-12-07 17:04:55.655053: train_loss -0.7855 
2025-12-07 17:04:55.656053: val_loss -0.7897 
2025-12-07 17:04:55.658070: Pseudo dice [0.891, 0.9279, 0.8986] 
2025-12-07 17:04:55.660072: Epoch time: 138.52 s 
2025-12-07 17:04:56.311609:  
2025-12-07 17:04:56.311609: Epoch 130 
2025-12-07 17:04:56.311609: Current learning rate: 0.00882 
2025-12-07 17:07:14.862648: train_loss -0.7718 
2025-12-07 17:07:14.862648: val_loss -0.7914 
2025-12-07 17:07:14.866652: Pseudo dice [0.882, 0.9234, 0.9139] 
2025-12-07 17:07:14.866652: Epoch time: 138.55 s 
2025-12-07 17:07:15.515313:  
2025-12-07 17:07:15.515313: Epoch 131 
2025-12-07 17:07:15.515313: Current learning rate: 0.00881 
2025-12-07 17:09:33.796189: train_loss -0.7823 
2025-12-07 17:09:33.796189: val_loss -0.8289 
2025-12-07 17:09:33.796189: Pseudo dice [0.9057, 0.9471, 0.9174] 
2025-12-07 17:09:33.796189: Epoch time: 138.28 s 
2025-12-07 17:09:34.623466:  
2025-12-07 17:09:34.623466: Epoch 132 
2025-12-07 17:09:34.623466: Current learning rate: 0.0088 
2025-12-07 17:11:52.643983: train_loss -0.8024 
2025-12-07 17:11:52.643983: val_loss -0.8341 
2025-12-07 17:11:52.647726: Pseudo dice [0.9091, 0.9439, 0.9227] 
2025-12-07 17:11:52.649852: Epoch time: 138.02 s 
2025-12-07 17:11:53.298155:  
2025-12-07 17:11:53.298155: Epoch 133 
2025-12-07 17:11:53.300162: Current learning rate: 0.00879 
2025-12-07 17:14:11.259985: train_loss -0.808 
2025-12-07 17:14:11.260984: val_loss -0.8228 
2025-12-07 17:14:11.263985: Pseudo dice [0.8961, 0.9345, 0.9263] 
2025-12-07 17:14:11.266268: Epoch time: 137.96 s 
2025-12-07 17:14:11.922715:  
2025-12-07 17:14:11.922715: Epoch 134 
2025-12-07 17:14:11.924720: Current learning rate: 0.00879 
2025-12-07 17:16:29.921141: train_loss -0.8093 
2025-12-07 17:16:29.921141: val_loss -0.8397 
2025-12-07 17:16:29.936005: Pseudo dice [0.9072, 0.9415, 0.9327] 
2025-12-07 17:16:29.937010: Epoch time: 138.0 s 
2025-12-07 17:16:30.561895:  
2025-12-07 17:16:30.577718: Epoch 135 
2025-12-07 17:16:30.577718: Current learning rate: 0.00878 
2025-12-07 17:18:48.555811: train_loss -0.8132 
2025-12-07 17:18:48.557814: val_loss -0.8256 
2025-12-07 17:18:48.557814: Pseudo dice [0.8993, 0.939, 0.9234] 
2025-12-07 17:18:48.557814: Epoch time: 137.99 s 
2025-12-07 17:18:49.202758:  
2025-12-07 17:18:49.202758: Epoch 136 
2025-12-07 17:18:49.210597: Current learning rate: 0.00877 
2025-12-07 17:21:07.139787: train_loss -0.8039 
2025-12-07 17:21:07.139787: val_loss -0.8217 
2025-12-07 17:21:07.155553: Pseudo dice [0.901, 0.9371, 0.9246] 
2025-12-07 17:21:07.155553: Epoch time: 137.94 s 
2025-12-07 17:21:07.811364:  
2025-12-07 17:21:07.811364: Epoch 137 
2025-12-07 17:21:07.811364: Current learning rate: 0.00876 
2025-12-07 17:23:25.937650: train_loss -0.7671 
2025-12-07 17:23:25.937650: val_loss -0.822 
2025-12-07 17:23:25.946115: Pseudo dice [0.9, 0.944, 0.9197] 
2025-12-07 17:23:25.946115: Epoch time: 138.14 s 
2025-12-07 17:23:26.773906:  
2025-12-07 17:23:26.774919: Epoch 138 
2025-12-07 17:23:26.776982: Current learning rate: 0.00875 
2025-12-07 17:25:44.794427: train_loss -0.7887 
2025-12-07 17:25:44.796169: val_loss -0.8158 
2025-12-07 17:25:44.798171: Pseudo dice [0.9024, 0.9362, 0.9011] 
2025-12-07 17:25:44.800174: Epoch time: 138.02 s 
2025-12-07 17:25:45.452436:  
2025-12-07 17:25:45.452436: Epoch 139 
2025-12-07 17:25:45.452436: Current learning rate: 0.00874 
2025-12-07 17:28:03.821480: train_loss -0.8007 
2025-12-07 17:28:03.823483: val_loss -0.8267 
2025-12-07 17:28:03.825486: Pseudo dice [0.9024, 0.9439, 0.9189] 
2025-12-07 17:28:03.827227: Epoch time: 138.37 s 
2025-12-07 17:28:04.483886:  
2025-12-07 17:28:04.483886: Epoch 140 
2025-12-07 17:28:04.483886: Current learning rate: 0.00873 
2025-12-07 17:30:24.088966: train_loss -0.8098 
2025-12-07 17:30:24.090969: val_loss -0.8107 
2025-12-07 17:30:24.093182: Pseudo dice [0.8943, 0.9312, 0.9172] 
2025-12-07 17:30:24.093182: Epoch time: 139.61 s 
2025-12-07 17:30:24.737122:  
2025-12-07 17:30:24.737122: Epoch 141 
2025-12-07 17:30:24.737122: Current learning rate: 0.00872 
2025-12-07 17:32:43.481237: train_loss -0.8128 
2025-12-07 17:32:43.482977: val_loss -0.8421 
2025-12-07 17:32:43.486983: Pseudo dice [0.9103, 0.9398, 0.9376] 
2025-12-07 17:32:43.488985: Epoch time: 138.75 s 
2025-12-07 17:32:44.151053:  
2025-12-07 17:32:44.151053: Epoch 142 
2025-12-07 17:32:44.153138: Current learning rate: 0.00871 
2025-12-07 17:35:02.927681: train_loss -0.8063 
2025-12-07 17:35:02.927681: val_loss -0.8428 
2025-12-07 17:35:02.930252: Pseudo dice [0.9111, 0.9524, 0.925] 
2025-12-07 17:35:02.932253: Epoch time: 138.78 s 
2025-12-07 17:35:03.686587:  
2025-12-07 17:35:03.686587: Epoch 143 
2025-12-07 17:35:03.702412: Current learning rate: 0.0087 
2025-12-07 17:37:22.536846: train_loss -0.8017 
2025-12-07 17:37:22.536846: val_loss -0.8295 
2025-12-07 17:37:22.538847: Pseudo dice [0.8999, 0.9379, 0.9332] 
2025-12-07 17:37:22.540849: Epoch time: 138.85 s 
2025-12-07 17:37:22.542851: Yayy! New best EMA pseudo Dice: 0.9214 
2025-12-07 17:37:23.659793:  
2025-12-07 17:37:23.659793: Epoch 144 
2025-12-07 17:37:23.659793: Current learning rate: 0.00869 
2025-12-07 17:39:42.089901: train_loss -0.8111 
2025-12-07 17:39:42.091906: val_loss -0.8318 
2025-12-07 17:39:42.097652: Pseudo dice [0.9071, 0.9429, 0.923] 
2025-12-07 17:39:42.099656: Epoch time: 138.43 s 
2025-12-07 17:39:42.101661: Yayy! New best EMA pseudo Dice: 0.9217 
2025-12-07 17:39:43.017161:  
2025-12-07 17:39:43.017161: Epoch 145 
2025-12-07 17:39:43.017161: Current learning rate: 0.00868 
2025-12-07 17:42:01.058166: train_loss -0.8121 
2025-12-07 17:42:01.058166: val_loss -0.8244 
2025-12-07 17:42:01.061909: Pseudo dice [0.898, 0.9388, 0.9324] 
2025-12-07 17:42:01.063912: Epoch time: 138.04 s 
2025-12-07 17:42:01.063912: Yayy! New best EMA pseudo Dice: 0.9218 
2025-12-07 17:42:02.014707:  
2025-12-07 17:42:02.014707: Epoch 146 
2025-12-07 17:42:02.014707: Current learning rate: 0.00868 
2025-12-07 17:44:19.997125: train_loss -0.8097 
2025-12-07 17:44:19.997125: val_loss -0.8341 
2025-12-07 17:44:20.000709: Pseudo dice [0.903, 0.9405, 0.9291] 
2025-12-07 17:44:20.002711: Epoch time: 137.98 s 
2025-12-07 17:44:20.004713: Yayy! New best EMA pseudo Dice: 0.9221 
2025-12-07 17:44:20.917750:  
2025-12-07 17:44:20.918749: Epoch 147 
2025-12-07 17:44:20.920387: Current learning rate: 0.00867 
2025-12-07 17:46:39.014913: train_loss -0.816 
2025-12-07 17:46:39.014913: val_loss -0.8485 
2025-12-07 17:46:39.017622: Pseudo dice [0.9127, 0.9456, 0.9335] 
2025-12-07 17:46:39.017622: Epoch time: 138.1 s 
2025-12-07 17:46:39.017622: Yayy! New best EMA pseudo Dice: 0.9229 
2025-12-07 17:46:39.930253:  
2025-12-07 17:46:39.930253: Epoch 148 
2025-12-07 17:46:39.932803: Current learning rate: 0.00866 
2025-12-07 17:48:57.969177: train_loss -0.8076 
2025-12-07 17:48:57.969177: val_loss -0.8384 
2025-12-07 17:48:57.976707: Pseudo dice [0.9076, 0.95, 0.9251] 
2025-12-07 17:48:57.978712: Epoch time: 138.04 s 
2025-12-07 17:48:57.978712: Yayy! New best EMA pseudo Dice: 0.9234 
2025-12-07 17:48:58.901242:  
2025-12-07 17:48:58.901242: Epoch 149 
2025-12-07 17:48:58.903246: Current learning rate: 0.00865 
2025-12-07 17:51:16.936489: train_loss -0.8105 
2025-12-07 17:51:16.938336: val_loss -0.8429 
2025-12-07 17:51:16.940338: Pseudo dice [0.9131, 0.9449, 0.9286] 
2025-12-07 17:51:16.942340: Epoch time: 138.04 s 
2025-12-07 17:51:17.192648: Yayy! New best EMA pseudo Dice: 0.9239 
2025-12-07 17:51:18.294205:  
2025-12-07 17:51:18.295945: Epoch 150 
2025-12-07 17:51:18.298096: Current learning rate: 0.00864 
2025-12-07 17:53:36.215772: train_loss -0.8147 
2025-12-07 17:53:36.216774: val_loss -0.8351 
2025-12-07 17:53:36.217776: Pseudo dice [0.905, 0.9453, 0.9263] 
2025-12-07 17:53:36.217776: Epoch time: 137.92 s 
2025-12-07 17:53:36.217776: Yayy! New best EMA pseudo Dice: 0.9241 
2025-12-07 17:53:37.148480:  
2025-12-07 17:53:37.148480: Epoch 151 
2025-12-07 17:53:37.150528: Current learning rate: 0.00863 
2025-12-07 17:55:55.216359: train_loss -0.821 
2025-12-07 17:55:55.217359: val_loss -0.8297 
2025-12-07 17:55:55.219403: Pseudo dice [0.9043, 0.9366, 0.9287] 
2025-12-07 17:55:55.221403: Epoch time: 138.07 s 
2025-12-07 17:55:55.883945:  
2025-12-07 17:55:55.883945: Epoch 152 
2025-12-07 17:55:55.886334: Current learning rate: 0.00862 
2025-12-07 17:58:13.901354: train_loss -0.8151 
2025-12-07 17:58:13.901354: val_loss -0.8464 
2025-12-07 17:58:13.903094: Pseudo dice [0.9128, 0.9509, 0.9303] 
2025-12-07 17:58:13.905096: Epoch time: 138.02 s 
2025-12-07 17:58:13.907099: Yayy! New best EMA pseudo Dice: 0.9247 
2025-12-07 17:58:14.812714:  
2025-12-07 17:58:14.812714: Epoch 153 
2025-12-07 17:58:14.824982: Current learning rate: 0.00861 
2025-12-07 18:00:32.796708: train_loss -0.8181 
2025-12-07 18:00:32.796708: val_loss -0.8428 
2025-12-07 18:00:32.805098: Pseudo dice [0.9102, 0.9464, 0.9244] 
2025-12-07 18:00:32.805098: Epoch time: 137.98 s 
2025-12-07 18:00:32.805098: Yayy! New best EMA pseudo Dice: 0.925 
2025-12-07 18:00:33.717705:  
2025-12-07 18:00:33.717705: Epoch 154 
2025-12-07 18:00:33.717705: Current learning rate: 0.0086 
2025-12-07 18:02:51.797120: train_loss -0.8096 
2025-12-07 18:02:51.799124: val_loss -0.8315 
2025-12-07 18:02:51.801126: Pseudo dice [0.9022, 0.9381, 0.9271] 
2025-12-07 18:02:51.801126: Epoch time: 138.08 s 
2025-12-07 18:02:52.686293:  
2025-12-07 18:02:52.687296: Epoch 155 
2025-12-07 18:02:52.689314: Current learning rate: 0.00859 
2025-12-07 18:05:10.515537: train_loss -0.8249 
2025-12-07 18:05:10.515537: val_loss -0.84 
2025-12-07 18:05:10.515537: Pseudo dice [0.908, 0.9443, 0.9323] 
2025-12-07 18:05:10.524654: Epoch time: 137.83 s 
2025-12-07 18:05:10.524654: Yayy! New best EMA pseudo Dice: 0.9251 
2025-12-07 18:05:11.445362:  
2025-12-07 18:05:11.445362: Epoch 156 
2025-12-07 18:05:11.445362: Current learning rate: 0.00858 
2025-12-07 18:07:29.468419: train_loss -0.8198 
2025-12-07 18:07:29.468419: val_loss -0.8294 
2025-12-07 18:07:29.468419: Pseudo dice [0.9018, 0.9448, 0.9306] 
2025-12-07 18:07:29.482199: Epoch time: 138.02 s 
2025-12-07 18:07:29.484202: Yayy! New best EMA pseudo Dice: 0.9251 
2025-12-07 18:07:30.390563:  
2025-12-07 18:07:30.390563: Epoch 157 
2025-12-07 18:07:30.406241: Current learning rate: 0.00858 
2025-12-07 18:09:48.483290: train_loss -0.8227 
2025-12-07 18:09:48.484290: val_loss -0.8407 
2025-12-07 18:09:48.487290: Pseudo dice [0.9129, 0.9473, 0.926] 
2025-12-07 18:09:48.489291: Epoch time: 138.09 s 
2025-12-07 18:09:48.492486: Yayy! New best EMA pseudo Dice: 0.9255 
2025-12-07 18:09:49.572466:  
2025-12-07 18:09:49.572466: Epoch 158 
2025-12-07 18:09:49.572466: Current learning rate: 0.00857 
2025-12-07 18:12:07.422258: train_loss -0.8202 
2025-12-07 18:12:07.423407: val_loss -0.8358 
2025-12-07 18:12:07.425417: Pseudo dice [0.9077, 0.9398, 0.9263] 
2025-12-07 18:12:07.428424: Epoch time: 137.86 s 
2025-12-07 18:12:08.084292:  
2025-12-07 18:12:08.084292: Epoch 159 
2025-12-07 18:12:08.087030: Current learning rate: 0.00856 
2025-12-07 18:14:26.050752: train_loss -0.8172 
2025-12-07 18:14:26.050752: val_loss -0.8353 
2025-12-07 18:14:26.062822: Pseudo dice [0.9036, 0.9388, 0.9309] 
2025-12-07 18:14:26.062822: Epoch time: 137.97 s 
2025-12-07 18:14:26.719042:  
2025-12-07 18:14:26.719042: Epoch 160 
2025-12-07 18:14:26.734987: Current learning rate: 0.00855 
2025-12-07 18:16:44.701471: train_loss -0.8114 
2025-12-07 18:16:44.701471: val_loss -0.8426 
2025-12-07 18:16:44.701471: Pseudo dice [0.9114, 0.9477, 0.927] 
2025-12-07 18:16:44.701471: Epoch time: 137.98 s 
2025-12-07 18:16:44.701471: Yayy! New best EMA pseudo Dice: 0.9256 
2025-12-07 18:16:45.951902:  
2025-12-07 18:16:45.951902: Epoch 161 
2025-12-07 18:16:45.969745: Current learning rate: 0.00854 
2025-12-07 18:19:03.939879: train_loss -0.821 
2025-12-07 18:19:03.939879: val_loss -0.8272 
2025-12-07 18:19:03.942886: Pseudo dice [0.8942, 0.9334, 0.9273] 
2025-12-07 18:19:03.944944: Epoch time: 137.99 s 
2025-12-07 18:19:04.607598:  
2025-12-07 18:19:04.607598: Epoch 162 
2025-12-07 18:19:04.608600: Current learning rate: 0.00853 
2025-12-07 18:21:22.592535: train_loss -0.8177 
2025-12-07 18:21:22.592535: val_loss -0.8321 
2025-12-07 18:21:22.592535: Pseudo dice [0.908, 0.9433, 0.9248] 
2025-12-07 18:21:22.598449: Epoch time: 137.99 s 
2025-12-07 18:21:23.233416:  
2025-12-07 18:21:23.233416: Epoch 163 
2025-12-07 18:21:23.249347: Current learning rate: 0.00852 
2025-12-07 18:23:41.187200: train_loss -0.8207 
2025-12-07 18:23:41.188203: val_loss -0.8483 
2025-12-07 18:23:41.190207: Pseudo dice [0.9087, 0.9471, 0.9393] 
2025-12-07 18:23:41.192462: Epoch time: 137.95 s 
2025-12-07 18:23:41.960069:  
2025-12-07 18:23:41.961072: Epoch 164 
2025-12-07 18:23:41.963077: Current learning rate: 0.00851 
2025-12-07 18:26:00.074785: train_loss -0.8141 
2025-12-07 18:26:00.074785: val_loss -0.8365 
2025-12-07 18:26:00.077102: Pseudo dice [0.9054, 0.9399, 0.9308] 
2025-12-07 18:26:00.079104: Epoch time: 138.12 s 
2025-12-07 18:26:00.733460:  
2025-12-07 18:26:00.733460: Epoch 165 
2025-12-07 18:26:00.733460: Current learning rate: 0.0085 
2025-12-07 18:28:18.824225: train_loss -0.8197 
2025-12-07 18:28:18.824225: val_loss -0.8272 
2025-12-07 18:28:18.827729: Pseudo dice [0.9012, 0.9337, 0.9263] 
2025-12-07 18:28:18.829807: Epoch time: 138.09 s 
2025-12-07 18:28:19.477584:  
2025-12-07 18:28:19.477584: Epoch 166 
2025-12-07 18:28:19.477584: Current learning rate: 0.00849 
2025-12-07 18:30:37.590889: train_loss -0.816 
2025-12-07 18:30:37.591889: val_loss -0.8428 
2025-12-07 18:30:37.595044: Pseudo dice [0.907, 0.9432, 0.9294] 
2025-12-07 18:30:37.596044: Epoch time: 138.12 s 
2025-12-07 18:30:38.498636:  
2025-12-07 18:30:38.498636: Epoch 167 
2025-12-07 18:30:38.505867: Current learning rate: 0.00848 
2025-12-07 18:32:56.404827: train_loss -0.8164 
2025-12-07 18:32:56.404827: val_loss -0.8412 
2025-12-07 18:32:56.404827: Pseudo dice [0.9132, 0.9438, 0.9343] 
2025-12-07 18:32:56.420504: Epoch time: 137.91 s 
2025-12-07 18:32:56.420504: Yayy! New best EMA pseudo Dice: 0.9257 
2025-12-07 18:32:57.351302:  
2025-12-07 18:32:57.353304: Epoch 168 
2025-12-07 18:32:57.353304: Current learning rate: 0.00847 
2025-12-07 18:35:15.244566: train_loss -0.8269 
2025-12-07 18:35:15.244566: val_loss -0.849 
2025-12-07 18:35:15.248570: Pseudo dice [0.9148, 0.9472, 0.9373] 
2025-12-07 18:35:15.250572: Epoch time: 137.89 s 
2025-12-07 18:35:15.252575: Yayy! New best EMA pseudo Dice: 0.9265 
2025-12-07 18:35:16.213330:  
2025-12-07 18:35:16.213330: Epoch 169 
2025-12-07 18:35:16.213330: Current learning rate: 0.00847 
2025-12-07 18:37:34.295702: train_loss -0.8229 
2025-12-07 18:37:34.295702: val_loss -0.8571 
2025-12-07 18:37:34.295702: Pseudo dice [0.9244, 0.9495, 0.9374] 
2025-12-07 18:37:34.295702: Epoch time: 138.08 s 
2025-12-07 18:37:34.311500: Yayy! New best EMA pseudo Dice: 0.9275 
2025-12-07 18:37:35.279917:  
2025-12-07 18:37:35.279917: Epoch 170 
2025-12-07 18:37:35.279917: Current learning rate: 0.00846 
2025-12-07 18:39:53.562235: train_loss -0.8204 
2025-12-07 18:39:53.578196: val_loss -0.8447 
2025-12-07 18:39:53.578196: Pseudo dice [0.9127, 0.9456, 0.9264] 
2025-12-07 18:39:53.578196: Epoch time: 138.28 s 
2025-12-07 18:39:53.578196: Yayy! New best EMA pseudo Dice: 0.9276 
2025-12-07 18:39:54.486213:  
2025-12-07 18:39:54.486213: Epoch 171 
2025-12-07 18:39:54.489742: Current learning rate: 0.00845 
2025-12-07 18:42:12.404204: train_loss -0.818 
2025-12-07 18:42:12.404204: val_loss -0.8347 
2025-12-07 18:42:12.407221: Pseudo dice [0.9028, 0.9419, 0.9343] 
2025-12-07 18:42:12.408319: Epoch time: 137.92 s 
2025-12-07 18:42:13.045727:  
2025-12-07 18:42:13.045727: Epoch 172 
2025-12-07 18:42:13.045727: Current learning rate: 0.00844 
2025-12-07 18:44:31.201588: train_loss -0.8208 
2025-12-07 18:44:31.203329: val_loss -0.8364 
2025-12-07 18:44:31.203329: Pseudo dice [0.9068, 0.9445, 0.9271] 
2025-12-07 18:44:31.203329: Epoch time: 138.16 s 
2025-12-07 18:44:32.171478:  
2025-12-07 18:44:32.171478: Epoch 173 
2025-12-07 18:44:32.171478: Current learning rate: 0.00843 
2025-12-07 18:46:50.074674: train_loss -0.8237 
2025-12-07 18:46:50.074674: val_loss -0.846 
2025-12-07 18:46:50.078722: Pseudo dice [0.9114, 0.9458, 0.9368] 
2025-12-07 18:46:50.080723: Epoch time: 137.9 s 
2025-12-07 18:46:50.083727: Yayy! New best EMA pseudo Dice: 0.9278 
2025-12-07 18:46:50.999908:  
2025-12-07 18:46:50.999908: Epoch 174 
2025-12-07 18:46:50.999908: Current learning rate: 0.00842 
2025-12-07 18:49:09.075900: train_loss -0.8222 
2025-12-07 18:49:09.077402: val_loss -0.8432 
2025-12-07 18:49:09.079404: Pseudo dice [0.9121, 0.9439, 0.9297] 
2025-12-07 18:49:09.079404: Epoch time: 138.08 s 
2025-12-07 18:49:09.082844: Yayy! New best EMA pseudo Dice: 0.9278 
2025-12-07 18:49:09.998808:  
2025-12-07 18:49:09.998808: Epoch 175 
2025-12-07 18:49:09.998808: Current learning rate: 0.00841 
2025-12-07 18:51:28.003251: train_loss -0.8225 
2025-12-07 18:51:28.003251: val_loss -0.8305 
2025-12-07 18:51:28.006258: Pseudo dice [0.9037, 0.9343, 0.9351] 
2025-12-07 18:51:28.008262: Epoch time: 138.01 s 
2025-12-07 18:51:28.777461:  
2025-12-07 18:51:28.777461: Epoch 176 
2025-12-07 18:51:28.780472: Current learning rate: 0.0084 
2025-12-07 18:53:46.807074: train_loss -0.82 
2025-12-07 18:53:46.808074: val_loss -0.8381 
2025-12-07 18:53:46.810096: Pseudo dice [0.9015, 0.9411, 0.9418] 
2025-12-07 18:53:46.811098: Epoch time: 138.03 s 
2025-12-07 18:53:47.467961:  
2025-12-07 18:53:47.467961: Epoch 177 
2025-12-07 18:53:47.467961: Current learning rate: 0.00839 
2025-12-07 18:56:05.474582: train_loss -0.8167 
2025-12-07 18:56:05.474582: val_loss -0.8488 
2025-12-07 18:56:05.477583: Pseudo dice [0.9109, 0.9509, 0.9309] 
2025-12-07 18:56:05.479593: Epoch time: 138.01 s 
2025-12-07 18:56:05.481598: Yayy! New best EMA pseudo Dice: 0.9279 
2025-12-07 18:56:06.577782:  
2025-12-07 18:56:06.577782: Epoch 178 
2025-12-07 18:56:06.577782: Current learning rate: 0.00838 
2025-12-07 18:58:24.343248: train_loss -0.8201 
2025-12-07 18:58:24.343248: val_loss -0.8374 
2025-12-07 18:58:24.347252: Pseudo dice [0.9085, 0.9379, 0.93] 
2025-12-07 18:58:24.347252: Epoch time: 137.77 s 
2025-12-07 18:58:25.117040:  
2025-12-07 18:58:25.117040: Epoch 179 
2025-12-07 18:58:25.117040: Current learning rate: 0.00837 
2025-12-07 19:00:43.133048: train_loss -0.8219 
2025-12-07 19:00:43.134050: val_loss -0.8527 
2025-12-07 19:00:43.137057: Pseudo dice [0.9169, 0.9428, 0.9412] 
2025-12-07 19:00:43.139068: Epoch time: 138.02 s 
2025-12-07 19:00:43.139068: Yayy! New best EMA pseudo Dice: 0.9282 
2025-12-07 19:00:44.030402:  
2025-12-07 19:00:44.030402: Epoch 180 
2025-12-07 19:00:44.046318: Current learning rate: 0.00836 
2025-12-07 19:03:02.109035: train_loss -0.8195 
2025-12-07 19:03:02.109035: val_loss -0.8392 
2025-12-07 19:03:02.109035: Pseudo dice [0.9078, 0.9451, 0.9347] 
2025-12-07 19:03:02.125158: Epoch time: 138.08 s 
2025-12-07 19:03:02.127405: Yayy! New best EMA pseudo Dice: 0.9283 
2025-12-07 19:03:03.071138:  
2025-12-07 19:03:03.071138: Epoch 181 
2025-12-07 19:03:03.071138: Current learning rate: 0.00836 
2025-12-07 19:05:20.875661: train_loss -0.8243 
2025-12-07 19:05:20.875661: val_loss -0.8422 
2025-12-07 19:05:20.881678: Pseudo dice [0.9062, 0.9414, 0.939] 
2025-12-07 19:05:20.885689: Epoch time: 137.81 s 
2025-12-07 19:05:20.887496: Yayy! New best EMA pseudo Dice: 0.9284 
2025-12-07 19:05:22.007797:  
2025-12-07 19:05:22.007797: Epoch 182 
2025-12-07 19:05:22.009802: Current learning rate: 0.00835 
2025-12-07 19:07:40.175119: train_loss -0.8224 
2025-12-07 19:07:40.175119: val_loss -0.8345 
2025-12-07 19:07:40.178126: Pseudo dice [0.9069, 0.9406, 0.9318] 
2025-12-07 19:07:40.180132: Epoch time: 138.17 s 
2025-12-07 19:07:40.811682:  
2025-12-07 19:07:40.811682: Epoch 183 
2025-12-07 19:07:40.811682: Current learning rate: 0.00834 
2025-12-07 19:09:58.655071: train_loss -0.8258 
2025-12-07 19:09:58.655071: val_loss -0.8466 
2025-12-07 19:09:58.655071: Pseudo dice [0.91, 0.9447, 0.9372] 
2025-12-07 19:09:58.655071: Epoch time: 137.84 s 
2025-12-07 19:09:58.655071: Yayy! New best EMA pseudo Dice: 0.9284 
2025-12-07 19:09:59.749969:  
2025-12-07 19:09:59.749969: Epoch 184 
2025-12-07 19:09:59.749969: Current learning rate: 0.00833 
2025-12-07 19:12:17.827423: train_loss -0.8188 
2025-12-07 19:12:17.833464: val_loss -0.8451 
2025-12-07 19:12:17.835465: Pseudo dice [0.9057, 0.9461, 0.9348] 
2025-12-07 19:12:17.837468: Epoch time: 138.08 s 
2025-12-07 19:12:17.839470: Yayy! New best EMA pseudo Dice: 0.9285 
2025-12-07 19:12:18.853768:  
2025-12-07 19:12:18.853768: Epoch 185 
2025-12-07 19:12:18.856777: Current learning rate: 0.00832 
2025-12-07 19:14:36.909649: train_loss -0.8167 
2025-12-07 19:14:36.909649: val_loss -0.8371 
2025-12-07 19:14:36.913653: Pseudo dice [0.9056, 0.9451, 0.9298] 
2025-12-07 19:14:36.915655: Epoch time: 138.06 s 
2025-12-07 19:14:37.566916:  
2025-12-07 19:14:37.568918: Epoch 186 
2025-12-07 19:14:37.568918: Current learning rate: 0.00831 
2025-12-07 19:16:55.717859: train_loss -0.816 
2025-12-07 19:16:55.717859: val_loss -0.8362 
2025-12-07 19:16:55.717859: Pseudo dice [0.9042, 0.9403, 0.9279] 
2025-12-07 19:16:55.717859: Epoch time: 138.15 s 
2025-12-07 19:16:56.367774:  
2025-12-07 19:16:56.367774: Epoch 187 
2025-12-07 19:16:56.367774: Current learning rate: 0.0083 
2025-12-07 19:19:14.427472: train_loss -0.8212 
2025-12-07 19:19:14.429475: val_loss -0.8554 
2025-12-07 19:19:14.431478: Pseudo dice [0.9188, 0.9529, 0.9318] 
2025-12-07 19:19:14.433481: Epoch time: 138.06 s 
2025-12-07 19:19:14.435483: Yayy! New best EMA pseudo Dice: 0.9286 
2025-12-07 19:19:15.373972:  
2025-12-07 19:19:15.373972: Epoch 188 
2025-12-07 19:19:15.377150: Current learning rate: 0.00829 
2025-12-07 19:21:33.502789: train_loss -0.8243 
2025-12-07 19:21:33.502789: val_loss -0.8516 
2025-12-07 19:21:33.506793: Pseudo dice [0.9168, 0.9495, 0.9336] 
2025-12-07 19:21:33.508794: Epoch time: 138.13 s 
2025-12-07 19:21:33.511840: Yayy! New best EMA pseudo Dice: 0.929 
2025-12-07 19:21:34.427148:  
2025-12-07 19:21:34.428889: Epoch 189 
2025-12-07 19:21:34.428889: Current learning rate: 0.00828 
2025-12-07 19:23:53.672543: train_loss -0.8254 
2025-12-07 19:23:53.673545: val_loss -0.8502 
2025-12-07 19:23:53.676548: Pseudo dice [0.9103, 0.9486, 0.9401] 
2025-12-07 19:23:53.678548: Epoch time: 139.25 s 
2025-12-07 19:23:53.680549: Yayy! New best EMA pseudo Dice: 0.9294 
2025-12-07 19:23:54.772289:  
2025-12-07 19:23:54.772289: Epoch 190 
2025-12-07 19:23:54.772289: Current learning rate: 0.00827 
2025-12-07 19:26:13.140501: train_loss -0.8251 
2025-12-07 19:26:13.140501: val_loss -0.8374 
2025-12-07 19:26:13.140501: Pseudo dice [0.9026, 0.9453, 0.9319] 
2025-12-07 19:26:13.148446: Epoch time: 138.37 s 
2025-12-07 19:26:13.967290:  
2025-12-07 19:26:13.967290: Epoch 191 
2025-12-07 19:26:13.972101: Current learning rate: 0.00826 
2025-12-07 19:28:32.276417: train_loss -0.8236 
2025-12-07 19:28:32.276417: val_loss -0.8456 
2025-12-07 19:28:32.282434: Pseudo dice [0.9068, 0.9443, 0.9371] 
2025-12-07 19:28:32.286445: Epoch time: 138.31 s 
2025-12-07 19:28:32.954730:  
2025-12-07 19:28:32.954730: Epoch 192 
2025-12-07 19:28:32.957001: Current learning rate: 0.00825 
2025-12-07 19:30:51.385888: train_loss -0.8112 
2025-12-07 19:30:51.387890: val_loss -0.8407 
2025-12-07 19:30:51.389392: Pseudo dice [0.9098, 0.9455, 0.929] 
2025-12-07 19:30:51.389392: Epoch time: 138.43 s 
2025-12-07 19:30:52.060239:  
2025-12-07 19:30:52.060239: Epoch 193 
2025-12-07 19:30:52.061743: Current learning rate: 0.00824 
2025-12-07 19:33:10.416735: train_loss -0.8228 
2025-12-07 19:33:10.416735: val_loss -0.8545 
2025-12-07 19:33:10.418738: Pseudo dice [0.9146, 0.9489, 0.9404] 
2025-12-07 19:33:10.420479: Epoch time: 138.36 s 
2025-12-07 19:33:10.420479: Yayy! New best EMA pseudo Dice: 0.9296 
2025-12-07 19:33:11.365000:  
2025-12-07 19:33:11.366005: Epoch 194 
2025-12-07 19:33:11.367747: Current learning rate: 0.00824 
2025-12-07 19:35:29.217067: train_loss -0.8256 
2025-12-07 19:35:29.217067: val_loss -0.833 
2025-12-07 19:35:29.234911: Pseudo dice [0.8962, 0.9376, 0.9317] 
2025-12-07 19:35:29.236913: Epoch time: 137.85 s 
2025-12-07 19:35:29.889876:  
2025-12-07 19:35:29.889876: Epoch 195 
2025-12-07 19:35:29.889876: Current learning rate: 0.00823 
2025-12-07 19:37:47.970228: train_loss -0.8265 
2025-12-07 19:37:47.970228: val_loss -0.8417 
2025-12-07 19:37:47.972231: Pseudo dice [0.9111, 0.9429, 0.9266] 
2025-12-07 19:37:47.972231: Epoch time: 138.08 s 
2025-12-07 19:37:48.889841:  
2025-12-07 19:37:48.889841: Epoch 196 
2025-12-07 19:37:48.889841: Current learning rate: 0.00822 
2025-12-07 19:40:07.002556: train_loss -0.8238 
2025-12-07 19:40:07.002556: val_loss -0.8395 
2025-12-07 19:40:07.005558: Pseudo dice [0.9061, 0.9477, 0.9338] 
2025-12-07 19:40:07.007559: Epoch time: 138.11 s 
2025-12-07 19:40:07.765582:  
2025-12-07 19:40:07.765582: Epoch 197 
2025-12-07 19:40:07.781512: Current learning rate: 0.00821 
2025-12-07 19:42:25.835589: train_loss -0.82 
2025-12-07 19:42:25.835589: val_loss -0.8436 
2025-12-07 19:42:25.845140: Pseudo dice [0.9152, 0.945, 0.9288] 
2025-12-07 19:42:25.847142: Epoch time: 138.07 s 
2025-12-07 19:42:26.499300:  
2025-12-07 19:42:26.499300: Epoch 198 
2025-12-07 19:42:26.514967: Current learning rate: 0.0082 
2025-12-07 19:44:44.458312: train_loss -0.8279 
2025-12-07 19:44:44.459312: val_loss -0.8525 
2025-12-07 19:44:44.461313: Pseudo dice [0.9124, 0.9574, 0.9283] 
2025-12-07 19:44:44.464313: Epoch time: 137.96 s 
2025-12-07 19:44:45.123506:  
2025-12-07 19:44:45.123506: Epoch 199 
2025-12-07 19:44:45.123506: Current learning rate: 0.00819 
2025-12-07 19:47:02.950369: train_loss -0.8179 
2025-12-07 19:47:02.950369: val_loss -0.847 
2025-12-07 19:47:02.952371: Pseudo dice [0.9144, 0.9478, 0.928] 
2025-12-07 19:47:02.955392: Epoch time: 137.83 s 
2025-12-07 19:47:04.034540:  
2025-12-07 19:47:04.034540: Epoch 200 
2025-12-07 19:47:04.034540: Current learning rate: 0.00818 
2025-12-07 19:49:22.014951: train_loss -0.8212 
2025-12-07 19:49:22.014951: val_loss -0.835 
2025-12-07 19:49:22.024478: Pseudo dice [0.901, 0.9364, 0.9307] 
2025-12-07 19:49:22.027309: Epoch time: 137.98 s 
2025-12-07 19:49:22.846105:  
2025-12-07 19:49:22.847108: Epoch 201 
2025-12-07 19:49:22.849117: Current learning rate: 0.00817 
2025-12-07 19:51:40.733444: train_loss -0.8258 
2025-12-07 19:51:40.733444: val_loss -0.8512 
2025-12-07 19:51:40.740831: Pseudo dice [0.915, 0.949, 0.9327] 
2025-12-07 19:51:40.742833: Epoch time: 137.89 s 
2025-12-07 19:51:41.404788:  
2025-12-07 19:51:41.404788: Epoch 202 
2025-12-07 19:51:41.408677: Current learning rate: 0.00816 
2025-12-07 19:53:59.282296: train_loss -0.8259 
2025-12-07 19:53:59.284299: val_loss -0.8431 
2025-12-07 19:53:59.286301: Pseudo dice [0.9097, 0.9404, 0.9382] 
2025-12-07 19:53:59.290306: Epoch time: 137.89 s 
2025-12-07 19:54:00.061769:  
2025-12-07 19:54:00.061769: Epoch 203 
2025-12-07 19:54:00.077420: Current learning rate: 0.00815 
2025-12-07 19:56:18.106199: train_loss -0.8202 
2025-12-07 19:56:18.106199: val_loss -0.845 
2025-12-07 19:56:18.108218: Pseudo dice [0.9073, 0.9494, 0.935] 
2025-12-07 19:56:18.108218: Epoch time: 138.04 s 
2025-12-07 19:56:18.764354:  
2025-12-07 19:56:18.764354: Epoch 204 
2025-12-07 19:56:18.764354: Current learning rate: 0.00814 
2025-12-07 19:58:36.915333: train_loss -0.8178 
2025-12-07 19:58:36.917335: val_loss -0.838 
2025-12-07 19:58:36.921079: Pseudo dice [0.9059, 0.9406, 0.9339] 
2025-12-07 19:58:36.923083: Epoch time: 138.15 s 
2025-12-07 19:58:37.592671:  
2025-12-07 19:58:37.592671: Epoch 205 
2025-12-07 19:58:37.592671: Current learning rate: 0.00813 
2025-12-07 20:00:55.452054: train_loss -0.8209 
2025-12-07 20:00:55.452054: val_loss -0.853 
2025-12-07 20:00:55.457753: Pseudo dice [0.9157, 0.9495, 0.9339] 
2025-12-07 20:00:55.457753: Epoch time: 137.86 s 
2025-12-07 20:00:56.078774:  
2025-12-07 20:00:56.078774: Epoch 206 
2025-12-07 20:00:56.081788: Current learning rate: 0.00813 
2025-12-07 20:03:14.140695: train_loss -0.8227 
2025-12-07 20:03:14.140695: val_loss -0.8243 
2025-12-07 20:03:14.140695: Pseudo dice [0.8941, 0.9312, 0.9341] 
2025-12-07 20:03:14.146950: Epoch time: 138.06 s 
2025-12-07 20:03:14.780078:  
2025-12-07 20:03:14.780078: Epoch 207 
2025-12-07 20:03:14.780078: Current learning rate: 0.00812 
2025-12-07 20:05:32.722013: train_loss -0.7927 
2025-12-07 20:05:32.722013: val_loss -0.8266 
2025-12-07 20:05:32.722013: Pseudo dice [0.9038, 0.9395, 0.92] 
2025-12-07 20:05:32.722013: Epoch time: 137.94 s 
2025-12-07 20:05:33.548093:  
2025-12-07 20:05:33.548093: Epoch 208 
2025-12-07 20:05:33.548093: Current learning rate: 0.00811 
2025-12-07 20:07:51.458176: train_loss -0.7879 
2025-12-07 20:07:51.458176: val_loss -0.8138 
2025-12-07 20:07:51.461197: Pseudo dice [0.8964, 0.9343, 0.9236] 
2025-12-07 20:07:51.463201: Epoch time: 137.91 s 
2025-12-07 20:07:52.217158:  
2025-12-07 20:07:52.232817: Epoch 209 
2025-12-07 20:07:52.232817: Current learning rate: 0.0081 
2025-12-07 20:10:10.092541: train_loss -0.8041 
2025-12-07 20:10:10.092541: val_loss -0.8375 
2025-12-07 20:10:10.092541: Pseudo dice [0.905, 0.941, 0.9282] 
2025-12-07 20:10:10.092541: Epoch time: 137.88 s 
2025-12-07 20:10:10.727145:  
2025-12-07 20:10:10.727145: Epoch 210 
2025-12-07 20:10:10.729157: Current learning rate: 0.00809 
2025-12-07 20:12:28.689175: train_loss -0.8133 
2025-12-07 20:12:28.689175: val_loss -0.8391 
2025-12-07 20:12:28.689175: Pseudo dice [0.9145, 0.9437, 0.9288] 
2025-12-07 20:12:28.689175: Epoch time: 137.96 s 
2025-12-07 20:12:29.327861:  
2025-12-07 20:12:29.327861: Epoch 211 
2025-12-07 20:12:29.327861: Current learning rate: 0.00808 
2025-12-07 20:14:47.327923: train_loss -0.812 
2025-12-07 20:14:47.327923: val_loss -0.8363 
2025-12-07 20:14:47.327923: Pseudo dice [0.9096, 0.945, 0.9256] 
2025-12-07 20:14:47.327923: Epoch time: 138.0 s 
2025-12-07 20:14:47.973922:  
2025-12-07 20:14:47.973922: Epoch 212 
2025-12-07 20:14:47.973922: Current learning rate: 0.00807 
2025-12-07 20:17:06.132528: train_loss -0.812 
2025-12-07 20:17:06.133530: val_loss -0.8395 
2025-12-07 20:17:06.136547: Pseudo dice [0.9105, 0.9498, 0.9238] 
2025-12-07 20:17:06.138554: Epoch time: 138.16 s 
2025-12-07 20:17:06.749240:  
2025-12-07 20:17:06.749240: Epoch 213 
2025-12-07 20:17:06.749240: Current learning rate: 0.00806 
2025-12-07 20:19:24.578490: train_loss -0.8107 
2025-12-07 20:19:24.578490: val_loss -0.8473 
2025-12-07 20:19:24.594319: Pseudo dice [0.915, 0.9518, 0.9315] 
2025-12-07 20:19:24.594319: Epoch time: 137.83 s 
2025-12-07 20:19:25.486346:  
2025-12-07 20:19:25.486346: Epoch 214 
2025-12-07 20:19:25.489359: Current learning rate: 0.00805 
2025-12-07 20:21:43.358577: train_loss -0.8168 
2025-12-07 20:21:43.358577: val_loss -0.8381 
2025-12-07 20:21:43.358577: Pseudo dice [0.9071, 0.9456, 0.9228] 
2025-12-07 20:21:43.358577: Epoch time: 137.87 s 
2025-12-07 20:21:43.983007:  
2025-12-07 20:21:43.983007: Epoch 215 
2025-12-07 20:21:43.983007: Current learning rate: 0.00804 
2025-12-07 20:24:01.857908: train_loss -0.8182 
2025-12-07 20:24:01.857908: val_loss -0.8425 
2025-12-07 20:24:01.863152: Pseudo dice [0.9107, 0.9429, 0.9345] 
2025-12-07 20:24:01.865155: Epoch time: 137.87 s 
2025-12-07 20:24:02.499253:  
2025-12-07 20:24:02.499253: Epoch 216 
2025-12-07 20:24:02.499253: Current learning rate: 0.00803 
2025-12-07 20:26:20.530557: train_loss -0.825 
2025-12-07 20:26:20.530557: val_loss -0.8476 
2025-12-07 20:26:20.530557: Pseudo dice [0.9153, 0.9458, 0.9377] 
2025-12-07 20:26:20.530557: Epoch time: 138.03 s 
2025-12-07 20:26:21.311542:  
2025-12-07 20:26:21.311542: Epoch 217 
2025-12-07 20:26:21.327261: Current learning rate: 0.00802 
2025-12-07 20:28:39.421726: train_loss -0.8189 
2025-12-07 20:28:39.421726: val_loss -0.8397 
2025-12-07 20:28:39.421726: Pseudo dice [0.906, 0.9436, 0.9337] 
2025-12-07 20:28:39.421726: Epoch time: 138.11 s 
2025-12-07 20:28:40.045655:  
2025-12-07 20:28:40.045655: Epoch 218 
2025-12-07 20:28:40.061619: Current learning rate: 0.00801 
2025-12-07 20:30:57.906782: train_loss -0.8248 
2025-12-07 20:30:57.906782: val_loss -0.8412 
2025-12-07 20:30:57.906782: Pseudo dice [0.9059, 0.9461, 0.9345] 
2025-12-07 20:30:57.906782: Epoch time: 137.86 s 
2025-12-07 20:30:58.562199:  
2025-12-07 20:30:58.562199: Epoch 219 
2025-12-07 20:30:58.562199: Current learning rate: 0.00801 
2025-12-07 20:33:16.500032: train_loss -0.8201 
2025-12-07 20:33:16.500032: val_loss -0.8524 
2025-12-07 20:33:16.500032: Pseudo dice [0.9192, 0.9524, 0.9255] 
2025-12-07 20:33:16.505838: Epoch time: 137.95 s 
2025-12-07 20:33:17.452533:  
2025-12-07 20:33:17.452533: Epoch 220 
2025-12-07 20:33:17.468335: Current learning rate: 0.008 
2025-12-07 20:35:35.382198: train_loss -0.8239 
2025-12-07 20:35:35.382198: val_loss -0.8395 
2025-12-07 20:35:35.386201: Pseudo dice [0.9031, 0.938, 0.9363] 
2025-12-07 20:35:35.388203: Epoch time: 137.93 s 
2025-12-07 20:35:36.018170:  
2025-12-07 20:35:36.018170: Epoch 221 
2025-12-07 20:35:36.018170: Current learning rate: 0.00799 
2025-12-07 20:37:53.940255: train_loss -0.8247 
2025-12-07 20:37:53.940255: val_loss -0.8469 
2025-12-07 20:37:53.943261: Pseudo dice [0.9104, 0.9463, 0.94] 
2025-12-07 20:37:53.945273: Epoch time: 137.92 s 
2025-12-07 20:37:54.592773:  
2025-12-07 20:37:54.592773: Epoch 222 
2025-12-07 20:37:54.608532: Current learning rate: 0.00798 
2025-12-07 20:40:12.644933: train_loss -0.8229 
2025-12-07 20:40:12.644933: val_loss -0.8444 
2025-12-07 20:40:12.648402: Pseudo dice [0.9086, 0.9472, 0.9347] 
2025-12-07 20:40:12.650404: Epoch time: 138.05 s 
2025-12-07 20:40:13.375329:  
2025-12-07 20:40:13.375329: Epoch 223 
2025-12-07 20:40:13.375329: Current learning rate: 0.00797 
2025-12-07 20:42:31.167648: train_loss -0.8253 
2025-12-07 20:42:31.169650: val_loss -0.8679 
2025-12-07 20:42:31.172509: Pseudo dice [0.9209, 0.9526, 0.9439] 
2025-12-07 20:42:31.175515: Epoch time: 137.79 s 
2025-12-07 20:42:31.177521: Yayy! New best EMA pseudo Dice: 0.9298 
2025-12-07 20:42:32.060571:  
2025-12-07 20:42:32.060571: Epoch 224 
2025-12-07 20:42:32.061657: Current learning rate: 0.00796 
2025-12-07 20:44:51.216740: train_loss -0.8328 
2025-12-07 20:44:51.216740: val_loss -0.8551 
2025-12-07 20:44:51.220483: Pseudo dice [0.9164, 0.9462, 0.9407] 
2025-12-07 20:44:51.222485: Epoch time: 139.16 s 
2025-12-07 20:44:51.224486: Yayy! New best EMA pseudo Dice: 0.9303 
2025-12-07 20:44:52.128910:  
2025-12-07 20:44:52.130913: Epoch 225 
2025-12-07 20:44:52.130913: Current learning rate: 0.00795 
2025-12-07 20:47:10.608327: train_loss -0.8276 
2025-12-07 20:47:10.608327: val_loss -0.8577 
2025-12-07 20:47:10.608327: Pseudo dice [0.9198, 0.9495, 0.9364] 
2025-12-07 20:47:10.608327: Epoch time: 138.48 s 
2025-12-07 20:47:10.608327: Yayy! New best EMA pseudo Dice: 0.9308 
2025-12-07 20:47:11.779070:  
2025-12-07 20:47:11.779070: Epoch 226 
2025-12-07 20:47:11.795063: Current learning rate: 0.00794 
2025-12-07 20:49:30.182772: train_loss -0.8235 
2025-12-07 20:49:30.182772: val_loss -0.8511 
2025-12-07 20:49:30.186777: Pseudo dice [0.9103, 0.9449, 0.9419] 
2025-12-07 20:49:30.188016: Epoch time: 138.4 s 
2025-12-07 20:49:30.191017: Yayy! New best EMA pseudo Dice: 0.9309 
2025-12-07 20:49:31.077151:  
2025-12-07 20:49:31.077151: Epoch 227 
2025-12-07 20:49:31.077151: Current learning rate: 0.00793 
2025-12-07 20:51:49.391018: train_loss -0.8273 
2025-12-07 20:51:49.391018: val_loss -0.8516 
2025-12-07 20:51:49.406980: Pseudo dice [0.9151, 0.9473, 0.9363] 
2025-12-07 20:51:49.409112: Epoch time: 138.31 s 
2025-12-07 20:51:49.410115: Yayy! New best EMA pseudo Dice: 0.9311 
2025-12-07 20:51:50.297872:  
2025-12-07 20:51:50.297872: Epoch 228 
2025-12-07 20:51:50.297872: Current learning rate: 0.00792 
2025-12-07 20:54:08.764357: train_loss -0.8291 
2025-12-07 20:54:08.764357: val_loss -0.8466 
2025-12-07 20:54:08.773907: Pseudo dice [0.912, 0.9508, 0.9384] 
2025-12-07 20:54:08.775910: Epoch time: 138.47 s 
2025-12-07 20:54:08.777912: Yayy! New best EMA pseudo Dice: 0.9314 
2025-12-07 20:54:09.670253:  
2025-12-07 20:54:09.670253: Epoch 229 
2025-12-07 20:54:09.672210: Current learning rate: 0.00791 
2025-12-07 20:56:27.608752: train_loss -0.8284 
2025-12-07 20:56:27.608752: val_loss -0.8492 
2025-12-07 20:56:27.614924: Pseudo dice [0.9098, 0.9493, 0.9386] 
2025-12-07 20:56:27.617476: Epoch time: 137.94 s 
2025-12-07 20:56:27.619478: Yayy! New best EMA pseudo Dice: 0.9315 
2025-12-07 20:56:28.498840:  
2025-12-07 20:56:28.498840: Epoch 230 
2025-12-07 20:56:28.498840: Current learning rate: 0.0079 
2025-12-07 20:58:46.662389: train_loss -0.831 
2025-12-07 20:58:46.664391: val_loss -0.8531 
2025-12-07 20:58:46.666393: Pseudo dice [0.9158, 0.9479, 0.9331] 
2025-12-07 20:58:46.668395: Epoch time: 138.16 s 
2025-12-07 20:58:46.670397: Yayy! New best EMA pseudo Dice: 0.9316 
2025-12-07 20:58:47.546303:  
2025-12-07 20:58:47.546303: Epoch 231 
2025-12-07 20:58:47.546303: Current learning rate: 0.00789 
2025-12-07 21:01:05.630060: train_loss -0.8247 
2025-12-07 21:01:05.630060: val_loss -0.8691 
2025-12-07 21:01:05.635821: Pseudo dice [0.9274, 0.9574, 0.9387] 
2025-12-07 21:01:05.637825: Epoch time: 138.08 s 
2025-12-07 21:01:05.639827: Yayy! New best EMA pseudo Dice: 0.9325 
2025-12-07 21:01:06.701637:  
2025-12-07 21:01:06.701637: Epoch 232 
2025-12-07 21:01:06.717332: Current learning rate: 0.00789 
2025-12-07 21:03:24.753635: train_loss -0.8231 
2025-12-07 21:03:24.753635: val_loss -0.8546 
2025-12-07 21:03:24.753635: Pseudo dice [0.9126, 0.9485, 0.9373] 
2025-12-07 21:03:24.764627: Epoch time: 138.05 s 
2025-12-07 21:03:24.766629: Yayy! New best EMA pseudo Dice: 0.9326 
2025-12-07 21:03:25.642739:  
2025-12-07 21:03:25.642739: Epoch 233 
2025-12-07 21:03:25.642739: Current learning rate: 0.00788 
2025-12-07 21:05:43.634435: train_loss -0.8312 
2025-12-07 21:05:43.635440: val_loss -0.8547 
2025-12-07 21:05:43.638450: Pseudo dice [0.9127, 0.9514, 0.94] 
2025-12-07 21:05:43.640517: Epoch time: 138.0 s 
2025-12-07 21:05:43.642525: Yayy! New best EMA pseudo Dice: 0.9328 
2025-12-07 21:05:44.499591:  
2025-12-07 21:05:44.499591: Epoch 234 
2025-12-07 21:05:44.516526: Current learning rate: 0.00787 
2025-12-07 21:08:02.615041: train_loss -0.8266 
2025-12-07 21:08:02.616041: val_loss -0.852 
2025-12-07 21:08:02.619042: Pseudo dice [0.916, 0.9464, 0.9354] 
2025-12-07 21:08:02.621043: Epoch time: 138.12 s 
2025-12-07 21:08:03.234133:  
2025-12-07 21:08:03.234133: Epoch 235 
2025-12-07 21:08:03.234133: Current learning rate: 0.00786 
2025-12-07 21:10:21.171710: train_loss -0.8297 
2025-12-07 21:10:21.171710: val_loss -0.8555 
2025-12-07 21:10:21.185844: Pseudo dice [0.9181, 0.9475, 0.9358] 
2025-12-07 21:10:21.187584: Epoch time: 137.94 s 
2025-12-07 21:10:21.187584: Yayy! New best EMA pseudo Dice: 0.9329 
2025-12-07 21:10:22.080126:  
2025-12-07 21:10:22.081125: Epoch 236 
2025-12-07 21:10:22.083573: Current learning rate: 0.00785 
2025-12-07 21:12:40.093121: train_loss -0.8291 
2025-12-07 21:12:40.093121: val_loss -0.8501 
2025-12-07 21:12:40.093121: Pseudo dice [0.9124, 0.9446, 0.9373] 
2025-12-07 21:12:40.093121: Epoch time: 138.01 s 
2025-12-07 21:12:40.868225:  
2025-12-07 21:12:40.868225: Epoch 237 
2025-12-07 21:12:40.868225: Current learning rate: 0.00784 
2025-12-07 21:14:58.995024: train_loss -0.832 
2025-12-07 21:14:58.995024: val_loss -0.8583 
2025-12-07 21:14:58.999028: Pseudo dice [0.919, 0.9506, 0.9406] 
2025-12-07 21:14:58.999028: Epoch time: 138.13 s 
2025-12-07 21:14:59.002529: Yayy! New best EMA pseudo Dice: 0.9331 
2025-12-07 21:14:59.922078:  
2025-12-07 21:14:59.923152: Epoch 238 
2025-12-07 21:14:59.925920: Current learning rate: 0.00783 
2025-12-07 21:17:17.795784: train_loss -0.8296 
2025-12-07 21:17:17.795784: val_loss -0.8522 
2025-12-07 21:17:17.795784: Pseudo dice [0.9124, 0.949, 0.9357] 
2025-12-07 21:17:17.795784: Epoch time: 137.89 s 
2025-12-07 21:17:18.406173:  
2025-12-07 21:17:18.406173: Epoch 239 
2025-12-07 21:17:18.406173: Current learning rate: 0.00782 
2025-12-07 21:19:36.430578: train_loss -0.8295 
2025-12-07 21:19:36.430578: val_loss -0.8465 
2025-12-07 21:19:36.434582: Pseudo dice [0.9149, 0.944, 0.9293] 
2025-12-07 21:19:36.436322: Epoch time: 138.02 s 
2025-12-07 21:19:37.072423:  
2025-12-07 21:19:37.073533: Epoch 240 
2025-12-07 21:19:37.075712: Current learning rate: 0.00781 
2025-12-07 21:21:55.078055: train_loss -0.8257 
2025-12-07 21:21:55.078055: val_loss -0.8577 
2025-12-07 21:21:55.094397: Pseudo dice [0.9146, 0.9535, 0.94] 
2025-12-07 21:21:55.096411: Epoch time: 138.01 s 
2025-12-07 21:21:55.889596:  
2025-12-07 21:21:55.889596: Epoch 241 
2025-12-07 21:21:55.889596: Current learning rate: 0.0078 
2025-12-07 21:24:13.749816: train_loss -0.8265 
2025-12-07 21:24:13.765867: val_loss -0.8666 
2025-12-07 21:24:13.768970: Pseudo dice [0.923, 0.9535, 0.9402] 
2025-12-07 21:24:13.771008: Epoch time: 137.86 s 
2025-12-07 21:24:13.773008: Yayy! New best EMA pseudo Dice: 0.9336 
2025-12-07 21:24:14.655297:  
2025-12-07 21:24:14.655297: Epoch 242 
2025-12-07 21:24:14.655297: Current learning rate: 0.00779 
2025-12-07 21:26:32.713045: train_loss -0.8304 
2025-12-07 21:26:32.715048: val_loss -0.8574 
2025-12-07 21:26:32.718052: Pseudo dice [0.9213, 0.9473, 0.9347] 
2025-12-07 21:26:32.720979: Epoch time: 138.06 s 
2025-12-07 21:26:32.722980: Yayy! New best EMA pseudo Dice: 0.9337 
2025-12-07 21:26:33.627991:  
2025-12-07 21:26:33.627991: Epoch 243 
2025-12-07 21:26:33.627991: Current learning rate: 0.00778 
2025-12-07 21:28:51.654844: train_loss -0.8316 
2025-12-07 21:28:51.654844: val_loss -0.8624 
2025-12-07 21:28:51.657147: Pseudo dice [0.9188, 0.9469, 0.9374] 
2025-12-07 21:28:51.660646: Epoch time: 138.03 s 
2025-12-07 21:28:51.662648: Yayy! New best EMA pseudo Dice: 0.9338 
2025-12-07 21:28:52.860897:  
2025-12-07 21:28:52.860897: Epoch 244 
2025-12-07 21:28:52.863908: Current learning rate: 0.00777 
2025-12-07 21:31:10.946009: train_loss -0.8266 
2025-12-07 21:31:10.948010: val_loss -0.8491 
2025-12-07 21:31:10.950012: Pseudo dice [0.913, 0.9513, 0.9363] 
2025-12-07 21:31:10.951753: Epoch time: 138.09 s 
2025-12-07 21:31:11.578771:  
2025-12-07 21:31:11.578771: Epoch 245 
2025-12-07 21:31:11.578771: Current learning rate: 0.00777 
2025-12-07 21:33:29.528265: train_loss -0.8295 
2025-12-07 21:33:29.530268: val_loss -0.8488 
2025-12-07 21:33:29.532270: Pseudo dice [0.9108, 0.95, 0.9295] 
2025-12-07 21:33:29.536274: Epoch time: 137.95 s 
2025-12-07 21:33:30.170769:  
2025-12-07 21:33:30.170769: Epoch 246 
2025-12-07 21:33:30.170769: Current learning rate: 0.00776 
2025-12-07 21:35:48.139231: train_loss -0.8264 
2025-12-07 21:35:48.139231: val_loss -0.8604 
2025-12-07 21:35:48.139231: Pseudo dice [0.9196, 0.953, 0.9347] 
2025-12-07 21:35:48.149452: Epoch time: 137.97 s 
2025-12-07 21:35:48.904662:  
2025-12-07 21:35:48.904662: Epoch 247 
2025-12-07 21:35:48.920391: Current learning rate: 0.00775 
2025-12-07 21:38:06.749270: train_loss -0.8339 
2025-12-07 21:38:06.749270: val_loss -0.8532 
2025-12-07 21:38:06.749270: Pseudo dice [0.9145, 0.9486, 0.9385] 
2025-12-07 21:38:06.766527: Epoch time: 137.84 s 
2025-12-07 21:38:07.390110:  
2025-12-07 21:38:07.390110: Epoch 248 
2025-12-07 21:38:07.390110: Current learning rate: 0.00774 
2025-12-07 21:40:25.536451: train_loss -0.8294 
2025-12-07 21:40:25.536451: val_loss -0.8607 
2025-12-07 21:40:25.536451: Pseudo dice [0.9158, 0.9571, 0.9426] 
2025-12-07 21:40:25.546232: Epoch time: 138.15 s 
2025-12-07 21:40:25.546232: Yayy! New best EMA pseudo Dice: 0.9341 
2025-12-07 21:40:26.421183:  
2025-12-07 21:40:26.421183: Epoch 249 
2025-12-07 21:40:26.436961: Current learning rate: 0.00773 
2025-12-07 21:42:44.547129: train_loss -0.8326 
2025-12-07 21:42:44.547129: val_loss -0.853 
2025-12-07 21:42:44.551135: Pseudo dice [0.9163, 0.9482, 0.9326] 
2025-12-07 21:42:44.555140: Epoch time: 138.13 s 
2025-12-07 21:42:45.749716:  
2025-12-07 21:42:45.749716: Epoch 250 
2025-12-07 21:42:45.753219: Current learning rate: 0.00772 
2025-12-07 21:45:03.689371: train_loss -0.8337 
2025-12-07 21:45:03.689371: val_loss -0.8532 
2025-12-07 21:45:03.692379: Pseudo dice [0.9143, 0.9474, 0.935] 
2025-12-07 21:45:03.694385: Epoch time: 137.94 s 
2025-12-07 21:45:04.310545:  
2025-12-07 21:45:04.310545: Epoch 251 
2025-12-07 21:45:04.310545: Current learning rate: 0.00771 
2025-12-07 21:47:22.239588: train_loss -0.8346 
2025-12-07 21:47:22.240591: val_loss -0.853 
2025-12-07 21:47:22.243597: Pseudo dice [0.9118, 0.9472, 0.9397] 
2025-12-07 21:47:22.246603: Epoch time: 137.93 s 
2025-12-07 21:47:22.874994:  
2025-12-07 21:47:22.874994: Epoch 252 
2025-12-07 21:47:22.874994: Current learning rate: 0.0077 
2025-12-07 21:49:40.702409: train_loss -0.8323 
2025-12-07 21:49:40.704412: val_loss -0.8576 
2025-12-07 21:49:40.708416: Pseudo dice [0.917, 0.9464, 0.9402] 
2025-12-07 21:49:40.712426: Epoch time: 137.83 s 
2025-12-07 21:49:41.448214:  
2025-12-07 21:49:41.448214: Epoch 253 
2025-12-07 21:49:41.451221: Current learning rate: 0.00769 
2025-12-07 21:51:59.733950: train_loss -0.8307 
2025-12-07 21:51:59.735953: val_loss -0.8629 
2025-12-07 21:51:59.738920: Pseudo dice [0.9205, 0.9529, 0.9382] 
2025-12-07 21:51:59.741266: Epoch time: 138.29 s 
2025-12-07 21:52:00.358394:  
2025-12-07 21:52:00.358394: Epoch 254 
2025-12-07 21:52:00.374187: Current learning rate: 0.00768 
2025-12-07 21:54:18.464573: train_loss -0.8334 
2025-12-07 21:54:18.466575: val_loss -0.8455 
2025-12-07 21:54:18.468315: Pseudo dice [0.9108, 0.9452, 0.9349] 
2025-12-07 21:54:18.472320: Epoch time: 138.11 s 
2025-12-07 21:54:19.093534:  
2025-12-07 21:54:19.093534: Epoch 255 
2025-12-07 21:54:19.093534: Current learning rate: 0.00767 
2025-12-07 21:56:37.170746: train_loss -0.8322 
2025-12-07 21:56:37.170746: val_loss -0.8575 
2025-12-07 21:56:37.186826: Pseudo dice [0.9148, 0.9506, 0.9424] 
2025-12-07 21:56:37.186826: Epoch time: 138.08 s 
2025-12-07 21:56:38.109541:  
2025-12-07 21:56:38.109541: Epoch 256 
2025-12-07 21:56:38.109541: Current learning rate: 0.00766 
2025-12-07 21:58:57.668011: train_loss -0.8373 
2025-12-07 21:58:57.669012: val_loss -0.8641 
2025-12-07 21:58:57.671012: Pseudo dice [0.9174, 0.9476, 0.9475] 
2025-12-07 21:58:57.674949: Epoch time: 139.56 s 
2025-12-07 21:58:57.676754: Yayy! New best EMA pseudo Dice: 0.9343 
2025-12-07 21:58:58.561255:  
2025-12-07 21:58:58.561255: Epoch 257 
2025-12-07 21:58:58.561255: Current learning rate: 0.00765 
2025-12-07 22:01:17.124300: train_loss -0.8242 
2025-12-07 22:01:17.126112: val_loss -0.8474 
2025-12-07 22:01:17.128115: Pseudo dice [0.9088, 0.948, 0.9426] 
2025-12-07 22:01:17.128115: Epoch time: 138.56 s 
2025-12-07 22:01:17.761024:  
2025-12-07 22:01:17.761024: Epoch 258 
2025-12-07 22:01:17.762027: Current learning rate: 0.00764 
2025-12-07 22:03:36.327931: train_loss -0.8316 
2025-12-07 22:03:36.327931: val_loss -0.856 
2025-12-07 22:03:36.327931: Pseudo dice [0.915, 0.947, 0.9394] 
2025-12-07 22:03:36.327931: Epoch time: 138.58 s 
2025-12-07 22:03:37.043583:  
2025-12-07 22:03:37.043583: Epoch 259 
2025-12-07 22:03:37.045591: Current learning rate: 0.00764 
2025-12-07 22:05:55.436077: train_loss -0.8351 
2025-12-07 22:05:55.436077: val_loss -0.8547 
2025-12-07 22:05:55.436077: Pseudo dice [0.9109, 0.9485, 0.9398] 
2025-12-07 22:05:55.436077: Epoch time: 138.39 s 
2025-12-07 22:05:56.083239:  
2025-12-07 22:05:56.083239: Epoch 260 
2025-12-07 22:05:56.086251: Current learning rate: 0.00763 
2025-12-07 22:08:14.575604: train_loss -0.8283 
2025-12-07 22:08:14.577606: val_loss -0.8558 
2025-12-07 22:08:14.580910: Pseudo dice [0.9217, 0.9509, 0.9339] 
2025-12-07 22:08:14.582910: Epoch time: 138.49 s 
2025-12-07 22:08:15.226619:  
2025-12-07 22:08:15.226619: Epoch 261 
2025-12-07 22:08:15.229722: Current learning rate: 0.00762 
2025-12-07 22:10:33.435554: train_loss -0.8382 
2025-12-07 22:10:33.437295: val_loss -0.8504 
2025-12-07 22:10:33.441546: Pseudo dice [0.9148, 0.9483, 0.9308] 
2025-12-07 22:10:33.444547: Epoch time: 138.21 s 
2025-12-07 22:10:34.298403:  
2025-12-07 22:10:34.298403: Epoch 262 
2025-12-07 22:10:34.298403: Current learning rate: 0.00761 
2025-12-07 22:12:52.277247: train_loss -0.8311 
2025-12-07 22:12:52.277247: val_loss -0.8636 
2025-12-07 22:12:52.281252: Pseudo dice [0.9198, 0.9548, 0.9429] 
2025-12-07 22:12:52.285256: Epoch time: 137.98 s 
2025-12-07 22:12:52.287258: Yayy! New best EMA pseudo Dice: 0.9344 
2025-12-07 22:12:53.187024:  
2025-12-07 22:12:53.187024: Epoch 263 
2025-12-07 22:12:53.190109: Current learning rate: 0.0076 
2025-12-07 22:15:11.218149: train_loss -0.831 
2025-12-07 22:15:11.218149: val_loss -0.86 
2025-12-07 22:15:11.233134: Pseudo dice [0.9179, 0.9498, 0.9436] 
2025-12-07 22:15:11.234136: Epoch time: 138.03 s 
2025-12-07 22:15:11.238141: Yayy! New best EMA pseudo Dice: 0.9347 
2025-12-07 22:15:12.124793:  
2025-12-07 22:15:12.124793: Epoch 264 
2025-12-07 22:15:12.124793: Current learning rate: 0.00759 
2025-12-07 22:17:30.340743: train_loss -0.8348 
2025-12-07 22:17:30.340743: val_loss -0.86 
2025-12-07 22:17:30.342484: Pseudo dice [0.9157, 0.9523, 0.9416] 
2025-12-07 22:17:30.347994: Epoch time: 138.22 s 
2025-12-07 22:17:30.349996: Yayy! New best EMA pseudo Dice: 0.9349 
2025-12-07 22:17:31.298331:  
2025-12-07 22:17:31.299333: Epoch 265 
2025-12-07 22:17:31.301639: Current learning rate: 0.00758 
2025-12-07 22:19:49.372313: train_loss -0.8284 
2025-12-07 22:19:49.372313: val_loss -0.8534 
2025-12-07 22:19:49.374053: Pseudo dice [0.9147, 0.945, 0.9351] 
2025-12-07 22:19:49.379553: Epoch time: 138.08 s 
2025-12-07 22:19:50.022130:  
2025-12-07 22:19:50.023871: Epoch 266 
2025-12-07 22:19:50.023871: Current learning rate: 0.00757 
2025-12-07 22:22:08.108613: train_loss -0.8332 
2025-12-07 22:22:08.108613: val_loss -0.8654 
2025-12-07 22:22:08.108613: Pseudo dice [0.9203, 0.9525, 0.9378] 
2025-12-07 22:22:08.124251: Epoch time: 138.09 s 
2025-12-07 22:22:08.758091:  
2025-12-07 22:22:08.760094: Epoch 267 
2025-12-07 22:22:08.760094: Current learning rate: 0.00756 
2025-12-07 22:24:26.763957: train_loss -0.828 
2025-12-07 22:24:26.765960: val_loss -0.8594 
2025-12-07 22:24:26.769966: Pseudo dice [0.9202, 0.95, 0.9408] 
2025-12-07 22:24:26.773970: Epoch time: 138.01 s 
2025-12-07 22:24:26.775710: Yayy! New best EMA pseudo Dice: 0.935 
2025-12-07 22:24:27.892126:  
2025-12-07 22:24:27.892126: Epoch 268 
2025-12-07 22:24:27.895138: Current learning rate: 0.00755 
2025-12-07 22:26:45.950401: train_loss -0.831 
2025-12-07 22:26:45.950401: val_loss -0.8697 
2025-12-07 22:26:45.952403: Pseudo dice [0.9244, 0.9561, 0.9409] 
2025-12-07 22:26:45.952403: Epoch time: 138.06 s 
2025-12-07 22:26:45.959905: Yayy! New best EMA pseudo Dice: 0.9356 
2025-12-07 22:26:46.889719:  
2025-12-07 22:26:46.889719: Epoch 269 
2025-12-07 22:26:46.905557: Current learning rate: 0.00754 
2025-12-07 22:29:04.827124: train_loss -0.8334 
2025-12-07 22:29:04.827124: val_loss -0.8494 
2025-12-07 22:29:04.834346: Pseudo dice [0.91, 0.9448, 0.9418] 
2025-12-07 22:29:04.836348: Epoch time: 137.94 s 
2025-12-07 22:29:05.467885:  
2025-12-07 22:29:05.467885: Epoch 270 
2025-12-07 22:29:05.478964: Current learning rate: 0.00753 
2025-12-07 22:31:23.547784: train_loss -0.8289 
2025-12-07 22:31:23.547784: val_loss -0.8627 
2025-12-07 22:31:23.565903: Pseudo dice [0.9171, 0.9534, 0.9406] 
2025-12-07 22:31:23.568177: Epoch time: 138.08 s 
2025-12-07 22:31:24.271743:  
2025-12-07 22:31:24.272745: Epoch 271 
2025-12-07 22:31:24.275752: Current learning rate: 0.00752 
2025-12-07 22:33:42.220912: train_loss -0.8294 
2025-12-07 22:33:42.220912: val_loss -0.8453 
2025-12-07 22:33:42.227914: Pseudo dice [0.9106, 0.9449, 0.929] 
2025-12-07 22:33:42.231915: Epoch time: 137.95 s 
2025-12-07 22:33:42.869613:  
2025-12-07 22:33:42.869613: Epoch 272 
2025-12-07 22:33:42.872625: Current learning rate: 0.00751 
2025-12-07 22:36:00.936425: train_loss -0.8321 
2025-12-07 22:36:00.936425: val_loss -0.8582 
2025-12-07 22:36:00.940253: Pseudo dice [0.9156, 0.9509, 0.9411] 
2025-12-07 22:36:00.942255: Epoch time: 138.07 s 
2025-12-07 22:36:01.584116:  
2025-12-07 22:36:01.584116: Epoch 273 
2025-12-07 22:36:01.584116: Current learning rate: 0.00751 
2025-12-07 22:38:19.890408: train_loss -0.8368 
2025-12-07 22:38:19.892410: val_loss -0.8643 
2025-12-07 22:38:19.894412: Pseudo dice [0.9183, 0.9543, 0.9437] 
2025-12-07 22:38:19.896414: Epoch time: 138.31 s 
2025-12-07 22:38:20.858843:  
2025-12-07 22:38:20.858843: Epoch 274 
2025-12-07 22:38:20.874658: Current learning rate: 0.0075 
2025-12-07 22:40:38.846540: train_loss -0.8326 
2025-12-07 22:40:38.846540: val_loss -0.8559 
2025-12-07 22:40:38.850545: Pseudo dice [0.9172, 0.9488, 0.9393] 
2025-12-07 22:40:38.852547: Epoch time: 137.99 s 
2025-12-07 22:40:39.485692:  
2025-12-07 22:40:39.485692: Epoch 275 
2025-12-07 22:40:39.485692: Current learning rate: 0.00749 
2025-12-07 22:42:57.607576: train_loss -0.8336 
2025-12-07 22:42:57.607576: val_loss -0.8494 
2025-12-07 22:42:57.610728: Pseudo dice [0.9128, 0.9499, 0.9327] 
2025-12-07 22:42:57.610728: Epoch time: 138.12 s 
2025-12-07 22:42:58.259645:  
2025-12-07 22:42:58.259645: Epoch 276 
2025-12-07 22:42:58.259645: Current learning rate: 0.00748 
2025-12-07 22:45:16.326764: train_loss -0.8303 
2025-12-07 22:45:16.326764: val_loss -0.8492 
2025-12-07 22:45:16.330818: Pseudo dice [0.9085, 0.9477, 0.9375] 
2025-12-07 22:45:16.332820: Epoch time: 138.07 s 
2025-12-07 22:45:17.086702:  
2025-12-07 22:45:17.087704: Epoch 277 
2025-12-07 22:45:17.090713: Current learning rate: 0.00747 
2025-12-07 22:47:35.171386: train_loss -0.8287 
2025-12-07 22:47:35.171386: val_loss -0.8554 
2025-12-07 22:47:35.171386: Pseudo dice [0.917, 0.9456, 0.9389] 
2025-12-07 22:47:35.171386: Epoch time: 138.09 s 
2025-12-07 22:47:35.810192:  
2025-12-07 22:47:35.810192: Epoch 278 
2025-12-07 22:47:35.810192: Current learning rate: 0.00746 
2025-12-07 22:49:53.717565: train_loss -0.8351 
2025-12-07 22:49:53.717565: val_loss -0.853 
2025-12-07 22:49:53.717565: Pseudo dice [0.9133, 0.944, 0.9385] 
2025-12-07 22:49:53.717565: Epoch time: 137.91 s 
2025-12-07 22:49:54.345709:  
2025-12-07 22:49:54.346714: Epoch 279 
2025-12-07 22:49:54.349069: Current learning rate: 0.00745 
2025-12-07 22:52:12.326843: train_loss -0.8296 
2025-12-07 22:52:12.326843: val_loss -0.857 
2025-12-07 22:52:12.331196: Pseudo dice [0.9143, 0.9534, 0.9365] 
2025-12-07 22:52:12.331196: Epoch time: 137.98 s 
2025-12-07 22:52:13.076559:  
2025-12-07 22:52:13.076559: Epoch 280 
2025-12-07 22:52:13.092209: Current learning rate: 0.00744 
2025-12-07 22:54:31.216544: train_loss -0.8194 
2025-12-07 22:54:31.217548: val_loss -0.8273 
2025-12-07 22:54:31.217548: Pseudo dice [0.9017, 0.9382, 0.9275] 
2025-12-07 22:54:31.217548: Epoch time: 138.14 s 
2025-12-07 22:54:32.024543:  
2025-12-07 22:54:32.024543: Epoch 281 
2025-12-07 22:54:32.024543: Current learning rate: 0.00743 
2025-12-07 22:56:50.005874: train_loss -0.7999 
2025-12-07 22:56:50.005874: val_loss -0.821 
2025-12-07 22:56:50.009616: Pseudo dice [0.8964, 0.9362, 0.9307] 
2025-12-07 22:56:50.013621: Epoch time: 137.98 s 
2025-12-07 22:56:50.655148:  
2025-12-07 22:56:50.655148: Epoch 282 
2025-12-07 22:56:50.655148: Current learning rate: 0.00742 
2025-12-07 22:59:08.811145: train_loss -0.8116 
2025-12-07 22:59:08.811145: val_loss -0.8453 
2025-12-07 22:59:08.815166: Pseudo dice [0.9179, 0.9498, 0.9184] 
2025-12-07 22:59:08.819172: Epoch time: 138.16 s 
2025-12-07 22:59:09.467377:  
2025-12-07 22:59:09.467377: Epoch 283 
2025-12-07 22:59:09.483089: Current learning rate: 0.00741 
2025-12-07 23:01:27.449691: train_loss -0.7979 
2025-12-07 23:01:27.449691: val_loss -0.8431 
2025-12-07 23:01:27.453728: Pseudo dice [0.9139, 0.9472, 0.9318] 
2025-12-07 23:01:27.456089: Epoch time: 137.98 s 
2025-12-07 23:01:28.077409:  
2025-12-07 23:01:28.077409: Epoch 284 
2025-12-07 23:01:28.088246: Current learning rate: 0.0074 
2025-12-07 23:03:46.029778: train_loss -0.8125 
2025-12-07 23:03:46.031811: val_loss -0.8368 
2025-12-07 23:03:46.037825: Pseudo dice [0.9048, 0.9467, 0.9344] 
2025-12-07 23:03:46.039828: Epoch time: 137.95 s 
2025-12-07 23:03:46.710685:  
2025-12-07 23:03:46.710685: Epoch 285 
2025-12-07 23:03:46.710685: Current learning rate: 0.00739 
2025-12-07 23:06:04.741943: train_loss -0.7908 
2025-12-07 23:06:04.741943: val_loss -0.8135 
2025-12-07 23:06:04.745947: Pseudo dice [0.8932, 0.9365, 0.9235] 
2025-12-07 23:06:04.747948: Epoch time: 138.03 s 
2025-12-07 23:06:05.386195:  
2025-12-07 23:06:05.386195: Epoch 286 
2025-12-07 23:06:05.390004: Current learning rate: 0.00738 
2025-12-07 23:08:23.308720: train_loss -0.8036 
2025-12-07 23:08:23.308720: val_loss -0.8378 
2025-12-07 23:08:23.312462: Pseudo dice [0.9066, 0.9452, 0.9297] 
2025-12-07 23:08:23.315462: Epoch time: 137.92 s 
2025-12-07 23:08:24.122929:  
2025-12-07 23:08:24.123934: Epoch 287 
2025-12-07 23:08:24.127041: Current learning rate: 0.00738 
2025-12-07 23:10:42.148884: train_loss -0.8064 
2025-12-07 23:10:42.150887: val_loss -0.8391 
2025-12-07 23:10:42.152889: Pseudo dice [0.9063, 0.9414, 0.9304] 
2025-12-07 23:10:42.154891: Epoch time: 138.03 s 
2025-12-07 23:10:42.805406:  
2025-12-07 23:10:42.805406: Epoch 288 
2025-12-07 23:10:42.805406: Current learning rate: 0.00737 
2025-12-07 23:13:00.671267: train_loss -0.822 
2025-12-07 23:13:00.671267: val_loss -0.8407 
2025-12-07 23:13:00.687845: Pseudo dice [0.9054, 0.9432, 0.9372] 
2025-12-07 23:13:00.690884: Epoch time: 137.87 s 
2025-12-07 23:13:01.312269:  
2025-12-07 23:13:01.312269: Epoch 289 
2025-12-07 23:13:01.328250: Current learning rate: 0.00736 
2025-12-07 23:15:19.280317: train_loss -0.8263 
2025-12-07 23:15:19.280317: val_loss -0.8572 
2025-12-07 23:15:19.280317: Pseudo dice [0.9187, 0.9522, 0.9345] 
2025-12-07 23:15:19.289331: Epoch time: 137.97 s 
2025-12-07 23:15:19.920658:  
2025-12-07 23:15:19.920658: Epoch 290 
2025-12-07 23:15:19.920658: Current learning rate: 0.00735 
2025-12-07 23:17:37.874197: train_loss -0.8236 
2025-12-07 23:17:37.890186: val_loss -0.8547 
2025-12-07 23:17:37.890186: Pseudo dice [0.9185, 0.9516, 0.9294] 
2025-12-07 23:17:37.890186: Epoch time: 137.95 s 
2025-12-07 23:17:38.514464:  
2025-12-07 23:17:38.514464: Epoch 291 
2025-12-07 23:17:38.514464: Current learning rate: 0.00734 
2025-12-07 23:19:56.467934: train_loss -0.8308 
2025-12-07 23:19:56.467934: val_loss -0.8706 
2025-12-07 23:19:56.483610: Pseudo dice [0.9255, 0.955, 0.9424] 
2025-12-07 23:19:56.483610: Epoch time: 137.95 s 
2025-12-07 23:19:57.107977:  
2025-12-07 23:19:57.107977: Epoch 292 
2025-12-07 23:19:57.107977: Current learning rate: 0.00733 
2025-12-07 23:22:15.014388: train_loss -0.8315 
2025-12-07 23:22:15.014388: val_loss -0.8504 
2025-12-07 23:22:15.014388: Pseudo dice [0.912, 0.9476, 0.9364] 
2025-12-07 23:22:15.014388: Epoch time: 137.91 s 
2025-12-07 23:22:15.827208:  
2025-12-07 23:22:15.827208: Epoch 293 
2025-12-07 23:22:15.838271: Current learning rate: 0.00732 
2025-12-07 23:24:33.743375: train_loss -0.8335 
2025-12-07 23:24:33.743375: val_loss -0.8525 
2025-12-07 23:24:33.749382: Pseudo dice [0.913, 0.9529, 0.939] 
2025-12-07 23:24:33.751097: Epoch time: 137.92 s 
2025-12-07 23:24:34.503320:  
2025-12-07 23:24:34.503320: Epoch 294 
2025-12-07 23:24:34.503320: Current learning rate: 0.00731 
2025-12-07 23:26:52.497139: train_loss -0.8301 
2025-12-07 23:26:52.497139: val_loss -0.8635 
2025-12-07 23:26:52.501012: Pseudo dice [0.922, 0.9537, 0.9401] 
2025-12-07 23:26:52.504754: Epoch time: 138.0 s 
2025-12-07 23:26:53.140279:  
2025-12-07 23:26:53.140279: Epoch 295 
2025-12-07 23:26:53.151899: Current learning rate: 0.0073 
2025-12-07 23:29:11.140428: train_loss -0.8316 
2025-12-07 23:29:11.140428: val_loss -0.8479 
2025-12-07 23:29:11.140428: Pseudo dice [0.9073, 0.945, 0.9451] 
2025-12-07 23:29:11.155829: Epoch time: 138.0 s 
2025-12-07 23:29:11.795320:  
2025-12-07 23:29:11.795320: Epoch 296 
2025-12-07 23:29:11.795320: Current learning rate: 0.00729 
2025-12-07 23:31:29.940754: train_loss -0.8346 
2025-12-07 23:31:29.941757: val_loss -0.8632 
2025-12-07 23:31:29.944775: Pseudo dice [0.9189, 0.9516, 0.9378] 
2025-12-07 23:31:29.946787: Epoch time: 138.15 s 
2025-12-07 23:31:30.687677:  
2025-12-07 23:31:30.687677: Epoch 297 
2025-12-07 23:31:30.687677: Current learning rate: 0.00728 
2025-12-07 23:33:49.086060: train_loss -0.8342 
2025-12-07 23:33:49.087062: val_loss -0.8636 
2025-12-07 23:33:49.091071: Pseudo dice [0.918, 0.9513, 0.9409] 
2025-12-07 23:33:49.093225: Epoch time: 138.4 s 
2025-12-07 23:33:49.728059:  
2025-12-07 23:33:49.728059: Epoch 298 
2025-12-07 23:33:49.744141: Current learning rate: 0.00727 
2025-12-07 23:36:08.140214: train_loss -0.8339 
2025-12-07 23:36:08.140214: val_loss -0.8646 
2025-12-07 23:36:08.140214: Pseudo dice [0.9159, 0.9496, 0.9452] 
2025-12-07 23:36:08.140214: Epoch time: 138.41 s 
2025-12-07 23:36:08.775344:  
2025-12-07 23:36:08.791089: Epoch 299 
2025-12-07 23:36:08.791089: Current learning rate: 0.00726 
2025-12-07 23:38:27.121349: train_loss -0.8343 
2025-12-07 23:38:27.123352: val_loss -0.8627 
2025-12-07 23:38:27.126856: Pseudo dice [0.919, 0.9496, 0.941] 
2025-12-07 23:38:27.128858: Epoch time: 138.35 s 
2025-12-07 23:38:28.327419:  
2025-12-07 23:38:28.327419: Epoch 300 
2025-12-07 23:38:28.343538: Current learning rate: 0.00725 
2025-12-07 23:40:46.722750: train_loss -0.8356 
2025-12-07 23:40:46.726755: val_loss -0.8571 
2025-12-07 23:40:46.731763: Pseudo dice [0.9096, 0.9502, 0.9478] 
2025-12-07 23:40:46.735768: Epoch time: 138.4 s 
2025-12-07 23:40:47.406730:  
2025-12-07 23:40:47.406730: Epoch 301 
2025-12-07 23:40:47.406730: Current learning rate: 0.00724 
2025-12-07 23:43:05.609263: train_loss -0.8345 
2025-12-07 23:43:05.609263: val_loss -0.8481 
2025-12-07 23:43:05.624980: Pseudo dice [0.9071, 0.9469, 0.9434] 
2025-12-07 23:43:05.626984: Epoch time: 138.2 s 
2025-12-07 23:43:06.265054:  
2025-12-07 23:43:06.265054: Epoch 302 
2025-12-07 23:43:06.265054: Current learning rate: 0.00724 
2025-12-07 23:45:24.298235: train_loss -0.832 
2025-12-07 23:45:24.298235: val_loss -0.8744 
2025-12-07 23:45:24.302242: Pseudo dice [0.9302, 0.9586, 0.9383] 
2025-12-07 23:45:24.304245: Epoch time: 138.03 s 
2025-12-07 23:45:24.998133:  
2025-12-07 23:45:24.998133: Epoch 303 
2025-12-07 23:45:24.998133: Current learning rate: 0.00723 
2025-12-07 23:47:43.064955: train_loss -0.8346 
2025-12-07 23:47:43.064955: val_loss -0.8548 
2025-12-07 23:47:43.068966: Pseudo dice [0.9112, 0.9494, 0.9437] 
2025-12-07 23:47:43.070993: Epoch time: 138.07 s 
2025-12-07 23:47:43.712336:  
2025-12-07 23:47:43.713340: Epoch 304 
2025-12-07 23:47:43.713340: Current learning rate: 0.00722 
2025-12-07 23:50:01.772634: train_loss -0.8341 
2025-12-07 23:50:01.772634: val_loss -0.8737 
2025-12-07 23:50:01.778641: Pseudo dice [0.9283, 0.9579, 0.9399] 
2025-12-07 23:50:01.780382: Epoch time: 138.07 s 
2025-12-07 23:50:02.422159:  
2025-12-07 23:50:02.422159: Epoch 305 
2025-12-07 23:50:02.422159: Current learning rate: 0.00721 
2025-12-07 23:52:20.515662: train_loss -0.8364 
2025-12-07 23:52:20.515662: val_loss -0.8719 
2025-12-07 23:52:20.515662: Pseudo dice [0.9265, 0.9583, 0.9424] 
2025-12-07 23:52:20.515662: Epoch time: 138.11 s 
2025-12-07 23:52:20.515662: Yayy! New best EMA pseudo Dice: 0.9361 
2025-12-07 23:52:21.790479:  
2025-12-07 23:52:21.790479: Epoch 306 
2025-12-07 23:52:21.794497: Current learning rate: 0.0072 
2025-12-07 23:54:39.765142: train_loss -0.8362 
2025-12-07 23:54:39.781145: val_loss -0.8619 
2025-12-07 23:54:39.784337: Pseudo dice [0.9201, 0.9503, 0.9313] 
2025-12-07 23:54:39.787501: Epoch time: 137.98 s 
2025-12-07 23:54:40.432220:  
2025-12-07 23:54:40.432220: Epoch 307 
2025-12-07 23:54:40.435117: Current learning rate: 0.00719 
2025-12-07 23:56:58.405448: train_loss -0.8356 
2025-12-07 23:56:58.407451: val_loss -0.8661 
2025-12-07 23:56:58.409453: Pseudo dice [0.9197, 0.9477, 0.9462] 
2025-12-07 23:56:58.412003: Epoch time: 137.97 s 
2025-12-07 23:56:59.045540:  
2025-12-07 23:56:59.045540: Epoch 308 
2025-12-07 23:56:59.045540: Current learning rate: 0.00718 
2025-12-07 23:59:17.092239: train_loss -0.8374 
2025-12-07 23:59:17.092239: val_loss -0.859 
2025-12-07 23:59:17.092239: Pseudo dice [0.9183, 0.9487, 0.9375] 
2025-12-07 23:59:17.092239: Epoch time: 138.05 s 
2025-12-07 23:59:17.830390:  
2025-12-07 23:59:17.830390: Epoch 309 
2025-12-07 23:59:17.832393: Current learning rate: 0.00717 
2025-12-08 00:01:35.780961: train_loss -0.8362 
2025-12-08 00:01:35.780961: val_loss -0.858 
2025-12-08 00:01:35.780961: Pseudo dice [0.9163, 0.9501, 0.9401] 
2025-12-08 00:01:35.780961: Epoch time: 137.95 s 
2025-12-08 00:01:36.422058:  
2025-12-08 00:01:36.422058: Epoch 310 
2025-12-08 00:01:36.437803: Current learning rate: 0.00716 
2025-12-08 00:03:54.439849: train_loss -0.8386 
2025-12-08 00:03:54.439849: val_loss -0.8592 
2025-12-08 00:03:54.445861: Pseudo dice [0.9155, 0.9502, 0.9394] 
2025-12-08 00:03:54.449874: Epoch time: 138.02 s 
2025-12-08 00:03:55.252268:  
2025-12-08 00:03:55.253270: Epoch 311 
2025-12-08 00:03:55.256277: Current learning rate: 0.00715 
2025-12-08 00:06:13.127785: train_loss -0.8401 
2025-12-08 00:06:13.128788: val_loss -0.8644 
2025-12-08 00:06:13.131797: Pseudo dice [0.92, 0.956, 0.9395] 
2025-12-08 00:06:13.133798: Epoch time: 137.88 s 
2025-12-08 00:06:13.843223:  
2025-12-08 00:06:13.843223: Epoch 312 
2025-12-08 00:06:13.856093: Current learning rate: 0.00714 
2025-12-08 00:08:32.048893: train_loss -0.8357 
2025-12-08 00:08:32.049895: val_loss -0.8647 
2025-12-08 00:08:32.052901: Pseudo dice [0.921, 0.9542, 0.9366] 
2025-12-08 00:08:32.055914: Epoch time: 138.21 s 
2025-12-08 00:08:32.057919: Yayy! New best EMA pseudo Dice: 0.9362 
2025-12-08 00:08:32.952033:  
2025-12-08 00:08:32.952033: Epoch 313 
2025-12-08 00:08:32.952033: Current learning rate: 0.00713 
2025-12-08 00:10:50.890639: train_loss -0.8333 
2025-12-08 00:10:50.890639: val_loss -0.8605 
2025-12-08 00:10:50.905008: Pseudo dice [0.9164, 0.9481, 0.9416] 
2025-12-08 00:10:50.906748: Epoch time: 137.94 s 
2025-12-08 00:10:51.586398:  
2025-12-08 00:10:51.586398: Epoch 314 
2025-12-08 00:10:51.590629: Current learning rate: 0.00712 
2025-12-08 00:13:09.561850: train_loss -0.838 
2025-12-08 00:13:09.561850: val_loss -0.87 
2025-12-08 00:13:09.577534: Pseudo dice [0.9191, 0.9573, 0.941] 
2025-12-08 00:13:09.579538: Epoch time: 137.98 s 
2025-12-08 00:13:09.581540: Yayy! New best EMA pseudo Dice: 0.9364 
2025-12-08 00:13:10.619074:  
2025-12-08 00:13:10.619074: Epoch 315 
2025-12-08 00:13:10.623226: Current learning rate: 0.00711 
2025-12-08 00:15:28.621215: train_loss -0.8367 
2025-12-08 00:15:28.621215: val_loss -0.8613 
2025-12-08 00:15:28.626116: Pseudo dice [0.916, 0.9518, 0.9412] 
2025-12-08 00:15:28.629124: Epoch time: 138.0 s 
2025-12-08 00:15:29.263845:  
2025-12-08 00:15:29.263845: Epoch 316 
2025-12-08 00:15:29.279652: Current learning rate: 0.0071 
2025-12-08 00:17:47.399035: train_loss -0.8347 
2025-12-08 00:17:47.400036: val_loss -0.8572 
2025-12-08 00:17:47.403522: Pseudo dice [0.9126, 0.9486, 0.9409] 
2025-12-08 00:17:47.406523: Epoch time: 138.14 s 
2025-12-08 00:17:48.217999:  
2025-12-08 00:17:48.217999: Epoch 317 
2025-12-08 00:17:48.217999: Current learning rate: 0.0071 
2025-12-08 00:20:06.287145: train_loss -0.8373 
2025-12-08 00:20:06.289148: val_loss -0.8614 
2025-12-08 00:20:06.295159: Pseudo dice [0.9197, 0.9511, 0.9445] 
2025-12-08 00:20:06.297162: Epoch time: 138.07 s 
2025-12-08 00:20:06.983799:  
2025-12-08 00:20:06.983799: Epoch 318 
2025-12-08 00:20:06.994499: Current learning rate: 0.00709 
2025-12-08 00:22:25.061189: train_loss -0.8318 
2025-12-08 00:22:25.061189: val_loss -0.8417 
2025-12-08 00:22:25.061189: Pseudo dice [0.9085, 0.9388, 0.9351] 
2025-12-08 00:22:25.061189: Epoch time: 138.08 s 
2025-12-08 00:22:25.718481:  
2025-12-08 00:22:25.718481: Epoch 319 
2025-12-08 00:22:25.718481: Current learning rate: 0.00708 
2025-12-08 00:24:43.704688: train_loss -0.8333 
2025-12-08 00:24:43.704688: val_loss -0.8489 
2025-12-08 00:24:43.722122: Pseudo dice [0.916, 0.9487, 0.9296] 
2025-12-08 00:24:43.724128: Epoch time: 138.0 s 
2025-12-08 00:24:44.358932:  
2025-12-08 00:24:44.358932: Epoch 320 
2025-12-08 00:24:44.358932: Current learning rate: 0.00707 
2025-12-08 00:27:03.726955: train_loss -0.8356 
2025-12-08 00:27:03.726955: val_loss -0.8494 
2025-12-08 00:27:03.726955: Pseudo dice [0.9102, 0.9473, 0.9368] 
2025-12-08 00:27:03.726955: Epoch time: 139.37 s 
2025-12-08 00:27:04.498457:  
2025-12-08 00:27:04.498457: Epoch 321 
2025-12-08 00:27:04.498457: Current learning rate: 0.00706 
2025-12-08 00:29:22.833615: train_loss -0.8397 
2025-12-08 00:29:22.833615: val_loss -0.8613 
2025-12-08 00:29:22.837620: Pseudo dice [0.9178, 0.9528, 0.9403] 
2025-12-08 00:29:22.839621: Epoch time: 138.34 s 
2025-12-08 00:29:23.500575:  
2025-12-08 00:29:23.500575: Epoch 322 
2025-12-08 00:29:23.504044: Current learning rate: 0.00705 
2025-12-08 00:31:42.093463: train_loss -0.8394 
2025-12-08 00:31:42.093463: val_loss -0.874 
2025-12-08 00:31:42.093463: Pseudo dice [0.9276, 0.9602, 0.9324] 
2025-12-08 00:31:42.110623: Epoch time: 138.59 s 
2025-12-08 00:31:42.751926:  
2025-12-08 00:31:42.751926: Epoch 323 
2025-12-08 00:31:42.751926: Current learning rate: 0.00704 
2025-12-08 00:34:01.202296: train_loss -0.8385 
2025-12-08 00:34:01.202296: val_loss -0.8637 
2025-12-08 00:34:01.202296: Pseudo dice [0.9195, 0.9504, 0.9429] 
2025-12-08 00:34:01.202296: Epoch time: 138.45 s 
2025-12-08 00:34:02.003758:  
2025-12-08 00:34:02.004763: Epoch 324 
2025-12-08 00:34:02.007787: Current learning rate: 0.00703 
2025-12-08 00:36:20.543963: train_loss -0.8371 
2025-12-08 00:36:20.545966: val_loss -0.8595 
2025-12-08 00:36:20.545966: Pseudo dice [0.9157, 0.9512, 0.942] 
2025-12-08 00:36:20.545966: Epoch time: 138.54 s 
2025-12-08 00:36:21.186123:  
2025-12-08 00:36:21.186123: Epoch 325 
2025-12-08 00:36:21.186123: Current learning rate: 0.00702 
2025-12-08 00:38:39.265363: train_loss -0.8381 
2025-12-08 00:38:39.266566: val_loss -0.8671 
2025-12-08 00:38:39.272568: Pseudo dice [0.921, 0.9508, 0.9439] 
2025-12-08 00:38:39.275568: Epoch time: 138.08 s 
2025-12-08 00:38:39.925719:  
2025-12-08 00:38:39.925719: Epoch 326 
2025-12-08 00:38:39.925719: Current learning rate: 0.00701 
2025-12-08 00:40:58.031832: train_loss -0.8404 
2025-12-08 00:40:58.031832: val_loss -0.8662 
2025-12-08 00:40:58.035837: Pseudo dice [0.9192, 0.9491, 0.9433] 
2025-12-08 00:40:58.039842: Epoch time: 138.11 s 
2025-12-08 00:40:58.811100:  
2025-12-08 00:40:58.811100: Epoch 327 
2025-12-08 00:40:58.811100: Current learning rate: 0.007 
2025-12-08 00:43:16.749996: train_loss -0.8433 
2025-12-08 00:43:16.749996: val_loss -0.8638 
2025-12-08 00:43:16.754000: Pseudo dice [0.9191, 0.9468, 0.9456] 
2025-12-08 00:43:16.758004: Epoch time: 137.95 s 
2025-12-08 00:43:17.413989:  
2025-12-08 00:43:17.413989: Epoch 328 
2025-12-08 00:43:17.413989: Current learning rate: 0.00699 
2025-12-08 00:45:35.344790: train_loss -0.8344 
2025-12-08 00:45:35.346792: val_loss -0.8561 
2025-12-08 00:45:35.350796: Pseudo dice [0.9144, 0.9511, 0.9426] 
2025-12-08 00:45:35.352798: Epoch time: 137.93 s 
2025-12-08 00:45:36.154520:  
2025-12-08 00:45:36.154520: Epoch 329 
2025-12-08 00:45:36.154520: Current learning rate: 0.00698 
2025-12-08 00:47:54.211820: train_loss -0.8371 
2025-12-08 00:47:54.213823: val_loss -0.8753 
2025-12-08 00:47:54.217566: Pseudo dice [0.9261, 0.956, 0.9473] 
2025-12-08 00:47:54.217566: Epoch time: 138.06 s 
2025-12-08 00:47:54.223063: Yayy! New best EMA pseudo Dice: 0.9369 
2025-12-08 00:47:55.242570:  
2025-12-08 00:47:55.242570: Epoch 330 
2025-12-08 00:47:55.246795: Current learning rate: 0.00697 
2025-12-08 00:50:13.170966: train_loss -0.8371 
2025-12-08 00:50:13.170966: val_loss -0.8652 
2025-12-08 00:50:13.176441: Pseudo dice [0.9231, 0.9542, 0.9376] 
2025-12-08 00:50:13.178443: Epoch time: 137.93 s 
2025-12-08 00:50:13.182447: Yayy! New best EMA pseudo Dice: 0.9371 
2025-12-08 00:50:14.093762:  
2025-12-08 00:50:14.093762: Epoch 331 
2025-12-08 00:50:14.093762: Current learning rate: 0.00696 
2025-12-08 00:52:32.236237: train_loss -0.8348 
2025-12-08 00:52:32.237237: val_loss -0.8538 
2025-12-08 00:52:32.241239: Pseudo dice [0.9123, 0.9469, 0.9399] 
2025-12-08 00:52:32.243239: Epoch time: 138.14 s 
2025-12-08 00:52:32.874624:  
2025-12-08 00:52:32.874624: Epoch 332 
2025-12-08 00:52:32.874624: Current learning rate: 0.00696 
2025-12-08 00:54:51.070688: train_loss -0.8361 
2025-12-08 00:54:51.070688: val_loss -0.8587 
2025-12-08 00:54:51.076432: Pseudo dice [0.9177, 0.9523, 0.9439] 
2025-12-08 00:54:51.080440: Epoch time: 138.2 s 
2025-12-08 00:54:51.827390:  
2025-12-08 00:54:51.827390: Epoch 333 
2025-12-08 00:54:51.827390: Current learning rate: 0.00695 
2025-12-08 00:57:10.046482: train_loss -0.8443 
2025-12-08 00:57:10.046482: val_loss -0.8656 
2025-12-08 00:57:10.062560: Pseudo dice [0.9211, 0.9543, 0.9408] 
2025-12-08 00:57:10.062560: Epoch time: 138.22 s 
2025-12-08 00:57:10.703147:  
2025-12-08 00:57:10.703147: Epoch 334 
2025-12-08 00:57:10.705663: Current learning rate: 0.00694 
2025-12-08 00:59:28.825096: train_loss -0.8399 
2025-12-08 00:59:28.825096: val_loss -0.8616 
2025-12-08 00:59:28.829157: Pseudo dice [0.9123, 0.948, 0.9473] 
2025-12-08 00:59:28.832157: Epoch time: 138.12 s 
2025-12-08 00:59:29.639856:  
2025-12-08 00:59:29.639856: Epoch 335 
2025-12-08 00:59:29.655511: Current learning rate: 0.00693 
2025-12-08 01:01:47.720448: train_loss -0.8444 
2025-12-08 01:01:47.720448: val_loss -0.8728 
2025-12-08 01:01:47.724528: Pseudo dice [0.9268, 0.9564, 0.9423] 
2025-12-08 01:01:47.727539: Epoch time: 138.08 s 
2025-12-08 01:01:47.729544: Yayy! New best EMA pseudo Dice: 0.9374 
2025-12-08 01:01:48.796588:  
2025-12-08 01:01:48.796588: Epoch 336 
2025-12-08 01:01:48.796588: Current learning rate: 0.00692 
2025-12-08 01:04:06.895915: train_loss -0.8412 
2025-12-08 01:04:06.895915: val_loss -0.8622 
2025-12-08 01:04:06.899920: Pseudo dice [0.9196, 0.9497, 0.9404] 
2025-12-08 01:04:06.901922: Epoch time: 138.1 s 
2025-12-08 01:04:07.555324:  
2025-12-08 01:04:07.555324: Epoch 337 
2025-12-08 01:04:07.559338: Current learning rate: 0.00691 
2025-12-08 01:06:25.592855: train_loss -0.8339 
2025-12-08 01:06:25.592855: val_loss -0.8533 
2025-12-08 01:06:25.592855: Pseudo dice [0.9088, 0.9481, 0.9409] 
2025-12-08 01:06:25.592855: Epoch time: 138.04 s 
2025-12-08 01:06:26.245044:  
2025-12-08 01:06:26.245044: Epoch 338 
2025-12-08 01:06:26.245044: Current learning rate: 0.0069 
2025-12-08 01:08:44.328248: train_loss -0.832 
2025-12-08 01:08:44.343976: val_loss -0.8684 
2025-12-08 01:08:44.343976: Pseudo dice [0.9254, 0.961, 0.9362] 
2025-12-08 01:08:44.343976: Epoch time: 138.08 s 
2025-12-08 01:08:45.040061:  
2025-12-08 01:08:45.041065: Epoch 339 
2025-12-08 01:08:45.044077: Current learning rate: 0.00689 
2025-12-08 01:11:03.092904: train_loss -0.8407 
2025-12-08 01:11:03.092904: val_loss -0.8619 
2025-12-08 01:11:03.098425: Pseudo dice [0.9176, 0.945, 0.9456] 
2025-12-08 01:11:03.100427: Epoch time: 138.05 s 
2025-12-08 01:11:03.748774:  
2025-12-08 01:11:03.748774: Epoch 340 
2025-12-08 01:11:03.748774: Current learning rate: 0.00688 
2025-12-08 01:13:21.807560: train_loss -0.8421 
2025-12-08 01:13:21.807560: val_loss -0.8628 
2025-12-08 01:13:21.811566: Pseudo dice [0.9191, 0.9501, 0.9396] 
2025-12-08 01:13:21.815308: Epoch time: 138.06 s 
2025-12-08 01:13:22.651364:  
2025-12-08 01:13:22.651364: Epoch 341 
2025-12-08 01:13:22.655158: Current learning rate: 0.00687 
2025-12-08 01:15:40.764422: train_loss -0.8392 
2025-12-08 01:15:40.764422: val_loss -0.8556 
2025-12-08 01:15:40.780231: Pseudo dice [0.9124, 0.9458, 0.9458] 
2025-12-08 01:15:40.780231: Epoch time: 138.11 s 
2025-12-08 01:15:41.421033:  
2025-12-08 01:15:41.421033: Epoch 342 
2025-12-08 01:15:41.421033: Current learning rate: 0.00686 
2025-12-08 01:17:59.605619: train_loss -0.7995 
2025-12-08 01:17:59.607621: val_loss -0.7946 
2025-12-08 01:17:59.609636: Pseudo dice [0.8933, 0.9287, 0.9201] 
2025-12-08 01:17:59.612760: Epoch time: 138.18 s 
2025-12-08 01:18:00.250533:  
2025-12-08 01:18:00.250533: Epoch 343 
2025-12-08 01:18:00.250533: Current learning rate: 0.00685 
2025-12-08 01:20:18.326825: train_loss -0.7811 
2025-12-08 01:20:18.326825: val_loss -0.8226 
2025-12-08 01:20:18.331953: Pseudo dice [0.8995, 0.9402, 0.9269] 
2025-12-08 01:20:18.335957: Epoch time: 138.08 s 
2025-12-08 01:20:18.984692:  
2025-12-08 01:20:18.984692: Epoch 344 
2025-12-08 01:20:18.984692: Current learning rate: 0.00684 
2025-12-08 01:22:36.951534: train_loss -0.8034 
2025-12-08 01:22:36.951534: val_loss -0.838 
2025-12-08 01:22:36.951534: Pseudo dice [0.9067, 0.947, 0.9338] 
2025-12-08 01:22:36.958352: Epoch time: 137.97 s 
2025-12-08 01:22:37.650197:  
2025-12-08 01:22:37.650197: Epoch 345 
2025-12-08 01:22:37.653610: Current learning rate: 0.00683 
2025-12-08 01:24:55.852500: train_loss -0.8204 
2025-12-08 01:24:55.852500: val_loss -0.8533 
2025-12-08 01:24:55.858245: Pseudo dice [0.9125, 0.9479, 0.9425] 
2025-12-08 01:24:55.860904: Epoch time: 138.2 s 
2025-12-08 01:24:56.514814:  
2025-12-08 01:24:56.514814: Epoch 346 
2025-12-08 01:24:56.514814: Current learning rate: 0.00682 
2025-12-08 01:27:14.725862: train_loss -0.8247 
2025-12-08 01:27:14.725862: val_loss -0.8462 
2025-12-08 01:27:14.731606: Pseudo dice [0.9152, 0.948, 0.9259] 
2025-12-08 01:27:14.733609: Epoch time: 138.21 s 
2025-12-08 01:27:15.577980:  
2025-12-08 01:27:15.577980: Epoch 347 
2025-12-08 01:27:15.577980: Current learning rate: 0.00681 
2025-12-08 01:29:33.735149: train_loss -0.8248 
2025-12-08 01:29:33.735149: val_loss -0.8482 
2025-12-08 01:29:33.738709: Pseudo dice [0.9112, 0.9427, 0.9371] 
2025-12-08 01:29:33.740711: Epoch time: 138.16 s 
2025-12-08 01:29:34.392215:  
2025-12-08 01:29:34.392215: Epoch 348 
2025-12-08 01:29:34.392215: Current learning rate: 0.0068 
2025-12-08 01:31:52.558987: train_loss -0.8316 
2025-12-08 01:31:52.560989: val_loss -0.8572 
2025-12-08 01:31:52.564088: Pseudo dice [0.9129, 0.948, 0.9471] 
2025-12-08 01:31:52.567147: Epoch time: 138.17 s 
2025-12-08 01:31:53.251940:  
2025-12-08 01:31:53.251940: Epoch 349 
2025-12-08 01:31:53.251940: Current learning rate: 0.0068 
2025-12-08 01:34:11.312023: train_loss -0.8365 
2025-12-08 01:34:11.312023: val_loss -0.8603 
2025-12-08 01:34:11.317610: Pseudo dice [0.9209, 0.9527, 0.9323] 
2025-12-08 01:34:11.319613: Epoch time: 138.06 s 
2025-12-08 01:34:12.230705:  
2025-12-08 01:34:12.230705: Epoch 350 
2025-12-08 01:34:12.232922: Current learning rate: 0.00679 
2025-12-08 01:36:30.561439: train_loss -0.8304 
2025-12-08 01:36:30.561439: val_loss -0.8519 
2025-12-08 01:36:30.577500: Pseudo dice [0.9085, 0.9462, 0.9415] 
2025-12-08 01:36:30.577500: Epoch time: 138.33 s 
2025-12-08 01:36:31.218225:  
2025-12-08 01:36:31.218225: Epoch 351 
2025-12-08 01:36:31.234223: Current learning rate: 0.00678 
2025-12-08 01:38:49.354671: train_loss -0.8347 
2025-12-08 01:38:49.354671: val_loss -0.8685 
2025-12-08 01:38:49.360415: Pseudo dice [0.9259, 0.9539, 0.9387] 
2025-12-08 01:38:49.362975: Epoch time: 138.14 s 
2025-12-08 01:38:50.015067:  
2025-12-08 01:38:50.015067: Epoch 352 
2025-12-08 01:38:50.015067: Current learning rate: 0.00677 
2025-12-08 01:41:08.108850: train_loss -0.8333 
2025-12-08 01:41:08.108850: val_loss -0.8684 
2025-12-08 01:41:08.124717: Pseudo dice [0.9172, 0.9557, 0.9453] 
2025-12-08 01:41:08.124717: Epoch time: 138.09 s 
2025-12-08 01:41:08.945081:  
2025-12-08 01:41:08.945081: Epoch 353 
2025-12-08 01:41:08.945081: Current learning rate: 0.00676 
2025-12-08 01:43:26.968684: train_loss -0.8279 
2025-12-08 01:43:26.968684: val_loss -0.8627 
2025-12-08 01:43:26.968684: Pseudo dice [0.9183, 0.953, 0.935] 
2025-12-08 01:43:26.984771: Epoch time: 138.03 s 
2025-12-08 01:43:27.639426:  
2025-12-08 01:43:27.639426: Epoch 354 
2025-12-08 01:43:27.639426: Current learning rate: 0.00675 
2025-12-08 01:45:45.717525: train_loss -0.8356 
2025-12-08 01:45:45.717525: val_loss -0.8698 
2025-12-08 01:45:45.733621: Pseudo dice [0.9221, 0.9576, 0.946] 
2025-12-08 01:45:45.733621: Epoch time: 138.09 s 
2025-12-08 01:45:46.389168:  
2025-12-08 01:45:46.389168: Epoch 355 
2025-12-08 01:45:46.389168: Current learning rate: 0.00674 
2025-12-08 01:48:04.371220: train_loss -0.8378 
2025-12-08 01:48:04.371220: val_loss -0.8699 
2025-12-08 01:48:04.376262: Pseudo dice [0.9244, 0.9558, 0.9416] 
2025-12-08 01:48:04.379269: Epoch time: 137.98 s 
2025-12-08 01:48:05.165694:  
2025-12-08 01:48:05.165694: Epoch 356 
2025-12-08 01:48:05.169703: Current learning rate: 0.00673 
2025-12-08 01:50:23.312317: train_loss -0.8368 
2025-12-08 01:50:23.312317: val_loss -0.8604 
2025-12-08 01:50:23.312317: Pseudo dice [0.9171, 0.9495, 0.9422] 
2025-12-08 01:50:23.328018: Epoch time: 138.15 s 
2025-12-08 01:50:23.952336:  
2025-12-08 01:50:23.952336: Epoch 357 
2025-12-08 01:50:23.968353: Current learning rate: 0.00672 
2025-12-08 01:52:42.171222: train_loss -0.8397 
2025-12-08 01:52:42.171222: val_loss -0.8647 
2025-12-08 01:52:42.176645: Pseudo dice [0.9231, 0.9532, 0.9369] 
2025-12-08 01:52:42.176645: Epoch time: 138.22 s 
2025-12-08 01:52:42.827331:  
2025-12-08 01:52:42.827331: Epoch 358 
2025-12-08 01:52:42.827331: Current learning rate: 0.00671 
2025-12-08 01:55:01.013851: train_loss -0.8443 
2025-12-08 01:55:01.014851: val_loss -0.8666 
2025-12-08 01:55:01.019182: Pseudo dice [0.9196, 0.954, 0.944] 
2025-12-08 01:55:01.022182: Epoch time: 138.19 s 
2025-12-08 01:55:02.041869:  
2025-12-08 01:55:02.041869: Epoch 359 
2025-12-08 01:55:02.046123: Current learning rate: 0.0067 
2025-12-08 01:57:20.124151: train_loss -0.8382 
2025-12-08 01:57:20.127131: val_loss -0.8574 
2025-12-08 01:57:20.130574: Pseudo dice [0.9165, 0.9488, 0.9435] 
2025-12-08 01:57:20.130574: Epoch time: 138.08 s 
2025-12-08 01:57:20.780443:  
2025-12-08 01:57:20.780443: Epoch 360 
2025-12-08 01:57:20.780443: Current learning rate: 0.00669 
2025-12-08 01:59:38.846765: train_loss -0.8385 
2025-12-08 01:59:38.847765: val_loss -0.8686 
2025-12-08 01:59:38.851766: Pseudo dice [0.9226, 0.9551, 0.9394] 
2025-12-08 01:59:38.854766: Epoch time: 138.07 s 
2025-12-08 01:59:39.499969:  
2025-12-08 01:59:39.499969: Epoch 361 
2025-12-08 01:59:39.518119: Current learning rate: 0.00668 
2025-12-08 02:01:57.582834: train_loss -0.8362 
2025-12-08 02:01:57.582834: val_loss -0.8644 
2025-12-08 02:01:57.586839: Pseudo dice [0.9205, 0.9573, 0.9392] 
2025-12-08 02:01:57.586839: Epoch time: 138.08 s 
2025-12-08 02:01:58.388101:  
2025-12-08 02:01:58.389105: Epoch 362 
2025-12-08 02:01:58.390108: Current learning rate: 0.00667 
2025-12-08 02:04:16.454195: train_loss -0.8386 
2025-12-08 02:04:16.455198: val_loss -0.8648 
2025-12-08 02:04:16.459213: Pseudo dice [0.9212, 0.952, 0.9433] 
2025-12-08 02:04:16.462224: Epoch time: 138.07 s 
2025-12-08 02:04:17.092880:  
2025-12-08 02:04:17.092880: Epoch 363 
2025-12-08 02:04:17.111848: Current learning rate: 0.00666 
2025-12-08 02:06:35.204291: train_loss -0.8296 
2025-12-08 02:06:35.204291: val_loss -0.8566 
2025-12-08 02:06:35.204291: Pseudo dice [0.9153, 0.9502, 0.9389] 
2025-12-08 02:06:35.204291: Epoch time: 138.11 s 
2025-12-08 02:06:35.842953:  
2025-12-08 02:06:35.842953: Epoch 364 
2025-12-08 02:06:35.858902: Current learning rate: 0.00665 
2025-12-08 02:08:54.124501: train_loss -0.8394 
2025-12-08 02:08:54.124501: val_loss -0.8642 
2025-12-08 02:08:54.128347: Pseudo dice [0.916, 0.9535, 0.945] 
2025-12-08 02:08:54.131843: Epoch time: 138.28 s 
2025-12-08 02:08:55.108622:  
2025-12-08 02:08:55.108622: Epoch 365 
2025-12-08 02:08:55.114011: Current learning rate: 0.00665 
2025-12-08 02:11:13.242517: train_loss -0.8414 
2025-12-08 02:11:13.244520: val_loss -0.8582 
2025-12-08 02:11:13.248523: Pseudo dice [0.9141, 0.9472, 0.9443] 
2025-12-08 02:11:13.252028: Epoch time: 138.13 s 
2025-12-08 02:11:13.951745:  
2025-12-08 02:11:13.951745: Epoch 366 
2025-12-08 02:11:13.967403: Current learning rate: 0.00664 
2025-12-08 02:13:32.140447: train_loss -0.8401 
2025-12-08 02:13:32.140447: val_loss -0.8699 
2025-12-08 02:13:32.158419: Pseudo dice [0.9207, 0.9599, 0.9378] 
2025-12-08 02:13:32.162423: Epoch time: 138.19 s 
2025-12-08 02:13:32.813192:  
2025-12-08 02:13:32.813192: Epoch 367 
2025-12-08 02:13:32.813192: Current learning rate: 0.00663 
2025-12-08 02:15:50.979984: train_loss -0.839 
2025-12-08 02:15:50.981987: val_loss -0.8521 
2025-12-08 02:15:50.985732: Pseudo dice [0.9093, 0.9418, 0.9429] 
2025-12-08 02:15:50.987735: Epoch time: 138.17 s 
2025-12-08 02:15:51.758043:  
2025-12-08 02:15:51.758043: Epoch 368 
2025-12-08 02:15:51.760046: Current learning rate: 0.00662 
2025-12-08 02:18:09.824323: train_loss -0.8444 
2025-12-08 02:18:09.824323: val_loss -0.8748 
2025-12-08 02:18:09.827139: Pseudo dice [0.9248, 0.9614, 0.9434] 
2025-12-08 02:18:09.827139: Epoch time: 138.07 s 
2025-12-08 02:18:10.483166:  
2025-12-08 02:18:10.483166: Epoch 369 
2025-12-08 02:18:10.483166: Current learning rate: 0.00661 
2025-12-08 02:20:28.647552: train_loss -0.8394 
2025-12-08 02:20:28.649554: val_loss -0.8763 
2025-12-08 02:20:28.651985: Pseudo dice [0.9246, 0.9604, 0.945] 
2025-12-08 02:20:28.655488: Epoch time: 138.16 s 
2025-12-08 02:20:28.659087: Yayy! New best EMA pseudo Dice: 0.9377 
2025-12-08 02:20:29.564861:  
2025-12-08 02:20:29.564861: Epoch 370 
2025-12-08 02:20:29.564861: Current learning rate: 0.0066 
2025-12-08 02:22:47.487225: train_loss -0.8282 
2025-12-08 02:22:47.488229: val_loss -0.8508 
2025-12-08 02:22:47.492233: Pseudo dice [0.9151, 0.9466, 0.9348] 
2025-12-08 02:22:47.495234: Epoch time: 137.92 s 
2025-12-08 02:22:48.405642:  
2025-12-08 02:22:48.405642: Epoch 371 
2025-12-08 02:22:48.405642: Current learning rate: 0.00659 
2025-12-08 02:25:06.483941: train_loss -0.8183 
2025-12-08 02:25:06.483941: val_loss -0.8434 
2025-12-08 02:25:06.491540: Pseudo dice [0.9136, 0.9454, 0.9262] 
2025-12-08 02:25:06.493543: Epoch time: 138.08 s 
2025-12-08 02:25:07.151245:  
2025-12-08 02:25:07.151245: Epoch 372 
2025-12-08 02:25:07.154933: Current learning rate: 0.00658 
2025-12-08 02:27:25.075832: train_loss -0.825 
2025-12-08 02:27:25.075832: val_loss -0.8476 
2025-12-08 02:27:25.081002: Pseudo dice [0.9109, 0.9462, 0.9405] 
2025-12-08 02:27:25.084002: Epoch time: 137.93 s 
2025-12-08 02:27:25.764031:  
2025-12-08 02:27:25.764031: Epoch 373 
2025-12-08 02:27:25.779832: Current learning rate: 0.00657 
2025-12-08 02:29:43.936963: train_loss -0.8283 
2025-12-08 02:29:43.938966: val_loss -0.873 
2025-12-08 02:29:43.942971: Pseudo dice [0.9268, 0.9564, 0.9432] 
2025-12-08 02:29:43.946713: Epoch time: 138.17 s 
2025-12-08 02:29:44.670276:  
2025-12-08 02:29:44.670276: Epoch 374 
2025-12-08 02:29:44.681874: Current learning rate: 0.00656 
2025-12-08 02:32:02.868458: train_loss -0.835 
2025-12-08 02:32:02.870461: val_loss -0.8624 
2025-12-08 02:32:02.874205: Pseudo dice [0.919, 0.9534, 0.9409] 
2025-12-08 02:32:02.874205: Epoch time: 138.2 s 
2025-12-08 02:32:03.530175:  
2025-12-08 02:32:03.530175: Epoch 375 
2025-12-08 02:32:03.530175: Current learning rate: 0.00655 
2025-12-08 02:34:21.592253: train_loss -0.8421 
2025-12-08 02:34:21.592253: val_loss -0.8704 
2025-12-08 02:34:21.608191: Pseudo dice [0.9219, 0.9569, 0.9439] 
2025-12-08 02:34:21.608191: Epoch time: 138.08 s 
2025-12-08 02:34:22.264355:  
2025-12-08 02:34:22.264355: Epoch 376 
2025-12-08 02:34:22.264355: Current learning rate: 0.00654 
2025-12-08 02:36:40.390229: train_loss -0.841 
2025-12-08 02:36:40.390229: val_loss -0.8527 
2025-12-08 02:36:40.399731: Pseudo dice [0.9141, 0.9436, 0.9419] 
2025-12-08 02:36:40.401734: Epoch time: 138.13 s 
2025-12-08 02:36:41.232527:  
2025-12-08 02:36:41.233535: Epoch 377 
2025-12-08 02:36:41.233535: Current learning rate: 0.00653 
2025-12-08 02:38:59.583930: train_loss -0.8316 
2025-12-08 02:38:59.587930: val_loss -0.8659 
2025-12-08 02:38:59.591931: Pseudo dice [0.92, 0.9551, 0.9401] 
2025-12-08 02:38:59.594999: Epoch time: 138.35 s 
2025-12-08 02:39:00.481476:  
2025-12-08 02:39:00.483479: Epoch 378 
2025-12-08 02:39:00.486238: Current learning rate: 0.00652 
2025-12-08 02:41:18.677762: train_loss -0.8364 
2025-12-08 02:41:18.678762: val_loss -0.8603 
2025-12-08 02:41:18.682194: Pseudo dice [0.9148, 0.9507, 0.9418] 
2025-12-08 02:41:18.685194: Epoch time: 138.2 s 
2025-12-08 02:41:19.346641:  
2025-12-08 02:41:19.347642: Epoch 379 
2025-12-08 02:41:19.350807: Current learning rate: 0.00651 
2025-12-08 02:43:37.487444: train_loss -0.8377 
2025-12-08 02:43:37.487444: val_loss -0.8735 
2025-12-08 02:43:37.487444: Pseudo dice [0.9245, 0.9589, 0.9465] 
2025-12-08 02:43:37.487444: Epoch time: 138.14 s 
2025-12-08 02:43:38.139395:  
2025-12-08 02:43:38.139395: Epoch 380 
2025-12-08 02:43:38.155071: Current learning rate: 0.0065 
2025-12-08 02:45:56.295943: train_loss -0.8448 
2025-12-08 02:45:56.295943: val_loss -0.8577 
2025-12-08 02:45:56.295943: Pseudo dice [0.913, 0.9456, 0.9423] 
2025-12-08 02:45:56.295943: Epoch time: 138.16 s 
2025-12-08 02:45:56.951688:  
2025-12-08 02:45:56.951688: Epoch 381 
2025-12-08 02:45:56.951688: Current learning rate: 0.00649 
2025-12-08 02:48:15.217619: train_loss -0.8397 
2025-12-08 02:48:15.217619: val_loss -0.872 
2025-12-08 02:48:15.221240: Pseudo dice [0.922, 0.9535, 0.9402] 
2025-12-08 02:48:15.225722: Epoch time: 138.27 s 
2025-12-08 02:48:15.873787:  
2025-12-08 02:48:15.873787: Epoch 382 
2025-12-08 02:48:15.873787: Current learning rate: 0.00648 
2025-12-08 02:50:34.107256: train_loss -0.8444 
2025-12-08 02:50:34.109001: val_loss -0.8674 
2025-12-08 02:50:34.113009: Pseudo dice [0.9207, 0.9543, 0.9361] 
2025-12-08 02:50:34.117013: Epoch time: 138.23 s 
2025-12-08 02:50:35.030485:  
2025-12-08 02:50:35.030485: Epoch 383 
2025-12-08 02:50:35.046127: Current learning rate: 0.00648 
2025-12-08 02:52:53.181716: train_loss -0.8495 
2025-12-08 02:52:53.181716: val_loss -0.86 
2025-12-08 02:52:53.187564: Pseudo dice [0.9168, 0.9484, 0.9478] 
2025-12-08 02:52:53.190568: Epoch time: 138.15 s 
2025-12-08 02:52:53.855164:  
2025-12-08 02:52:53.855164: Epoch 384 
2025-12-08 02:52:53.858153: Current learning rate: 0.00647 
2025-12-08 02:55:12.061866: train_loss -0.8437 
2025-12-08 02:55:12.061866: val_loss -0.8639 
2025-12-08 02:55:12.077723: Pseudo dice [0.9171, 0.9476, 0.9466] 
2025-12-08 02:55:12.077723: Epoch time: 138.21 s 
2025-12-08 02:55:12.733779:  
2025-12-08 02:55:12.733779: Epoch 385 
2025-12-08 02:55:12.749818: Current learning rate: 0.00646 
2025-12-08 02:57:30.735100: train_loss -0.8416 
2025-12-08 02:57:30.735100: val_loss -0.8721 
2025-12-08 02:57:30.735100: Pseudo dice [0.9287, 0.9572, 0.9451] 
2025-12-08 02:57:30.735100: Epoch time: 138.0 s 
2025-12-08 02:57:30.735100: Yayy! New best EMA pseudo Dice: 0.9379 
2025-12-08 02:57:31.786474:  
2025-12-08 02:57:31.788477: Epoch 386 
2025-12-08 02:57:31.792483: Current learning rate: 0.00645 
2025-12-08 02:59:49.942345: train_loss -0.8341 
2025-12-08 02:59:49.943347: val_loss -0.8669 
2025-12-08 02:59:49.947356: Pseudo dice [0.9189, 0.9476, 0.949] 
2025-12-08 02:59:49.950357: Epoch time: 138.16 s 
2025-12-08 02:59:49.954278: Yayy! New best EMA pseudo Dice: 0.9379 
2025-12-08 02:59:50.921900:  
2025-12-08 02:59:50.922902: Epoch 387 
2025-12-08 02:59:50.925962: Current learning rate: 0.00644 
2025-12-08 03:02:09.124265: train_loss -0.8449 
2025-12-08 03:02:09.124265: val_loss -0.8562 
2025-12-08 03:02:09.142216: Pseudo dice [0.9161, 0.9476, 0.9387] 
2025-12-08 03:02:09.144219: Epoch time: 138.2 s 
2025-12-08 03:02:09.808990:  
2025-12-08 03:02:09.808990: Epoch 388 
2025-12-08 03:02:09.813210: Current learning rate: 0.00643 
2025-12-08 03:04:27.968601: train_loss -0.8448 
2025-12-08 03:04:27.968601: val_loss -0.8572 
2025-12-08 03:04:27.968601: Pseudo dice [0.9146, 0.947, 0.937] 
2025-12-08 03:04:27.983935: Epoch time: 138.16 s 
2025-12-08 03:04:28.952362:  
2025-12-08 03:04:28.952362: Epoch 389 
2025-12-08 03:04:28.952362: Current learning rate: 0.00642 
2025-12-08 03:06:47.077363: train_loss -0.8412 
2025-12-08 03:06:47.077363: val_loss -0.8699 
2025-12-08 03:06:47.093205: Pseudo dice [0.9214, 0.9549, 0.9484] 
2025-12-08 03:06:47.093205: Epoch time: 138.14 s 
2025-12-08 03:06:47.784683:  
2025-12-08 03:06:47.785685: Epoch 390 
2025-12-08 03:06:47.788692: Current learning rate: 0.00641 
2025-12-08 03:09:06.078344: train_loss -0.8399 
2025-12-08 03:09:06.078344: val_loss -0.8639 
2025-12-08 03:09:06.083585: Pseudo dice [0.9156, 0.9525, 0.9453] 
2025-12-08 03:09:06.083585: Epoch time: 138.29 s 
2025-12-08 03:09:06.733888:  
2025-12-08 03:09:06.733888: Epoch 391 
2025-12-08 03:09:06.733888: Current learning rate: 0.0064 
2025-12-08 03:11:24.836907: train_loss -0.8387 
2025-12-08 03:11:24.836907: val_loss -0.8686 
2025-12-08 03:11:24.840911: Pseudo dice [0.9233, 0.954, 0.9407] 
2025-12-08 03:11:24.842912: Epoch time: 138.1 s 
2025-12-08 03:11:25.509063:  
2025-12-08 03:11:25.509063: Epoch 392 
2025-12-08 03:11:25.509063: Current learning rate: 0.00639 
2025-12-08 03:13:43.632042: train_loss -0.8453 
2025-12-08 03:13:43.632042: val_loss -0.8676 
2025-12-08 03:13:43.636046: Pseudo dice [0.9191, 0.956, 0.947] 
2025-12-08 03:13:43.641791: Epoch time: 138.12 s 
2025-12-08 03:13:43.643794: Yayy! New best EMA pseudo Dice: 0.938 
2025-12-08 03:13:44.609759:  
2025-12-08 03:13:44.609759: Epoch 393 
2025-12-08 03:13:44.609759: Current learning rate: 0.00638 
2025-12-08 03:16:02.657092: train_loss -0.843 
2025-12-08 03:16:02.657092: val_loss -0.8646 
2025-12-08 03:16:02.661096: Pseudo dice [0.9182, 0.9535, 0.947] 
2025-12-08 03:16:02.665100: Epoch time: 138.05 s 
2025-12-08 03:16:02.667102: Yayy! New best EMA pseudo Dice: 0.9382 
2025-12-08 03:16:03.612159:  
2025-12-08 03:16:03.612159: Epoch 394 
2025-12-08 03:16:03.616231: Current learning rate: 0.00637 
2025-12-08 03:18:21.594995: train_loss -0.8362 
2025-12-08 03:18:21.594995: val_loss -0.8691 
2025-12-08 03:18:21.599014: Pseudo dice [0.9263, 0.9552, 0.9373] 
2025-12-08 03:18:21.602023: Epoch time: 137.98 s 
2025-12-08 03:18:21.605032: Yayy! New best EMA pseudo Dice: 0.9383 
2025-12-08 03:18:22.515700:  
2025-12-08 03:18:22.515700: Epoch 395 
2025-12-08 03:18:22.530218: Current learning rate: 0.00636 
2025-12-08 03:20:40.606604: train_loss -0.8373 
2025-12-08 03:20:40.608344: val_loss -0.8663 
2025-12-08 03:20:40.614354: Pseudo dice [0.9227, 0.9539, 0.9458] 
2025-12-08 03:20:40.618360: Epoch time: 138.09 s 
2025-12-08 03:20:40.622364: Yayy! New best EMA pseudo Dice: 0.9386 
2025-12-08 03:20:41.578708:  
2025-12-08 03:20:41.578708: Epoch 396 
2025-12-08 03:20:41.578708: Current learning rate: 0.00635 
2025-12-08 03:22:59.704244: train_loss -0.842 
2025-12-08 03:22:59.704244: val_loss -0.8651 
2025-12-08 03:22:59.708248: Pseudo dice [0.9164, 0.9501, 0.9515] 
2025-12-08 03:22:59.710250: Epoch time: 138.13 s 
2025-12-08 03:22:59.714256: Yayy! New best EMA pseudo Dice: 0.9386 
2025-12-08 03:23:00.651760:  
2025-12-08 03:23:00.653500: Epoch 397 
2025-12-08 03:23:00.657289: Current learning rate: 0.00634 
2025-12-08 03:25:18.843692: train_loss -0.8387 
2025-12-08 03:25:18.843692: val_loss -0.8817 
2025-12-08 03:25:18.848744: Pseudo dice [0.93, 0.9595, 0.9471] 
2025-12-08 03:25:18.853226: Epoch time: 138.19 s 
2025-12-08 03:25:18.856241: Yayy! New best EMA pseudo Dice: 0.9393 
2025-12-08 03:25:19.796421:  
2025-12-08 03:25:19.796421: Epoch 398 
2025-12-08 03:25:19.796421: Current learning rate: 0.00633 
2025-12-08 03:27:37.898034: train_loss -0.8438 
2025-12-08 03:27:37.899036: val_loss -0.8692 
2025-12-08 03:27:37.902038: Pseudo dice [0.9198, 0.9604, 0.9428] 
2025-12-08 03:27:37.905398: Epoch time: 138.1 s 
2025-12-08 03:27:37.905398: Yayy! New best EMA pseudo Dice: 0.9395 
2025-12-08 03:27:38.844100:  
2025-12-08 03:27:38.844100: Epoch 399 
2025-12-08 03:27:38.855774: Current learning rate: 0.00632 
2025-12-08 03:29:56.905093: train_loss -0.8466 
2025-12-08 03:29:56.907132: val_loss -0.856 
2025-12-08 03:29:56.909134: Pseudo dice [0.9121, 0.9491, 0.9414] 
2025-12-08 03:29:56.914598: Epoch time: 138.06 s 
2025-12-08 03:29:57.997496:  
2025-12-08 03:29:57.998498: Epoch 400 
2025-12-08 03:29:57.999501: Current learning rate: 0.00631 
2025-12-08 03:32:15.973520: train_loss -0.8398 
2025-12-08 03:32:15.973520: val_loss -0.8713 
2025-12-08 03:32:15.975522: Pseudo dice [0.9202, 0.9549, 0.9446] 
2025-12-08 03:32:15.981361: Epoch time: 137.98 s 
2025-12-08 03:32:16.678240:  
2025-12-08 03:32:16.678240: Epoch 401 
2025-12-08 03:32:16.680244: Current learning rate: 0.0063 
2025-12-08 03:34:34.480013: train_loss -0.8459 
2025-12-08 03:34:34.480013: val_loss -0.8769 
2025-12-08 03:34:34.485519: Pseudo dice [0.9247, 0.9573, 0.9474] 
2025-12-08 03:34:34.489523: Epoch time: 137.81 s 
2025-12-08 03:34:35.139940:  
2025-12-08 03:34:35.139940: Epoch 402 
2025-12-08 03:34:35.158858: Current learning rate: 0.0063 
2025-12-08 03:36:53.233999: train_loss -0.8394 
2025-12-08 03:36:53.233999: val_loss -0.8556 
2025-12-08 03:36:53.233999: Pseudo dice [0.9148, 0.9464, 0.9412] 
2025-12-08 03:36:53.241812: Epoch time: 138.09 s 
2025-12-08 03:36:53.890372:  
2025-12-08 03:36:53.890372: Epoch 403 
2025-12-08 03:36:53.890372: Current learning rate: 0.00629 
2025-12-08 03:39:12.027005: train_loss -0.8364 
2025-12-08 03:39:12.028007: val_loss -0.8705 
2025-12-08 03:39:12.032205: Pseudo dice [0.9221, 0.955, 0.9471] 
2025-12-08 03:39:12.032205: Epoch time: 138.14 s 
2025-12-08 03:39:12.718785:  
2025-12-08 03:39:12.718785: Epoch 404 
2025-12-08 03:39:12.718785: Current learning rate: 0.00628 
2025-12-08 03:41:31.069227: train_loss -0.8408 
2025-12-08 03:41:31.071230: val_loss -0.8509 
2025-12-08 03:41:31.075236: Pseudo dice [0.9118, 0.9502, 0.9361] 
2025-12-08 03:41:31.077238: Epoch time: 138.35 s 
2025-12-08 03:41:31.904927:  
2025-12-08 03:41:31.904927: Epoch 405 
2025-12-08 03:41:31.904927: Current learning rate: 0.00627 
2025-12-08 03:43:50.056937: train_loss -0.8406 
2025-12-08 03:43:50.057938: val_loss -0.8555 
2025-12-08 03:43:50.060939: Pseudo dice [0.9133, 0.951, 0.9398] 
2025-12-08 03:43:50.066652: Epoch time: 138.15 s 
2025-12-08 03:43:50.719065:  
2025-12-08 03:43:50.719065: Epoch 406 
2025-12-08 03:43:50.719065: Current learning rate: 0.00626 
2025-12-08 03:46:08.916267: train_loss -0.8316 
2025-12-08 03:46:08.916267: val_loss -0.8566 
2025-12-08 03:46:08.920272: Pseudo dice [0.9154, 0.9492, 0.9412] 
2025-12-08 03:46:08.924170: Epoch time: 138.2 s 
2025-12-08 03:46:09.584572:  
2025-12-08 03:46:09.585577: Epoch 407 
2025-12-08 03:46:09.588320: Current learning rate: 0.00625 
2025-12-08 03:48:27.671250: train_loss -0.8335 
2025-12-08 03:48:27.671250: val_loss -0.8674 
2025-12-08 03:48:27.682055: Pseudo dice [0.923, 0.9537, 0.9422] 
2025-12-08 03:48:27.682055: Epoch time: 138.09 s 
2025-12-08 03:48:28.327754:  
2025-12-08 03:48:28.327754: Epoch 408 
2025-12-08 03:48:28.337674: Current learning rate: 0.00624 
2025-12-08 03:50:46.390258: train_loss -0.8379 
2025-12-08 03:50:46.390258: val_loss -0.8678 
2025-12-08 03:50:46.397342: Pseudo dice [0.9205, 0.9591, 0.9444] 
2025-12-08 03:50:46.397342: Epoch time: 138.06 s 
2025-12-08 03:50:47.055384:  
2025-12-08 03:50:47.056397: Epoch 409 
2025-12-08 03:50:47.056397: Current learning rate: 0.00623 
2025-12-08 03:53:05.265937: train_loss -0.8405 
2025-12-08 03:53:05.265937: val_loss -0.8636 
2025-12-08 03:53:05.269941: Pseudo dice [0.9153, 0.955, 0.9437] 
2025-12-08 03:53:05.273945: Epoch time: 138.22 s 
2025-12-08 03:53:05.937830:  
2025-12-08 03:53:05.937830: Epoch 410 
2025-12-08 03:53:05.937830: Current learning rate: 0.00622 
2025-12-08 03:55:24.264482: train_loss -0.8416 
2025-12-08 03:55:24.264482: val_loss -0.8626 
2025-12-08 03:55:24.280422: Pseudo dice [0.915, 0.9494, 0.9406] 
2025-12-08 03:55:24.280422: Epoch time: 138.33 s 
2025-12-08 03:55:25.078295:  
2025-12-08 03:55:25.078295: Epoch 411 
2025-12-08 03:55:25.078295: Current learning rate: 0.00621 
2025-12-08 03:57:43.248443: train_loss -0.8467 
2025-12-08 03:57:43.248443: val_loss -0.877 
2025-12-08 03:57:43.248443: Pseudo dice [0.926, 0.9551, 0.9504] 
2025-12-08 03:57:43.248443: Epoch time: 138.19 s 
2025-12-08 03:57:43.889479:  
2025-12-08 03:57:43.889479: Epoch 412 
2025-12-08 03:57:43.889479: Current learning rate: 0.0062 
2025-12-08 04:00:02.046167: train_loss -0.8395 
2025-12-08 04:00:02.046167: val_loss -0.8635 
2025-12-08 04:00:02.053979: Pseudo dice [0.922, 0.9522, 0.9394] 
2025-12-08 04:00:02.053979: Epoch time: 138.16 s 
2025-12-08 04:00:02.687552:  
2025-12-08 04:00:02.687552: Epoch 413 
2025-12-08 04:00:02.687552: Current learning rate: 0.00619 
2025-12-08 04:02:21.028466: train_loss -0.8401 
2025-12-08 04:02:21.030207: val_loss -0.8649 
2025-12-08 04:02:21.030207: Pseudo dice [0.9202, 0.9539, 0.9393] 
2025-12-08 04:02:21.036333: Epoch time: 138.34 s 
2025-12-08 04:02:21.654998:  
2025-12-08 04:02:21.654998: Epoch 414 
2025-12-08 04:02:21.670675: Current learning rate: 0.00618 
2025-12-08 04:04:39.889251: train_loss -0.8442 
2025-12-08 04:04:39.889251: val_loss -0.8683 
2025-12-08 04:04:39.895257: Pseudo dice [0.9224, 0.9538, 0.9472] 
2025-12-08 04:04:39.898999: Epoch time: 138.23 s 
2025-12-08 04:04:40.530149:  
2025-12-08 04:04:40.530149: Epoch 415 
2025-12-08 04:04:40.530149: Current learning rate: 0.00617 
2025-12-08 04:06:58.717176: train_loss -0.8432 
2025-12-08 04:06:58.718917: val_loss -0.8669 
2025-12-08 04:06:58.724041: Pseudo dice [0.9213, 0.9531, 0.9443] 
2025-12-08 04:06:58.728042: Epoch time: 138.19 s 
2025-12-08 04:06:59.367639:  
2025-12-08 04:06:59.367639: Epoch 416 
2025-12-08 04:06:59.371012: Current learning rate: 0.00616 
2025-12-08 04:09:17.525694: train_loss -0.8453 
2025-12-08 04:09:17.527696: val_loss -0.8649 
2025-12-08 04:09:17.530699: Pseudo dice [0.9157, 0.9489, 0.9474] 
2025-12-08 04:09:17.530699: Epoch time: 138.16 s 
2025-12-08 04:09:18.171477:  
2025-12-08 04:09:18.171477: Epoch 417 
2025-12-08 04:09:18.171477: Current learning rate: 0.00615 
2025-12-08 04:11:36.343222: train_loss -0.8472 
2025-12-08 04:11:36.343222: val_loss -0.8651 
2025-12-08 04:11:36.343222: Pseudo dice [0.9154, 0.9528, 0.9426] 
2025-12-08 04:11:36.343222: Epoch time: 138.17 s 
2025-12-08 04:11:37.159213:  
2025-12-08 04:11:37.159213: Epoch 418 
2025-12-08 04:11:37.159213: Current learning rate: 0.00614 
2025-12-08 04:13:55.369683: train_loss -0.8429 
2025-12-08 04:13:55.369683: val_loss -0.8663 
2025-12-08 04:13:55.373686: Pseudo dice [0.9221, 0.9541, 0.9398] 
2025-12-08 04:13:55.377691: Epoch time: 138.21 s 
2025-12-08 04:13:55.999895:  
2025-12-08 04:13:55.999895: Epoch 419 
2025-12-08 04:13:56.015930: Current learning rate: 0.00613 
2025-12-08 04:16:14.213716: train_loss -0.845 
2025-12-08 04:16:14.215718: val_loss -0.8661 
2025-12-08 04:16:14.219723: Pseudo dice [0.9187, 0.9508, 0.9463] 
2025-12-08 04:16:14.221725: Epoch time: 138.21 s 
2025-12-08 04:16:14.842891:  
2025-12-08 04:16:14.842891: Epoch 420 
2025-12-08 04:16:14.842891: Current learning rate: 0.00612 
2025-12-08 04:18:33.217798: train_loss -0.8374 
2025-12-08 04:18:33.217798: val_loss -0.8743 
2025-12-08 04:18:33.217798: Pseudo dice [0.9224, 0.9592, 0.9456] 
2025-12-08 04:18:33.217798: Epoch time: 138.37 s 
2025-12-08 04:18:33.874552:  
2025-12-08 04:18:33.874552: Epoch 421 
2025-12-08 04:18:33.874552: Current learning rate: 0.00612 
2025-12-08 04:20:52.074597: train_loss -0.8418 
2025-12-08 04:20:52.076601: val_loss -0.8718 
2025-12-08 04:20:52.082350: Pseudo dice [0.9258, 0.9589, 0.9427] 
2025-12-08 04:20:52.086355: Epoch time: 138.2 s 
2025-12-08 04:20:52.723272:  
2025-12-08 04:20:52.723272: Epoch 422 
2025-12-08 04:20:52.723272: Current learning rate: 0.00611 
2025-12-08 04:23:10.843787: train_loss -0.8362 
2025-12-08 04:23:10.843787: val_loss -0.8568 
2025-12-08 04:23:10.859681: Pseudo dice [0.9111, 0.9537, 0.9432] 
2025-12-08 04:23:10.862787: Epoch time: 138.12 s 
2025-12-08 04:23:11.483188:  
2025-12-08 04:23:11.483188: Epoch 423 
2025-12-08 04:23:11.483188: Current learning rate: 0.0061 
2025-12-08 04:25:29.608536: train_loss -0.8438 
2025-12-08 04:25:29.608536: val_loss -0.8714 
2025-12-08 04:25:29.608536: Pseudo dice [0.919, 0.9572, 0.9447] 
2025-12-08 04:25:29.608536: Epoch time: 138.14 s 
2025-12-08 04:25:30.493695:  
2025-12-08 04:25:30.494741: Epoch 424 
2025-12-08 04:25:30.497749: Current learning rate: 0.00609 
2025-12-08 04:27:48.656250: train_loss -0.8406 
2025-12-08 04:27:48.656250: val_loss -0.8562 
2025-12-08 04:27:48.656250: Pseudo dice [0.9143, 0.9465, 0.9446] 
2025-12-08 04:27:48.656250: Epoch time: 138.16 s 
2025-12-08 04:27:49.280776:  
2025-12-08 04:27:49.280776: Epoch 425 
2025-12-08 04:27:49.298748: Current learning rate: 0.00608 
2025-12-08 04:30:07.378622: train_loss -0.8444 
2025-12-08 04:30:07.378622: val_loss -0.8733 
2025-12-08 04:30:07.384628: Pseudo dice [0.9237, 0.9506, 0.9455] 
2025-12-08 04:30:07.388632: Epoch time: 138.1 s 
2025-12-08 04:30:08.026947:  
2025-12-08 04:30:08.026947: Epoch 426 
2025-12-08 04:30:08.030803: Current learning rate: 0.00607 
2025-12-08 04:32:26.185552: train_loss -0.8421 
2025-12-08 04:32:26.185552: val_loss -0.8702 
2025-12-08 04:32:26.186553: Pseudo dice [0.9218, 0.9546, 0.9471] 
2025-12-08 04:32:26.186553: Epoch time: 138.16 s 
2025-12-08 04:32:26.931798:  
2025-12-08 04:32:26.933800: Epoch 427 
2025-12-08 04:32:26.937544: Current learning rate: 0.00606 
2025-12-08 04:34:44.992664: train_loss -0.8372 
2025-12-08 04:34:44.993666: val_loss -0.867 
2025-12-08 04:34:44.997669: Pseudo dice [0.9162, 0.9517, 0.9483] 
2025-12-08 04:34:44.998670: Epoch time: 138.06 s 
2025-12-08 04:34:45.640112:  
2025-12-08 04:34:45.640112: Epoch 428 
2025-12-08 04:34:45.644178: Current learning rate: 0.00605 
2025-12-08 04:37:03.704918: train_loss -0.8415 
2025-12-08 04:37:03.705920: val_loss -0.8692 
2025-12-08 04:37:03.710933: Pseudo dice [0.9189, 0.9557, 0.9385] 
2025-12-08 04:37:03.713934: Epoch time: 138.07 s 
2025-12-08 04:37:04.385855:  
2025-12-08 04:37:04.386861: Epoch 429 
2025-12-08 04:37:04.390876: Current learning rate: 0.00604 
2025-12-08 04:39:22.468029: train_loss -0.8413 
2025-12-08 04:39:22.468029: val_loss -0.8531 
2025-12-08 04:39:22.484149: Pseudo dice [0.9128, 0.9491, 0.9399] 
2025-12-08 04:39:22.484149: Epoch time: 138.08 s 
2025-12-08 04:39:23.436585:  
2025-12-08 04:39:23.436585: Epoch 430 
2025-12-08 04:39:23.452533: Current learning rate: 0.00603 
2025-12-08 04:41:41.512358: train_loss -0.8445 
2025-12-08 04:41:41.514361: val_loss -0.8753 
2025-12-08 04:41:41.514361: Pseudo dice [0.9251, 0.9545, 0.9447] 
2025-12-08 04:41:41.521347: Epoch time: 138.08 s 
2025-12-08 04:41:42.167205:  
2025-12-08 04:41:42.167205: Epoch 431 
2025-12-08 04:41:42.171210: Current learning rate: 0.00602 
2025-12-08 04:44:00.317755: train_loss -0.8366 
2025-12-08 04:44:00.317755: val_loss -0.8517 
2025-12-08 04:44:00.323760: Pseudo dice [0.913, 0.9486, 0.9351] 
2025-12-08 04:44:00.325762: Epoch time: 138.15 s 
2025-12-08 04:44:00.952704:  
2025-12-08 04:44:00.952704: Epoch 432 
2025-12-08 04:44:00.968697: Current learning rate: 0.00601 
2025-12-08 04:46:19.030457: train_loss -0.8366 
2025-12-08 04:46:19.032427: val_loss -0.8595 
2025-12-08 04:46:19.036431: Pseudo dice [0.918, 0.955, 0.9379] 
2025-12-08 04:46:19.038433: Epoch time: 138.08 s 
2025-12-08 04:46:19.670521:  
2025-12-08 04:46:19.670521: Epoch 433 
2025-12-08 04:46:19.686603: Current learning rate: 0.006 
2025-12-08 04:48:37.870573: train_loss -0.8408 
2025-12-08 04:48:37.872576: val_loss -0.8628 
2025-12-08 04:48:37.878082: Pseudo dice [0.921, 0.9465, 0.942] 
2025-12-08 04:48:37.880085: Epoch time: 138.2 s 
2025-12-08 04:48:38.523712:  
2025-12-08 04:48:38.525715: Epoch 434 
2025-12-08 04:48:38.525715: Current learning rate: 0.00599 
2025-12-08 04:50:56.573106: train_loss -0.8452 
2025-12-08 04:50:56.573106: val_loss -0.8651 
2025-12-08 04:50:56.576848: Pseudo dice [0.9183, 0.9529, 0.9389] 
2025-12-08 04:50:56.580853: Epoch time: 138.05 s 
2025-12-08 04:50:57.217012:  
2025-12-08 04:50:57.217012: Epoch 435 
2025-12-08 04:50:57.217012: Current learning rate: 0.00598 
2025-12-08 04:53:15.324461: train_loss -0.843 
2025-12-08 04:53:15.324461: val_loss -0.8665 
2025-12-08 04:53:15.328343: Pseudo dice [0.9173, 0.9523, 0.944] 
2025-12-08 04:53:15.330345: Epoch time: 138.11 s 
2025-12-08 04:53:15.984052:  
2025-12-08 04:53:15.984052: Epoch 436 
2025-12-08 04:53:16.000031: Current learning rate: 0.00597 
2025-12-08 04:55:34.293838: train_loss -0.843 
2025-12-08 04:55:34.293838: val_loss -0.8758 
2025-12-08 04:55:34.296382: Pseudo dice [0.9248, 0.9541, 0.9483] 
2025-12-08 04:55:34.296382: Epoch time: 138.31 s 
2025-12-08 04:55:35.108673:  
2025-12-08 04:55:35.108673: Epoch 437 
2025-12-08 04:55:35.108673: Current learning rate: 0.00596 
2025-12-08 04:57:53.266028: train_loss -0.8441 
2025-12-08 04:57:53.266028: val_loss -0.8596 
2025-12-08 04:57:53.271029: Pseudo dice [0.9133, 0.9522, 0.9433] 
2025-12-08 04:57:53.275030: Epoch time: 138.16 s 
2025-12-08 04:57:53.952893:  
2025-12-08 04:57:53.968717: Epoch 438 
2025-12-08 04:57:53.968717: Current learning rate: 0.00595 
2025-12-08 05:00:12.168419: train_loss -0.8436 
2025-12-08 05:00:12.168419: val_loss -0.8756 
2025-12-08 05:00:12.177450: Pseudo dice [0.9279, 0.9539, 0.945] 
2025-12-08 05:00:12.181454: Epoch time: 138.22 s 
2025-12-08 05:00:12.813382:  
2025-12-08 05:00:12.813382: Epoch 439 
2025-12-08 05:00:12.827391: Current learning rate: 0.00594 
2025-12-08 05:02:31.155185: train_loss -0.8374 
2025-12-08 05:02:31.155185: val_loss -0.8682 
2025-12-08 05:02:31.160370: Pseudo dice [0.9187, 0.9539, 0.9439] 
2025-12-08 05:02:31.164088: Epoch time: 138.34 s 
2025-12-08 05:02:31.796096:  
2025-12-08 05:02:31.796096: Epoch 440 
2025-12-08 05:02:31.812061: Current learning rate: 0.00593 
2025-12-08 05:04:49.875850: train_loss -0.835 
2025-12-08 05:04:49.875850: val_loss -0.8644 
2025-12-08 05:04:49.875850: Pseudo dice [0.9222, 0.9531, 0.9357] 
2025-12-08 05:04:49.875850: Epoch time: 138.08 s 
2025-12-08 05:04:50.515215:  
2025-12-08 05:04:50.515215: Epoch 441 
2025-12-08 05:04:50.515215: Current learning rate: 0.00592 
2025-12-08 05:07:08.734112: train_loss -0.8409 
2025-12-08 05:07:08.734112: val_loss -0.8717 
2025-12-08 05:07:08.734112: Pseudo dice [0.9227, 0.9551, 0.946] 
2025-12-08 05:07:08.750076: Epoch time: 138.22 s 
2025-12-08 05:07:09.374291:  
2025-12-08 05:07:09.374291: Epoch 442 
2025-12-08 05:07:09.374291: Current learning rate: 0.00592 
2025-12-08 05:09:27.461574: train_loss -0.8416 
2025-12-08 05:09:27.462574: val_loss -0.8728 
2025-12-08 05:09:27.466580: Pseudo dice [0.9261, 0.9541, 0.9421] 
2025-12-08 05:09:27.467584: Epoch time: 138.09 s 
2025-12-08 05:09:28.296798:  
2025-12-08 05:09:28.296798: Epoch 443 
2025-12-08 05:09:28.310115: Current learning rate: 0.00591 
2025-12-08 05:11:46.414550: train_loss -0.8451 
2025-12-08 05:11:46.415550: val_loss -0.8632 
2025-12-08 05:11:46.419036: Pseudo dice [0.9197, 0.9546, 0.9444] 
2025-12-08 05:11:46.421163: Epoch time: 138.12 s 
2025-12-08 05:11:47.037868:  
2025-12-08 05:11:47.037868: Epoch 444 
2025-12-08 05:11:47.037868: Current learning rate: 0.0059 
2025-12-08 05:14:05.123485: train_loss -0.8437 
2025-12-08 05:14:05.123485: val_loss -0.8681 
2025-12-08 05:14:05.143210: Pseudo dice [0.9224, 0.9509, 0.9461] 
2025-12-08 05:14:05.145212: Epoch time: 138.09 s 
2025-12-08 05:14:05.775430:  
2025-12-08 05:14:05.775430: Epoch 445 
2025-12-08 05:14:05.779784: Current learning rate: 0.00589 
2025-12-08 05:16:23.951935: train_loss -0.844 
2025-12-08 05:16:23.951935: val_loss -0.8732 
2025-12-08 05:16:23.956809: Pseudo dice [0.9267, 0.9552, 0.9406] 
2025-12-08 05:16:23.960813: Epoch time: 138.18 s 
2025-12-08 05:16:24.584570:  
2025-12-08 05:16:24.585582: Epoch 446 
2025-12-08 05:16:24.588773: Current learning rate: 0.00588 
2025-12-08 05:18:42.721341: train_loss -0.8414 
2025-12-08 05:18:42.722341: val_loss -0.8724 
2025-12-08 05:18:42.726342: Pseudo dice [0.9241, 0.9585, 0.9441] 
2025-12-08 05:18:42.729343: Epoch time: 138.14 s 
2025-12-08 05:18:43.352829:  
2025-12-08 05:18:43.352829: Epoch 447 
2025-12-08 05:18:43.352829: Current learning rate: 0.00587 
2025-12-08 05:21:01.456614: train_loss -0.8425 
2025-12-08 05:21:01.456614: val_loss -0.8703 
2025-12-08 05:21:01.464511: Pseudo dice [0.9232, 0.9546, 0.9442] 
2025-12-08 05:21:01.470256: Epoch time: 138.11 s 
2025-12-08 05:21:01.472258: Yayy! New best EMA pseudo Dice: 0.9396 
2025-12-08 05:21:02.378389:  
2025-12-08 05:21:02.378389: Epoch 448 
2025-12-08 05:21:02.382407: Current learning rate: 0.00586 
2025-12-08 05:23:20.515336: train_loss -0.8461 
2025-12-08 05:23:20.515336: val_loss -0.8625 
2025-12-08 05:23:20.531023: Pseudo dice [0.9192, 0.9487, 0.94] 
2025-12-08 05:23:20.535611: Epoch time: 138.14 s 
2025-12-08 05:23:21.326668:  
2025-12-08 05:23:21.326668: Epoch 449 
2025-12-08 05:23:21.333194: Current learning rate: 0.00585 
2025-12-08 05:25:39.483210: train_loss -0.8384 
2025-12-08 05:25:39.483210: val_loss -0.8619 
2025-12-08 05:25:39.483210: Pseudo dice [0.9188, 0.9482, 0.9355] 
2025-12-08 05:25:39.490305: Epoch time: 138.16 s 
2025-12-08 05:25:40.374905:  
2025-12-08 05:25:40.374905: Epoch 450 
2025-12-08 05:25:40.384761: Current learning rate: 0.00584 
2025-12-08 05:27:58.421380: train_loss -0.8453 
2025-12-08 05:27:58.421380: val_loss -0.8689 
2025-12-08 05:27:58.421380: Pseudo dice [0.9262, 0.9558, 0.9365] 
2025-12-08 05:27:58.437293: Epoch time: 138.05 s 
2025-12-08 05:27:59.047946:  
2025-12-08 05:27:59.047946: Epoch 451 
2025-12-08 05:27:59.053955: Current learning rate: 0.00583 
2025-12-08 05:30:17.216994: train_loss -0.8334 
2025-12-08 05:30:17.216994: val_loss -0.8222 
2025-12-08 05:30:17.221119: Pseudo dice [0.8941, 0.943, 0.9254] 
2025-12-08 05:30:17.223811: Epoch time: 138.17 s 
2025-12-08 05:30:17.847966:  
2025-12-08 05:30:17.849149: Epoch 452 
2025-12-08 05:30:17.853165: Current learning rate: 0.00582 
2025-12-08 05:32:36.025360: train_loss -0.8021 
2025-12-08 05:32:36.026364: val_loss -0.8591 
2025-12-08 05:32:36.030375: Pseudo dice [0.9191, 0.9532, 0.9347] 
2025-12-08 05:32:36.030375: Epoch time: 138.18 s 
2025-12-08 05:32:36.639990:  
2025-12-08 05:32:36.639990: Epoch 453 
2025-12-08 05:32:36.655903: Current learning rate: 0.00581 
2025-12-08 05:34:54.808411: train_loss -0.8176 
2025-12-08 05:34:54.810413: val_loss -0.8524 
2025-12-08 05:34:54.814417: Pseudo dice [0.9154, 0.9497, 0.9387] 
2025-12-08 05:34:54.816404: Epoch time: 138.17 s 
2025-12-08 05:34:55.436534:  
2025-12-08 05:34:55.436534: Epoch 454 
2025-12-08 05:34:55.436534: Current learning rate: 0.0058 
2025-12-08 05:37:13.704451: train_loss -0.8302 
2025-12-08 05:37:13.706456: val_loss -0.8671 
2025-12-08 05:37:13.712477: Pseudo dice [0.9236, 0.9541, 0.9434] 
2025-12-08 05:37:13.717852: Epoch time: 138.27 s 
2025-12-08 05:37:14.545344:  
2025-12-08 05:37:14.545344: Epoch 455 
2025-12-08 05:37:14.561262: Current learning rate: 0.00579 
2025-12-08 05:39:32.745559: train_loss -0.8217 
2025-12-08 05:39:32.747562: val_loss -0.837 
2025-12-08 05:39:32.751306: Pseudo dice [0.9056, 0.9423, 0.9373] 
2025-12-08 05:39:32.756998: Epoch time: 138.2 s 
2025-12-08 05:39:33.373315:  
2025-12-08 05:39:33.373315: Epoch 456 
2025-12-08 05:39:33.389080: Current learning rate: 0.00578 
2025-12-08 05:41:51.714415: train_loss -0.7944 
2025-12-08 05:41:51.715417: val_loss -0.8499 
2025-12-08 05:41:51.719455: Pseudo dice [0.9154, 0.9536, 0.9351] 
2025-12-08 05:41:51.723460: Epoch time: 138.34 s 
2025-12-08 05:41:52.373981:  
2025-12-08 05:41:52.373981: Epoch 457 
2025-12-08 05:41:52.373981: Current learning rate: 0.00577 
2025-12-08 05:44:10.577240: train_loss -0.8114 
2025-12-08 05:44:10.579049: val_loss -0.8515 
2025-12-08 05:44:10.583055: Pseudo dice [0.9157, 0.9498, 0.9387] 
2025-12-08 05:44:10.587059: Epoch time: 138.2 s 
2025-12-08 05:44:11.218941:  
2025-12-08 05:44:11.218941: Epoch 458 
2025-12-08 05:44:11.218941: Current learning rate: 0.00576 
2025-12-08 05:46:29.300604: train_loss -0.8203 
2025-12-08 05:46:29.300604: val_loss -0.854 
2025-12-08 05:46:29.306612: Pseudo dice [0.9133, 0.9518, 0.9377] 
2025-12-08 05:46:29.308615: Epoch time: 138.08 s 
2025-12-08 05:46:29.936109:  
2025-12-08 05:46:29.936109: Epoch 459 
2025-12-08 05:46:29.936109: Current learning rate: 0.00575 
2025-12-08 05:48:48.109591: train_loss -0.8259 
2025-12-08 05:48:48.109591: val_loss -0.854 
2025-12-08 05:48:48.109591: Pseudo dice [0.9186, 0.9495, 0.9323] 
2025-12-08 05:48:48.109591: Epoch time: 138.17 s 
2025-12-08 05:48:48.733154:  
2025-12-08 05:48:48.733154: Epoch 460 
2025-12-08 05:48:48.733154: Current learning rate: 0.00574 
2025-12-08 05:51:06.782135: train_loss -0.8338 
2025-12-08 05:51:06.783139: val_loss -0.8543 
2025-12-08 05:51:06.787152: Pseudo dice [0.9138, 0.942, 0.9431] 
2025-12-08 05:51:06.790167: Epoch time: 138.05 s 
2025-12-08 05:51:07.405884:  
2025-12-08 05:51:07.405884: Epoch 461 
2025-12-08 05:51:07.405884: Current learning rate: 0.00573 
2025-12-08 05:53:25.325693: train_loss -0.8348 
2025-12-08 05:53:25.325693: val_loss -0.8574 
2025-12-08 05:53:25.326696: Pseudo dice [0.9181, 0.9502, 0.9418] 
2025-12-08 05:53:25.326696: Epoch time: 137.92 s 
2025-12-08 05:53:26.186282:  
2025-12-08 05:53:26.186282: Epoch 462 
2025-12-08 05:53:26.186282: Current learning rate: 0.00572 
2025-12-08 05:55:44.358374: train_loss -0.8347 
2025-12-08 05:55:44.358374: val_loss -0.863 
2025-12-08 05:55:44.374285: Pseudo dice [0.9197, 0.9519, 0.9441] 
2025-12-08 05:55:44.374285: Epoch time: 138.17 s 
2025-12-08 05:55:44.984594:  
2025-12-08 05:55:44.984594: Epoch 463 
2025-12-08 05:55:44.984594: Current learning rate: 0.00571 
2025-12-08 05:58:03.045187: train_loss -0.8398 
2025-12-08 05:58:03.045187: val_loss -0.8624 
2025-12-08 05:58:03.060919: Pseudo dice [0.9161, 0.9533, 0.948] 
2025-12-08 05:58:03.064924: Epoch time: 138.06 s 
2025-12-08 05:58:03.686740:  
2025-12-08 05:58:03.686740: Epoch 464 
2025-12-08 05:58:03.686740: Current learning rate: 0.0057 
2025-12-08 06:00:21.726662: train_loss -0.8429 
2025-12-08 06:00:21.728664: val_loss -0.8709 
2025-12-08 06:00:21.734409: Pseudo dice [0.921, 0.9527, 0.9518] 
2025-12-08 06:00:21.741626: Epoch time: 138.04 s 
2025-12-08 06:00:22.483474:  
2025-12-08 06:00:22.483474: Epoch 465 
2025-12-08 06:00:22.483474: Current learning rate: 0.0057 
2025-12-08 06:02:40.717708: train_loss -0.8372 
2025-12-08 06:02:40.717708: val_loss -0.871 
2025-12-08 06:02:40.717708: Pseudo dice [0.9236, 0.9544, 0.941] 
2025-12-08 06:02:40.727214: Epoch time: 138.23 s 
2025-12-08 06:02:41.359803:  
2025-12-08 06:02:41.359803: Epoch 466 
2025-12-08 06:02:41.359803: Current learning rate: 0.00569 
2025-12-08 06:04:59.577625: train_loss -0.8429 
2025-12-08 06:04:59.577625: val_loss -0.8647 
2025-12-08 06:04:59.593708: Pseudo dice [0.9191, 0.952, 0.9496] 
2025-12-08 06:04:59.593708: Epoch time: 138.22 s 
2025-12-08 06:05:00.202204:  
2025-12-08 06:05:00.202204: Epoch 467 
2025-12-08 06:05:00.202204: Current learning rate: 0.00568 
2025-12-08 06:07:18.271718: train_loss -0.8435 
2025-12-08 06:07:18.271718: val_loss -0.8632 
2025-12-08 06:07:18.276719: Pseudo dice [0.9203, 0.9548, 0.937] 
2025-12-08 06:07:18.279719: Epoch time: 138.07 s 
2025-12-08 06:07:19.046460:  
2025-12-08 06:07:19.046460: Epoch 468 
2025-12-08 06:07:19.061726: Current learning rate: 0.00567 
2025-12-08 06:09:37.204686: train_loss -0.8402 
2025-12-08 06:09:37.204686: val_loss -0.8657 
2025-12-08 06:09:37.218350: Pseudo dice [0.9212, 0.952, 0.9402] 
2025-12-08 06:09:37.223823: Epoch time: 138.16 s 
2025-12-08 06:09:38.014571:  
2025-12-08 06:09:38.014571: Epoch 469 
2025-12-08 06:09:38.014571: Current learning rate: 0.00566 
2025-12-08 06:11:56.101418: train_loss -0.846 
2025-12-08 06:11:56.101418: val_loss -0.8722 
2025-12-08 06:11:56.105421: Pseudo dice [0.9215, 0.9557, 0.9436] 
2025-12-08 06:11:56.109164: Epoch time: 138.09 s 
2025-12-08 06:11:56.737579:  
2025-12-08 06:11:56.737579: Epoch 470 
2025-12-08 06:11:56.737579: Current learning rate: 0.00565 
2025-12-08 06:14:14.915096: train_loss -0.846 
2025-12-08 06:14:14.916097: val_loss -0.857 
2025-12-08 06:14:14.919597: Pseudo dice [0.9136, 0.9494, 0.9413] 
2025-12-08 06:14:14.923831: Epoch time: 138.18 s 
2025-12-08 06:14:15.712318:  
2025-12-08 06:14:15.712318: Epoch 471 
2025-12-08 06:14:15.712318: Current learning rate: 0.00564 
2025-12-08 06:16:33.792442: train_loss -0.8427 
2025-12-08 06:16:33.794444: val_loss -0.8784 
2025-12-08 06:16:33.796445: Pseudo dice [0.9264, 0.9567, 0.9465] 
2025-12-08 06:16:33.802008: Epoch time: 138.08 s 
2025-12-08 06:16:34.422307:  
2025-12-08 06:16:34.422307: Epoch 472 
2025-12-08 06:16:34.424309: Current learning rate: 0.00563 
2025-12-08 06:18:52.473480: train_loss -0.8443 
2025-12-08 06:18:52.473480: val_loss -0.8626 
2025-12-08 06:18:52.477484: Pseudo dice [0.9185, 0.9497, 0.9421] 
2025-12-08 06:18:52.481488: Epoch time: 138.05 s 
2025-12-08 06:18:53.155477:  
2025-12-08 06:18:53.155477: Epoch 473 
2025-12-08 06:18:53.155477: Current learning rate: 0.00562 
2025-12-08 06:21:11.404872: train_loss -0.8417 
2025-12-08 06:21:11.404872: val_loss -0.8683 
2025-12-08 06:21:11.415123: Pseudo dice [0.9225, 0.9544, 0.9409] 
2025-12-08 06:21:11.417126: Epoch time: 138.27 s 
2025-12-08 06:21:12.092856:  
2025-12-08 06:21:12.092856: Epoch 474 
2025-12-08 06:21:12.110533: Current learning rate: 0.00561 
2025-12-08 06:23:30.216406: train_loss -0.8417 
2025-12-08 06:23:30.218147: val_loss -0.8659 
2025-12-08 06:23:30.222709: Pseudo dice [0.9174, 0.9484, 0.9467] 
2025-12-08 06:23:30.226713: Epoch time: 138.12 s 
2025-12-08 06:23:31.027474:  
2025-12-08 06:23:31.027474: Epoch 475 
2025-12-08 06:23:31.029976: Current learning rate: 0.0056 
2025-12-08 06:25:49.178159: train_loss -0.8383 
2025-12-08 06:25:49.180162: val_loss -0.8611 
2025-12-08 06:25:49.180162: Pseudo dice [0.9191, 0.9528, 0.9384] 
2025-12-08 06:25:49.185809: Epoch time: 138.15 s 
2025-12-08 06:25:49.795794:  
2025-12-08 06:25:49.795794: Epoch 476 
2025-12-08 06:25:49.795794: Current learning rate: 0.00559 
2025-12-08 06:28:07.895010: train_loss -0.8392 
2025-12-08 06:28:07.895010: val_loss -0.8686 
2025-12-08 06:28:07.901016: Pseudo dice [0.9272, 0.9527, 0.9345] 
2025-12-08 06:28:07.905760: Epoch time: 138.1 s 
2025-12-08 06:28:08.592438:  
2025-12-08 06:28:08.592438: Epoch 477 
2025-12-08 06:28:08.599945: Current learning rate: 0.00558 
2025-12-08 06:30:26.872214: train_loss -0.8427 
2025-12-08 06:30:26.872214: val_loss -0.8686 
2025-12-08 06:30:26.878296: Pseudo dice [0.9218, 0.9541, 0.9457] 
2025-12-08 06:30:26.882296: Epoch time: 138.28 s 
2025-12-08 06:30:27.522088:  
2025-12-08 06:30:27.522088: Epoch 478 
2025-12-08 06:30:27.522088: Current learning rate: 0.00557 
2025-12-08 06:32:45.859542: train_loss -0.8424 
2025-12-08 06:32:45.860628: val_loss -0.8639 
2025-12-08 06:32:45.864631: Pseudo dice [0.9198, 0.9506, 0.9447] 
2025-12-08 06:32:45.867632: Epoch time: 138.34 s 
2025-12-08 06:32:46.509107:  
2025-12-08 06:32:46.509107: Epoch 479 
2025-12-08 06:32:46.514996: Current learning rate: 0.00556 
2025-12-08 06:35:04.559544: train_loss -0.8449 
2025-12-08 06:35:04.560546: val_loss -0.8659 
2025-12-08 06:35:04.561548: Pseudo dice [0.9217, 0.9558, 0.9369] 
2025-12-08 06:35:04.567582: Epoch time: 138.05 s 
2025-12-08 06:35:05.265440:  
2025-12-08 06:35:05.265440: Epoch 480 
2025-12-08 06:35:05.268877: Current learning rate: 0.00555 
2025-12-08 06:37:23.378318: train_loss -0.8454 
2025-12-08 06:37:23.380320: val_loss -0.8694 
2025-12-08 06:37:23.384324: Pseudo dice [0.9238, 0.9522, 0.9495] 
2025-12-08 06:37:23.388327: Epoch time: 138.13 s 
2025-12-08 06:37:24.014509:  
2025-12-08 06:37:24.014509: Epoch 481 
2025-12-08 06:37:24.014509: Current learning rate: 0.00554 
2025-12-08 06:39:42.528482: train_loss -0.8376 
2025-12-08 06:39:42.533823: val_loss -0.8647 
2025-12-08 06:39:42.535825: Pseudo dice [0.9162, 0.9492, 0.9422] 
2025-12-08 06:39:42.539829: Epoch time: 138.51 s 
2025-12-08 06:39:43.352092:  
2025-12-08 06:39:43.352092: Epoch 482 
2025-12-08 06:39:43.355803: Current learning rate: 0.00553 
2025-12-08 06:42:01.220183: train_loss -0.8476 
2025-12-08 06:42:01.220183: val_loss -0.8692 
2025-12-08 06:42:01.226191: Pseudo dice [0.9234, 0.9573, 0.9431] 
2025-12-08 06:42:01.226191: Epoch time: 137.87 s 
2025-12-08 06:42:01.958833:  
2025-12-08 06:42:01.959835: Epoch 483 
2025-12-08 06:42:01.963845: Current learning rate: 0.00552 
2025-12-08 06:44:20.088468: train_loss -0.847 
2025-12-08 06:44:20.088468: val_loss -0.8694 
2025-12-08 06:44:20.093950: Pseudo dice [0.9198, 0.9549, 0.9477] 
2025-12-08 06:44:20.097954: Epoch time: 138.13 s 
2025-12-08 06:44:20.739543:  
2025-12-08 06:44:20.740547: Epoch 484 
2025-12-08 06:44:20.740547: Current learning rate: 0.00551 
2025-12-08 06:46:38.985071: train_loss -0.8453 
2025-12-08 06:46:38.985071: val_loss -0.8621 
2025-12-08 06:46:38.989077: Pseudo dice [0.9197, 0.9498, 0.9411] 
2025-12-08 06:46:38.993916: Epoch time: 138.25 s 
2025-12-08 06:46:39.625150:  
2025-12-08 06:46:39.625150: Epoch 485 
2025-12-08 06:46:39.625150: Current learning rate: 0.0055 
2025-12-08 06:48:57.811582: train_loss -0.8416 
2025-12-08 06:48:57.811582: val_loss -0.8657 
2025-12-08 06:48:57.811582: Pseudo dice [0.9184, 0.9534, 0.9436] 
2025-12-08 06:48:57.820384: Epoch time: 138.19 s 
2025-12-08 06:48:58.468880:  
2025-12-08 06:48:58.484672: Epoch 486 
2025-12-08 06:48:58.488679: Current learning rate: 0.00549 
2025-12-08 06:51:16.515791: train_loss -0.843 
2025-12-08 06:51:16.515791: val_loss -0.8694 
2025-12-08 06:51:16.515791: Pseudo dice [0.9235, 0.954, 0.9458] 
2025-12-08 06:51:16.531629: Epoch time: 138.05 s 
2025-12-08 06:51:17.139551:  
2025-12-08 06:51:17.139551: Epoch 487 
2025-12-08 06:51:17.155187: Current learning rate: 0.00548 
2025-12-08 06:53:35.373274: train_loss -0.8436 
2025-12-08 06:53:35.373274: val_loss -0.8714 
2025-12-08 06:53:35.375014: Pseudo dice [0.9236, 0.9561, 0.9455] 
2025-12-08 06:53:35.375014: Epoch time: 138.23 s 
2025-12-08 06:53:36.172153:  
2025-12-08 06:53:36.172153: Epoch 488 
2025-12-08 06:53:36.172153: Current learning rate: 0.00547 
2025-12-08 06:55:54.233932: train_loss -0.8435 
2025-12-08 06:55:54.233932: val_loss -0.861 
2025-12-08 06:55:54.233932: Pseudo dice [0.9175, 0.9514, 0.9412] 
2025-12-08 06:55:54.233932: Epoch time: 138.06 s 
2025-12-08 06:55:54.889833:  
2025-12-08 06:55:54.889833: Epoch 489 
2025-12-08 06:55:54.889833: Current learning rate: 0.00546 
2025-12-08 06:58:12.873818: train_loss -0.8478 
2025-12-08 06:58:12.873818: val_loss -0.8691 
2025-12-08 06:58:12.877962: Pseudo dice [0.922, 0.9524, 0.9447] 
2025-12-08 06:58:12.881966: Epoch time: 137.98 s 
2025-12-08 06:58:13.499788:  
2025-12-08 06:58:13.499788: Epoch 490 
2025-12-08 06:58:13.515759: Current learning rate: 0.00546 
2025-12-08 07:00:31.623969: train_loss -0.8445 
2025-12-08 07:00:31.623969: val_loss -0.8664 
2025-12-08 07:00:31.628327: Pseudo dice [0.9177, 0.9508, 0.9473] 
2025-12-08 07:00:31.632342: Epoch time: 138.12 s 
2025-12-08 07:00:32.265008:  
2025-12-08 07:00:32.265008: Epoch 491 
2025-12-08 07:00:32.265008: Current learning rate: 0.00545 
2025-12-08 07:02:50.344769: train_loss -0.8465 
2025-12-08 07:02:50.344769: val_loss -0.8664 
2025-12-08 07:02:50.358777: Pseudo dice [0.9205, 0.953, 0.9441] 
2025-12-08 07:02:50.360553: Epoch time: 138.08 s 
2025-12-08 07:02:51.015721:  
2025-12-08 07:02:51.015721: Epoch 492 
2025-12-08 07:02:51.015721: Current learning rate: 0.00544 
2025-12-08 07:05:09.149130: train_loss -0.844 
2025-12-08 07:05:09.149130: val_loss -0.8725 
2025-12-08 07:05:09.155099: Pseudo dice [0.9214, 0.9526, 0.9451] 
2025-12-08 07:05:09.156913: Epoch time: 138.14 s 
2025-12-08 07:05:09.779927:  
2025-12-08 07:05:09.779927: Epoch 493 
2025-12-08 07:05:09.779927: Current learning rate: 0.00543 
2025-12-08 07:07:27.968527: train_loss -0.8448 
2025-12-08 07:07:27.968527: val_loss -0.8745 
2025-12-08 07:07:27.986614: Pseudo dice [0.9254, 0.9525, 0.9489] 
2025-12-08 07:07:27.986614: Epoch time: 138.19 s 
2025-12-08 07:07:28.624251:  
2025-12-08 07:07:28.624251: Epoch 494 
2025-12-08 07:07:28.624251: Current learning rate: 0.00542 
2025-12-08 07:09:46.668461: train_loss -0.8442 
2025-12-08 07:09:46.670464: val_loss -0.8701 
2025-12-08 07:09:46.673487: Pseudo dice [0.9238, 0.9571, 0.9448] 
2025-12-08 07:09:46.673487: Epoch time: 138.04 s 
2025-12-08 07:09:46.673487: Yayy! New best EMA pseudo Dice: 0.9396 
2025-12-08 07:09:47.765152:  
2025-12-08 07:09:47.765152: Epoch 495 
2025-12-08 07:09:47.774718: Current learning rate: 0.00541 
2025-12-08 07:12:05.827110: train_loss -0.8456 
2025-12-08 07:12:05.827110: val_loss -0.8703 
2025-12-08 07:12:05.838676: Pseudo dice [0.9206, 0.9487, 0.9497] 
2025-12-08 07:12:05.838676: Epoch time: 138.06 s 
2025-12-08 07:12:05.843058: Yayy! New best EMA pseudo Dice: 0.9396 
2025-12-08 07:12:06.734819:  
2025-12-08 07:12:06.734819: Epoch 496 
2025-12-08 07:12:06.746399: Current learning rate: 0.0054 
2025-12-08 07:14:24.749332: train_loss -0.845 
2025-12-08 07:14:24.749332: val_loss -0.8747 
2025-12-08 07:14:24.765076: Pseudo dice [0.9291, 0.9561, 0.9413] 
2025-12-08 07:14:24.769814: Epoch time: 138.01 s 
2025-12-08 07:14:24.769814: Yayy! New best EMA pseudo Dice: 0.9399 
2025-12-08 07:14:25.703366:  
2025-12-08 07:14:25.703366: Epoch 497 
2025-12-08 07:14:25.703366: Current learning rate: 0.00539 
2025-12-08 07:16:43.809098: train_loss -0.8427 
2025-12-08 07:16:43.809098: val_loss -0.8734 
2025-12-08 07:16:43.811103: Pseudo dice [0.9235, 0.9532, 0.9454] 
2025-12-08 07:16:43.811103: Epoch time: 138.11 s 
2025-12-08 07:16:43.811103: Yayy! New best EMA pseudo Dice: 0.9399 
2025-12-08 07:16:44.723553:  
2025-12-08 07:16:44.725555: Epoch 498 
2025-12-08 07:16:44.725555: Current learning rate: 0.00538 
2025-12-08 07:19:02.798606: train_loss -0.839 
2025-12-08 07:19:02.798606: val_loss -0.8727 
2025-12-08 07:19:02.804612: Pseudo dice [0.9214, 0.9554, 0.9484] 
2025-12-08 07:19:02.808616: Epoch time: 138.08 s 
2025-12-08 07:19:02.814360: Yayy! New best EMA pseudo Dice: 0.9401 
2025-12-08 07:19:03.732311:  
2025-12-08 07:19:03.732311: Epoch 499 
2025-12-08 07:19:03.732311: Current learning rate: 0.00537 
2025-12-08 07:21:21.779516: train_loss -0.8455 
2025-12-08 07:21:21.779516: val_loss -0.8595 
2025-12-08 07:21:21.785523: Pseudo dice [0.9145, 0.9464, 0.9446] 
2025-12-08 07:21:21.789438: Epoch time: 138.05 s 
2025-12-08 07:21:22.867194:  
2025-12-08 07:21:22.868194: Epoch 500 
2025-12-08 07:21:22.872492: Current learning rate: 0.00536 
2025-12-08 07:23:40.958572: train_loss -0.8457 
2025-12-08 07:23:40.958572: val_loss -0.8658 
2025-12-08 07:23:40.963588: Pseudo dice [0.9197, 0.9511, 0.9519] 
2025-12-08 07:23:40.967606: Epoch time: 138.09 s 
2025-12-08 07:23:41.627552:  
2025-12-08 07:23:41.627552: Epoch 501 
2025-12-08 07:23:41.629555: Current learning rate: 0.00535 
2025-12-08 07:25:59.903878: train_loss -0.8442 
2025-12-08 07:25:59.903878: val_loss -0.8784 
2025-12-08 07:25:59.907884: Pseudo dice [0.9237, 0.9609, 0.9474] 
2025-12-08 07:25:59.911888: Epoch time: 138.28 s 
2025-12-08 07:25:59.917894: Yayy! New best EMA pseudo Dice: 0.9402 
2025-12-08 07:26:00.821723:  
2025-12-08 07:26:00.821723: Epoch 502 
2025-12-08 07:26:00.826736: Current learning rate: 0.00534 
2025-12-08 07:28:18.991899: train_loss -0.8359 
2025-12-08 07:28:18.991899: val_loss -0.8652 
2025-12-08 07:28:18.997905: Pseudo dice [0.9205, 0.9521, 0.9424] 
2025-12-08 07:28:19.001648: Epoch time: 138.17 s 
2025-12-08 07:28:19.639965:  
2025-12-08 07:28:19.639965: Epoch 503 
2025-12-08 07:28:19.639965: Current learning rate: 0.00533 
2025-12-08 07:30:37.744917: train_loss -0.8401 
2025-12-08 07:30:37.745919: val_loss -0.8718 
2025-12-08 07:30:37.748929: Pseudo dice [0.9215, 0.9538, 0.9484] 
2025-12-08 07:30:37.748929: Epoch time: 138.1 s 
2025-12-08 07:30:38.404575:  
2025-12-08 07:30:38.405580: Epoch 504 
2025-12-08 07:30:38.405580: Current learning rate: 0.00532 
2025-12-08 07:32:56.519256: train_loss -0.8461 
2025-12-08 07:32:56.519256: val_loss -0.869 
2025-12-08 07:32:56.525262: Pseudo dice [0.9205, 0.9538, 0.946] 
2025-12-08 07:32:56.531327: Epoch time: 138.12 s 
2025-12-08 07:32:57.155596:  
2025-12-08 07:32:57.155596: Epoch 505 
2025-12-08 07:32:57.164142: Current learning rate: 0.00531 
2025-12-08 07:35:15.372190: train_loss -0.8441 
2025-12-08 07:35:15.372190: val_loss -0.8717 
2025-12-08 07:35:15.380202: Pseudo dice [0.9211, 0.9522, 0.9502] 
2025-12-08 07:35:15.383271: Epoch time: 138.22 s 
2025-12-08 07:35:15.387139: Yayy! New best EMA pseudo Dice: 0.9402 
2025-12-08 07:35:16.477893:  
2025-12-08 07:35:16.479896: Epoch 506 
2025-12-08 07:35:16.483655: Current learning rate: 0.0053 
2025-12-08 07:37:34.585011: train_loss -0.8465 
2025-12-08 07:37:34.586011: val_loss -0.8751 
2025-12-08 07:37:34.592012: Pseudo dice [0.9259, 0.9573, 0.9471] 
2025-12-08 07:37:34.595326: Epoch time: 138.11 s 
2025-12-08 07:37:34.600327: Yayy! New best EMA pseudo Dice: 0.9405 
2025-12-08 07:37:35.656071:  
2025-12-08 07:37:35.656071: Epoch 507 
2025-12-08 07:37:35.656071: Current learning rate: 0.00529 
2025-12-08 07:39:53.605713: train_loss -0.8516 
2025-12-08 07:39:53.605713: val_loss -0.8725 
2025-12-08 07:39:53.609458: Pseudo dice [0.9216, 0.9571, 0.9455] 
2025-12-08 07:39:53.614959: Epoch time: 137.95 s 
2025-12-08 07:39:53.618963: Yayy! New best EMA pseudo Dice: 0.9406 
2025-12-08 07:39:54.530602:  
2025-12-08 07:39:54.530602: Epoch 508 
2025-12-08 07:39:54.530602: Current learning rate: 0.00528 
2025-12-08 07:42:12.578354: train_loss -0.8471 
2025-12-08 07:42:12.578354: val_loss -0.8683 
2025-12-08 07:42:12.593941: Pseudo dice [0.9149, 0.953, 0.9488] 
2025-12-08 07:42:12.593941: Epoch time: 138.06 s 
2025-12-08 07:42:13.233741:  
2025-12-08 07:42:13.233741: Epoch 509 
2025-12-08 07:42:13.233741: Current learning rate: 0.00527 
2025-12-08 07:44:31.203125: train_loss -0.8462 
2025-12-08 07:44:31.203125: val_loss -0.884 
2025-12-08 07:44:31.208144: Pseudo dice [0.9321, 0.957, 0.9488] 
2025-12-08 07:44:31.212155: Epoch time: 137.97 s 
2025-12-08 07:44:31.216165: Yayy! New best EMA pseudo Dice: 0.941 
2025-12-08 07:44:32.220291:  
2025-12-08 07:44:32.221303: Epoch 510 
2025-12-08 07:44:32.225307: Current learning rate: 0.00526 
2025-12-08 07:46:50.330163: train_loss -0.8476 
2025-12-08 07:46:50.330163: val_loss -0.8743 
2025-12-08 07:46:50.342403: Pseudo dice [0.9234, 0.956, 0.9503] 
2025-12-08 07:46:50.342403: Epoch time: 138.11 s 
2025-12-08 07:46:50.342403: Yayy! New best EMA pseudo Dice: 0.9412 
2025-12-08 07:46:51.249294:  
2025-12-08 07:46:51.249294: Epoch 511 
2025-12-08 07:46:51.249294: Current learning rate: 0.00525 
2025-12-08 07:49:09.315890: train_loss -0.8325 
2025-12-08 07:49:09.316895: val_loss -0.849 
2025-12-08 07:49:09.321898: Pseudo dice [0.913, 0.9424, 0.9373] 
2025-12-08 07:49:09.325898: Epoch time: 138.07 s 
2025-12-08 07:49:10.124212:  
2025-12-08 07:49:10.124212: Epoch 512 
2025-12-08 07:49:10.124212: Current learning rate: 0.00524 
2025-12-08 07:51:28.293964: train_loss -0.829 
2025-12-08 07:51:28.295705: val_loss -0.8596 
2025-12-08 07:51:28.301713: Pseudo dice [0.9124, 0.948, 0.9465] 
2025-12-08 07:51:28.305718: Epoch time: 138.17 s 
2025-12-08 07:51:29.046477:  
2025-12-08 07:51:29.046477: Epoch 513 
2025-12-08 07:51:29.046477: Current learning rate: 0.00523 
2025-12-08 07:53:47.156377: train_loss -0.8393 
2025-12-08 07:53:47.156377: val_loss -0.8636 
2025-12-08 07:53:47.156377: Pseudo dice [0.9218, 0.9518, 0.9449] 
2025-12-08 07:53:47.172035: Epoch time: 138.11 s 
2025-12-08 07:53:47.781952:  
2025-12-08 07:53:47.781952: Epoch 514 
2025-12-08 07:53:47.801920: Current learning rate: 0.00522 
2025-12-08 07:56:05.780976: train_loss -0.8378 
2025-12-08 07:56:05.780976: val_loss -0.8594 
2025-12-08 07:56:05.796868: Pseudo dice [0.9169, 0.9455, 0.9451] 
2025-12-08 07:56:05.796868: Epoch time: 138.0 s 
2025-12-08 07:56:06.428741:  
2025-12-08 07:56:06.428741: Epoch 515 
2025-12-08 07:56:06.433755: Current learning rate: 0.00521 
2025-12-08 07:58:24.617564: train_loss -0.8354 
2025-12-08 07:58:24.617564: val_loss -0.8599 
2025-12-08 07:58:24.623571: Pseudo dice [0.9194, 0.9554, 0.9325] 
2025-12-08 07:58:24.625312: Epoch time: 138.19 s 
2025-12-08 07:58:25.388320:  
2025-12-08 07:58:25.388320: Epoch 516 
2025-12-08 07:58:25.393124: Current learning rate: 0.0052 
2025-12-08 08:00:43.592191: train_loss -0.8393 
2025-12-08 08:00:43.592191: val_loss -0.8647 
2025-12-08 08:00:43.592191: Pseudo dice [0.9184, 0.9501, 0.9459] 
2025-12-08 08:00:43.592191: Epoch time: 138.21 s 
2025-12-08 08:00:44.266498:  
2025-12-08 08:00:44.266498: Epoch 517 
2025-12-08 08:00:44.266498: Current learning rate: 0.00519 
2025-12-08 08:03:02.467193: train_loss -0.8408 
2025-12-08 08:03:02.467193: val_loss -0.8686 
2025-12-08 08:03:02.482886: Pseudo dice [0.9202, 0.9492, 0.9459] 
2025-12-08 08:03:02.482886: Epoch time: 138.2 s 
2025-12-08 08:03:03.279865:  
2025-12-08 08:03:03.279865: Epoch 518 
2025-12-08 08:03:03.279865: Current learning rate: 0.00518 
2025-12-08 08:05:21.437251: train_loss -0.8422 
2025-12-08 08:05:21.437251: val_loss -0.8669 
2025-12-08 08:05:21.457336: Pseudo dice [0.9184, 0.9501, 0.9461] 
2025-12-08 08:05:21.461340: Epoch time: 138.16 s 
2025-12-08 08:05:22.187038:  
2025-12-08 08:05:22.187038: Epoch 519 
2025-12-08 08:05:22.187038: Current learning rate: 0.00518 
2025-12-08 08:07:40.173646: train_loss -0.8441 
2025-12-08 08:07:40.175648: val_loss -0.8673 
2025-12-08 08:07:40.179652: Pseudo dice [0.922, 0.9541, 0.9421] 
2025-12-08 08:07:40.183656: Epoch time: 137.99 s 
2025-12-08 08:07:40.811400:  
2025-12-08 08:07:40.811400: Epoch 520 
2025-12-08 08:07:40.811400: Current learning rate: 0.00517 
2025-12-08 08:09:59.019669: train_loss -0.8366 
2025-12-08 08:09:59.021672: val_loss -0.8625 
2025-12-08 08:09:59.026502: Pseudo dice [0.9174, 0.9522, 0.9386] 
2025-12-08 08:09:59.028505: Epoch time: 138.21 s 
2025-12-08 08:09:59.655467:  
2025-12-08 08:09:59.655467: Epoch 521 
2025-12-08 08:09:59.671438: Current learning rate: 0.00516 
2025-12-08 08:12:17.592239: train_loss -0.8467 
2025-12-08 08:12:17.592239: val_loss -0.8745 
2025-12-08 08:12:17.593979: Pseudo dice [0.9233, 0.9556, 0.9477] 
2025-12-08 08:12:17.593979: Epoch time: 137.94 s 
2025-12-08 08:12:18.233467:  
2025-12-08 08:12:18.233467: Epoch 522 
2025-12-08 08:12:18.233467: Current learning rate: 0.00515 
2025-12-08 08:14:36.499630: train_loss -0.844 
2025-12-08 08:14:36.499630: val_loss -0.8603 
2025-12-08 08:14:36.505805: Pseudo dice [0.9164, 0.9517, 0.9364] 
2025-12-08 08:14:36.509806: Epoch time: 138.27 s 
2025-12-08 08:14:37.140701:  
2025-12-08 08:14:37.140701: Epoch 523 
2025-12-08 08:14:37.140701: Current learning rate: 0.00514 
2025-12-08 08:16:55.165982: train_loss -0.8401 
2025-12-08 08:16:55.166982: val_loss -0.8511 
2025-12-08 08:16:55.170983: Pseudo dice [0.9099, 0.9452, 0.9417] 
2025-12-08 08:16:55.170983: Epoch time: 138.03 s 
2025-12-08 08:16:55.983569:  
2025-12-08 08:16:55.983569: Epoch 524 
2025-12-08 08:16:55.999230: Current learning rate: 0.00513 
2025-12-08 08:19:14.028756: train_loss -0.8465 
2025-12-08 08:19:14.030498: val_loss -0.8726 
2025-12-08 08:19:14.035598: Pseudo dice [0.9234, 0.9576, 0.9457] 
2025-12-08 08:19:14.039614: Epoch time: 138.05 s 
2025-12-08 08:19:14.701984:  
2025-12-08 08:19:14.701984: Epoch 525 
2025-12-08 08:19:14.701984: Current learning rate: 0.00512 
2025-12-08 08:21:32.860739: train_loss -0.8464 
2025-12-08 08:21:32.860739: val_loss -0.8563 
2025-12-08 08:21:32.870755: Pseudo dice [0.91, 0.9483, 0.9471] 
2025-12-08 08:21:32.874529: Epoch time: 138.16 s 
2025-12-08 08:21:33.514123:  
2025-12-08 08:21:33.514123: Epoch 526 
2025-12-08 08:21:33.514123: Current learning rate: 0.00511 
2025-12-08 08:23:51.810933: train_loss -0.8451 
2025-12-08 08:23:51.810933: val_loss -0.8715 
2025-12-08 08:23:51.810933: Pseudo dice [0.9232, 0.9525, 0.948] 
2025-12-08 08:23:51.810933: Epoch time: 138.3 s 
2025-12-08 08:23:52.448523:  
2025-12-08 08:23:52.448523: Epoch 527 
2025-12-08 08:23:52.451529: Current learning rate: 0.0051 
2025-12-08 08:26:10.549318: train_loss -0.8452 
2025-12-08 08:26:10.551320: val_loss -0.8641 
2025-12-08 08:26:10.559069: Pseudo dice [0.9162, 0.9493, 0.9437] 
2025-12-08 08:26:10.565076: Epoch time: 138.1 s 
2025-12-08 08:26:11.203157:  
2025-12-08 08:26:11.203157: Epoch 528 
2025-12-08 08:26:11.203157: Current learning rate: 0.00509 
2025-12-08 08:28:29.396263: train_loss -0.8446 
2025-12-08 08:28:29.396263: val_loss -0.8686 
2025-12-08 08:28:29.400267: Pseudo dice [0.922, 0.9567, 0.941] 
2025-12-08 08:28:29.406011: Epoch time: 138.19 s 
2025-12-08 08:28:30.031121:  
2025-12-08 08:28:30.031121: Epoch 529 
2025-12-08 08:28:30.031121: Current learning rate: 0.00508 
2025-12-08 08:30:48.144091: train_loss -0.845 
2025-12-08 08:30:48.144091: val_loss -0.8708 
2025-12-08 08:30:48.150098: Pseudo dice [0.923, 0.9556, 0.944] 
2025-12-08 08:30:48.154102: Epoch time: 138.11 s 
2025-12-08 08:30:49.000961:  
2025-12-08 08:30:49.000961: Epoch 530 
2025-12-08 08:30:49.000961: Current learning rate: 0.00507 
2025-12-08 08:33:07.213083: train_loss -0.8424 
2025-12-08 08:33:07.217677: val_loss -0.876 
2025-12-08 08:33:07.221500: Pseudo dice [0.9265, 0.9565, 0.9507] 
2025-12-08 08:33:07.226982: Epoch time: 138.21 s 
2025-12-08 08:33:07.857776:  
2025-12-08 08:33:07.857776: Epoch 531 
2025-12-08 08:33:07.873434: Current learning rate: 0.00506 
2025-12-08 08:35:25.929753: train_loss -0.8516 
2025-12-08 08:35:25.929753: val_loss -0.8754 
2025-12-08 08:35:25.934765: Pseudo dice [0.9246, 0.9568, 0.9467] 
2025-12-08 08:35:25.936770: Epoch time: 138.07 s 
2025-12-08 08:35:26.608288:  
2025-12-08 08:35:26.608288: Epoch 532 
2025-12-08 08:35:26.623954: Current learning rate: 0.00505 
2025-12-08 08:37:44.748628: train_loss -0.8498 
2025-12-08 08:37:44.748628: val_loss -0.8617 
2025-12-08 08:37:44.764560: Pseudo dice [0.915, 0.9501, 0.9444] 
2025-12-08 08:37:44.764560: Epoch time: 138.14 s 
2025-12-08 08:37:45.543654:  
2025-12-08 08:37:45.545041: Epoch 533 
2025-12-08 08:37:45.546044: Current learning rate: 0.00504 
2025-12-08 08:40:03.717402: train_loss -0.8433 
2025-12-08 08:40:03.717402: val_loss -0.8642 
2025-12-08 08:40:03.723543: Pseudo dice [0.915, 0.9496, 0.9428] 
2025-12-08 08:40:03.729116: Epoch time: 138.17 s 
2025-12-08 08:40:04.393683:  
2025-12-08 08:40:04.395101: Epoch 534 
2025-12-08 08:40:04.399103: Current learning rate: 0.00503 
2025-12-08 08:42:22.577264: train_loss -0.8446 
2025-12-08 08:42:22.577264: val_loss -0.8727 
2025-12-08 08:42:22.582350: Pseudo dice [0.9249, 0.9577, 0.9439] 
2025-12-08 08:42:22.588140: Epoch time: 138.18 s 
2025-12-08 08:42:23.220554:  
2025-12-08 08:42:23.220554: Epoch 535 
2025-12-08 08:42:23.224564: Current learning rate: 0.00502 
2025-12-08 08:44:41.353803: train_loss -0.8449 
2025-12-08 08:44:41.353803: val_loss -0.8812 
2025-12-08 08:44:41.359549: Pseudo dice [0.9295, 0.9612, 0.9465] 
2025-12-08 08:44:41.369564: Epoch time: 138.13 s 
2025-12-08 08:44:42.342937:  
2025-12-08 08:44:42.342937: Epoch 536 
2025-12-08 08:44:42.342937: Current learning rate: 0.00501 
2025-12-08 08:47:00.470068: train_loss -0.851 
2025-12-08 08:47:00.472069: val_loss -0.8726 
2025-12-08 08:47:00.478954: Pseudo dice [0.9217, 0.9528, 0.944] 
2025-12-08 08:47:00.481955: Epoch time: 138.13 s 
2025-12-08 08:47:01.157351:  
2025-12-08 08:47:01.157351: Epoch 537 
2025-12-08 08:47:01.157351: Current learning rate: 0.005 
2025-12-08 08:49:19.275853: train_loss -0.8485 
2025-12-08 08:49:19.275853: val_loss -0.8703 
2025-12-08 08:49:19.280433: Pseudo dice [0.9223, 0.951, 0.9459] 
2025-12-08 08:49:19.280433: Epoch time: 138.12 s 
2025-12-08 08:49:19.915541:  
2025-12-08 08:49:19.915541: Epoch 538 
2025-12-08 08:49:19.921118: Current learning rate: 0.00499 
2025-12-08 08:51:38.108196: train_loss -0.8477 
2025-12-08 08:51:38.108196: val_loss -0.8689 
2025-12-08 08:51:38.114202: Pseudo dice [0.9203, 0.9553, 0.9462] 
2025-12-08 08:51:38.120212: Epoch time: 138.19 s 
2025-12-08 08:51:38.936848:  
2025-12-08 08:51:38.936848: Epoch 539 
2025-12-08 08:51:38.942354: Current learning rate: 0.00498 
2025-12-08 08:53:57.042389: train_loss -0.8452 
2025-12-08 08:53:57.042389: val_loss -0.8769 
2025-12-08 08:53:57.049382: Pseudo dice [0.9255, 0.9529, 0.9519] 
2025-12-08 08:53:57.058384: Epoch time: 138.11 s 
2025-12-08 08:53:57.697227:  
2025-12-08 08:53:57.697227: Epoch 540 
2025-12-08 08:53:57.702594: Current learning rate: 0.00497 
2025-12-08 08:56:15.749310: train_loss -0.85 
2025-12-08 08:56:15.749310: val_loss -0.8761 
2025-12-08 08:56:15.765157: Pseudo dice [0.9259, 0.9586, 0.9458] 
2025-12-08 08:56:15.765157: Epoch time: 138.05 s 
2025-12-08 08:56:16.395381:  
2025-12-08 08:56:16.395381: Epoch 541 
2025-12-08 08:56:16.399394: Current learning rate: 0.00496 
2025-12-08 08:58:34.612226: train_loss -0.8521 
2025-12-08 08:58:34.612226: val_loss -0.8785 
2025-12-08 08:58:34.618232: Pseudo dice [0.9304, 0.9574, 0.9481] 
2025-12-08 08:58:34.623977: Epoch time: 138.22 s 
2025-12-08 08:58:35.286827:  
2025-12-08 08:58:35.287832: Epoch 542 
2025-12-08 08:58:35.291848: Current learning rate: 0.00495 
2025-12-08 09:00:53.295754: train_loss -0.8471 
2025-12-08 09:00:53.295754: val_loss -0.8598 
2025-12-08 09:00:53.308195: Pseudo dice [0.9145, 0.9441, 0.951] 
2025-12-08 09:00:53.313702: Epoch time: 138.01 s 
2025-12-08 09:00:54.109309:  
2025-12-08 09:00:54.109309: Epoch 543 
2025-12-08 09:00:54.109309: Current learning rate: 0.00494 
2025-12-08 09:03:12.248769: train_loss -0.8503 
2025-12-08 09:03:12.251712: val_loss -0.8711 
2025-12-08 09:03:12.256013: Pseudo dice [0.9229, 0.9557, 0.9423] 
2025-12-08 09:03:12.260017: Epoch time: 138.14 s 
2025-12-08 09:03:12.903055:  
2025-12-08 09:03:12.904058: Epoch 544 
2025-12-08 09:03:12.905076: Current learning rate: 0.00493 
2025-12-08 09:05:30.829271: train_loss -0.8484 
2025-12-08 09:05:30.829271: val_loss -0.866 
2025-12-08 09:05:30.835278: Pseudo dice [0.9203, 0.9514, 0.9394] 
2025-12-08 09:05:30.841283: Epoch time: 137.93 s 
2025-12-08 09:05:31.468428:  
2025-12-08 09:05:31.468428: Epoch 545 
2025-12-08 09:05:31.484177: Current learning rate: 0.00492 
2025-12-08 09:07:49.634703: train_loss -0.8436 
2025-12-08 09:07:49.635703: val_loss -0.8623 
2025-12-08 09:07:49.640704: Pseudo dice [0.9184, 0.9551, 0.9356] 
2025-12-08 09:07:49.644815: Epoch time: 138.17 s 
2025-12-08 09:07:50.428660:  
2025-12-08 09:07:50.428660: Epoch 546 
2025-12-08 09:07:50.433683: Current learning rate: 0.00491 
2025-12-08 09:10:08.622172: train_loss -0.842 
2025-12-08 09:10:08.622172: val_loss -0.8668 
2025-12-08 09:10:08.627962: Pseudo dice [0.919, 0.9554, 0.9496] 
2025-12-08 09:10:08.631966: Epoch time: 138.2 s 
2025-12-08 09:10:09.271993:  
2025-12-08 09:10:09.271993: Epoch 547 
2025-12-08 09:10:09.271993: Current learning rate: 0.0049 
2025-12-08 09:12:27.376120: train_loss -0.8478 
2025-12-08 09:12:27.378122: val_loss -0.8828 
2025-12-08 09:12:27.384128: Pseudo dice [0.9293, 0.9601, 0.9446] 
2025-12-08 09:12:27.388132: Epoch time: 138.11 s 
2025-12-08 09:12:28.025664:  
2025-12-08 09:12:28.026669: Epoch 548 
2025-12-08 09:12:28.030237: Current learning rate: 0.00489 
2025-12-08 09:14:46.187159: train_loss -0.8482 
2025-12-08 09:14:46.187159: val_loss -0.8685 
2025-12-08 09:14:46.202865: Pseudo dice [0.9207, 0.9523, 0.9438] 
2025-12-08 09:14:46.207516: Epoch time: 138.16 s 
2025-12-08 09:14:47.000050:  
2025-12-08 09:14:47.000050: Epoch 549 
2025-12-08 09:14:47.005127: Current learning rate: 0.00488 
2025-12-08 09:17:05.342887: train_loss -0.848 
2025-12-08 09:17:05.342887: val_loss -0.8684 
2025-12-08 09:17:05.342887: Pseudo dice [0.9206, 0.9549, 0.9471] 
2025-12-08 09:17:05.358592: Epoch time: 138.36 s 
2025-12-08 09:17:06.291917:  
2025-12-08 09:17:06.291917: Epoch 550 
2025-12-08 09:17:06.296480: Current learning rate: 0.00487 
2025-12-08 09:19:24.514457: train_loss -0.8459 
2025-12-08 09:19:24.516198: val_loss -0.8704 
2025-12-08 09:19:24.522381: Pseudo dice [0.9229, 0.9532, 0.9429] 
2025-12-08 09:19:24.527382: Epoch time: 138.22 s 
2025-12-08 09:19:25.173270:  
2025-12-08 09:19:25.173270: Epoch 551 
2025-12-08 09:19:25.177623: Current learning rate: 0.00486 
2025-12-08 09:21:43.368073: train_loss -0.848 
2025-12-08 09:21:43.368073: val_loss -0.8708 
2025-12-08 09:21:43.374151: Pseudo dice [0.9203, 0.9533, 0.9471] 
2025-12-08 09:21:43.378160: Epoch time: 138.2 s 
2025-12-08 09:21:44.082054:  
2025-12-08 09:21:44.082054: Epoch 552 
2025-12-08 09:21:44.087073: Current learning rate: 0.00485 
2025-12-08 09:24:02.249671: train_loss -0.8507 
2025-12-08 09:24:02.249671: val_loss -0.864 
2025-12-08 09:24:02.249671: Pseudo dice [0.9162, 0.9477, 0.9472] 
2025-12-08 09:24:02.265309: Epoch time: 138.17 s 
2025-12-08 09:24:02.890312:  
2025-12-08 09:24:02.890312: Epoch 553 
2025-12-08 09:24:02.890312: Current learning rate: 0.00484 
2025-12-08 09:26:21.017901: train_loss -0.8475 
2025-12-08 09:26:21.018901: val_loss -0.8783 
2025-12-08 09:26:21.024902: Pseudo dice [0.9284, 0.9552, 0.9477] 
2025-12-08 09:26:21.029904: Epoch time: 138.13 s 
2025-12-08 09:26:21.671298:  
2025-12-08 09:26:21.671298: Epoch 554 
2025-12-08 09:26:21.676367: Current learning rate: 0.00484 
2025-12-08 09:28:39.882823: train_loss -0.8444 
2025-12-08 09:28:39.884825: val_loss -0.8764 
2025-12-08 09:28:39.893783: Pseudo dice [0.9267, 0.9519, 0.9484] 
2025-12-08 09:28:39.897784: Epoch time: 138.23 s 
2025-12-08 09:28:40.696256:  
2025-12-08 09:28:40.697262: Epoch 555 
2025-12-08 09:28:40.700921: Current learning rate: 0.00483 
2025-12-08 09:30:58.788129: train_loss -0.8485 
2025-12-08 09:30:58.788129: val_loss -0.8703 
2025-12-08 09:30:58.795877: Pseudo dice [0.9208, 0.9535, 0.9437] 
2025-12-08 09:30:58.801897: Epoch time: 138.09 s 
2025-12-08 09:30:59.436984:  
2025-12-08 09:30:59.436984: Epoch 556 
2025-12-08 09:30:59.454298: Current learning rate: 0.00482 
2025-12-08 09:33:17.633950: train_loss -0.8497 
2025-12-08 09:33:17.633950: val_loss -0.8678 
2025-12-08 09:33:17.639956: Pseudo dice [0.9168, 0.9538, 0.9464] 
2025-12-08 09:33:17.643548: Epoch time: 138.2 s 
2025-12-08 09:33:18.285843:  
2025-12-08 09:33:18.285843: Epoch 557 
2025-12-08 09:33:18.285843: Current learning rate: 0.00481 
2025-12-08 09:35:36.608333: train_loss -0.8452 
2025-12-08 09:35:36.608333: val_loss -0.8697 
2025-12-08 09:35:36.613949: Pseudo dice [0.9212, 0.9504, 0.9456] 
2025-12-08 09:35:36.617953: Epoch time: 138.32 s 
2025-12-08 09:35:37.308359:  
2025-12-08 09:35:37.308359: Epoch 558 
2025-12-08 09:35:37.312446: Current learning rate: 0.0048 
2025-12-08 09:37:55.438079: train_loss -0.853 
2025-12-08 09:37:55.438079: val_loss -0.8748 
2025-12-08 09:37:55.451584: Pseudo dice [0.9281, 0.9572, 0.9429] 
2025-12-08 09:37:55.456745: Epoch time: 138.13 s 
2025-12-08 09:37:56.092868:  
2025-12-08 09:37:56.094871: Epoch 559 
2025-12-08 09:37:56.094871: Current learning rate: 0.00479 
2025-12-08 09:40:14.254556: train_loss -0.8392 
2025-12-08 09:40:14.256562: val_loss -0.8709 
2025-12-08 09:40:14.262572: Pseudo dice [0.9207, 0.9505, 0.9477] 
2025-12-08 09:40:14.270086: Epoch time: 138.16 s 
2025-12-08 09:40:14.910752:  
2025-12-08 09:40:14.910752: Epoch 560 
2025-12-08 09:40:14.910752: Current learning rate: 0.00478 
2025-12-08 09:42:33.014987: train_loss -0.8504 
2025-12-08 09:42:33.014987: val_loss -0.8782 
2025-12-08 09:42:33.024507: Pseudo dice [0.9286, 0.9575, 0.9415] 
2025-12-08 09:42:33.030513: Epoch time: 138.1 s 
2025-12-08 09:42:33.838246:  
2025-12-08 09:42:33.838246: Epoch 561 
2025-12-08 09:42:33.842721: Current learning rate: 0.00477 
2025-12-08 09:44:52.078267: train_loss -0.8453 
2025-12-08 09:44:52.078267: val_loss -0.8744 
2025-12-08 09:44:52.085787: Pseudo dice [0.9226, 0.9567, 0.949] 
2025-12-08 09:44:52.089792: Epoch time: 138.24 s 
2025-12-08 09:44:52.718794:  
2025-12-08 09:44:52.718794: Epoch 562 
2025-12-08 09:44:52.718794: Current learning rate: 0.00476 
2025-12-08 09:47:10.977910: train_loss -0.8442 
2025-12-08 09:47:10.979913: val_loss -0.8766 
2025-12-08 09:47:10.985657: Pseudo dice [0.9275, 0.9545, 0.9461] 
2025-12-08 09:47:10.993668: Epoch time: 138.26 s 
2025-12-08 09:47:11.640536:  
2025-12-08 09:47:11.640536: Epoch 563 
2025-12-08 09:47:11.640536: Current learning rate: 0.00475 
2025-12-08 09:49:29.864729: train_loss -0.8462 
2025-12-08 09:49:29.864729: val_loss -0.876 
2025-12-08 09:49:29.869737: Pseudo dice [0.926, 0.9516, 0.9466] 
2025-12-08 09:49:29.873739: Epoch time: 138.22 s 
2025-12-08 09:49:30.500667:  
2025-12-08 09:49:30.500667: Epoch 564 
2025-12-08 09:49:30.500667: Current learning rate: 0.00474 
2025-12-08 09:51:48.814432: train_loss -0.8394 
2025-12-08 09:51:48.814432: val_loss -0.8628 
2025-12-08 09:51:48.820441: Pseudo dice [0.9178, 0.9504, 0.9421] 
2025-12-08 09:51:48.824448: Epoch time: 138.31 s 
2025-12-08 09:51:49.640462:  
2025-12-08 09:51:49.640462: Epoch 565 
2025-12-08 09:51:49.644622: Current learning rate: 0.00473 
2025-12-08 09:54:07.780750: train_loss -0.8501 
2025-12-08 09:54:07.780750: val_loss -0.8792 
2025-12-08 09:54:07.796628: Pseudo dice [0.9316, 0.9565, 0.9423] 
2025-12-08 09:54:07.800516: Epoch time: 138.16 s 
2025-12-08 09:54:08.420606:  
2025-12-08 09:54:08.420606: Epoch 566 
2025-12-08 09:54:08.436584: Current learning rate: 0.00472 
2025-12-08 09:56:26.640449: train_loss -0.8461 
2025-12-08 09:56:26.640449: val_loss -0.8702 
2025-12-08 09:56:26.646455: Pseudo dice [0.9221, 0.9525, 0.9493] 
2025-12-08 09:56:26.650459: Epoch time: 138.22 s 
2025-12-08 09:56:27.297971:  
2025-12-08 09:56:27.297971: Epoch 567 
2025-12-08 09:56:27.297971: Current learning rate: 0.00471 
2025-12-08 09:58:45.562676: train_loss -0.8514 
2025-12-08 09:58:45.562676: val_loss -0.8766 
2025-12-08 09:58:45.571089: Pseudo dice [0.9264, 0.9567, 0.947] 
2025-12-08 09:58:45.575096: Epoch time: 138.27 s 
2025-12-08 09:58:46.546638:  
2025-12-08 09:58:46.546638: Epoch 568 
2025-12-08 09:58:46.559893: Current learning rate: 0.0047 
2025-12-08 10:01:04.826621: train_loss -0.8472 
2025-12-08 10:01:04.826621: val_loss -0.8567 
2025-12-08 10:01:04.837887: Pseudo dice [0.9144, 0.9494, 0.9393] 
2025-12-08 10:01:04.841891: Epoch time: 138.28 s 
2025-12-08 10:01:05.490356:  
2025-12-08 10:01:05.490356: Epoch 569 
2025-12-08 10:01:05.490356: Current learning rate: 0.00469 
2025-12-08 10:03:23.641619: train_loss -0.845 
2025-12-08 10:03:23.642621: val_loss -0.8753 
2025-12-08 10:03:23.647629: Pseudo dice [0.925, 0.9572, 0.9455] 
2025-12-08 10:03:23.651780: Epoch time: 138.15 s 
2025-12-08 10:03:24.297075:  
2025-12-08 10:03:24.298077: Epoch 570 
2025-12-08 10:03:24.302111: Current learning rate: 0.00468 
2025-12-08 10:05:42.391172: train_loss -0.8483 
2025-12-08 10:05:42.392175: val_loss -0.8776 
2025-12-08 10:05:42.396192: Pseudo dice [0.9238, 0.9568, 0.9465] 
2025-12-08 10:05:42.400202: Epoch time: 138.1 s 
2025-12-08 10:05:43.116364:  
2025-12-08 10:05:43.116364: Epoch 571 
2025-12-08 10:05:43.121372: Current learning rate: 0.00467 
2025-12-08 10:08:01.177659: train_loss -0.848 
2025-12-08 10:08:01.178661: val_loss -0.8739 
2025-12-08 10:08:01.182663: Pseudo dice [0.9229, 0.9532, 0.949] 
2025-12-08 10:08:01.185816: Epoch time: 138.06 s 
2025-12-08 10:08:01.814438:  
2025-12-08 10:08:01.815843: Epoch 572 
2025-12-08 10:08:01.819846: Current learning rate: 0.00466 
2025-12-08 10:10:19.952151: train_loss -0.8474 
2025-12-08 10:10:19.952151: val_loss -0.8706 
2025-12-08 10:10:19.968020: Pseudo dice [0.9229, 0.9553, 0.9489] 
2025-12-08 10:10:19.973167: Epoch time: 138.14 s 
2025-12-08 10:10:20.641559:  
2025-12-08 10:10:20.641559: Epoch 573 
2025-12-08 10:10:20.655317: Current learning rate: 0.00465 
2025-12-08 10:12:39.846951: train_loss -0.8478 
2025-12-08 10:12:39.848953: val_loss -0.8766 
2025-12-08 10:12:39.852958: Pseudo dice [0.9261, 0.9588, 0.9524] 
2025-12-08 10:12:39.856962: Epoch time: 139.21 s 
2025-12-08 10:12:39.860966: Yayy! New best EMA pseudo Dice: 0.9416 
2025-12-08 10:12:41.063480:  
2025-12-08 10:12:41.063480: Epoch 574 
2025-12-08 10:12:41.063480: Current learning rate: 0.00464 
2025-12-08 10:14:59.530400: train_loss -0.8469 
2025-12-08 10:14:59.530400: val_loss -0.8769 
2025-12-08 10:14:59.530400: Pseudo dice [0.9277, 0.9591, 0.9459] 
2025-12-08 10:14:59.530400: Epoch time: 138.47 s 
2025-12-08 10:14:59.547438: Yayy! New best EMA pseudo Dice: 0.9418 
2025-12-08 10:15:00.526584:  
2025-12-08 10:15:00.526584: Epoch 575 
2025-12-08 10:15:00.531934: Current learning rate: 0.00463 
2025-12-08 10:17:19.085349: train_loss -0.8524 
2025-12-08 10:17:19.087351: val_loss -0.8638 
2025-12-08 10:17:19.093356: Pseudo dice [0.9153, 0.9499, 0.9423] 
2025-12-08 10:17:19.095359: Epoch time: 138.56 s 
2025-12-08 10:17:19.744732:  
2025-12-08 10:17:19.744732: Epoch 576 
2025-12-08 10:17:19.744732: Current learning rate: 0.00462 
2025-12-08 10:19:38.315783: train_loss -0.8497 
2025-12-08 10:19:38.315783: val_loss -0.8752 
2025-12-08 10:19:38.321789: Pseudo dice [0.9279, 0.9562, 0.9412] 
2025-12-08 10:19:38.329535: Epoch time: 138.57 s 
2025-12-08 10:19:38.983898:  
2025-12-08 10:19:38.983898: Epoch 577 
2025-12-08 10:19:38.983898: Current learning rate: 0.00461 
2025-12-08 10:21:57.825167: train_loss -0.847 
2025-12-08 10:21:57.825167: val_loss -0.866 
2025-12-08 10:21:57.830132: Pseudo dice [0.9236, 0.9508, 0.945] 
2025-12-08 10:21:57.834136: Epoch time: 138.84 s 
2025-12-08 10:21:58.478226:  
2025-12-08 10:21:58.478226: Epoch 578 
2025-12-08 10:21:58.478226: Current learning rate: 0.0046 
2025-12-08 10:24:17.143631: train_loss -0.8426 
2025-12-08 10:24:17.143631: val_loss -0.8783 
2025-12-08 10:24:17.149376: Pseudo dice [0.927, 0.9572, 0.9486] 
2025-12-08 10:24:17.151378: Epoch time: 138.67 s 
2025-12-08 10:24:17.983595:  
2025-12-08 10:24:17.983595: Epoch 579 
2025-12-08 10:24:17.983595: Current learning rate: 0.00459 
2025-12-08 10:26:37.526812: train_loss -0.8486 
2025-12-08 10:26:37.526812: val_loss -0.8645 
2025-12-08 10:26:37.532819: Pseudo dice [0.9163, 0.9509, 0.9461] 
2025-12-08 10:26:37.536824: Epoch time: 139.54 s 
2025-12-08 10:26:38.181467:  
2025-12-08 10:26:38.181467: Epoch 580 
2025-12-08 10:26:38.185361: Current learning rate: 0.00458 
2025-12-08 10:28:56.716027: train_loss -0.8542 
2025-12-08 10:28:56.716027: val_loss -0.8691 
2025-12-08 10:28:56.730884: Pseudo dice [0.9194, 0.9507, 0.9463] 
2025-12-08 10:28:56.730884: Epoch time: 138.54 s 
2025-12-08 10:28:57.517035:  
2025-12-08 10:28:57.517035: Epoch 581 
2025-12-08 10:28:57.517035: Current learning rate: 0.00457 
2025-12-08 10:31:16.076910: train_loss -0.8498 
2025-12-08 10:31:16.076910: val_loss -0.8729 
2025-12-08 10:31:16.076910: Pseudo dice [0.9215, 0.9533, 0.951] 
2025-12-08 10:31:16.076910: Epoch time: 138.56 s 
2025-12-08 10:31:16.715948:  
2025-12-08 10:31:16.715948: Epoch 582 
2025-12-08 10:31:16.715948: Current learning rate: 0.00456 
2025-12-08 10:33:35.483987: train_loss -0.849 
2025-12-08 10:33:35.483987: val_loss -0.8757 
2025-12-08 10:33:35.489042: Pseudo dice [0.9231, 0.9559, 0.9491] 
2025-12-08 10:33:35.493053: Epoch time: 138.77 s 
2025-12-08 10:33:36.124057:  
2025-12-08 10:33:36.124057: Epoch 583 
2025-12-08 10:33:36.124057: Current learning rate: 0.00455 
2025-12-08 10:35:54.629456: train_loss -0.8506 
2025-12-08 10:35:54.629456: val_loss -0.8728 
2025-12-08 10:35:54.636457: Pseudo dice [0.9224, 0.9571, 0.9434] 
2025-12-08 10:35:54.643549: Epoch time: 138.51 s 
2025-12-08 10:35:55.373566:  
2025-12-08 10:35:55.373566: Epoch 584 
2025-12-08 10:35:55.389345: Current learning rate: 0.00454 
2025-12-08 10:38:13.646049: train_loss -0.8495 
2025-12-08 10:38:13.646049: val_loss -0.8739 
2025-12-08 10:38:13.652055: Pseudo dice [0.9226, 0.9544, 0.944] 
2025-12-08 10:38:13.655797: Epoch time: 138.27 s 
2025-12-08 10:38:14.478320:  
2025-12-08 10:38:14.478320: Epoch 585 
2025-12-08 10:38:14.483825: Current learning rate: 0.00453 
2025-12-08 10:40:32.619751: train_loss -0.8479 
2025-12-08 10:40:32.619751: val_loss -0.8789 
2025-12-08 10:40:32.627430: Pseudo dice [0.9293, 0.9587, 0.9473] 
2025-12-08 10:40:32.631435: Epoch time: 138.14 s 
2025-12-08 10:40:33.294771:  
2025-12-08 10:40:33.295876: Epoch 586 
2025-12-08 10:40:33.295876: Current learning rate: 0.00452 
2025-12-08 10:42:51.405753: train_loss -0.8431 
2025-12-08 10:42:51.405753: val_loss -0.8771 
2025-12-08 10:42:51.405753: Pseudo dice [0.9239, 0.955, 0.9463] 
2025-12-08 10:42:51.416932: Epoch time: 138.11 s 
2025-12-08 10:42:52.213477:  
2025-12-08 10:42:52.213477: Epoch 587 
2025-12-08 10:42:52.218479: Current learning rate: 0.00451 
2025-12-08 10:45:10.513573: train_loss -0.8486 
2025-12-08 10:45:10.515314: val_loss -0.8802 
2025-12-08 10:45:10.519178: Pseudo dice [0.927, 0.9517, 0.9465] 
2025-12-08 10:45:10.523182: Epoch time: 138.3 s 
2025-12-08 10:45:11.166549:  
2025-12-08 10:45:11.166549: Epoch 588 
2025-12-08 10:45:11.166549: Current learning rate: 0.0045 
2025-12-08 10:47:29.525609: train_loss -0.8468 
2025-12-08 10:47:29.525609: val_loss -0.8767 
2025-12-08 10:47:29.531540: Pseudo dice [0.9271, 0.9539, 0.9453] 
2025-12-08 10:47:29.534649: Epoch time: 138.36 s 
2025-12-08 10:47:30.172115:  
2025-12-08 10:47:30.172115: Epoch 589 
2025-12-08 10:47:30.190361: Current learning rate: 0.00449 
2025-12-08 10:49:48.393316: train_loss -0.8497 
2025-12-08 10:49:48.393316: val_loss -0.8744 
2025-12-08 10:49:48.398319: Pseudo dice [0.9228, 0.9575, 0.9441] 
2025-12-08 10:49:48.402782: Epoch time: 138.22 s 
2025-12-08 10:49:49.171736:  
2025-12-08 10:49:49.171736: Epoch 590 
2025-12-08 10:49:49.190457: Current learning rate: 0.00448 
2025-12-08 10:52:07.562145: train_loss -0.8444 
2025-12-08 10:52:07.562145: val_loss -0.8665 
2025-12-08 10:52:07.583274: Pseudo dice [0.9191, 0.9512, 0.949] 
2025-12-08 10:52:07.588285: Epoch time: 138.39 s 
2025-12-08 10:52:08.220322:  
2025-12-08 10:52:08.220322: Epoch 591 
2025-12-08 10:52:08.220322: Current learning rate: 0.00447 
2025-12-08 10:54:26.444059: train_loss -0.8449 
2025-12-08 10:54:26.444059: val_loss -0.8641 
2025-12-08 10:54:26.450069: Pseudo dice [0.9206, 0.9503, 0.9404] 
2025-12-08 10:54:26.454211: Epoch time: 138.22 s 
2025-12-08 10:54:27.267821:  
2025-12-08 10:54:27.268823: Epoch 592 
2025-12-08 10:54:27.273608: Current learning rate: 0.00446 
2025-12-08 10:56:45.425279: train_loss -0.8493 
2025-12-08 10:56:45.425279: val_loss -0.8589 
2025-12-08 10:56:45.427282: Pseudo dice [0.9133, 0.9529, 0.9455] 
2025-12-08 10:56:45.427282: Epoch time: 138.16 s 
2025-12-08 10:56:46.198904:  
2025-12-08 10:56:46.198904: Epoch 593 
2025-12-08 10:56:46.204860: Current learning rate: 0.00445 
2025-12-08 10:59:04.405008: train_loss -0.8498 
2025-12-08 10:59:04.405008: val_loss -0.86 
2025-12-08 10:59:04.422963: Pseudo dice [0.9125, 0.9496, 0.9448] 
2025-12-08 10:59:04.422963: Epoch time: 138.21 s 
2025-12-08 10:59:05.061343:  
2025-12-08 10:59:05.061343: Epoch 594 
2025-12-08 10:59:05.061343: Current learning rate: 0.00444 
2025-12-08 11:01:23.142632: train_loss -0.8531 
2025-12-08 11:01:23.142632: val_loss -0.8716 
2025-12-08 11:01:23.150194: Pseudo dice [0.9204, 0.9523, 0.9498] 
2025-12-08 11:01:23.155939: Epoch time: 138.08 s 
2025-12-08 11:01:23.795926:  
2025-12-08 11:01:23.795926: Epoch 595 
2025-12-08 11:01:23.811869: Current learning rate: 0.00443 
2025-12-08 11:03:42.064077: train_loss -0.8506 
2025-12-08 11:03:42.066079: val_loss -0.8724 
2025-12-08 11:03:42.074091: Pseudo dice [0.9214, 0.9482, 0.9457] 
2025-12-08 11:03:42.077834: Epoch time: 138.27 s 
2025-12-08 11:03:42.831482:  
2025-12-08 11:03:42.833485: Epoch 596 
2025-12-08 11:03:42.833485: Current learning rate: 0.00442 
2025-12-08 11:06:01.109091: train_loss -0.846 
2025-12-08 11:06:01.109091: val_loss -0.8724 
2025-12-08 11:06:01.123594: Pseudo dice [0.9225, 0.9553, 0.9458] 
2025-12-08 11:06:01.129100: Epoch time: 138.28 s 
2025-12-08 11:06:01.766088:  
2025-12-08 11:06:01.766088: Epoch 597 
2025-12-08 11:06:01.766088: Current learning rate: 0.00441 
2025-12-08 11:08:20.093657: train_loss -0.8482 
2025-12-08 11:08:20.093657: val_loss -0.8759 
2025-12-08 11:08:20.093657: Pseudo dice [0.9246, 0.9557, 0.9481] 
2025-12-08 11:08:20.093657: Epoch time: 138.33 s 
2025-12-08 11:08:20.905095:  
2025-12-08 11:08:20.905095: Epoch 598 
2025-12-08 11:08:20.905095: Current learning rate: 0.0044 
2025-12-08 11:10:39.106498: train_loss -0.8515 
2025-12-08 11:10:39.107498: val_loss -0.884 
2025-12-08 11:10:39.108545: Pseudo dice [0.9292, 0.9564, 0.9508] 
2025-12-08 11:10:39.108545: Epoch time: 138.2 s 
2025-12-08 11:10:39.873326:  
2025-12-08 11:10:39.873326: Epoch 599 
2025-12-08 11:10:39.880598: Current learning rate: 0.00439 
2025-12-08 11:12:58.171264: train_loss -0.8531 
2025-12-08 11:12:58.171264: val_loss -0.8754 
2025-12-08 11:12:58.171264: Pseudo dice [0.9233, 0.9544, 0.9503] 
2025-12-08 11:12:58.187120: Epoch time: 138.3 s 
2025-12-08 11:12:59.084806:  
2025-12-08 11:12:59.085807: Epoch 600 
2025-12-08 11:12:59.090566: Current learning rate: 0.00438 
2025-12-08 11:15:17.406298: train_loss -0.853 
2025-12-08 11:15:17.406298: val_loss -0.8797 
2025-12-08 11:15:17.415494: Pseudo dice [0.9254, 0.9604, 0.9476] 
2025-12-08 11:15:17.421541: Epoch time: 138.32 s 
2025-12-08 11:15:18.071161:  
2025-12-08 11:15:18.071161: Epoch 601 
2025-12-08 11:15:18.075681: Current learning rate: 0.00437 
2025-12-08 11:17:36.300196: train_loss -0.8521 
2025-12-08 11:17:36.300196: val_loss -0.8828 
2025-12-08 11:17:36.308204: Pseudo dice [0.9303, 0.961, 0.9459] 
2025-12-08 11:17:36.313950: Epoch time: 138.23 s 
2025-12-08 11:17:36.319957: Yayy! New best EMA pseudo Dice: 0.9418 
2025-12-08 11:17:37.389695:  
2025-12-08 11:17:37.389695: Epoch 602 
2025-12-08 11:17:37.405398: Current learning rate: 0.00436 
2025-12-08 11:19:55.645820: train_loss -0.8494 
2025-12-08 11:19:55.645820: val_loss -0.8765 
2025-12-08 11:19:55.653833: Pseudo dice [0.9259, 0.9538, 0.9489] 
2025-12-08 11:19:55.658716: Epoch time: 138.26 s 
2025-12-08 11:19:55.663717: Yayy! New best EMA pseudo Dice: 0.9419 
2025-12-08 11:19:56.799054:  
2025-12-08 11:19:56.799054: Epoch 603 
2025-12-08 11:19:56.799054: Current learning rate: 0.00435 
2025-12-08 11:22:15.030008: train_loss -0.848 
2025-12-08 11:22:15.045730: val_loss -0.88 
2025-12-08 11:22:15.045730: Pseudo dice [0.9304, 0.953, 0.9444] 
2025-12-08 11:22:15.045730: Epoch time: 138.23 s 
2025-12-08 11:22:15.045730: Yayy! New best EMA pseudo Dice: 0.942 
2025-12-08 11:22:15.960745:  
2025-12-08 11:22:15.960745: Epoch 604 
2025-12-08 11:22:15.960745: Current learning rate: 0.00434 
2025-12-08 11:24:34.213158: train_loss -0.8511 
2025-12-08 11:24:34.213158: val_loss -0.8815 
2025-12-08 11:24:34.218165: Pseudo dice [0.9276, 0.9613, 0.9505] 
2025-12-08 11:24:34.222170: Epoch time: 138.25 s 
2025-12-08 11:24:34.228178: Yayy! New best EMA pseudo Dice: 0.9424 
2025-12-08 11:24:35.218259:  
2025-12-08 11:24:35.218259: Epoch 605 
2025-12-08 11:24:35.218259: Current learning rate: 0.00433 
2025-12-08 11:26:53.442507: train_loss -0.8567 
2025-12-08 11:26:53.442507: val_loss -0.8681 
2025-12-08 11:26:53.448514: Pseudo dice [0.9155, 0.951, 0.9507] 
2025-12-08 11:26:53.452256: Epoch time: 138.22 s 
2025-12-08 11:26:54.092959:  
2025-12-08 11:26:54.092959: Epoch 606 
2025-12-08 11:26:54.092959: Current learning rate: 0.00432 
2025-12-08 11:29:12.498939: train_loss -0.8538 
2025-12-08 11:29:12.498939: val_loss -0.8762 
2025-12-08 11:29:12.504945: Pseudo dice [0.9261, 0.9541, 0.9506] 
2025-12-08 11:29:12.508949: Epoch time: 138.41 s 
2025-12-08 11:29:13.155500:  
2025-12-08 11:29:13.155500: Epoch 607 
2025-12-08 11:29:13.155500: Current learning rate: 0.00431 
2025-12-08 11:31:31.405615: train_loss -0.8496 
2025-12-08 11:31:31.405615: val_loss -0.8689 
2025-12-08 11:31:31.410798: Pseudo dice [0.9201, 0.9512, 0.9483] 
2025-12-08 11:31:31.415800: Epoch time: 138.25 s 
2025-12-08 11:31:32.149358:  
2025-12-08 11:31:32.149358: Epoch 608 
2025-12-08 11:31:32.149358: Current learning rate: 0.0043 
2025-12-08 11:33:50.372574: train_loss -0.8567 
2025-12-08 11:33:50.372574: val_loss -0.8746 
2025-12-08 11:33:50.378319: Pseudo dice [0.923, 0.9542, 0.9453] 
2025-12-08 11:33:50.382323: Epoch time: 138.22 s 
2025-12-08 11:33:51.202030:  
2025-12-08 11:33:51.202030: Epoch 609 
2025-12-08 11:33:51.202030: Current learning rate: 0.00429 
2025-12-08 11:36:09.369503: train_loss -0.8505 
2025-12-08 11:36:09.370504: val_loss -0.8751 
2025-12-08 11:36:09.375585: Pseudo dice [0.9249, 0.955, 0.9463] 
2025-12-08 11:36:09.379595: Epoch time: 138.17 s 
2025-12-08 11:36:10.014740:  
2025-12-08 11:36:10.014740: Epoch 610 
2025-12-08 11:36:10.014740: Current learning rate: 0.00429 
2025-12-08 11:38:28.210448: train_loss -0.8535 
2025-12-08 11:38:28.212450: val_loss -0.8797 
2025-12-08 11:38:28.217956: Pseudo dice [0.9259, 0.9536, 0.9475] 
2025-12-08 11:38:28.221831: Epoch time: 138.2 s 
2025-12-08 11:38:28.967634:  
2025-12-08 11:38:28.967634: Epoch 611 
2025-12-08 11:38:28.967634: Current learning rate: 0.00428 
2025-12-08 11:40:47.357665: train_loss -0.8515 
2025-12-08 11:40:47.365667: val_loss -0.8643 
2025-12-08 11:40:47.372669: Pseudo dice [0.9208, 0.9481, 0.9379] 
2025-12-08 11:40:47.377718: Epoch time: 138.39 s 
2025-12-08 11:40:48.061474:  
2025-12-08 11:40:48.061474: Epoch 612 
2025-12-08 11:40:48.061474: Current learning rate: 0.00427 
2025-12-08 11:43:06.157527: train_loss -0.8461 
2025-12-08 11:43:06.157527: val_loss -0.8812 
2025-12-08 11:43:06.163271: Pseudo dice [0.9301, 0.9566, 0.9473] 
2025-12-08 11:43:06.171264: Epoch time: 138.1 s 
2025-12-08 11:43:06.824162:  
2025-12-08 11:43:06.826164: Epoch 613 
2025-12-08 11:43:06.826164: Current learning rate: 0.00426 
2025-12-08 11:45:25.061231: train_loss -0.8476 
2025-12-08 11:45:25.061231: val_loss -0.8658 
2025-12-08 11:45:25.061231: Pseudo dice [0.9197, 0.9497, 0.9478] 
2025-12-08 11:45:25.061231: Epoch time: 138.24 s 
2025-12-08 11:45:25.786443:  
2025-12-08 11:45:25.787443: Epoch 614 
2025-12-08 11:45:25.792643: Current learning rate: 0.00425 
2025-12-08 11:47:43.687563: train_loss -0.8536 
2025-12-08 11:47:43.687563: val_loss -0.8762 
2025-12-08 11:47:43.693070: Pseudo dice [0.9253, 0.9549, 0.9466] 
2025-12-08 11:47:43.698550: Epoch time: 137.9 s 
2025-12-08 11:47:44.512382:  
2025-12-08 11:47:44.513387: Epoch 615 
2025-12-08 11:47:44.517420: Current learning rate: 0.00424 
2025-12-08 11:50:02.546664: train_loss -0.8489 
2025-12-08 11:50:02.546664: val_loss -0.8593 
2025-12-08 11:50:02.562541: Pseudo dice [0.9153, 0.9482, 0.9395] 
2025-12-08 11:50:02.562541: Epoch time: 138.04 s 
2025-12-08 11:50:03.201932:  
2025-12-08 11:50:03.201932: Epoch 616 
2025-12-08 11:50:03.201932: Current learning rate: 0.00423 
2025-12-08 11:52:21.484701: train_loss -0.8529 
2025-12-08 11:52:21.485701: val_loss -0.876 
2025-12-08 11:52:21.491930: Pseudo dice [0.9263, 0.955, 0.9422] 
2025-12-08 11:52:21.495931: Epoch time: 138.28 s 
2025-12-08 11:52:22.305726:  
2025-12-08 11:52:22.305726: Epoch 617 
2025-12-08 11:52:22.305726: Current learning rate: 0.00422 
2025-12-08 11:54:40.500879: train_loss -0.8566 
2025-12-08 11:54:40.500879: val_loss -0.8682 
2025-12-08 11:54:40.508887: Pseudo dice [0.9223, 0.9517, 0.943] 
2025-12-08 11:54:40.510889: Epoch time: 138.2 s 
2025-12-08 11:54:41.155396:  
2025-12-08 11:54:41.155396: Epoch 618 
2025-12-08 11:54:41.155396: Current learning rate: 0.00421 
2025-12-08 11:56:59.420792: train_loss -0.8489 
2025-12-08 11:56:59.420792: val_loss -0.8719 
2025-12-08 11:56:59.426293: Pseudo dice [0.9223, 0.9521, 0.9448] 
2025-12-08 11:56:59.430297: Epoch time: 138.27 s 
2025-12-08 11:57:00.081447:  
2025-12-08 11:57:00.083450: Epoch 619 
2025-12-08 11:57:00.083450: Current learning rate: 0.0042 
2025-12-08 11:59:18.498548: train_loss -0.8464 
2025-12-08 11:59:18.498548: val_loss -0.8766 
2025-12-08 11:59:18.511791: Pseudo dice [0.9255, 0.9569, 0.9496] 
2025-12-08 11:59:18.513794: Epoch time: 138.42 s 
2025-12-08 11:59:19.358364:  
2025-12-08 11:59:19.358364: Epoch 620 
2025-12-08 11:59:19.370532: Current learning rate: 0.00419 
2025-12-08 12:01:37.622609: train_loss -0.853 
2025-12-08 12:01:37.622609: val_loss -0.8695 
2025-12-08 12:01:37.630357: Pseudo dice [0.9193, 0.9518, 0.951] 
2025-12-08 12:01:37.636363: Epoch time: 138.26 s 
2025-12-08 12:01:38.466359:  
2025-12-08 12:01:38.467361: Epoch 621 
2025-12-08 12:01:38.468364: Current learning rate: 0.00418 
2025-12-08 12:03:56.608423: train_loss -0.8483 
2025-12-08 12:03:56.608423: val_loss -0.8784 
2025-12-08 12:03:56.608423: Pseudo dice [0.9259, 0.9558, 0.9461] 
2025-12-08 12:03:56.608423: Epoch time: 138.14 s 
2025-12-08 12:03:57.295645:  
2025-12-08 12:03:57.299144: Epoch 622 
2025-12-08 12:03:57.299144: Current learning rate: 0.00417 
2025-12-08 12:06:15.187115: train_loss -0.8468 
2025-12-08 12:06:15.187115: val_loss -0.8822 
2025-12-08 12:06:15.206437: Pseudo dice [0.9315, 0.9595, 0.9436] 
2025-12-08 12:06:15.210437: Epoch time: 137.89 s 
2025-12-08 12:06:15.930506:  
2025-12-08 12:06:15.930506: Epoch 623 
2025-12-08 12:06:15.936160: Current learning rate: 0.00416 
2025-12-08 12:08:34.107363: train_loss -0.8467 
2025-12-08 12:08:34.107363: val_loss -0.8829 
2025-12-08 12:08:34.114259: Pseudo dice [0.9279, 0.9582, 0.9516] 
2025-12-08 12:08:34.118259: Epoch time: 138.18 s 
2025-12-08 12:08:34.763387:  
2025-12-08 12:08:34.763387: Epoch 624 
2025-12-08 12:08:34.768507: Current learning rate: 0.00415 
2025-12-08 12:10:52.787512: train_loss -0.8506 
2025-12-08 12:10:52.789515: val_loss -0.8746 
2025-12-08 12:10:52.794888: Pseudo dice [0.923, 0.9542, 0.9492] 
2025-12-08 12:10:52.799895: Epoch time: 138.03 s 
2025-12-08 12:10:53.496061:  
2025-12-08 12:10:53.497066: Epoch 625 
2025-12-08 12:10:53.502118: Current learning rate: 0.00414 
2025-12-08 12:13:11.530668: train_loss -0.8549 
2025-12-08 12:13:11.530668: val_loss -0.8735 
2025-12-08 12:13:11.534675: Pseudo dice [0.9218, 0.9529, 0.9462] 
2025-12-08 12:13:11.538681: Epoch time: 138.04 s 
2025-12-08 12:13:12.256603:  
2025-12-08 12:13:12.257605: Epoch 626 
2025-12-08 12:13:12.262615: Current learning rate: 0.00413 
2025-12-08 12:15:30.682299: train_loss -0.8499 
2025-12-08 12:15:30.683300: val_loss -0.8703 
2025-12-08 12:15:30.690130: Pseudo dice [0.9204, 0.9533, 0.9473] 
2025-12-08 12:15:30.696136: Epoch time: 138.43 s 
2025-12-08 12:15:31.390268:  
2025-12-08 12:15:31.390268: Epoch 627 
2025-12-08 12:15:31.390268: Current learning rate: 0.00412 
2025-12-08 12:17:49.390009: train_loss -0.8502 
2025-12-08 12:17:49.390009: val_loss -0.8609 
2025-12-08 12:17:49.390009: Pseudo dice [0.9157, 0.9459, 0.9449] 
2025-12-08 12:17:49.405677: Epoch time: 138.0 s 
2025-12-08 12:17:50.218261:  
2025-12-08 12:17:50.218261: Epoch 628 
2025-12-08 12:17:50.234213: Current learning rate: 0.00411 
2025-12-08 12:20:08.339077: train_loss -0.8468 
2025-12-08 12:20:08.339077: val_loss -0.8728 
2025-12-08 12:20:08.345078: Pseudo dice [0.9238, 0.9495, 0.9431] 
2025-12-08 12:20:08.350079: Epoch time: 138.12 s 
2025-12-08 12:20:09.104075:  
2025-12-08 12:20:09.104075: Epoch 629 
2025-12-08 12:20:09.109162: Current learning rate: 0.0041 
2025-12-08 12:22:27.361389: train_loss -0.8479 
2025-12-08 12:22:27.362390: val_loss -0.8784 
2025-12-08 12:22:27.368390: Pseudo dice [0.9241, 0.9594, 0.9469] 
2025-12-08 12:22:27.373391: Epoch time: 138.26 s 
2025-12-08 12:22:28.015139:  
2025-12-08 12:22:28.015139: Epoch 630 
2025-12-08 12:22:28.030999: Current learning rate: 0.00409 
2025-12-08 12:24:46.295503: train_loss -0.8451 
2025-12-08 12:24:46.295503: val_loss -0.8629 
2025-12-08 12:24:46.315543: Pseudo dice [0.92, 0.9529, 0.9399] 
2025-12-08 12:24:46.321549: Epoch time: 138.28 s 
2025-12-08 12:24:46.952246:  
2025-12-08 12:24:46.952246: Epoch 631 
2025-12-08 12:24:46.968308: Current learning rate: 0.00408 
2025-12-08 12:27:05.041759: train_loss -0.847 
2025-12-08 12:27:05.041759: val_loss -0.874 
2025-12-08 12:27:05.045763: Pseudo dice [0.9228, 0.9557, 0.9474] 
2025-12-08 12:27:05.052637: Epoch time: 138.09 s 
2025-12-08 12:27:05.858378:  
2025-12-08 12:27:05.858378: Epoch 632 
2025-12-08 12:27:05.863616: Current learning rate: 0.00407 
2025-12-08 12:29:24.063162: train_loss -0.8465 
2025-12-08 12:29:24.065165: val_loss -0.8755 
2025-12-08 12:29:24.071172: Pseudo dice [0.9219, 0.9567, 0.9515] 
2025-12-08 12:29:24.075176: Epoch time: 138.2 s 
2025-12-08 12:29:24.702618:  
2025-12-08 12:29:24.702618: Epoch 633 
2025-12-08 12:29:24.718655: Current learning rate: 0.00406 
2025-12-08 12:31:42.971310: train_loss -0.8462 
2025-12-08 12:31:42.971310: val_loss -0.8716 
2025-12-08 12:31:42.976793: Pseudo dice [0.9229, 0.9559, 0.9501] 
2025-12-08 12:31:42.980803: Epoch time: 138.27 s 
2025-12-08 12:31:43.621922:  
2025-12-08 12:31:43.621922: Epoch 634 
2025-12-08 12:31:43.629534: Current learning rate: 0.00405 
2025-12-08 12:34:01.682093: train_loss -0.8533 
2025-12-08 12:34:01.682093: val_loss -0.8695 
2025-12-08 12:34:01.685836: Pseudo dice [0.9213, 0.9488, 0.9485] 
2025-12-08 12:34:01.693342: Epoch time: 138.06 s 
2025-12-08 12:34:02.479089:  
2025-12-08 12:34:02.479089: Epoch 635 
2025-12-08 12:34:02.484558: Current learning rate: 0.00404 
2025-12-08 12:36:20.505781: train_loss -0.8467 
2025-12-08 12:36:20.505781: val_loss -0.8792 
2025-12-08 12:36:20.511789: Pseudo dice [0.9274, 0.9588, 0.9447] 
2025-12-08 12:36:20.517536: Epoch time: 138.03 s 
2025-12-08 12:36:21.161222:  
2025-12-08 12:36:21.161222: Epoch 636 
2025-12-08 12:36:21.166617: Current learning rate: 0.00403 
2025-12-08 12:38:39.384805: train_loss -0.8521 
2025-12-08 12:38:39.386807: val_loss -0.8772 
2025-12-08 12:38:39.392551: Pseudo dice [0.9242, 0.9548, 0.949] 
2025-12-08 12:38:39.398557: Epoch time: 138.22 s 
2025-12-08 12:38:40.071875:  
2025-12-08 12:38:40.071875: Epoch 637 
2025-12-08 12:38:40.076886: Current learning rate: 0.00402 
2025-12-08 12:40:58.201819: train_loss -0.8494 
2025-12-08 12:40:58.202852: val_loss -0.8639 
2025-12-08 12:40:58.209970: Pseudo dice [0.9165, 0.9454, 0.9463] 
2025-12-08 12:40:58.213978: Epoch time: 138.13 s 
2025-12-08 12:40:58.952604:  
2025-12-08 12:40:58.952604: Epoch 638 
2025-12-08 12:40:58.968668: Current learning rate: 0.00401 
2025-12-08 12:43:17.202959: train_loss -0.8538 
2025-12-08 12:43:17.202959: val_loss -0.8772 
2025-12-08 12:43:17.202959: Pseudo dice [0.9259, 0.958, 0.948] 
2025-12-08 12:43:17.218887: Epoch time: 138.25 s 
2025-12-08 12:43:18.061367:  
2025-12-08 12:43:18.061367: Epoch 639 
2025-12-08 12:43:18.061367: Current learning rate: 0.004 
2025-12-08 12:45:36.186646: train_loss -0.8497 
2025-12-08 12:45:36.186646: val_loss -0.8796 
2025-12-08 12:45:36.197527: Pseudo dice [0.9307, 0.9575, 0.9476] 
2025-12-08 12:45:36.204708: Epoch time: 138.13 s 
2025-12-08 12:45:36.836503:  
2025-12-08 12:45:36.837781: Epoch 640 
2025-12-08 12:45:36.842793: Current learning rate: 0.00399 
2025-12-08 12:47:55.055684: train_loss -0.8514 
2025-12-08 12:47:55.055684: val_loss -0.8796 
2025-12-08 12:47:55.061689: Pseudo dice [0.9272, 0.9547, 0.9491] 
2025-12-08 12:47:55.066866: Epoch time: 138.22 s 
2025-12-08 12:47:55.732917:  
2025-12-08 12:47:55.732917: Epoch 641 
2025-12-08 12:47:55.732917: Current learning rate: 0.00398 
2025-12-08 12:50:13.796073: train_loss -0.8495 
2025-12-08 12:50:13.796073: val_loss -0.8814 
2025-12-08 12:50:13.796073: Pseudo dice [0.9294, 0.9582, 0.9482] 
2025-12-08 12:50:13.811918: Epoch time: 138.06 s 
2025-12-08 12:50:14.451980:  
2025-12-08 12:50:14.451980: Epoch 642 
2025-12-08 12:50:14.451980: Current learning rate: 0.00397 
2025-12-08 12:52:32.466749: train_loss -0.8481 
2025-12-08 12:52:32.467750: val_loss -0.8626 
2025-12-08 12:52:32.473797: Pseudo dice [0.9166, 0.9483, 0.9405] 
2025-12-08 12:52:32.479798: Epoch time: 138.01 s 
2025-12-08 12:52:33.130265:  
2025-12-08 12:52:33.130265: Epoch 643 
2025-12-08 12:52:33.135283: Current learning rate: 0.00396 
2025-12-08 12:54:51.125425: train_loss -0.8495 
2025-12-08 12:54:51.125425: val_loss -0.8736 
2025-12-08 12:54:51.141081: Pseudo dice [0.9265, 0.9588, 0.9412] 
2025-12-08 12:54:51.141081: Epoch time: 138.0 s 
2025-12-08 12:54:51.780529:  
2025-12-08 12:54:51.780529: Epoch 644 
2025-12-08 12:54:51.780529: Current learning rate: 0.00395 
2025-12-08 12:57:09.844167: train_loss -0.8462 
2025-12-08 12:57:09.844167: val_loss -0.8747 
2025-12-08 12:57:09.851676: Pseudo dice [0.9247, 0.9585, 0.9422] 
2025-12-08 12:57:09.851676: Epoch time: 138.06 s 
2025-12-08 12:57:10.554338:  
2025-12-08 12:57:10.554338: Epoch 645 
2025-12-08 12:57:10.559352: Current learning rate: 0.00394 
2025-12-08 12:59:28.682719: train_loss -0.8491 
2025-12-08 12:59:28.682719: val_loss -0.8805 
2025-12-08 12:59:28.686916: Pseudo dice [0.9306, 0.9603, 0.9405] 
2025-12-08 12:59:28.692058: Epoch time: 138.13 s 
2025-12-08 12:59:29.511787:  
2025-12-08 12:59:29.511787: Epoch 646 
2025-12-08 12:59:29.515794: Current learning rate: 0.00393 
2025-12-08 13:01:47.577433: train_loss -0.8503 
2025-12-08 13:01:47.577433: val_loss -0.8708 
2025-12-08 13:01:47.595304: Pseudo dice [0.9182, 0.9563, 0.9436] 
2025-12-08 13:01:47.601310: Epoch time: 138.07 s 
2025-12-08 13:01:48.246366:  
2025-12-08 13:01:48.246366: Epoch 647 
2025-12-08 13:01:48.248692: Current learning rate: 0.00392 
2025-12-08 13:04:06.263833: train_loss -0.8515 
2025-12-08 13:04:06.263833: val_loss -0.8723 
2025-12-08 13:04:06.270432: Pseudo dice [0.921, 0.954, 0.9481] 
2025-12-08 13:04:06.274436: Epoch time: 138.02 s 
2025-12-08 13:04:06.923144:  
2025-12-08 13:04:06.923144: Epoch 648 
2025-12-08 13:04:06.923144: Current learning rate: 0.00391 
2025-12-08 13:06:25.076009: train_loss -0.8512 
2025-12-08 13:06:25.076009: val_loss -0.8826 
2025-12-08 13:06:25.081069: Pseudo dice [0.927, 0.9625, 0.9515] 
2025-12-08 13:06:25.086075: Epoch time: 138.15 s 
2025-12-08 13:06:25.736226:  
2025-12-08 13:06:25.736226: Epoch 649 
2025-12-08 13:06:25.741611: Current learning rate: 0.0039 
2025-12-08 13:08:43.779920: train_loss -0.8528 
2025-12-08 13:08:43.795563: val_loss -0.8786 
2025-12-08 13:08:43.799568: Pseudo dice [0.9274, 0.956, 0.9487] 
2025-12-08 13:08:43.803572: Epoch time: 138.04 s 
2025-12-08 13:08:44.805733:  
2025-12-08 13:08:44.805733: Epoch 650 
2025-12-08 13:08:44.811478: Current learning rate: 0.00389 
2025-12-08 13:11:03.074291: train_loss -0.8493 
2025-12-08 13:11:03.075291: val_loss -0.8761 
2025-12-08 13:11:03.081501: Pseudo dice [0.9271, 0.9593, 0.9403] 
2025-12-08 13:11:03.087502: Epoch time: 138.27 s 
2025-12-08 13:11:03.737605:  
2025-12-08 13:11:03.739607: Epoch 651 
2025-12-08 13:11:03.739607: Current learning rate: 0.00388 
2025-12-08 13:13:22.036629: train_loss -0.8576 
2025-12-08 13:13:22.036629: val_loss -0.876 
2025-12-08 13:13:22.041649: Pseudo dice [0.9249, 0.9596, 0.9437] 
2025-12-08 13:13:22.045661: Epoch time: 138.3 s 
2025-12-08 13:13:22.687684:  
2025-12-08 13:13:22.688865: Epoch 652 
2025-12-08 13:13:22.692799: Current learning rate: 0.00387 
2025-12-08 13:15:40.876158: train_loss -0.8509 
2025-12-08 13:15:40.878163: val_loss -0.873 
2025-12-08 13:15:40.884170: Pseudo dice [0.923, 0.9541, 0.9468] 
2025-12-08 13:15:40.889914: Epoch time: 138.2 s 
2025-12-08 13:15:41.530931:  
2025-12-08 13:15:41.530931: Epoch 653 
2025-12-08 13:15:41.546314: Current learning rate: 0.00386 
2025-12-08 13:17:59.666878: train_loss -0.8518 
2025-12-08 13:17:59.666878: val_loss -0.874 
2025-12-08 13:17:59.670907: Pseudo dice [0.9242, 0.9545, 0.9501] 
2025-12-08 13:17:59.670907: Epoch time: 138.14 s 
2025-12-08 13:18:00.317849:  
2025-12-08 13:18:00.318849: Epoch 654 
2025-12-08 13:18:00.323081: Current learning rate: 0.00385 
2025-12-08 13:20:18.284275: train_loss -0.852 
2025-12-08 13:20:18.284275: val_loss -0.8768 
2025-12-08 13:20:18.290285: Pseudo dice [0.924, 0.9546, 0.9491] 
2025-12-08 13:20:18.294290: Epoch time: 137.97 s 
2025-12-08 13:20:18.957392:  
2025-12-08 13:20:18.957392: Epoch 655 
2025-12-08 13:20:18.957392: Current learning rate: 0.00384 
2025-12-08 13:22:37.208921: train_loss -0.8519 
2025-12-08 13:22:37.210923: val_loss -0.8775 
2025-12-08 13:22:37.214926: Pseudo dice [0.9246, 0.9557, 0.9454] 
2025-12-08 13:22:37.220747: Epoch time: 138.25 s 
2025-12-08 13:22:37.920427:  
2025-12-08 13:22:37.920427: Epoch 656 
2025-12-08 13:22:37.936234: Current learning rate: 0.00383 
2025-12-08 13:24:56.140154: train_loss -0.8506 
2025-12-08 13:24:56.140154: val_loss -0.8784 
2025-12-08 13:24:56.148244: Pseudo dice [0.9237, 0.955, 0.952] 
2025-12-08 13:24:56.154905: Epoch time: 138.22 s 
2025-12-08 13:24:56.952526:  
2025-12-08 13:24:56.952526: Epoch 657 
2025-12-08 13:24:56.968234: Current learning rate: 0.00382 
2025-12-08 13:27:15.185112: train_loss -0.851 
2025-12-08 13:27:15.186114: val_loss -0.8845 
2025-12-08 13:27:15.186114: Pseudo dice [0.9315, 0.9533, 0.9538] 
2025-12-08 13:27:15.195626: Epoch time: 138.23 s 
2025-12-08 13:27:15.199631: Yayy! New best EMA pseudo Dice: 0.9428 
2025-12-08 13:27:16.156150:  
2025-12-08 13:27:16.156150: Epoch 658 
2025-12-08 13:27:16.156150: Current learning rate: 0.00381 
2025-12-08 13:29:34.123275: train_loss -0.8551 
2025-12-08 13:29:34.125064: val_loss -0.8738 
2025-12-08 13:29:34.127066: Pseudo dice [0.9215, 0.9526, 0.95] 
2025-12-08 13:29:34.134416: Epoch time: 137.97 s 
2025-12-08 13:29:34.779781:  
2025-12-08 13:29:34.779781: Epoch 659 
2025-12-08 13:29:34.779781: Current learning rate: 0.0038 
2025-12-08 13:31:52.920936: train_loss -0.8375 
2025-12-08 13:31:52.920936: val_loss -0.8666 
2025-12-08 13:31:52.920936: Pseudo dice [0.9132, 0.9472, 0.953] 
2025-12-08 13:31:52.920936: Epoch time: 138.14 s 
2025-12-08 13:31:53.561152:  
2025-12-08 13:31:53.561152: Epoch 660 
2025-12-08 13:31:53.561152: Current learning rate: 0.00379 
2025-12-08 13:34:11.655358: train_loss -0.8367 
2025-12-08 13:34:11.655358: val_loss -0.8659 
2025-12-08 13:34:11.655358: Pseudo dice [0.921, 0.9563, 0.9431] 
2025-12-08 13:34:11.655358: Epoch time: 138.09 s 
2025-12-08 13:34:12.416150:  
2025-12-08 13:34:12.417152: Epoch 661 
2025-12-08 13:34:12.422212: Current learning rate: 0.00378 
2025-12-08 13:36:30.378357: train_loss -0.8428 
2025-12-08 13:36:30.379359: val_loss -0.8678 
2025-12-08 13:36:30.384370: Pseudo dice [0.9195, 0.9521, 0.9471] 
2025-12-08 13:36:30.388379: Epoch time: 137.96 s 
2025-12-08 13:36:31.015163:  
2025-12-08 13:36:31.015163: Epoch 662 
2025-12-08 13:36:31.015163: Current learning rate: 0.00377 
2025-12-08 13:38:48.950665: train_loss -0.8474 
2025-12-08 13:38:48.952406: val_loss -0.8791 
2025-12-08 13:38:48.959559: Pseudo dice [0.927, 0.9598, 0.9507] 
2025-12-08 13:38:48.964560: Epoch time: 137.94 s 
2025-12-08 13:38:49.639631:  
2025-12-08 13:38:49.639631: Epoch 663 
2025-12-08 13:38:49.639631: Current learning rate: 0.00376 
2025-12-08 13:41:07.859092: train_loss -0.8485 
2025-12-08 13:41:07.859092: val_loss -0.8763 
2025-12-08 13:41:07.859092: Pseudo dice [0.9261, 0.9571, 0.9499] 
2025-12-08 13:41:07.859092: Epoch time: 138.22 s 
2025-12-08 13:41:08.878801:  
2025-12-08 13:41:08.879804: Epoch 664 
2025-12-08 13:41:08.885817: Current learning rate: 0.00375 
2025-12-08 13:43:26.907921: train_loss -0.8461 
2025-12-08 13:43:26.908922: val_loss -0.8768 
2025-12-08 13:43:26.915942: Pseudo dice [0.9259, 0.9593, 0.953] 
2025-12-08 13:43:26.921955: Epoch time: 138.03 s 
2025-12-08 13:43:27.562299:  
2025-12-08 13:43:27.562299: Epoch 665 
2025-12-08 13:43:27.562299: Current learning rate: 0.00374 
2025-12-08 13:45:45.720987: train_loss -0.8485 
2025-12-08 13:45:45.721988: val_loss -0.8729 
2025-12-08 13:45:45.727014: Pseudo dice [0.9237, 0.9541, 0.9462] 
2025-12-08 13:45:45.732029: Epoch time: 138.16 s 
2025-12-08 13:45:46.374135:  
2025-12-08 13:45:46.374135: Epoch 666 
2025-12-08 13:45:46.390042: Current learning rate: 0.00373 
2025-12-08 13:48:04.329099: train_loss -0.8539 
2025-12-08 13:48:04.330099: val_loss -0.8764 
2025-12-08 13:48:04.335121: Pseudo dice [0.9244, 0.9555, 0.9459] 
2025-12-08 13:48:04.339128: Epoch time: 137.95 s 
2025-12-08 13:48:05.093156:  
2025-12-08 13:48:05.093156: Epoch 667 
2025-12-08 13:48:05.093156: Current learning rate: 0.00372 
2025-12-08 13:50:23.187428: train_loss -0.8466 
2025-12-08 13:50:23.187428: val_loss -0.8746 
2025-12-08 13:50:23.191364: Pseudo dice [0.9231, 0.9572, 0.9523] 
2025-12-08 13:50:23.197370: Epoch time: 138.09 s 
2025-12-08 13:50:23.859921:  
2025-12-08 13:50:23.859921: Epoch 668 
2025-12-08 13:50:23.859921: Current learning rate: 0.00371 
2025-12-08 13:52:41.640111: train_loss -0.8551 
2025-12-08 13:52:41.640111: val_loss -0.885 
2025-12-08 13:52:41.646566: Pseudo dice [0.9316, 0.9633, 0.9467] 
2025-12-08 13:52:41.650570: Epoch time: 137.8 s 
2025-12-08 13:52:41.654574: Yayy! New best EMA pseudo Dice: 0.9431 
2025-12-08 13:52:42.733728:  
2025-12-08 13:52:42.739226: Epoch 669 
2025-12-08 13:52:42.739226: Current learning rate: 0.0037 
2025-12-08 13:55:00.776456: train_loss -0.8571 
2025-12-08 13:55:00.778459: val_loss -0.879 
2025-12-08 13:55:00.788223: Pseudo dice [0.9281, 0.9551, 0.95] 
2025-12-08 13:55:00.794233: Epoch time: 138.04 s 
2025-12-08 13:55:00.801980: Yayy! New best EMA pseudo Dice: 0.9433 
2025-12-08 13:55:01.791488:  
2025-12-08 13:55:01.791488: Epoch 670 
2025-12-08 13:55:01.798554: Current learning rate: 0.00369 
2025-12-08 13:57:19.883137: train_loss -0.8569 
2025-12-08 13:57:19.883137: val_loss -0.8703 
2025-12-08 13:57:19.889146: Pseudo dice [0.9218, 0.9539, 0.9454] 
2025-12-08 13:57:19.895155: Epoch time: 138.09 s 
2025-12-08 13:57:20.547247:  
2025-12-08 13:57:20.547247: Epoch 671 
2025-12-08 13:57:20.563160: Current learning rate: 0.00368 
2025-12-08 13:59:38.639825: train_loss -0.851 
2025-12-08 13:59:38.639825: val_loss -0.8778 
2025-12-08 13:59:38.651332: Pseudo dice [0.9268, 0.9564, 0.948] 
2025-12-08 13:59:38.657338: Epoch time: 138.09 s 
2025-12-08 13:59:39.311259:  
2025-12-08 13:59:39.311259: Epoch 672 
2025-12-08 13:59:39.311259: Current learning rate: 0.00367 
2025-12-08 14:01:57.503399: train_loss -0.8495 
2025-12-08 14:01:57.505403: val_loss -0.8764 
2025-12-08 14:01:57.515160: Pseudo dice [0.9246, 0.9556, 0.9492] 
2025-12-08 14:01:57.521169: Epoch time: 138.19 s 
2025-12-08 14:01:58.226948:  
2025-12-08 14:01:58.226948: Epoch 673 
2025-12-08 14:01:58.232206: Current learning rate: 0.00366 
2025-12-08 14:04:16.421546: train_loss -0.8544 
2025-12-08 14:04:16.421546: val_loss -0.8823 
2025-12-08 14:04:16.428849: Pseudo dice [0.9272, 0.9575, 0.9527] 
2025-12-08 14:04:16.433204: Epoch time: 138.2 s 
2025-12-08 14:04:16.437432: Yayy! New best EMA pseudo Dice: 0.9433 
2025-12-08 14:04:17.368157:  
2025-12-08 14:04:17.369160: Epoch 674 
2025-12-08 14:04:17.373160: Current learning rate: 0.00365 
2025-12-08 14:06:35.379320: train_loss -0.8573 
2025-12-08 14:06:35.380321: val_loss -0.8849 
2025-12-08 14:06:35.385486: Pseudo dice [0.9324, 0.9622, 0.9481] 
2025-12-08 14:06:35.389491: Epoch time: 138.01 s 
2025-12-08 14:06:35.389491: Yayy! New best EMA pseudo Dice: 0.9438 
2025-12-08 14:06:36.522148:  
2025-12-08 14:06:36.522148: Epoch 675 
2025-12-08 14:06:36.527151: Current learning rate: 0.00364 
2025-12-08 14:08:54.505797: train_loss -0.854 
2025-12-08 14:08:54.505797: val_loss -0.8808 
2025-12-08 14:08:54.513805: Pseudo dice [0.9264, 0.9564, 0.9494] 
2025-12-08 14:08:54.519752: Epoch time: 137.98 s 
2025-12-08 14:08:54.523753: Yayy! New best EMA pseudo Dice: 0.9438 
2025-12-08 14:08:55.623903:  
2025-12-08 14:08:55.623903: Epoch 676 
2025-12-08 14:08:55.641427: Current learning rate: 0.00363 
2025-12-08 14:11:13.809203: train_loss -0.8492 
2025-12-08 14:11:13.809203: val_loss -0.8823 
2025-12-08 14:11:13.816720: Pseudo dice [0.929, 0.9605, 0.9456] 
2025-12-08 14:11:13.820724: Epoch time: 138.19 s 
2025-12-08 14:11:13.826730: Yayy! New best EMA pseudo Dice: 0.9439 
2025-12-08 14:11:14.767010:  
2025-12-08 14:11:14.767010: Epoch 677 
2025-12-08 14:11:14.767010: Current learning rate: 0.00362 
2025-12-08 14:13:32.906380: train_loss -0.8514 
2025-12-08 14:13:32.906380: val_loss -0.871 
2025-12-08 14:13:32.906380: Pseudo dice [0.9194, 0.9498, 0.9495] 
2025-12-08 14:13:32.924267: Epoch time: 138.14 s 
2025-12-08 14:13:33.577213:  
2025-12-08 14:13:33.577213: Epoch 678 
2025-12-08 14:13:33.577213: Current learning rate: 0.00361 
2025-12-08 14:15:51.697707: train_loss -0.8552 
2025-12-08 14:15:51.697707: val_loss -0.8754 
2025-12-08 14:15:51.704954: Pseudo dice [0.9245, 0.9542, 0.9522] 
2025-12-08 14:15:51.706955: Epoch time: 138.12 s 
2025-12-08 14:15:52.390827:  
2025-12-08 14:15:52.390827: Epoch 679 
2025-12-08 14:15:52.409650: Current learning rate: 0.0036 
2025-12-08 14:18:10.436878: train_loss -0.8514 
2025-12-08 14:18:10.436878: val_loss -0.8764 
2025-12-08 14:18:10.455440: Pseudo dice [0.9282, 0.9522, 0.94] 
2025-12-08 14:18:10.461185: Epoch time: 138.05 s 
2025-12-08 14:18:11.107991:  
2025-12-08 14:18:11.109029: Epoch 680 
2025-12-08 14:18:11.113734: Current learning rate: 0.00359 
2025-12-08 14:20:29.183959: train_loss -0.8499 
2025-12-08 14:20:29.183959: val_loss -0.8855 
2025-12-08 14:20:29.186929: Pseudo dice [0.931, 0.9633, 0.9524] 
2025-12-08 14:20:29.194530: Epoch time: 138.08 s 
2025-12-08 14:20:29.876988:  
2025-12-08 14:20:29.876988: Epoch 681 
2025-12-08 14:20:29.882746: Current learning rate: 0.00358 
2025-12-08 14:22:47.878353: train_loss -0.855 
2025-12-08 14:22:47.880356: val_loss -0.8866 
2025-12-08 14:22:47.886361: Pseudo dice [0.9307, 0.9586, 0.9464] 
2025-12-08 14:22:47.893872: Epoch time: 138.0 s 
2025-12-08 14:22:48.545602:  
2025-12-08 14:22:48.545602: Epoch 682 
2025-12-08 14:22:48.545602: Current learning rate: 0.00357 
2025-12-08 14:25:06.606699: train_loss -0.8555 
2025-12-08 14:25:06.608439: val_loss -0.8752 
2025-12-08 14:25:06.613319: Pseudo dice [0.9195, 0.9583, 0.952] 
2025-12-08 14:25:06.617322: Epoch time: 138.06 s 
2025-12-08 14:25:07.312084:  
2025-12-08 14:25:07.312084: Epoch 683 
2025-12-08 14:25:07.312084: Current learning rate: 0.00356 
2025-12-08 14:27:25.361518: train_loss -0.8478 
2025-12-08 14:27:25.363520: val_loss -0.8766 
2025-12-08 14:27:25.369264: Pseudo dice [0.9272, 0.9574, 0.9429] 
2025-12-08 14:27:25.373268: Epoch time: 138.05 s 
2025-12-08 14:27:26.014367:  
2025-12-08 14:27:26.014367: Epoch 684 
2025-12-08 14:27:26.030026: Current learning rate: 0.00355 
2025-12-08 14:29:45.748864: train_loss -0.8596 
2025-12-08 14:29:45.748864: val_loss -0.8849 
2025-12-08 14:29:45.756612: Pseudo dice [0.9335, 0.963, 0.9442] 
2025-12-08 14:29:45.764621: Epoch time: 139.73 s 
2025-12-08 14:29:45.770629: Yayy! New best EMA pseudo Dice: 0.944 
2025-12-08 14:29:46.799966:  
2025-12-08 14:29:46.799966: Epoch 685 
2025-12-08 14:29:46.811840: Current learning rate: 0.00354 
2025-12-08 14:32:05.424462: train_loss -0.8565 
2025-12-08 14:32:05.426464: val_loss -0.8789 
2025-12-08 14:32:05.430469: Pseudo dice [0.9272, 0.9539, 0.949] 
2025-12-08 14:32:05.438172: Epoch time: 138.62 s 
2025-12-08 14:32:06.265668:  
2025-12-08 14:32:06.265668: Epoch 686 
2025-12-08 14:32:06.272129: Current learning rate: 0.00353 
2025-12-08 14:34:24.760601: train_loss -0.8516 
2025-12-08 14:34:24.760601: val_loss -0.8749 
2025-12-08 14:34:24.768873: Pseudo dice [0.9254, 0.9566, 0.9446] 
2025-12-08 14:34:24.774616: Epoch time: 138.49 s 
2025-12-08 14:34:25.433776:  
2025-12-08 14:34:25.434779: Epoch 687 
2025-12-08 14:34:25.439952: Current learning rate: 0.00352 
2025-12-08 14:36:44.061196: train_loss -0.8514 
2025-12-08 14:36:44.061196: val_loss -0.8857 
2025-12-08 14:36:44.077057: Pseudo dice [0.9297, 0.961, 0.9521] 
2025-12-08 14:36:44.077057: Epoch time: 138.63 s 
2025-12-08 14:36:44.077057: Yayy! New best EMA pseudo Dice: 0.9442 
2025-12-08 14:36:45.045638:  
2025-12-08 14:36:45.045638: Epoch 688 
2025-12-08 14:36:45.061318: Current learning rate: 0.00351 
2025-12-08 14:39:03.537052: train_loss -0.8495 
2025-12-08 14:39:03.543052: val_loss -0.8803 
2025-12-08 14:39:03.548106: Pseudo dice [0.928, 0.9555, 0.9497] 
2025-12-08 14:39:03.553108: Epoch time: 138.49 s 
2025-12-08 14:39:03.557119: Yayy! New best EMA pseudo Dice: 0.9442 
2025-12-08 14:39:04.748383:  
2025-12-08 14:39:04.748383: Epoch 689 
2025-12-08 14:39:04.748383: Current learning rate: 0.0035 
2025-12-08 14:41:23.075969: train_loss -0.8569 
2025-12-08 14:41:23.078872: val_loss -0.884 
2025-12-08 14:41:23.087086: Pseudo dice [0.9301, 0.9611, 0.9493] 
2025-12-08 14:41:23.095119: Epoch time: 138.33 s 
2025-12-08 14:41:23.100863: Yayy! New best EMA pseudo Dice: 0.9444 
2025-12-08 14:41:24.030869:  
2025-12-08 14:41:24.030869: Epoch 690 
2025-12-08 14:41:24.046531: Current learning rate: 0.00349 
2025-12-08 14:43:42.276862: train_loss -0.8538 
2025-12-08 14:43:42.278863: val_loss -0.8714 
2025-12-08 14:43:42.280604: Pseudo dice [0.9199, 0.9554, 0.9489] 
2025-12-08 14:43:42.280604: Epoch time: 138.25 s 
2025-12-08 14:43:43.157835:  
2025-12-08 14:43:43.157835: Epoch 691 
2025-12-08 14:43:43.157835: Current learning rate: 0.00348 
2025-12-08 14:46:01.244288: train_loss -0.8508 
2025-12-08 14:46:01.246290: val_loss -0.8931 
2025-12-08 14:46:01.251446: Pseudo dice [0.9371, 0.9627, 0.9511] 
2025-12-08 14:46:01.256457: Epoch time: 138.09 s 
2025-12-08 14:46:01.260458: Yayy! New best EMA pseudo Dice: 0.9448 
2025-12-08 14:46:02.187280:  
2025-12-08 14:46:02.187280: Epoch 692 
2025-12-08 14:46:02.187280: Current learning rate: 0.00346 
2025-12-08 14:48:20.374037: train_loss -0.8538 
2025-12-08 14:48:20.374037: val_loss -0.8776 
2025-12-08 14:48:20.374037: Pseudo dice [0.9246, 0.9564, 0.9469] 
2025-12-08 14:48:20.389688: Epoch time: 138.19 s 
2025-12-08 14:48:21.033115:  
2025-12-08 14:48:21.034119: Epoch 693 
2025-12-08 14:48:21.034119: Current learning rate: 0.00345 
2025-12-08 14:50:39.214491: train_loss -0.8524 
2025-12-08 14:50:39.216493: val_loss -0.8894 
2025-12-08 14:50:39.222499: Pseudo dice [0.9321, 0.9608, 0.9519] 
2025-12-08 14:50:39.226503: Epoch time: 138.18 s 
2025-12-08 14:50:39.230507: Yayy! New best EMA pseudo Dice: 0.9449 
2025-12-08 14:50:40.170980:  
2025-12-08 14:50:40.170980: Epoch 694 
2025-12-08 14:50:40.186890: Current learning rate: 0.00344 
2025-12-08 14:52:58.237664: train_loss -0.8514 
2025-12-08 14:52:58.237664: val_loss -0.8758 
2025-12-08 14:52:58.237664: Pseudo dice [0.9237, 0.9585, 0.9446] 
2025-12-08 14:52:58.249638: Epoch time: 138.07 s 
2025-12-08 14:52:58.889695:  
2025-12-08 14:52:58.889695: Epoch 695 
2025-12-08 14:52:58.905593: Current learning rate: 0.00343 
2025-12-08 14:55:16.933279: train_loss -0.8574 
2025-12-08 14:55:16.933279: val_loss -0.8717 
2025-12-08 14:55:16.939348: Pseudo dice [0.9204, 0.9502, 0.9472] 
2025-12-08 14:55:16.944362: Epoch time: 138.04 s 
2025-12-08 14:55:17.592209:  
2025-12-08 14:55:17.592209: Epoch 696 
2025-12-08 14:55:17.592209: Current learning rate: 0.00342 
2025-12-08 14:57:35.687188: train_loss -0.853 
2025-12-08 14:57:35.687188: val_loss -0.8822 
2025-12-08 14:57:35.703288: Pseudo dice [0.9273, 0.9569, 0.9478] 
2025-12-08 14:57:35.703288: Epoch time: 138.09 s 
2025-12-08 14:57:36.530059:  
2025-12-08 14:57:36.530059: Epoch 697 
2025-12-08 14:57:36.530059: Current learning rate: 0.00341 
2025-12-08 14:59:54.594146: train_loss -0.8521 
2025-12-08 14:59:54.596151: val_loss -0.8788 
2025-12-08 14:59:54.604166: Pseudo dice [0.9252, 0.9563, 0.9469] 
2025-12-08 14:59:54.609910: Epoch time: 138.06 s 
2025-12-08 14:59:55.265494:  
2025-12-08 14:59:55.265494: Epoch 698 
2025-12-08 14:59:55.265494: Current learning rate: 0.0034 
2025-12-08 15:02:13.295466: train_loss -0.8512 
2025-12-08 15:02:13.295466: val_loss -0.8742 
2025-12-08 15:02:13.298509: Pseudo dice [0.9231, 0.9529, 0.9486] 
2025-12-08 15:02:13.308017: Epoch time: 138.03 s 
2025-12-08 15:02:13.984174:  
2025-12-08 15:02:13.984174: Epoch 699 
2025-12-08 15:02:13.984174: Current learning rate: 0.00339 
2025-12-08 15:04:32.133641: train_loss -0.8561 
2025-12-08 15:04:32.134644: val_loss -0.8834 
2025-12-08 15:04:32.139721: Pseudo dice [0.9295, 0.958, 0.9492] 
2025-12-08 15:04:32.144183: Epoch time: 138.15 s 
2025-12-08 15:04:33.060843:  
2025-12-08 15:04:33.060843: Epoch 700 
2025-12-08 15:04:33.060843: Current learning rate: 0.00338 
2025-12-08 15:06:51.173586: train_loss -0.8585 
2025-12-08 15:06:51.174588: val_loss -0.8767 
2025-12-08 15:06:51.182713: Pseudo dice [0.925, 0.9527, 0.9491] 
2025-12-08 15:06:51.186730: Epoch time: 138.11 s 
2025-12-08 15:06:51.842302:  
2025-12-08 15:06:51.842302: Epoch 701 
2025-12-08 15:06:51.858160: Current learning rate: 0.00337 
2025-12-08 15:09:10.185847: train_loss -0.8553 
2025-12-08 15:09:10.187885: val_loss -0.8771 
2025-12-08 15:09:10.195895: Pseudo dice [0.9245, 0.9546, 0.9494] 
2025-12-08 15:09:10.201640: Epoch time: 138.34 s 
2025-12-08 15:09:10.862355:  
2025-12-08 15:09:10.862355: Epoch 702 
2025-12-08 15:09:10.868383: Current learning rate: 0.00336 
2025-12-08 15:11:28.861055: train_loss -0.8542 
2025-12-08 15:11:28.861055: val_loss -0.8747 
2025-12-08 15:11:28.869066: Pseudo dice [0.9218, 0.955, 0.9458] 
2025-12-08 15:11:28.876076: Epoch time: 138.0 s 
2025-12-08 15:11:29.764257:  
2025-12-08 15:11:29.764257: Epoch 703 
2025-12-08 15:11:29.764257: Current learning rate: 0.00335 
2025-12-08 15:13:47.735636: train_loss -0.8498 
2025-12-08 15:13:47.737639: val_loss -0.8784 
2025-12-08 15:13:47.739642: Pseudo dice [0.9266, 0.9552, 0.9504] 
2025-12-08 15:13:47.749339: Epoch time: 137.97 s 
2025-12-08 15:13:48.394916:  
2025-12-08 15:13:48.394916: Epoch 704 
2025-12-08 15:13:48.405310: Current learning rate: 0.00334 
2025-12-08 15:16:06.511687: train_loss -0.852 
2025-12-08 15:16:06.512689: val_loss -0.8772 
2025-12-08 15:16:06.518733: Pseudo dice [0.9224, 0.9592, 0.9519] 
2025-12-08 15:16:06.523748: Epoch time: 138.12 s 
2025-12-08 15:16:07.171134:  
2025-12-08 15:16:07.171134: Epoch 705 
2025-12-08 15:16:07.187208: Current learning rate: 0.00333 
2025-12-08 15:18:25.311920: train_loss -0.8554 
2025-12-08 15:18:25.311920: val_loss -0.8725 
2025-12-08 15:18:25.311920: Pseudo dice [0.9208, 0.9474, 0.9516] 
2025-12-08 15:18:25.311920: Epoch time: 138.14 s 
2025-12-08 15:18:26.077391:  
2025-12-08 15:18:26.093311: Epoch 706 
2025-12-08 15:18:26.096830: Current learning rate: 0.00332 
2025-12-08 15:20:43.994702: train_loss -0.8558 
2025-12-08 15:20:43.994702: val_loss -0.8742 
2025-12-08 15:20:43.998703: Pseudo dice [0.923, 0.9553, 0.943] 
2025-12-08 15:20:44.007097: Epoch time: 137.92 s 
2025-12-08 15:20:44.654953:  
2025-12-08 15:20:44.654953: Epoch 707 
2025-12-08 15:20:44.670748: Current learning rate: 0.00331 
2025-12-08 15:23:02.835400: train_loss -0.8521 
2025-12-08 15:23:02.836401: val_loss -0.8735 
2025-12-08 15:23:02.842675: Pseudo dice [0.9225, 0.956, 0.9477] 
2025-12-08 15:23:02.847931: Epoch time: 138.18 s 
2025-12-08 15:23:03.499043:  
2025-12-08 15:23:03.499043: Epoch 708 
2025-12-08 15:23:03.499043: Current learning rate: 0.0033 
2025-12-08 15:25:21.555880: train_loss -0.8567 
2025-12-08 15:25:21.555880: val_loss -0.8848 
2025-12-08 15:25:21.561628: Pseudo dice [0.9306, 0.9597, 0.9505] 
2025-12-08 15:25:21.566023: Epoch time: 138.06 s 
2025-12-08 15:25:22.484155:  
2025-12-08 15:25:22.484155: Epoch 709 
2025-12-08 15:25:22.504245: Current learning rate: 0.00329 
2025-12-08 15:27:40.560529: train_loss -0.8537 
2025-12-08 15:27:40.560529: val_loss -0.884 
2025-12-08 15:27:40.565109: Pseudo dice [0.9298, 0.9567, 0.9552] 
2025-12-08 15:27:40.570751: Epoch time: 138.08 s 
2025-12-08 15:27:41.220109:  
2025-12-08 15:27:41.234573: Epoch 710 
2025-12-08 15:27:41.234573: Current learning rate: 0.00328 
2025-12-08 15:29:59.371914: train_loss -0.8539 
2025-12-08 15:29:59.372916: val_loss -0.882 
2025-12-08 15:29:59.373924: Pseudo dice [0.9301, 0.9606, 0.9455] 
2025-12-08 15:29:59.373924: Epoch time: 138.15 s 
2025-12-08 15:30:00.030276:  
2025-12-08 15:30:00.030276: Epoch 711 
2025-12-08 15:30:00.030276: Current learning rate: 0.00327 
2025-12-08 15:32:18.297550: train_loss -0.8539 
2025-12-08 15:32:18.297550: val_loss -0.8782 
2025-12-08 15:32:18.297550: Pseudo dice [0.9284, 0.9569, 0.9488] 
2025-12-08 15:32:18.317600: Epoch time: 138.27 s 
2025-12-08 15:32:19.092685:  
2025-12-08 15:32:19.092685: Epoch 712 
2025-12-08 15:32:19.108673: Current learning rate: 0.00326 
2025-12-08 15:34:37.249512: train_loss -0.8508 
2025-12-08 15:34:37.249512: val_loss -0.8741 
2025-12-08 15:34:37.249512: Pseudo dice [0.9206, 0.9496, 0.9506] 
2025-12-08 15:34:37.263076: Epoch time: 138.16 s 
2025-12-08 15:34:37.906699:  
2025-12-08 15:34:37.906699: Epoch 713 
2025-12-08 15:34:37.906699: Current learning rate: 0.00325 
2025-12-08 15:36:55.968328: train_loss -0.8538 
2025-12-08 15:36:55.968328: val_loss -0.8734 
2025-12-08 15:36:55.983577: Pseudo dice [0.9196, 0.9496, 0.9496] 
2025-12-08 15:36:55.987581: Epoch time: 138.06 s 
2025-12-08 15:36:56.642704:  
2025-12-08 15:36:56.642704: Epoch 714 
2025-12-08 15:36:56.642704: Current learning rate: 0.00324 
2025-12-08 15:39:14.765977: train_loss -0.8568 
2025-12-08 15:39:14.765977: val_loss -0.8758 
2025-12-08 15:39:14.772019: Pseudo dice [0.9245, 0.9564, 0.9502] 
2025-12-08 15:39:14.777043: Epoch time: 138.12 s 
2025-12-08 15:39:15.763789:  
2025-12-08 15:39:15.763789: Epoch 715 
2025-12-08 15:39:15.770974: Current learning rate: 0.00323 
2025-12-08 15:41:34.061836: train_loss -0.8515 
2025-12-08 15:41:34.061836: val_loss -0.8789 
2025-12-08 15:41:34.077581: Pseudo dice [0.9279, 0.9584, 0.9528] 
2025-12-08 15:41:34.077581: Epoch time: 138.3 s 
2025-12-08 15:41:34.733670:  
2025-12-08 15:41:34.733670: Epoch 716 
2025-12-08 15:41:34.733670: Current learning rate: 0.00322 
2025-12-08 15:43:52.670922: train_loss -0.859 
2025-12-08 15:43:52.670922: val_loss -0.8717 
2025-12-08 15:43:52.686578: Pseudo dice [0.92, 0.9524, 0.9521] 
2025-12-08 15:43:52.686578: Epoch time: 137.95 s 
2025-12-08 15:43:53.326801:  
2025-12-08 15:43:53.326801: Epoch 717 
2025-12-08 15:43:53.342566: Current learning rate: 0.00321 
2025-12-08 15:46:11.600828: train_loss -0.857 
2025-12-08 15:46:11.600828: val_loss -0.8657 
2025-12-08 15:46:11.604832: Pseudo dice [0.9172, 0.9487, 0.9437] 
2025-12-08 15:46:11.610838: Epoch time: 138.27 s 
2025-12-08 15:46:12.358357:  
2025-12-08 15:46:12.358357: Epoch 718 
2025-12-08 15:46:12.374274: Current learning rate: 0.0032 
2025-12-08 15:48:30.355407: train_loss -0.8506 
2025-12-08 15:48:30.357409: val_loss -0.8806 
2025-12-08 15:48:30.363153: Pseudo dice [0.9254, 0.957, 0.9509] 
2025-12-08 15:48:30.369159: Epoch time: 138.0 s 
2025-12-08 15:48:31.030609:  
2025-12-08 15:48:31.030609: Epoch 719 
2025-12-08 15:48:31.030609: Current learning rate: 0.00319 
2025-12-08 15:50:49.069439: train_loss -0.8579 
2025-12-08 15:50:49.070441: val_loss -0.878 
2025-12-08 15:50:49.075457: Pseudo dice [0.9242, 0.9577, 0.9509] 
2025-12-08 15:50:49.076459: Epoch time: 138.04 s 
2025-12-08 15:50:49.731134:  
2025-12-08 15:50:49.731134: Epoch 720 
2025-12-08 15:50:49.737223: Current learning rate: 0.00318 
2025-12-08 15:53:07.853988: train_loss -0.8553 
2025-12-08 15:53:07.853988: val_loss -0.8811 
2025-12-08 15:53:07.858010: Pseudo dice [0.9274, 0.9573, 0.949] 
2025-12-08 15:53:07.858010: Epoch time: 138.12 s 
2025-12-08 15:53:08.842216:  
2025-12-08 15:53:08.842216: Epoch 721 
2025-12-08 15:53:08.842216: Current learning rate: 0.00317 
2025-12-08 15:55:26.796894: train_loss -0.8569 
2025-12-08 15:55:26.796894: val_loss -0.8779 
2025-12-08 15:55:26.812653: Pseudo dice [0.9265, 0.9556, 0.9524] 
2025-12-08 15:55:26.812653: Epoch time: 137.96 s 
2025-12-08 15:55:27.468003:  
2025-12-08 15:55:27.468003: Epoch 722 
2025-12-08 15:55:27.468003: Current learning rate: 0.00316 
2025-12-08 15:57:45.437224: train_loss -0.8562 
2025-12-08 15:57:45.437224: val_loss -0.8776 
2025-12-08 15:57:45.437224: Pseudo dice [0.9257, 0.9533, 0.9447] 
2025-12-08 15:57:45.437224: Epoch time: 137.97 s 
2025-12-08 15:57:46.092521:  
2025-12-08 15:57:46.092521: Epoch 723 
2025-12-08 15:57:46.092521: Current learning rate: 0.00315 
2025-12-08 16:00:04.237739: train_loss -0.8545 
2025-12-08 16:00:04.239741: val_loss -0.8695 
2025-12-08 16:00:04.249504: Pseudo dice [0.9209, 0.9524, 0.9505] 
2025-12-08 16:00:04.252740: Epoch time: 138.15 s 
2025-12-08 16:00:05.014384:  
2025-12-08 16:00:05.016387: Epoch 724 
2025-12-08 16:00:05.018391: Current learning rate: 0.00314 
2025-12-08 16:02:23.216543: train_loss -0.8496 
2025-12-08 16:02:23.216543: val_loss -0.8692 
2025-12-08 16:02:23.222549: Pseudo dice [0.9173, 0.9505, 0.9507] 
2025-12-08 16:02:23.228292: Epoch time: 138.2 s 
2025-12-08 16:02:23.873899:  
2025-12-08 16:02:23.873899: Epoch 725 
2025-12-08 16:02:23.889968: Current learning rate: 0.00313 
2025-12-08 16:04:41.911976: train_loss -0.8565 
2025-12-08 16:04:41.911976: val_loss -0.8796 
2025-12-08 16:04:41.921727: Pseudo dice [0.9274, 0.9563, 0.9506] 
2025-12-08 16:04:41.927736: Epoch time: 138.04 s 
2025-12-08 16:04:42.577304:  
2025-12-08 16:04:42.577304: Epoch 726 
2025-12-08 16:04:42.593094: Current learning rate: 0.00312 
2025-12-08 16:07:00.827195: train_loss -0.8585 
2025-12-08 16:07:00.827195: val_loss -0.8738 
2025-12-08 16:07:00.834531: Pseudo dice [0.921, 0.9533, 0.9515] 
2025-12-08 16:07:00.840537: Epoch time: 138.25 s 
2025-12-08 16:07:01.783680:  
2025-12-08 16:07:01.784683: Epoch 727 
2025-12-08 16:07:01.790703: Current learning rate: 0.00311 
2025-12-08 16:09:19.836418: train_loss -0.8551 
2025-12-08 16:09:19.836418: val_loss -0.8833 
2025-12-08 16:09:19.842504: Pseudo dice [0.9295, 0.9613, 0.9428] 
2025-12-08 16:09:19.848091: Epoch time: 138.05 s 
2025-12-08 16:09:20.548191:  
2025-12-08 16:09:20.548191: Epoch 728 
2025-12-08 16:09:20.553205: Current learning rate: 0.0031 
2025-12-08 16:11:38.705555: train_loss -0.8547 
2025-12-08 16:11:38.707558: val_loss -0.8867 
2025-12-08 16:11:38.713565: Pseudo dice [0.933, 0.9584, 0.9507] 
2025-12-08 16:11:38.717569: Epoch time: 138.17 s 
2025-12-08 16:11:39.374153:  
2025-12-08 16:11:39.374153: Epoch 729 
2025-12-08 16:11:39.374153: Current learning rate: 0.00309 
2025-12-08 16:13:57.492908: train_loss -0.8544 
2025-12-08 16:13:57.493910: val_loss -0.8826 
2025-12-08 16:13:57.498925: Pseudo dice [0.9316, 0.956, 0.9509] 
2025-12-08 16:13:57.505085: Epoch time: 138.12 s 
2025-12-08 16:13:58.280923:  
2025-12-08 16:13:58.280923: Epoch 730 
2025-12-08 16:13:58.296801: Current learning rate: 0.00308 
2025-12-08 16:16:16.356356: train_loss -0.8573 
2025-12-08 16:16:16.356356: val_loss -0.8693 
2025-12-08 16:16:16.358096: Pseudo dice [0.9209, 0.9515, 0.941] 
2025-12-08 16:16:16.358096: Epoch time: 138.08 s 
2025-12-08 16:16:17.030430:  
2025-12-08 16:16:17.030430: Epoch 731 
2025-12-08 16:16:17.030430: Current learning rate: 0.00307 
2025-12-08 16:18:35.155793: train_loss -0.8526 
2025-12-08 16:18:35.155793: val_loss -0.8743 
2025-12-08 16:18:35.155793: Pseudo dice [0.9222, 0.9545, 0.9486] 
2025-12-08 16:18:35.155793: Epoch time: 138.14 s 
2025-12-08 16:18:35.843461:  
2025-12-08 16:18:35.843461: Epoch 732 
2025-12-08 16:18:35.858978: Current learning rate: 0.00306 
2025-12-08 16:20:54.015244: train_loss -0.854 
2025-12-08 16:20:54.015244: val_loss -0.8866 
2025-12-08 16:20:54.035081: Pseudo dice [0.9321, 0.9578, 0.9483] 
2025-12-08 16:20:54.039448: Epoch time: 138.17 s 
2025-12-08 16:20:54.686515:  
2025-12-08 16:20:54.686515: Epoch 733 
2025-12-08 16:20:54.694112: Current learning rate: 0.00305 
2025-12-08 16:23:12.841616: train_loss -0.8571 
2025-12-08 16:23:12.842620: val_loss -0.8839 
2025-12-08 16:23:12.848621: Pseudo dice [0.9305, 0.9571, 0.9482] 
2025-12-08 16:23:12.852570: Epoch time: 138.16 s 
2025-12-08 16:23:13.540438:  
2025-12-08 16:23:13.540438: Epoch 734 
2025-12-08 16:23:13.549816: Current learning rate: 0.00304 
2025-12-08 16:25:31.499775: train_loss -0.8519 
2025-12-08 16:25:31.499775: val_loss -0.8679 
2025-12-08 16:25:31.507985: Pseudo dice [0.916, 0.9514, 0.9461] 
2025-12-08 16:25:31.513629: Epoch time: 137.96 s 
2025-12-08 16:25:32.156291:  
2025-12-08 16:25:32.156291: Epoch 735 
2025-12-08 16:25:32.162977: Current learning rate: 0.00303 
2025-12-08 16:27:50.219733: train_loss -0.8563 
2025-12-08 16:27:50.219733: val_loss -0.8811 
2025-12-08 16:27:50.230608: Pseudo dice [0.9235, 0.9591, 0.9477] 
2025-12-08 16:27:50.237345: Epoch time: 138.06 s 
2025-12-08 16:27:50.952289:  
2025-12-08 16:27:50.968227: Epoch 736 
2025-12-08 16:27:50.968227: Current learning rate: 0.00302 
2025-12-08 16:30:09.076736: train_loss -0.851 
2025-12-08 16:30:09.076736: val_loss -0.8865 
2025-12-08 16:30:09.086309: Pseudo dice [0.9326, 0.9608, 0.9481] 
2025-12-08 16:30:09.090828: Epoch time: 138.12 s 
2025-12-08 16:30:09.749058:  
2025-12-08 16:30:09.749058: Epoch 737 
2025-12-08 16:30:09.749058: Current learning rate: 0.00301 
2025-12-08 16:32:27.873856: train_loss -0.8532 
2025-12-08 16:32:27.875858: val_loss -0.8699 
2025-12-08 16:32:27.881864: Pseudo dice [0.9196, 0.9534, 0.9483] 
2025-12-08 16:32:27.885868: Epoch time: 138.12 s 
2025-12-08 16:32:28.551021:  
2025-12-08 16:32:28.551021: Epoch 738 
2025-12-08 16:32:28.557045: Current learning rate: 0.003 
2025-12-08 16:34:46.699082: train_loss -0.8559 
2025-12-08 16:34:46.699082: val_loss -0.8763 
2025-12-08 16:34:46.706011: Pseudo dice [0.9256, 0.9546, 0.9472] 
2025-12-08 16:34:46.706011: Epoch time: 138.15 s 
2025-12-08 16:34:47.515096:  
2025-12-08 16:34:47.515096: Epoch 739 
2025-12-08 16:34:47.530977: Current learning rate: 0.00299 
2025-12-08 16:37:06.613407: train_loss -0.8493 
2025-12-08 16:37:06.614411: val_loss -0.8827 
2025-12-08 16:37:06.619438: Pseudo dice [0.9308, 0.9597, 0.9492] 
2025-12-08 16:37:06.623824: Epoch time: 139.1 s 
2025-12-08 16:37:07.280059:  
2025-12-08 16:37:07.280059: Epoch 740 
2025-12-08 16:37:07.280059: Current learning rate: 0.00297 
2025-12-08 16:39:25.779861: train_loss -0.8539 
2025-12-08 16:39:25.779861: val_loss -0.886 
2025-12-08 16:39:25.779861: Pseudo dice [0.9303, 0.96, 0.9502] 
2025-12-08 16:39:25.779861: Epoch time: 138.5 s 
2025-12-08 16:39:26.464347:  
2025-12-08 16:39:26.465352: Epoch 741 
2025-12-08 16:39:26.471559: Current learning rate: 0.00296 
2025-12-08 16:41:45.323546: train_loss -0.8542 
2025-12-08 16:41:45.323546: val_loss -0.8789 
2025-12-08 16:41:45.331293: Pseudo dice [0.9276, 0.9578, 0.948] 
2025-12-08 16:41:45.335297: Epoch time: 138.86 s 
2025-12-08 16:41:46.171733:  
2025-12-08 16:41:46.171733: Epoch 742 
2025-12-08 16:41:46.186994: Current learning rate: 0.00295 
2025-12-08 16:44:04.825731: train_loss -0.8509 
2025-12-08 16:44:04.827472: val_loss -0.87 
2025-12-08 16:44:04.833478: Pseudo dice [0.9225, 0.9566, 0.9429] 
2025-12-08 16:44:04.839483: Epoch time: 138.65 s 
2025-12-08 16:44:05.499713:  
2025-12-08 16:44:05.499713: Epoch 743 
2025-12-08 16:44:05.499713: Current learning rate: 0.00294 
2025-12-08 16:46:23.992178: train_loss -0.8496 
2025-12-08 16:46:23.992178: val_loss -0.8859 
2025-12-08 16:46:23.998200: Pseudo dice [0.9317, 0.9574, 0.949] 
2025-12-08 16:46:24.003062: Epoch time: 138.49 s 
2025-12-08 16:46:24.655903:  
2025-12-08 16:46:24.655903: Epoch 744 
2025-12-08 16:46:24.655903: Current learning rate: 0.00293 
2025-12-08 16:48:42.784578: train_loss -0.8462 
2025-12-08 16:48:42.784578: val_loss -0.8757 
2025-12-08 16:48:42.792586: Pseudo dice [0.9253, 0.9542, 0.9501] 
2025-12-08 16:48:42.798912: Epoch time: 138.13 s 
2025-12-08 16:48:43.796178:  
2025-12-08 16:48:43.796178: Epoch 745 
2025-12-08 16:48:43.812204: Current learning rate: 0.00292 
2025-12-08 16:51:01.784065: train_loss -0.8556 
2025-12-08 16:51:01.784065: val_loss -0.8789 
2025-12-08 16:51:01.790068: Pseudo dice [0.9273, 0.9582, 0.9425] 
2025-12-08 16:51:01.794395: Epoch time: 137.99 s 
2025-12-08 16:51:02.467763:  
2025-12-08 16:51:02.467763: Epoch 746 
2025-12-08 16:51:02.467763: Current learning rate: 0.00291 
2025-12-08 16:53:20.542840: train_loss -0.8506 
2025-12-08 16:53:20.544844: val_loss -0.8683 
2025-12-08 16:53:20.551853: Pseudo dice [0.9177, 0.9542, 0.9482] 
2025-12-08 16:53:20.557859: Epoch time: 138.08 s 
2025-12-08 16:53:21.250190:  
2025-12-08 16:53:21.250190: Epoch 747 
2025-12-08 16:53:21.257366: Current learning rate: 0.0029 
2025-12-08 16:55:39.219191: train_loss -0.8484 
2025-12-08 16:55:39.219191: val_loss -0.8795 
2025-12-08 16:55:39.221194: Pseudo dice [0.9267, 0.9576, 0.9473] 
2025-12-08 16:55:39.229772: Epoch time: 137.98 s 
2025-12-08 16:55:39.983727:  
2025-12-08 16:55:39.983727: Epoch 748 
2025-12-08 16:55:39.994255: Current learning rate: 0.00289 
2025-12-08 16:57:58.207278: train_loss -0.8521 
2025-12-08 16:57:58.208280: val_loss -0.8824 
2025-12-08 16:57:58.213281: Pseudo dice [0.9296, 0.9584, 0.9465] 
2025-12-08 16:57:58.217702: Epoch time: 138.22 s 
2025-12-08 16:57:58.926049:  
2025-12-08 16:57:58.926049: Epoch 749 
2025-12-08 16:57:58.932053: Current learning rate: 0.00288 
2025-12-08 17:00:16.935865: train_loss -0.8499 
2025-12-08 17:00:16.935865: val_loss -0.8687 
2025-12-08 17:00:16.941366: Pseudo dice [0.9183, 0.9514, 0.9466] 
2025-12-08 17:00:16.945370: Epoch time: 138.01 s 
2025-12-08 17:00:17.858153:  
2025-12-08 17:00:17.858153: Epoch 750 
2025-12-08 17:00:17.873908: Current learning rate: 0.00287 
2025-12-08 17:02:36.045734: train_loss -0.8539 
2025-12-08 17:02:36.045734: val_loss -0.8804 
2025-12-08 17:02:36.045734: Pseudo dice [0.9276, 0.9529, 0.9543] 
2025-12-08 17:02:36.045734: Epoch time: 138.19 s 
2025-12-08 17:02:37.061607:  
2025-12-08 17:02:37.061607: Epoch 751 
2025-12-08 17:02:37.061607: Current learning rate: 0.00286 
2025-12-08 17:04:55.101326: train_loss -0.859 
2025-12-08 17:04:55.103330: val_loss -0.8748 
2025-12-08 17:04:55.112329: Pseudo dice [0.9246, 0.9551, 0.9455] 
2025-12-08 17:04:55.118330: Epoch time: 138.04 s 
2025-12-08 17:04:55.843242:  
2025-12-08 17:04:55.843242: Epoch 752 
2025-12-08 17:04:55.843242: Current learning rate: 0.00285 
2025-12-08 17:07:14.030074: train_loss -0.8571 
2025-12-08 17:07:14.031887: val_loss -0.8714 
2025-12-08 17:07:14.037893: Pseudo dice [0.9231, 0.9548, 0.9437] 
2025-12-08 17:07:14.043638: Epoch time: 138.19 s 
2025-12-08 17:07:14.697573:  
2025-12-08 17:07:14.698585: Epoch 753 
2025-12-08 17:07:14.703943: Current learning rate: 0.00284 
2025-12-08 17:09:32.779102: train_loss -0.8483 
2025-12-08 17:09:32.780103: val_loss -0.8731 
2025-12-08 17:09:32.788105: Pseudo dice [0.9219, 0.9529, 0.9531] 
2025-12-08 17:09:32.794106: Epoch time: 138.08 s 
2025-12-08 17:09:33.592262:  
2025-12-08 17:09:33.592262: Epoch 754 
2025-12-08 17:09:33.608342: Current learning rate: 0.00283 
2025-12-08 17:11:51.722028: train_loss -0.8516 
2025-12-08 17:11:51.724029: val_loss -0.8864 
2025-12-08 17:11:51.725770: Pseudo dice [0.9279, 0.9586, 0.9558] 
2025-12-08 17:11:51.733921: Epoch time: 138.13 s 
2025-12-08 17:11:52.436433:  
2025-12-08 17:11:52.436433: Epoch 755 
2025-12-08 17:11:52.452170: Current learning rate: 0.00282 
2025-12-08 17:14:10.565205: train_loss -0.8547 
2025-12-08 17:14:10.565205: val_loss -0.8768 
2025-12-08 17:14:10.572953: Pseudo dice [0.9228, 0.9575, 0.9461] 
2025-12-08 17:14:10.576957: Epoch time: 138.13 s 
2025-12-08 17:14:11.241823:  
2025-12-08 17:14:11.241823: Epoch 756 
2025-12-08 17:14:11.247529: Current learning rate: 0.00281 
2025-12-08 17:16:29.382347: train_loss -0.8536 
2025-12-08 17:16:29.389982: val_loss -0.869 
2025-12-08 17:16:29.393926: Pseudo dice [0.9213, 0.9525, 0.9442] 
2025-12-08 17:16:29.399932: Epoch time: 138.14 s 
2025-12-08 17:16:30.358339:  
2025-12-08 17:16:30.358339: Epoch 757 
2025-12-08 17:16:30.375442: Current learning rate: 0.0028 
2025-12-08 17:18:48.580821: train_loss -0.847 
2025-12-08 17:18:48.580821: val_loss -0.8746 
2025-12-08 17:18:48.589859: Pseudo dice [0.9246, 0.9586, 0.9421] 
2025-12-08 17:18:48.592870: Epoch time: 138.22 s 
2025-12-08 17:18:49.248597:  
2025-12-08 17:18:49.248597: Epoch 758 
2025-12-08 17:18:49.248597: Current learning rate: 0.00279 
2025-12-08 17:21:07.275146: train_loss -0.8554 
2025-12-08 17:21:07.275146: val_loss -0.8774 
2025-12-08 17:21:07.284902: Pseudo dice [0.9282, 0.9531, 0.9452] 
2025-12-08 17:21:07.290908: Epoch time: 138.03 s 
2025-12-08 17:21:07.948934:  
2025-12-08 17:21:07.948934: Epoch 759 
2025-12-08 17:21:07.954946: Current learning rate: 0.00278 
2025-12-08 17:23:26.061362: train_loss -0.8597 
2025-12-08 17:23:26.061362: val_loss -0.882 
2025-12-08 17:23:26.070410: Pseudo dice [0.9282, 0.96, 0.9506] 
2025-12-08 17:23:26.076131: Epoch time: 138.11 s 
2025-12-08 17:23:26.756088:  
2025-12-08 17:23:26.756088: Epoch 760 
2025-12-08 17:23:26.761101: Current learning rate: 0.00277 
2025-12-08 17:25:44.873870: train_loss -0.8518 
2025-12-08 17:25:44.874980: val_loss -0.8777 
2025-12-08 17:25:44.882015: Pseudo dice [0.9292, 0.9554, 0.9409] 
2025-12-08 17:25:44.888018: Epoch time: 138.12 s 
2025-12-08 17:25:45.531067:  
2025-12-08 17:25:45.531067: Epoch 761 
2025-12-08 17:25:45.543736: Current learning rate: 0.00276 
2025-12-08 17:28:03.593118: train_loss -0.8519 
2025-12-08 17:28:03.593118: val_loss -0.8843 
2025-12-08 17:28:03.608939: Pseudo dice [0.9289, 0.9555, 0.9504] 
2025-12-08 17:28:03.613745: Epoch time: 138.06 s 
2025-12-08 17:28:04.325301:  
2025-12-08 17:28:04.326306: Epoch 762 
2025-12-08 17:28:04.331353: Current learning rate: 0.00275 
2025-12-08 17:30:22.344583: train_loss -0.8541 
2025-12-08 17:30:22.344583: val_loss -0.8805 
2025-12-08 17:30:22.350589: Pseudo dice [0.9281, 0.9565, 0.9495] 
2025-12-08 17:30:22.356595: Epoch time: 138.02 s 
2025-12-08 17:30:23.187927:  
2025-12-08 17:30:23.187927: Epoch 763 
2025-12-08 17:30:23.187927: Current learning rate: 0.00274 
2025-12-08 17:32:41.344105: train_loss -0.8537 
2025-12-08 17:32:41.345115: val_loss -0.8706 
2025-12-08 17:32:41.351178: Pseudo dice [0.9182, 0.9544, 0.9444] 
2025-12-08 17:32:41.355402: Epoch time: 138.16 s 
2025-12-08 17:32:42.071291:  
2025-12-08 17:32:42.071291: Epoch 764 
2025-12-08 17:32:42.077787: Current learning rate: 0.00273 
2025-12-08 17:35:00.234174: train_loss -0.855 
2025-12-08 17:35:00.234174: val_loss -0.8775 
2025-12-08 17:35:00.234174: Pseudo dice [0.9237, 0.953, 0.9516] 
2025-12-08 17:35:00.249863: Epoch time: 138.16 s 
2025-12-08 17:35:00.910100:  
2025-12-08 17:35:00.910100: Epoch 765 
2025-12-08 17:35:00.916125: Current learning rate: 0.00272 
2025-12-08 17:37:19.046699: train_loss -0.8531 
2025-12-08 17:37:19.062497: val_loss -0.8738 
2025-12-08 17:37:19.062497: Pseudo dice [0.9253, 0.9538, 0.9493] 
2025-12-08 17:37:19.062497: Epoch time: 138.14 s 
2025-12-08 17:37:19.717976:  
2025-12-08 17:37:19.717976: Epoch 766 
2025-12-08 17:37:19.733917: Current learning rate: 0.00271 
2025-12-08 17:39:38.108955: train_loss -0.8552 
2025-12-08 17:39:38.124943: val_loss -0.8774 
2025-12-08 17:39:38.124943: Pseudo dice [0.9243, 0.9573, 0.9469] 
2025-12-08 17:39:38.124943: Epoch time: 138.39 s 
2025-12-08 17:39:38.780824:  
2025-12-08 17:39:38.780824: Epoch 767 
2025-12-08 17:39:38.780824: Current learning rate: 0.0027 
2025-12-08 17:41:57.091994: train_loss -0.8428 
2025-12-08 17:41:57.092994: val_loss -0.8786 
2025-12-08 17:41:57.094779: Pseudo dice [0.927, 0.9584, 0.9484] 
2025-12-08 17:41:57.102768: Epoch time: 138.31 s 
2025-12-08 17:41:57.780260:  
2025-12-08 17:41:57.780260: Epoch 768 
2025-12-08 17:41:57.784266: Current learning rate: 0.00268 
2025-12-08 17:44:15.907614: train_loss -0.8485 
2025-12-08 17:44:15.907614: val_loss -0.8759 
2025-12-08 17:44:15.907614: Pseudo dice [0.9246, 0.9563, 0.9478] 
2025-12-08 17:44:15.907614: Epoch time: 138.13 s 
2025-12-08 17:44:16.753181:  
2025-12-08 17:44:16.754184: Epoch 769 
2025-12-08 17:44:16.759426: Current learning rate: 0.00267 
2025-12-08 17:46:34.939950: train_loss -0.8519 
2025-12-08 17:46:34.940952: val_loss -0.8789 
2025-12-08 17:46:34.946960: Pseudo dice [0.9276, 0.9562, 0.948] 
2025-12-08 17:46:34.952224: Epoch time: 138.19 s 
2025-12-08 17:46:35.608722:  
2025-12-08 17:46:35.608722: Epoch 770 
2025-12-08 17:46:35.620910: Current learning rate: 0.00266 
2025-12-08 17:48:53.624125: train_loss -0.8519 
2025-12-08 17:48:53.625933: val_loss -0.8875 
2025-12-08 17:48:53.631137: Pseudo dice [0.9341, 0.9578, 0.9467] 
2025-12-08 17:48:53.635141: Epoch time: 138.02 s 
2025-12-08 17:48:54.327237:  
2025-12-08 17:48:54.329239: Epoch 771 
2025-12-08 17:48:54.329239: Current learning rate: 0.00265 
2025-12-08 17:51:12.543224: train_loss -0.8549 
2025-12-08 17:51:12.543224: val_loss -0.8813 
2025-12-08 17:51:12.550232: Pseudo dice [0.929, 0.9565, 0.9477] 
2025-12-08 17:51:12.556238: Epoch time: 138.22 s 
2025-12-08 17:51:13.215364:  
2025-12-08 17:51:13.217366: Epoch 772 
2025-12-08 17:51:13.217366: Current learning rate: 0.00264 
2025-12-08 17:53:31.240237: train_loss -0.8515 
2025-12-08 17:53:31.242238: val_loss -0.8825 
2025-12-08 17:53:31.251465: Pseudo dice [0.9276, 0.9596, 0.9489] 
2025-12-08 17:53:31.263483: Epoch time: 138.02 s 
2025-12-08 17:53:31.982326:  
2025-12-08 17:53:31.982326: Epoch 773 
2025-12-08 17:53:31.987885: Current learning rate: 0.00263 
2025-12-08 17:55:50.096360: train_loss -0.8487 
2025-12-08 17:55:50.096360: val_loss -0.8709 
2025-12-08 17:55:50.102367: Pseudo dice [0.9218, 0.9517, 0.9475] 
2025-12-08 17:55:50.110277: Epoch time: 138.12 s 
2025-12-08 17:55:50.859495:  
2025-12-08 17:55:50.859495: Epoch 774 
2025-12-08 17:55:50.875237: Current learning rate: 0.00262 
2025-12-08 17:58:08.932349: train_loss -0.8512 
2025-12-08 17:58:08.932349: val_loss -0.8817 
2025-12-08 17:58:08.936353: Pseudo dice [0.9285, 0.9581, 0.9474] 
2025-12-08 17:58:08.945596: Epoch time: 138.07 s 
2025-12-08 17:58:09.811704:  
2025-12-08 17:58:09.811704: Epoch 775 
2025-12-08 17:58:09.827582: Current learning rate: 0.00261 
2025-12-08 18:00:27.850961: train_loss -0.8564 
2025-12-08 18:00:27.850961: val_loss -0.8749 
2025-12-08 18:00:27.856967: Pseudo dice [0.9264, 0.9528, 0.9496] 
2025-12-08 18:00:27.858969: Epoch time: 138.04 s 
2025-12-08 18:00:28.514806:  
2025-12-08 18:00:28.514806: Epoch 776 
2025-12-08 18:00:28.530729: Current learning rate: 0.0026 
2025-12-08 18:02:46.358360: train_loss -0.8563 
2025-12-08 18:02:46.358360: val_loss -0.8878 
2025-12-08 18:02:46.365446: Pseudo dice [0.9332, 0.961, 0.9487] 
2025-12-08 18:02:46.371452: Epoch time: 137.84 s 
2025-12-08 18:02:47.124254:  
2025-12-08 18:02:47.124254: Epoch 777 
2025-12-08 18:02:47.140063: Current learning rate: 0.00259 
2025-12-08 18:05:05.179268: train_loss -0.8529 
2025-12-08 18:05:05.179268: val_loss -0.8797 
2025-12-08 18:05:05.190872: Pseudo dice [0.9261, 0.9577, 0.9464] 
2025-12-08 18:05:05.196878: Epoch time: 138.06 s 
2025-12-08 18:05:05.914452:  
2025-12-08 18:05:05.915457: Epoch 778 
2025-12-08 18:05:05.921471: Current learning rate: 0.00258 
2025-12-08 18:07:23.995018: train_loss -0.8516 
2025-12-08 18:07:23.995018: val_loss -0.8762 
2025-12-08 18:07:24.002979: Pseudo dice [0.9255, 0.9571, 0.9467] 
2025-12-08 18:07:24.006982: Epoch time: 138.08 s 
2025-12-08 18:07:24.725975:  
2025-12-08 18:07:24.726977: Epoch 779 
2025-12-08 18:07:24.732988: Current learning rate: 0.00257 
2025-12-08 18:09:42.667406: train_loss -0.8552 
2025-12-08 18:09:42.669408: val_loss -0.879 
2025-12-08 18:09:42.675205: Pseudo dice [0.9265, 0.9567, 0.9508] 
2025-12-08 18:09:42.681211: Epoch time: 137.94 s 
2025-12-08 18:09:43.484574:  
2025-12-08 18:09:43.484574: Epoch 780 
2025-12-08 18:09:43.484574: Current learning rate: 0.00256 
2025-12-08 18:12:01.529047: train_loss -0.8551 
2025-12-08 18:12:01.529047: val_loss -0.8816 
2025-12-08 18:12:01.538178: Pseudo dice [0.9271, 0.9566, 0.9495] 
2025-12-08 18:12:01.544180: Epoch time: 138.04 s 
2025-12-08 18:12:02.444346:  
2025-12-08 18:12:02.444346: Epoch 781 
2025-12-08 18:12:02.444346: Current learning rate: 0.00255 
2025-12-08 18:14:20.592723: train_loss -0.8545 
2025-12-08 18:14:20.592723: val_loss -0.8806 
2025-12-08 18:14:20.615051: Pseudo dice [0.9284, 0.9569, 0.9516] 
2025-12-08 18:14:20.619055: Epoch time: 138.15 s 
2025-12-08 18:14:21.334038:  
2025-12-08 18:14:21.334038: Epoch 782 
2025-12-08 18:14:21.340299: Current learning rate: 0.00254 
2025-12-08 18:16:39.378533: train_loss -0.8568 
2025-12-08 18:16:39.379534: val_loss -0.8792 
2025-12-08 18:16:39.385535: Pseudo dice [0.926, 0.9567, 0.9525] 
2025-12-08 18:16:39.390582: Epoch time: 138.05 s 
2025-12-08 18:16:40.138682:  
2025-12-08 18:16:40.142182: Epoch 783 
2025-12-08 18:16:40.142182: Current learning rate: 0.00253 
2025-12-08 18:18:58.218020: train_loss -0.8569 
2025-12-08 18:18:58.218020: val_loss -0.8778 
2025-12-08 18:18:58.218020: Pseudo dice [0.9218, 0.9569, 0.949] 
2025-12-08 18:18:58.233988: Epoch time: 138.08 s 
2025-12-08 18:18:58.874449:  
2025-12-08 18:18:58.874449: Epoch 784 
2025-12-08 18:18:58.890095: Current learning rate: 0.00252 
2025-12-08 18:21:18.236622: train_loss -0.8571 
2025-12-08 18:21:18.237624: val_loss -0.8816 
2025-12-08 18:21:18.242642: Pseudo dice [0.9253, 0.9548, 0.9522] 
2025-12-08 18:21:18.247658: Epoch time: 139.36 s 
2025-12-08 18:21:18.904968:  
2025-12-08 18:21:18.904968: Epoch 785 
2025-12-08 18:21:18.904968: Current learning rate: 0.00251 
2025-12-08 18:23:37.267286: train_loss -0.8613 
2025-12-08 18:23:37.267286: val_loss -0.8769 
2025-12-08 18:23:37.277035: Pseudo dice [0.9227, 0.9547, 0.9509] 
2025-12-08 18:23:37.283042: Epoch time: 138.36 s 
2025-12-08 18:23:37.958024:  
2025-12-08 18:23:37.960026: Epoch 786 
2025-12-08 18:23:37.960026: Current learning rate: 0.0025 
2025-12-08 18:25:56.529596: train_loss -0.8605 
2025-12-08 18:25:56.529596: val_loss -0.8749 
2025-12-08 18:25:56.529596: Pseudo dice [0.9209, 0.9601, 0.9488] 
2025-12-08 18:25:56.529596: Epoch time: 138.57 s 
2025-12-08 18:25:57.420424:  
2025-12-08 18:25:57.420424: Epoch 787 
2025-12-08 18:25:57.420424: Current learning rate: 0.00249 
2025-12-08 18:28:15.919500: train_loss -0.8554 
2025-12-08 18:28:15.921241: val_loss -0.8781 
2025-12-08 18:28:15.927110: Pseudo dice [0.9269, 0.9575, 0.9466] 
2025-12-08 18:28:15.931114: Epoch time: 138.5 s 
2025-12-08 18:28:16.608731:  
2025-12-08 18:28:16.608731: Epoch 788 
2025-12-08 18:28:16.608731: Current learning rate: 0.00248 
2025-12-08 18:30:35.154491: train_loss -0.861 
2025-12-08 18:30:35.154491: val_loss -0.8818 
2025-12-08 18:30:35.155493: Pseudo dice [0.9244, 0.9575, 0.9553] 
2025-12-08 18:30:35.155493: Epoch time: 138.55 s 
2025-12-08 18:30:35.843200:  
2025-12-08 18:30:35.858974: Epoch 789 
2025-12-08 18:30:35.858974: Current learning rate: 0.00247 
2025-12-08 18:32:53.984088: train_loss -0.8531 
2025-12-08 18:32:53.984088: val_loss -0.8613 
2025-12-08 18:32:53.984088: Pseudo dice [0.915, 0.947, 0.9488] 
2025-12-08 18:32:53.995827: Epoch time: 138.14 s 
2025-12-08 18:32:54.765583:  
2025-12-08 18:32:54.765583: Epoch 790 
2025-12-08 18:32:54.765583: Current learning rate: 0.00245 
2025-12-08 18:35:12.765426: train_loss -0.8562 
2025-12-08 18:35:12.765426: val_loss -0.8705 
2025-12-08 18:35:12.781476: Pseudo dice [0.9206, 0.9497, 0.9482] 
2025-12-08 18:35:12.781476: Epoch time: 138.02 s 
2025-12-08 18:35:13.436925:  
2025-12-08 18:35:13.436925: Epoch 791 
2025-12-08 18:35:13.436925: Current learning rate: 0.00244 
2025-12-08 18:37:31.389206: train_loss -0.8547 
2025-12-08 18:37:31.389206: val_loss -0.8822 
2025-12-08 18:37:31.389206: Pseudo dice [0.9283, 0.9618, 0.9488] 
2025-12-08 18:37:31.389206: Epoch time: 137.95 s 
2025-12-08 18:37:32.045753:  
2025-12-08 18:37:32.045753: Epoch 792 
2025-12-08 18:37:32.045753: Current learning rate: 0.00243 
2025-12-08 18:39:50.186106: train_loss -0.8547 
2025-12-08 18:39:50.186106: val_loss -0.8846 
2025-12-08 18:39:50.186106: Pseudo dice [0.9292, 0.9605, 0.9482] 
2025-12-08 18:39:50.186106: Epoch time: 138.14 s 
2025-12-08 18:39:51.155434:  
2025-12-08 18:39:51.155434: Epoch 793 
2025-12-08 18:39:51.170934: Current learning rate: 0.00242 
2025-12-08 18:42:09.201605: train_loss -0.8574 
2025-12-08 18:42:09.201605: val_loss -0.877 
2025-12-08 18:42:09.214620: Pseudo dice [0.9229, 0.9539, 0.9476] 
2025-12-08 18:42:09.217625: Epoch time: 138.05 s 
2025-12-08 18:42:09.885997:  
2025-12-08 18:42:09.885997: Epoch 794 
2025-12-08 18:42:09.889933: Current learning rate: 0.00241 
2025-12-08 18:44:28.041142: train_loss -0.8555 
2025-12-08 18:44:28.041142: val_loss -0.8762 
2025-12-08 18:44:28.046873: Pseudo dice [0.9229, 0.9579, 0.9486] 
2025-12-08 18:44:28.048730: Epoch time: 138.16 s 
2025-12-08 18:44:28.704955:  
2025-12-08 18:44:28.704955: Epoch 795 
2025-12-08 18:44:28.718768: Current learning rate: 0.0024 
2025-12-08 18:46:46.733986: train_loss -0.8572 
2025-12-08 18:46:46.733986: val_loss -0.8724 
2025-12-08 18:46:46.750016: Pseudo dice [0.9203, 0.9551, 0.943] 
2025-12-08 18:46:46.754516: Epoch time: 138.03 s 
2025-12-08 18:46:47.562033:  
2025-12-08 18:46:47.562033: Epoch 796 
2025-12-08 18:46:47.578003: Current learning rate: 0.00239 
2025-12-08 18:49:05.655196: train_loss -0.853 
2025-12-08 18:49:05.655196: val_loss -0.8818 
2025-12-08 18:49:05.671305: Pseudo dice [0.931, 0.9586, 0.9485] 
2025-12-08 18:49:05.671305: Epoch time: 138.09 s 
2025-12-08 18:49:06.327442:  
2025-12-08 18:49:06.327442: Epoch 797 
2025-12-08 18:49:06.327442: Current learning rate: 0.00238 
2025-12-08 18:51:24.657383: train_loss -0.86 
2025-12-08 18:51:24.658382: val_loss -0.8785 
2025-12-08 18:51:24.668852: Pseudo dice [0.9265, 0.9549, 0.9475] 
2025-12-08 18:51:24.674781: Epoch time: 138.33 s 
2025-12-08 18:51:25.342435:  
2025-12-08 18:51:25.342435: Epoch 798 
2025-12-08 18:51:25.342435: Current learning rate: 0.00237 
2025-12-08 18:53:43.420893: train_loss -0.8549 
2025-12-08 18:53:43.420893: val_loss -0.8881 
2025-12-08 18:53:43.420893: Pseudo dice [0.9343, 0.9605, 0.9461] 
2025-12-08 18:53:43.432140: Epoch time: 138.09 s 
2025-12-08 18:53:44.406447:  
2025-12-08 18:53:44.406447: Epoch 799 
2025-12-08 18:53:44.413548: Current learning rate: 0.00236 
2025-12-08 18:56:02.453576: train_loss -0.8515 
2025-12-08 18:56:02.453576: val_loss -0.8693 
2025-12-08 18:56:02.453576: Pseudo dice [0.9198, 0.9544, 0.9476] 
2025-12-08 18:56:02.469539: Epoch time: 138.05 s 
2025-12-08 18:56:03.411101:  
2025-12-08 18:56:03.411101: Epoch 800 
2025-12-08 18:56:03.411101: Current learning rate: 0.00235 
2025-12-08 18:58:21.290149: train_loss -0.8578 
2025-12-08 18:58:21.292151: val_loss -0.8794 
2025-12-08 18:58:21.297896: Pseudo dice [0.9241, 0.9607, 0.9532] 
2025-12-08 18:58:21.303901: Epoch time: 137.88 s 
2025-12-08 18:58:21.967714:  
2025-12-08 18:58:21.967714: Epoch 801 
2025-12-08 18:58:21.967714: Current learning rate: 0.00234 
2025-12-08 19:00:39.870021: train_loss -0.8628 
2025-12-08 19:00:39.872024: val_loss -0.8782 
2025-12-08 19:00:39.873766: Pseudo dice [0.9262, 0.9566, 0.9464] 
2025-12-08 19:00:39.873766: Epoch time: 137.9 s 
2025-12-08 19:00:40.593046:  
2025-12-08 19:00:40.593046: Epoch 802 
2025-12-08 19:00:40.600563: Current learning rate: 0.00233 
2025-12-08 19:02:58.573763: train_loss -0.8585 
2025-12-08 19:02:58.573763: val_loss -0.8741 
2025-12-08 19:02:58.581004: Pseudo dice [0.9217, 0.952, 0.9528] 
2025-12-08 19:02:58.585966: Epoch time: 138.0 s 
2025-12-08 19:02:59.311864:  
2025-12-08 19:02:59.327599: Epoch 803 
2025-12-08 19:02:59.331664: Current learning rate: 0.00232 
2025-12-08 19:05:17.248889: train_loss -0.8562 
2025-12-08 19:05:17.248889: val_loss -0.8736 
2025-12-08 19:05:17.268758: Pseudo dice [0.9231, 0.955, 0.9449] 
2025-12-08 19:05:17.272762: Epoch time: 137.94 s 
2025-12-08 19:05:17.986116:  
2025-12-08 19:05:17.986116: Epoch 804 
2025-12-08 19:05:17.992145: Current learning rate: 0.00231 
2025-12-08 19:07:35.967156: train_loss -0.8542 
2025-12-08 19:07:35.967156: val_loss -0.8822 
2025-12-08 19:07:35.982802: Pseudo dice [0.9265, 0.9583, 0.9514] 
2025-12-08 19:07:35.982802: Epoch time: 137.98 s 
2025-12-08 19:07:36.835065:  
2025-12-08 19:07:36.835065: Epoch 805 
2025-12-08 19:07:36.841093: Current learning rate: 0.0023 
2025-12-08 19:09:54.837471: train_loss -0.8581 
2025-12-08 19:09:54.839473: val_loss -0.8812 
2025-12-08 19:09:54.851233: Pseudo dice [0.9281, 0.9591, 0.9506] 
2025-12-08 19:09:54.860997: Epoch time: 138.0 s 
2025-12-08 19:09:55.515122:  
2025-12-08 19:09:55.515122: Epoch 806 
2025-12-08 19:09:55.533233: Current learning rate: 0.00229 
2025-12-08 19:12:13.488602: train_loss -0.855 
2025-12-08 19:12:13.489602: val_loss -0.887 
2025-12-08 19:12:13.498604: Pseudo dice [0.9313, 0.9601, 0.9503] 
2025-12-08 19:12:13.504680: Epoch time: 137.97 s 
2025-12-08 19:12:14.233557:  
2025-12-08 19:12:14.233557: Epoch 807 
2025-12-08 19:12:14.233557: Current learning rate: 0.00228 
2025-12-08 19:14:32.229224: train_loss -0.8567 
2025-12-08 19:14:32.229224: val_loss -0.8858 
2025-12-08 19:14:32.236920: Pseudo dice [0.9301, 0.9575, 0.9474] 
2025-12-08 19:14:32.241268: Epoch time: 138.01 s 
2025-12-08 19:14:32.901841:  
2025-12-08 19:14:32.901841: Epoch 808 
2025-12-08 19:14:32.904853: Current learning rate: 0.00226 
2025-12-08 19:16:50.946065: train_loss -0.8552 
2025-12-08 19:16:50.948067: val_loss -0.8841 
2025-12-08 19:16:50.956075: Pseudo dice [0.9271, 0.9575, 0.9506] 
2025-12-08 19:16:50.962081: Epoch time: 138.05 s 
2025-12-08 19:16:51.639742:  
2025-12-08 19:16:51.639742: Epoch 809 
2025-12-08 19:16:51.639742: Current learning rate: 0.00225 
2025-12-08 19:19:09.685284: train_loss -0.8575 
2025-12-08 19:19:09.686284: val_loss -0.8829 
2025-12-08 19:19:09.691285: Pseudo dice [0.9277, 0.957, 0.9508] 
2025-12-08 19:19:09.697287: Epoch time: 138.05 s 
2025-12-08 19:19:10.577804:  
2025-12-08 19:19:10.577804: Epoch 810 
2025-12-08 19:19:10.577804: Current learning rate: 0.00224 
2025-12-08 19:21:28.538909: train_loss -0.8557 
2025-12-08 19:21:28.538909: val_loss -0.8815 
2025-12-08 19:21:28.544916: Pseudo dice [0.9237, 0.9586, 0.9543] 
2025-12-08 19:21:28.550661: Epoch time: 137.96 s 
2025-12-08 19:21:29.296805:  
2025-12-08 19:21:29.296805: Epoch 811 
2025-12-08 19:21:29.312562: Current learning rate: 0.00223 
2025-12-08 19:23:47.386775: train_loss -0.855 
2025-12-08 19:23:47.388777: val_loss -0.8829 
2025-12-08 19:23:47.395020: Pseudo dice [0.9265, 0.9589, 0.9522] 
2025-12-08 19:23:47.401026: Epoch time: 138.09 s 
2025-12-08 19:23:48.072648:  
2025-12-08 19:23:48.072648: Epoch 812 
2025-12-08 19:23:48.078875: Current learning rate: 0.00222 
2025-12-08 19:26:06.366960: train_loss -0.8575 
2025-12-08 19:26:06.368962: val_loss -0.8844 
2025-12-08 19:26:06.378475: Pseudo dice [0.9312, 0.9599, 0.9504] 
2025-12-08 19:26:06.384481: Epoch time: 138.3 s 
2025-12-08 19:26:07.046837:  
2025-12-08 19:26:07.046837: Epoch 813 
2025-12-08 19:26:07.046837: Current learning rate: 0.00221 
2025-12-08 19:28:25.103093: train_loss -0.8618 
2025-12-08 19:28:25.105095: val_loss -0.8786 
2025-12-08 19:28:25.111225: Pseudo dice [0.924, 0.9558, 0.9501] 
2025-12-08 19:28:25.116226: Epoch time: 138.06 s 
2025-12-08 19:28:25.780141:  
2025-12-08 19:28:25.780141: Epoch 814 
2025-12-08 19:28:25.780141: Current learning rate: 0.0022 
2025-12-08 19:30:43.970251: train_loss -0.8568 
2025-12-08 19:30:43.970251: val_loss -0.8811 
2025-12-08 19:30:43.983253: Pseudo dice [0.9311, 0.9547, 0.9478] 
2025-12-08 19:30:43.989281: Epoch time: 138.19 s 
2025-12-08 19:30:44.717874:  
2025-12-08 19:30:44.717874: Epoch 815 
2025-12-08 19:30:44.723909: Current learning rate: 0.00219 
2025-12-08 19:33:02.874304: train_loss -0.8612 
2025-12-08 19:33:02.890149: val_loss -0.8867 
2025-12-08 19:33:02.893602: Pseudo dice [0.9312, 0.9588, 0.9503] 
2025-12-08 19:33:02.893602: Epoch time: 138.16 s 
2025-12-08 19:33:03.732724:  
2025-12-08 19:33:03.732724: Epoch 816 
2025-12-08 19:33:03.732724: Current learning rate: 0.00218 
2025-12-08 19:35:21.878896: train_loss -0.8551 
2025-12-08 19:35:21.878896: val_loss -0.8781 
2025-12-08 19:35:21.886904: Pseudo dice [0.9248, 0.9566, 0.9486] 
2025-12-08 19:35:21.894794: Epoch time: 138.15 s 
2025-12-08 19:35:22.631432:  
2025-12-08 19:35:22.631432: Epoch 817 
2025-12-08 19:35:22.638453: Current learning rate: 0.00217 
2025-12-08 19:37:40.792414: train_loss -0.8566 
2025-12-08 19:37:40.792414: val_loss -0.8795 
2025-12-08 19:37:40.799288: Pseudo dice [0.926, 0.9564, 0.9542] 
2025-12-08 19:37:40.801291: Epoch time: 138.16 s 
2025-12-08 19:37:41.476904:  
2025-12-08 19:37:41.476904: Epoch 818 
2025-12-08 19:37:41.482933: Current learning rate: 0.00216 
2025-12-08 19:39:59.741018: train_loss -0.8564 
2025-12-08 19:39:59.741018: val_loss -0.8831 
2025-12-08 19:39:59.747183: Pseudo dice [0.9274, 0.9598, 0.95] 
2025-12-08 19:39:59.753190: Epoch time: 138.27 s 
2025-12-08 19:40:00.508635:  
2025-12-08 19:40:00.509640: Epoch 819 
2025-12-08 19:40:00.514655: Current learning rate: 0.00215 
2025-12-08 19:42:18.545534: train_loss -0.8555 
2025-12-08 19:42:18.545534: val_loss -0.8755 
2025-12-08 19:42:18.564286: Pseudo dice [0.9208, 0.9538, 0.9517] 
2025-12-08 19:42:18.570292: Epoch time: 138.04 s 
2025-12-08 19:42:19.212644:  
2025-12-08 19:42:19.212644: Epoch 820 
2025-12-08 19:42:19.218464: Current learning rate: 0.00214 
2025-12-08 19:44:37.373867: train_loss -0.8565 
2025-12-08 19:44:37.375871: val_loss -0.8765 
2025-12-08 19:44:37.385870: Pseudo dice [0.9228, 0.9559, 0.9527] 
2025-12-08 19:44:37.395963: Epoch time: 138.16 s 
2025-12-08 19:44:38.015818:  
2025-12-08 19:44:38.015818: Epoch 821 
2025-12-08 19:44:38.031682: Current learning rate: 0.00213 
2025-12-08 19:46:56.190500: train_loss -0.8566 
2025-12-08 19:46:56.190500: val_loss -0.8667 
2025-12-08 19:46:56.198762: Pseudo dice [0.919, 0.9488, 0.9483] 
2025-12-08 19:46:56.202494: Epoch time: 138.17 s 
2025-12-08 19:46:57.154943:  
2025-12-08 19:46:57.154943: Epoch 822 
2025-12-08 19:46:57.154943: Current learning rate: 0.00212 
2025-12-08 19:49:15.203988: train_loss -0.8596 
2025-12-08 19:49:15.205991: val_loss -0.8825 
2025-12-08 19:49:15.214209: Pseudo dice [0.9243, 0.9589, 0.9553] 
2025-12-08 19:49:15.219954: Epoch time: 138.05 s 
2025-12-08 19:49:15.858793:  
2025-12-08 19:49:15.858793: Epoch 823 
2025-12-08 19:49:15.874435: Current learning rate: 0.0021 
2025-12-08 19:51:34.046142: train_loss -0.8593 
2025-12-08 19:51:34.046142: val_loss -0.8871 
2025-12-08 19:51:34.065470: Pseudo dice [0.9309, 0.9607, 0.9501] 
2025-12-08 19:51:34.069469: Epoch time: 138.19 s 
2025-12-08 19:51:34.686307:  
2025-12-08 19:51:34.686307: Epoch 824 
2025-12-08 19:51:34.702253: Current learning rate: 0.00209 
2025-12-08 19:53:52.631636: train_loss -0.8592 
2025-12-08 19:53:52.631636: val_loss -0.8909 
2025-12-08 19:53:52.637643: Pseudo dice [0.932, 0.9642, 0.9519] 
2025-12-08 19:53:52.643388: Epoch time: 137.95 s 
2025-12-08 19:53:52.649393: Yayy! New best EMA pseudo Dice: 0.945 
2025-12-08 19:53:53.660229:  
2025-12-08 19:53:53.661233: Epoch 825 
2025-12-08 19:53:53.667261: Current learning rate: 0.00208 
2025-12-08 19:56:11.577435: train_loss -0.8591 
2025-12-08 19:56:11.577435: val_loss -0.8753 
2025-12-08 19:56:11.583827: Pseudo dice [0.9256, 0.9542, 0.9467] 
2025-12-08 19:56:11.589834: Epoch time: 137.92 s 
2025-12-08 19:56:12.217752:  
2025-12-08 19:56:12.217752: Epoch 826 
2025-12-08 19:56:12.233420: Current learning rate: 0.00207 
2025-12-08 19:58:30.307872: train_loss -0.8563 
2025-12-08 19:58:30.309875: val_loss -0.8838 
2025-12-08 19:58:30.317624: Pseudo dice [0.9291, 0.9575, 0.9549] 
2025-12-08 19:58:30.323368: Epoch time: 138.09 s 
2025-12-08 19:58:31.019893:  
2025-12-08 19:58:31.019893: Epoch 827 
2025-12-08 19:58:31.026908: Current learning rate: 0.00206 
2025-12-08 20:00:49.189579: train_loss -0.8601 
2025-12-08 20:00:49.189579: val_loss -0.878 
2025-12-08 20:00:49.197075: Pseudo dice [0.9276, 0.9548, 0.9442] 
2025-12-08 20:00:49.201079: Epoch time: 138.17 s 
2025-12-08 20:00:49.920916:  
2025-12-08 20:00:49.920916: Epoch 828 
2025-12-08 20:00:49.920916: Current learning rate: 0.00205 
2025-12-08 20:03:08.014956: train_loss -0.858 
2025-12-08 20:03:08.014956: val_loss -0.8756 
2025-12-08 20:03:08.014956: Pseudo dice [0.9222, 0.9536, 0.9557] 
2025-12-08 20:03:08.030941: Epoch time: 138.09 s 
2025-12-08 20:03:08.844064:  
2025-12-08 20:03:08.844064: Epoch 829 
2025-12-08 20:03:08.844064: Current learning rate: 0.00204 
2025-12-08 20:05:26.963784: train_loss -0.8537 
2025-12-08 20:05:26.965786: val_loss -0.8708 
2025-12-08 20:05:26.971930: Pseudo dice [0.9202, 0.951, 0.9517] 
2025-12-08 20:05:26.976949: Epoch time: 138.12 s 
2025-12-08 20:05:27.670239:  
2025-12-08 20:05:27.670239: Epoch 830 
2025-12-08 20:05:27.685898: Current learning rate: 0.00203 
2025-12-08 20:07:45.759203: train_loss -0.8546 
2025-12-08 20:07:45.761205: val_loss -0.8773 
2025-12-08 20:07:45.766949: Pseudo dice [0.9256, 0.9574, 0.9459] 
2025-12-08 20:07:45.766949: Epoch time: 138.09 s 
2025-12-08 20:07:46.471664:  
2025-12-08 20:07:46.471664: Epoch 831 
2025-12-08 20:07:46.478684: Current learning rate: 0.00202 
2025-12-08 20:10:04.654881: train_loss -0.8578 
2025-12-08 20:10:04.654881: val_loss -0.8734 
2025-12-08 20:10:04.654881: Pseudo dice [0.9214, 0.9533, 0.9481] 
2025-12-08 20:10:04.670535: Epoch time: 138.18 s 
2025-12-08 20:10:05.295662:  
2025-12-08 20:10:05.295662: Epoch 832 
2025-12-08 20:10:05.295662: Current learning rate: 0.00201 
2025-12-08 20:12:23.362376: train_loss -0.8535 
2025-12-08 20:12:23.362376: val_loss -0.8737 
2025-12-08 20:12:23.364377: Pseudo dice [0.9232, 0.9536, 0.947] 
2025-12-08 20:12:23.374270: Epoch time: 138.07 s 
2025-12-08 20:12:24.014679:  
2025-12-08 20:12:24.014679: Epoch 833 
2025-12-08 20:12:24.014679: Current learning rate: 0.002 
2025-12-08 20:14:42.233750: train_loss -0.8587 
2025-12-08 20:14:42.233750: val_loss -0.8798 
2025-12-08 20:14:42.239757: Pseudo dice [0.9266, 0.9543, 0.9503] 
2025-12-08 20:14:42.245763: Epoch time: 138.22 s 
2025-12-08 20:14:42.883367:  
2025-12-08 20:14:42.885369: Epoch 834 
2025-12-08 20:14:42.889818: Current learning rate: 0.00199 
2025-12-08 20:17:01.014964: train_loss -0.8632 
2025-12-08 20:17:01.014964: val_loss -0.8852 
2025-12-08 20:17:01.035213: Pseudo dice [0.9287, 0.9602, 0.9501] 
2025-12-08 20:17:01.040236: Epoch time: 138.13 s 
2025-12-08 20:17:01.826707:  
2025-12-08 20:17:01.826707: Epoch 835 
2025-12-08 20:17:01.842831: Current learning rate: 0.00198 
2025-12-08 20:19:20.014034: train_loss -0.8602 
2025-12-08 20:19:20.014034: val_loss -0.8887 
2025-12-08 20:19:20.014034: Pseudo dice [0.9332, 0.9615, 0.9526] 
2025-12-08 20:19:20.014034: Epoch time: 138.19 s 
2025-12-08 20:19:20.718606:  
2025-12-08 20:19:20.718606: Epoch 836 
2025-12-08 20:19:20.718606: Current learning rate: 0.00196 
2025-12-08 20:21:38.971270: train_loss -0.8625 
2025-12-08 20:21:38.971270: val_loss -0.8737 
2025-12-08 20:21:38.980756: Pseudo dice [0.9199, 0.9551, 0.95] 
2025-12-08 20:21:38.986763: Epoch time: 138.25 s 
2025-12-08 20:21:39.686005:  
2025-12-08 20:21:39.686005: Epoch 837 
2025-12-08 20:21:39.686005: Current learning rate: 0.00195 
2025-12-08 20:23:57.736133: train_loss -0.8513 
2025-12-08 20:23:57.736133: val_loss -0.8845 
2025-12-08 20:23:57.736133: Pseudo dice [0.9287, 0.9604, 0.9523] 
2025-12-08 20:23:57.751778: Epoch time: 138.05 s 
2025-12-08 20:23:58.467860:  
2025-12-08 20:23:58.467860: Epoch 838 
2025-12-08 20:23:58.467860: Current learning rate: 0.00194 
2025-12-08 20:26:16.561401: train_loss -0.8596 
2025-12-08 20:26:16.561401: val_loss -0.8673 
2025-12-08 20:26:16.561401: Pseudo dice [0.9161, 0.9475, 0.9477] 
2025-12-08 20:26:16.561401: Epoch time: 138.09 s 
2025-12-08 20:26:17.217859:  
2025-12-08 20:26:17.217859: Epoch 839 
2025-12-08 20:26:17.217859: Current learning rate: 0.00193 
2025-12-08 20:28:35.380162: train_loss -0.8555 
2025-12-08 20:28:35.381164: val_loss -0.8805 
2025-12-08 20:28:35.387178: Pseudo dice [0.9263, 0.9524, 0.9493] 
2025-12-08 20:28:35.389186: Epoch time: 138.16 s 
2025-12-08 20:28:36.077481:  
2025-12-08 20:28:36.077481: Epoch 840 
2025-12-08 20:28:36.093191: Current learning rate: 0.00192 
2025-12-08 20:30:54.314471: train_loss -0.8562 
2025-12-08 20:30:54.314471: val_loss -0.8889 
2025-12-08 20:30:54.321669: Pseudo dice [0.933, 0.9555, 0.955] 
2025-12-08 20:30:54.327664: Epoch time: 138.24 s 
2025-12-08 20:30:55.124665:  
2025-12-08 20:30:55.124665: Epoch 841 
2025-12-08 20:30:55.124665: Current learning rate: 0.00191 
2025-12-08 20:33:13.278963: train_loss -0.8593 
2025-12-08 20:33:13.280703: val_loss -0.8821 
2025-12-08 20:33:13.286712: Pseudo dice [0.9275, 0.9558, 0.951] 
2025-12-08 20:33:13.294420: Epoch time: 138.15 s 
2025-12-08 20:33:13.984424:  
2025-12-08 20:33:13.984424: Epoch 842 
2025-12-08 20:33:13.984424: Current learning rate: 0.0019 
2025-12-08 20:35:32.043719: train_loss -0.8603 
2025-12-08 20:35:32.043719: val_loss -0.8814 
2025-12-08 20:35:32.053228: Pseudo dice [0.9243, 0.9537, 0.9521] 
2025-12-08 20:35:32.060974: Epoch time: 138.06 s 
2025-12-08 20:35:32.701906:  
2025-12-08 20:35:32.701906: Epoch 843 
2025-12-08 20:35:32.701906: Current learning rate: 0.00189 
2025-12-08 20:37:50.873913: train_loss -0.858 
2025-12-08 20:37:50.873913: val_loss -0.884 
2025-12-08 20:37:50.881185: Pseudo dice [0.9272, 0.9554, 0.9561] 
2025-12-08 20:37:50.887192: Epoch time: 138.19 s 
2025-12-08 20:37:51.700486:  
2025-12-08 20:37:51.700486: Epoch 844 
2025-12-08 20:37:51.702228: Current learning rate: 0.00188 
2025-12-08 20:40:09.827553: train_loss -0.8563 
2025-12-08 20:40:09.827553: val_loss -0.8759 
2025-12-08 20:40:09.845301: Pseudo dice [0.9238, 0.9503, 0.953] 
2025-12-08 20:40:09.845301: Epoch time: 138.13 s 
2025-12-08 20:40:10.484773:  
2025-12-08 20:40:10.484773: Epoch 845 
2025-12-08 20:40:10.484773: Current learning rate: 0.00187 
2025-12-08 20:42:28.462438: train_loss -0.8628 
2025-12-08 20:42:28.462438: val_loss -0.8854 
2025-12-08 20:42:28.470188: Pseudo dice [0.93, 0.9579, 0.948] 
2025-12-08 20:42:28.478196: Epoch time: 137.98 s 
2025-12-08 20:42:29.170966:  
2025-12-08 20:42:29.170966: Epoch 846 
2025-12-08 20:42:29.170966: Current learning rate: 0.00186 
2025-12-08 20:44:47.204086: train_loss -0.861 
2025-12-08 20:44:47.204086: val_loss -0.8729 
2025-12-08 20:44:47.211810: Pseudo dice [0.9201, 0.955, 0.9525] 
2025-12-08 20:44:47.217554: Epoch time: 138.03 s 
2025-12-08 20:44:48.076614:  
2025-12-08 20:44:48.092267: Epoch 847 
2025-12-08 20:44:48.092267: Current learning rate: 0.00185 
2025-12-08 20:47:05.996790: train_loss -0.8612 
2025-12-08 20:47:05.996790: val_loss -0.891 
2025-12-08 20:47:06.000708: Pseudo dice [0.9325, 0.9597, 0.9503] 
2025-12-08 20:47:06.008218: Epoch time: 137.92 s 
2025-12-08 20:47:06.763971:  
2025-12-08 20:47:06.763971: Epoch 848 
2025-12-08 20:47:06.783162: Current learning rate: 0.00184 
2025-12-08 20:49:24.874495: train_loss -0.8621 
2025-12-08 20:49:24.874495: val_loss -0.8761 
2025-12-08 20:49:24.874495: Pseudo dice [0.9235, 0.9538, 0.9484] 
2025-12-08 20:49:24.890402: Epoch time: 138.11 s 
2025-12-08 20:49:25.514901:  
2025-12-08 20:49:25.514901: Epoch 849 
2025-12-08 20:49:25.514901: Current learning rate: 0.00182 
2025-12-08 20:51:43.609506: train_loss -0.8558 
2025-12-08 20:51:43.610506: val_loss -0.8798 
2025-12-08 20:51:43.616956: Pseudo dice [0.924, 0.9554, 0.9568] 
2025-12-08 20:51:43.622957: Epoch time: 138.09 s 
2025-12-08 20:51:44.528773:  
2025-12-08 20:51:44.528773: Epoch 850 
2025-12-08 20:51:44.529777: Current learning rate: 0.00181 
2025-12-08 20:54:02.690138: train_loss -0.8524 
2025-12-08 20:54:02.692140: val_loss -0.8446 
2025-12-08 20:54:02.692140: Pseudo dice [0.9128, 0.9415, 0.9414] 
2025-12-08 20:54:02.705089: Epoch time: 138.16 s 
2025-12-08 20:54:03.436871:  
2025-12-08 20:54:03.436871: Epoch 851 
2025-12-08 20:54:03.436871: Current learning rate: 0.0018 
2025-12-08 20:56:21.548438: train_loss -0.8302 
2025-12-08 20:56:21.548438: val_loss -0.8582 
2025-12-08 20:56:21.554444: Pseudo dice [0.9151, 0.9502, 0.9469] 
2025-12-08 20:56:21.560450: Epoch time: 138.11 s 
2025-12-08 20:56:22.200755:  
2025-12-08 20:56:22.201755: Epoch 852 
2025-12-08 20:56:22.203681: Current learning rate: 0.00179 
2025-12-08 20:58:41.119598: train_loss -0.8453 
2025-12-08 20:58:41.119598: val_loss -0.886 
2025-12-08 20:58:41.129493: Pseudo dice [0.9305, 0.9579, 0.9532] 
2025-12-08 20:58:41.138668: Epoch time: 138.92 s 
2025-12-08 20:58:42.050856:  
2025-12-08 20:58:42.050856: Epoch 853 
2025-12-08 20:58:42.063916: Current learning rate: 0.00178 
2025-12-08 21:01:01.642681: train_loss -0.848 
2025-12-08 21:01:01.643681: val_loss -0.8755 
2025-12-08 21:01:01.648371: Pseudo dice [0.9246, 0.957, 0.9475] 
2025-12-08 21:01:01.654559: Epoch time: 139.59 s 
2025-12-08 21:01:02.292306:  
2025-12-08 21:01:02.292306: Epoch 854 
2025-12-08 21:01:02.306144: Current learning rate: 0.00177 
2025-12-08 21:03:20.985643: train_loss -0.8533 
2025-12-08 21:03:20.987646: val_loss -0.8835 
2025-12-08 21:03:20.995830: Pseudo dice [0.9276, 0.9543, 0.9545] 
2025-12-08 21:03:21.003596: Epoch time: 138.69 s 
2025-12-08 21:03:21.784941:  
2025-12-08 21:03:21.784941: Epoch 855 
2025-12-08 21:03:21.796477: Current learning rate: 0.00176 
2025-12-08 21:05:40.503781: train_loss -0.8538 
2025-12-08 21:05:40.503781: val_loss -0.8887 
2025-12-08 21:05:40.503781: Pseudo dice [0.9308, 0.958, 0.9536] 
2025-12-08 21:05:40.514116: Epoch time: 138.72 s 
2025-12-08 21:05:41.155556:  
2025-12-08 21:05:41.155556: Epoch 856 
2025-12-08 21:05:41.155556: Current learning rate: 0.00175 
2025-12-08 21:08:00.077375: train_loss -0.8537 
2025-12-08 21:08:00.077375: val_loss -0.8702 
2025-12-08 21:08:00.097130: Pseudo dice [0.9173, 0.9503, 0.9521] 
2025-12-08 21:08:00.103135: Epoch time: 138.92 s 
2025-12-08 21:08:00.780620:  
2025-12-08 21:08:00.780620: Epoch 857 
2025-12-08 21:08:00.796667: Current learning rate: 0.00174 
2025-12-08 21:10:19.943634: train_loss -0.8575 
2025-12-08 21:10:19.950293: val_loss -0.883 
2025-12-08 21:10:19.955333: Pseudo dice [0.9303, 0.9583, 0.9499] 
2025-12-08 21:10:19.961608: Epoch time: 139.16 s 
2025-12-08 21:10:20.865422:  
2025-12-08 21:10:20.865422: Epoch 858 
2025-12-08 21:10:20.871698: Current learning rate: 0.00173 
2025-12-08 21:12:41.916282: train_loss -0.8581 
2025-12-08 21:12:41.917288: val_loss -0.8786 
2025-12-08 21:12:41.923925: Pseudo dice [0.9289, 0.9533, 0.951] 
2025-12-08 21:12:41.929927: Epoch time: 141.06 s 
2025-12-08 21:12:42.702041:  
2025-12-08 21:12:42.702041: Epoch 859 
2025-12-08 21:12:42.710253: Current learning rate: 0.00172 
2025-12-08 21:15:03.118529: train_loss -0.8599 
2025-12-08 21:15:03.119529: val_loss -0.8761 
2025-12-08 21:15:03.128207: Pseudo dice [0.9212, 0.955, 0.9516] 
2025-12-08 21:15:03.135149: Epoch time: 140.42 s 
2025-12-08 21:15:04.085816:  
2025-12-08 21:15:04.085816: Epoch 860 
2025-12-08 21:15:04.088742: Current learning rate: 0.0017 
2025-12-08 21:17:24.331582: train_loss -0.8577 
2025-12-08 21:17:24.332582: val_loss -0.8793 
2025-12-08 21:17:24.341471: Pseudo dice [0.9261, 0.9546, 0.9498] 
2025-12-08 21:17:24.347914: Epoch time: 140.25 s 
2025-12-08 21:17:25.018127:  
2025-12-08 21:17:25.018127: Epoch 861 
2025-12-08 21:17:25.026038: Current learning rate: 0.00169 
2025-12-08 21:19:45.673506: train_loss -0.8546 
2025-12-08 21:19:45.673506: val_loss -0.8708 
2025-12-08 21:19:45.679512: Pseudo dice [0.9191, 0.9523, 0.9491] 
2025-12-08 21:19:45.685518: Epoch time: 140.66 s 
2025-12-08 21:19:46.339595:  
2025-12-08 21:19:46.339595: Epoch 862 
2025-12-08 21:19:46.346446: Current learning rate: 0.00168 
2025-12-08 21:22:06.889476: train_loss -0.8525 
2025-12-08 21:22:06.890523: val_loss -0.8894 
2025-12-08 21:22:06.896544: Pseudo dice [0.9341, 0.96, 0.9458] 
2025-12-08 21:22:06.902570: Epoch time: 140.55 s 
2025-12-08 21:22:07.554304:  
2025-12-08 21:22:07.555304: Epoch 863 
2025-12-08 21:22:07.561334: Current learning rate: 0.00167 
2025-12-08 21:24:27.262975: train_loss -0.8541 
2025-12-08 21:24:27.263976: val_loss -0.8802 
2025-12-08 21:24:27.270982: Pseudo dice [0.9268, 0.9564, 0.9506] 
2025-12-08 21:24:27.277278: Epoch time: 139.71 s 
2025-12-08 21:24:28.105320:  
2025-12-08 21:24:28.105320: Epoch 864 
2025-12-08 21:24:28.112329: Current learning rate: 0.00166 
2025-12-08 21:26:48.230374: train_loss -0.8571 
2025-12-08 21:26:48.230374: val_loss -0.8724 
2025-12-08 21:26:48.238349: Pseudo dice [0.9232, 0.9493, 0.9506] 
2025-12-08 21:26:48.243042: Epoch time: 140.13 s 
2025-12-08 21:26:48.873294:  
2025-12-08 21:26:48.873294: Epoch 865 
2025-12-08 21:26:48.877955: Current learning rate: 0.00165 
2025-12-08 21:29:10.475772: train_loss -0.855 
2025-12-08 21:29:10.475772: val_loss -0.8629 
2025-12-08 21:29:10.483131: Pseudo dice [0.9171, 0.9469, 0.941] 
2025-12-08 21:29:10.489356: Epoch time: 141.6 s 
2025-12-08 21:29:11.312366:  
2025-12-08 21:29:11.312366: Epoch 866 
2025-12-08 21:29:11.328161: Current learning rate: 0.00164 
2025-12-08 21:31:32.805335: train_loss -0.8595 
2025-12-08 21:31:32.805335: val_loss -0.8812 
2025-12-08 21:31:32.811336: Pseudo dice [0.9255, 0.9605, 0.951] 
2025-12-08 21:31:32.817176: Epoch time: 141.49 s 
2025-12-08 21:31:33.457348:  
2025-12-08 21:31:33.457348: Epoch 867 
2025-12-08 21:31:33.464374: Current learning rate: 0.00163 
2025-12-08 21:33:54.321192: train_loss -0.859 
2025-12-08 21:33:54.322195: val_loss -0.8866 
2025-12-08 21:33:54.327221: Pseudo dice [0.9311, 0.9589, 0.9502] 
2025-12-08 21:33:54.334760: Epoch time: 140.86 s 
2025-12-08 21:33:55.003225:  
2025-12-08 21:33:55.005228: Epoch 868 
2025-12-08 21:33:55.005228: Current learning rate: 0.00162 
2025-12-08 21:36:13.499388: train_loss -0.8625 
2025-12-08 21:36:13.506887: val_loss -0.8785 
2025-12-08 21:36:13.512893: Pseudo dice [0.9255, 0.953, 0.9545] 
2025-12-08 21:36:13.518517: Epoch time: 138.5 s 
2025-12-08 21:36:14.202589:  
2025-12-08 21:36:14.202589: Epoch 869 
2025-12-08 21:36:14.206095: Current learning rate: 0.00161 
2025-12-08 21:38:32.749557: train_loss -0.8629 
2025-12-08 21:38:32.749557: val_loss -0.8825 
2025-12-08 21:38:32.765322: Pseudo dice [0.9282, 0.9544, 0.9518] 
2025-12-08 21:38:32.765322: Epoch time: 138.55 s 
2025-12-08 21:38:33.421762:  
2025-12-08 21:38:33.421762: Epoch 870 
2025-12-08 21:38:33.441218: Current learning rate: 0.00159 
2025-12-08 21:40:52.140175: train_loss -0.8615 
2025-12-08 21:40:52.155946: val_loss -0.8763 
2025-12-08 21:40:52.164306: Pseudo dice [0.9238, 0.9542, 0.9492] 
2025-12-08 21:40:52.169307: Epoch time: 138.72 s 
2025-12-08 21:40:52.874351:  
2025-12-08 21:40:52.874351: Epoch 871 
2025-12-08 21:40:52.874351: Current learning rate: 0.00158 
2025-12-08 21:43:11.198414: train_loss -0.8636 
2025-12-08 21:43:11.199415: val_loss -0.889 
2025-12-08 21:43:11.207117: Pseudo dice [0.9325, 0.9595, 0.9505] 
2025-12-08 21:43:11.213122: Epoch time: 138.32 s 
2025-12-08 21:43:11.848518:  
2025-12-08 21:43:11.848518: Epoch 872 
2025-12-08 21:43:11.854541: Current learning rate: 0.00157 
2025-12-08 21:45:30.452594: train_loss -0.8607 
2025-12-08 21:45:30.452594: val_loss -0.8753 
2025-12-08 21:45:30.458177: Pseudo dice [0.9231, 0.9532, 0.9475] 
2025-12-08 21:45:30.464183: Epoch time: 138.61 s 
2025-12-08 21:45:31.406051:  
2025-12-08 21:45:31.406051: Epoch 873 
2025-12-08 21:45:31.406051: Current learning rate: 0.00156 
2025-12-08 21:47:49.483148: train_loss -0.861 
2025-12-08 21:47:49.498960: val_loss -0.8881 
2025-12-08 21:47:49.498960: Pseudo dice [0.9297, 0.9632, 0.9494] 
2025-12-08 21:47:49.498960: Epoch time: 138.08 s 
2025-12-08 21:47:50.139557:  
2025-12-08 21:47:50.140624: Epoch 874 
2025-12-08 21:47:50.146776: Current learning rate: 0.00155 
2025-12-08 21:50:07.967714: train_loss -0.8636 
2025-12-08 21:50:07.967714: val_loss -0.8847 
2025-12-08 21:50:07.983816: Pseudo dice [0.9278, 0.9603, 0.953] 
2025-12-08 21:50:07.983816: Epoch time: 137.83 s 
2025-12-08 21:50:08.614652:  
2025-12-08 21:50:08.614652: Epoch 875 
2025-12-08 21:50:08.620672: Current learning rate: 0.00154 
2025-12-08 21:52:26.723044: train_loss -0.8579 
2025-12-08 21:52:26.723044: val_loss -0.8813 
2025-12-08 21:52:26.723044: Pseudo dice [0.9246, 0.9565, 0.9518] 
2025-12-08 21:52:26.733360: Epoch time: 138.11 s 
2025-12-08 21:52:27.356089:  
2025-12-08 21:52:27.356089: Epoch 876 
2025-12-08 21:52:27.357830: Current learning rate: 0.00153 
2025-12-08 21:54:45.450783: train_loss -0.8595 
2025-12-08 21:54:45.450783: val_loss -0.8794 
2025-12-08 21:54:45.458277: Pseudo dice [0.9254, 0.9556, 0.9504] 
2025-12-08 21:54:45.462283: Epoch time: 138.09 s 
2025-12-08 21:54:46.158461:  
2025-12-08 21:54:46.158461: Epoch 877 
2025-12-08 21:54:46.165479: Current learning rate: 0.00152 
2025-12-08 21:57:04.170472: train_loss -0.864 
2025-12-08 21:57:04.172474: val_loss -0.8712 
2025-12-08 21:57:04.178480: Pseudo dice [0.9191, 0.9507, 0.9546] 
2025-12-08 21:57:04.184486: Epoch time: 138.01 s 
2025-12-08 21:57:04.884621:  
2025-12-08 21:57:04.886361: Epoch 878 
2025-12-08 21:57:04.889124: Current learning rate: 0.00151 
2025-12-08 21:59:23.076955: train_loss -0.8618 
2025-12-08 21:59:23.078959: val_loss -0.8692 
2025-12-08 21:59:23.088970: Pseudo dice [0.9169, 0.9521, 0.9463] 
2025-12-08 21:59:23.094714: Epoch time: 138.19 s 
2025-12-08 21:59:23.889063:  
2025-12-08 21:59:23.889063: Epoch 879 
2025-12-08 21:59:23.904813: Current learning rate: 0.00149 
2025-12-08 22:01:41.844756: train_loss -0.8625 
2025-12-08 22:01:41.846759: val_loss -0.8849 
2025-12-08 22:01:41.854505: Pseudo dice [0.9326, 0.9594, 0.9481] 
2025-12-08 22:01:41.863594: Epoch time: 137.96 s 
2025-12-08 22:01:42.501500:  
2025-12-08 22:01:42.501500: Epoch 880 
2025-12-08 22:01:42.501500: Current learning rate: 0.00148 
2025-12-08 22:04:00.426143: train_loss -0.8583 
2025-12-08 22:04:00.426143: val_loss -0.8804 
2025-12-08 22:04:00.436153: Pseudo dice [0.926, 0.9559, 0.9498] 
2025-12-08 22:04:00.443901: Epoch time: 137.93 s 
2025-12-08 22:04:01.191188:  
2025-12-08 22:04:01.192188: Epoch 881 
2025-12-08 22:04:01.197696: Current learning rate: 0.00147 
2025-12-08 22:06:19.326842: train_loss -0.8625 
2025-12-08 22:06:19.326842: val_loss -0.8805 
2025-12-08 22:06:19.337438: Pseudo dice [0.9249, 0.9559, 0.9506] 
2025-12-08 22:06:19.342943: Epoch time: 138.14 s 
2025-12-08 22:06:20.014690:  
2025-12-08 22:06:20.014690: Epoch 882 
2025-12-08 22:06:20.014690: Current learning rate: 0.00146 
2025-12-08 22:08:38.093192: train_loss -0.8574 
2025-12-08 22:08:38.093192: val_loss -0.8873 
2025-12-08 22:08:38.104438: Pseudo dice [0.9313, 0.9634, 0.9529] 
2025-12-08 22:08:38.108442: Epoch time: 138.08 s 
2025-12-08 22:08:38.810440:  
2025-12-08 22:08:38.811445: Epoch 883 
2025-12-08 22:08:38.811445: Current learning rate: 0.00145 
2025-12-08 22:10:56.702685: train_loss -0.8604 
2025-12-08 22:10:56.702685: val_loss -0.8678 
2025-12-08 22:10:56.710687: Pseudo dice [0.9167, 0.9519, 0.9478] 
2025-12-08 22:10:56.715696: Epoch time: 137.89 s 
2025-12-08 22:10:57.467975:  
2025-12-08 22:10:57.468980: Epoch 884 
2025-12-08 22:10:57.476024: Current learning rate: 0.00144 
2025-12-08 22:13:15.498992: train_loss -0.8595 
2025-12-08 22:13:15.498992: val_loss -0.8835 
2025-12-08 22:13:15.498992: Pseudo dice [0.9268, 0.9584, 0.953] 
2025-12-08 22:13:15.498992: Epoch time: 138.03 s 
2025-12-08 22:13:16.125149:  
2025-12-08 22:13:16.125149: Epoch 885 
2025-12-08 22:13:16.125149: Current learning rate: 0.00143 
2025-12-08 22:15:34.179533: train_loss -0.8609 
2025-12-08 22:15:34.181535: val_loss -0.8883 
2025-12-08 22:15:34.187541: Pseudo dice [0.9312, 0.9626, 0.9537] 
2025-12-08 22:15:34.192547: Epoch time: 138.05 s 
2025-12-08 22:15:35.062373:  
2025-12-08 22:15:35.078081: Epoch 886 
2025-12-08 22:15:35.078081: Current learning rate: 0.00142 
2025-12-08 22:17:53.236816: train_loss -0.8613 
2025-12-08 22:17:53.237818: val_loss -0.8897 
2025-12-08 22:17:53.244820: Pseudo dice [0.9315, 0.9597, 0.954] 
2025-12-08 22:17:53.250865: Epoch time: 138.17 s 
2025-12-08 22:17:53.952148:  
2025-12-08 22:17:53.952148: Epoch 887 
2025-12-08 22:17:53.967852: Current learning rate: 0.00141 
2025-12-08 22:20:11.998894: train_loss -0.86 
2025-12-08 22:20:11.998894: val_loss -0.8767 
2025-12-08 22:20:12.014554: Pseudo dice [0.9242, 0.9562, 0.9515] 
2025-12-08 22:20:12.014554: Epoch time: 138.05 s 
2025-12-08 22:20:12.639304:  
2025-12-08 22:20:12.639304: Epoch 888 
2025-12-08 22:20:12.639304: Current learning rate: 0.00139 
2025-12-08 22:22:30.558100: train_loss -0.8604 
2025-12-08 22:22:30.558100: val_loss -0.8739 
2025-12-08 22:22:30.561843: Pseudo dice [0.9195, 0.9534, 0.9565] 
2025-12-08 22:22:30.567724: Epoch time: 137.92 s 
2025-12-08 22:22:31.235452:  
2025-12-08 22:22:31.235452: Epoch 889 
2025-12-08 22:22:31.251581: Current learning rate: 0.00138 
2025-12-08 22:24:49.188931: train_loss -0.8659 
2025-12-08 22:24:49.188931: val_loss -0.8789 
2025-12-08 22:24:49.202699: Pseudo dice [0.9251, 0.9549, 0.9517] 
2025-12-08 22:24:49.208707: Epoch time: 137.95 s 
2025-12-08 22:24:49.859715:  
2025-12-08 22:24:49.859715: Epoch 890 
2025-12-08 22:24:49.875382: Current learning rate: 0.00137 
2025-12-08 22:27:08.209919: train_loss -0.8569 
2025-12-08 22:27:08.209919: val_loss -0.8911 
2025-12-08 22:27:08.219671: Pseudo dice [0.9322, 0.9656, 0.9523] 
2025-12-08 22:27:08.229685: Epoch time: 138.35 s 
2025-12-08 22:27:08.237433: Yayy! New best EMA pseudo Dice: 0.9451 
2025-12-08 22:27:09.221732:  
2025-12-08 22:27:09.221732: Epoch 891 
2025-12-08 22:27:09.221732: Current learning rate: 0.00136 
2025-12-08 22:29:27.490243: train_loss -0.8578 
2025-12-08 22:29:27.490243: val_loss -0.8854 
2025-12-08 22:29:27.496248: Pseudo dice [0.9305, 0.9593, 0.9496] 
2025-12-08 22:29:27.500252: Epoch time: 138.27 s 
2025-12-08 22:29:27.506665: Yayy! New best EMA pseudo Dice: 0.9452 
2025-12-08 22:29:28.729039:  
2025-12-08 22:29:28.730057: Epoch 892 
2025-12-08 22:29:28.736173: Current learning rate: 0.00135 
2025-12-08 22:31:46.659729: train_loss -0.8598 
2025-12-08 22:31:46.659729: val_loss -0.8869 
2025-12-08 22:31:46.668731: Pseudo dice [0.9314, 0.9628, 0.9513] 
2025-12-08 22:31:46.676522: Epoch time: 137.93 s 
2025-12-08 22:31:46.682527: Yayy! New best EMA pseudo Dice: 0.9456 
2025-12-08 22:31:47.770421:  
2025-12-08 22:31:47.770421: Epoch 893 
2025-12-08 22:31:47.777450: Current learning rate: 0.00134 
2025-12-08 22:34:05.751729: train_loss -0.8589 
2025-12-08 22:34:05.751729: val_loss -0.8813 
2025-12-08 22:34:05.761739: Pseudo dice [0.9243, 0.9593, 0.9536] 
2025-12-08 22:34:05.767484: Epoch time: 137.98 s 
2025-12-08 22:34:05.773489: Yayy! New best EMA pseudo Dice: 0.9456 
2025-12-08 22:34:06.718661:  
2025-12-08 22:34:06.718661: Epoch 894 
2025-12-08 22:34:06.734374: Current learning rate: 0.00133 
2025-12-08 22:36:24.640201: train_loss -0.8666 
2025-12-08 22:36:24.640201: val_loss -0.8818 
2025-12-08 22:36:24.655457: Pseudo dice [0.9265, 0.9564, 0.9516] 
2025-12-08 22:36:24.661721: Epoch time: 137.92 s 
2025-12-08 22:36:25.295728:  
2025-12-08 22:36:25.295728: Epoch 895 
2025-12-08 22:36:25.295728: Current learning rate: 0.00132 
2025-12-08 22:38:43.231928: train_loss -0.8609 
2025-12-08 22:38:43.233668: val_loss -0.8941 
2025-12-08 22:38:43.241679: Pseudo dice [0.9325, 0.9667, 0.9542] 
2025-12-08 22:38:43.249425: Epoch time: 137.94 s 
2025-12-08 22:38:43.256501: Yayy! New best EMA pseudo Dice: 0.9461 
2025-12-08 22:38:44.180835:  
2025-12-08 22:38:44.180835: Epoch 896 
2025-12-08 22:38:44.186863: Current learning rate: 0.0013 
2025-12-08 22:41:02.190971: train_loss -0.8609 
2025-12-08 22:41:02.200574: val_loss -0.8717 
2025-12-08 22:41:02.208055: Pseudo dice [0.9185, 0.9529, 0.952] 
2025-12-08 22:41:02.215539: Epoch time: 138.02 s 
2025-12-08 22:41:02.842445:  
2025-12-08 22:41:02.842445: Epoch 897 
2025-12-08 22:41:02.842445: Current learning rate: 0.00129 
2025-12-08 22:43:20.907752: train_loss -0.8627 
2025-12-08 22:43:20.907752: val_loss -0.8887 
2025-12-08 22:43:20.915497: Pseudo dice [0.9305, 0.9604, 0.9505] 
2025-12-08 22:43:20.921241: Epoch time: 138.07 s 
2025-12-08 22:43:21.715903:  
2025-12-08 22:43:21.715903: Epoch 898 
2025-12-08 22:43:21.723046: Current learning rate: 0.00128 
2025-12-08 22:45:39.736147: train_loss -0.8588 
2025-12-08 22:45:39.736147: val_loss -0.8792 
2025-12-08 22:45:39.751767: Pseudo dice [0.9294, 0.9563, 0.9402] 
2025-12-08 22:45:39.751767: Epoch time: 138.02 s 
2025-12-08 22:45:40.376297:  
2025-12-08 22:45:40.376297: Epoch 899 
2025-12-08 22:45:40.390313: Current learning rate: 0.00127 
2025-12-08 22:47:58.344433: train_loss -0.8601 
2025-12-08 22:47:58.344433: val_loss -0.8874 
2025-12-08 22:47:58.360085: Pseudo dice [0.9322, 0.96, 0.953] 
2025-12-08 22:47:58.360085: Epoch time: 137.97 s 
2025-12-08 22:47:59.289320:  
2025-12-08 22:47:59.290323: Epoch 900 
2025-12-08 22:47:59.296319: Current learning rate: 0.00126 
2025-12-08 22:50:17.514726: train_loss -0.8584 
2025-12-08 22:50:17.514726: val_loss -0.8851 
2025-12-08 22:50:17.522221: Pseudo dice [0.9273, 0.9536, 0.9546] 
2025-12-08 22:50:17.528227: Epoch time: 138.23 s 
2025-12-08 22:50:18.165370:  
2025-12-08 22:50:18.165370: Epoch 901 
2025-12-08 22:50:18.171767: Current learning rate: 0.00125 
2025-12-08 22:52:36.173424: train_loss -0.8587 
2025-12-08 22:52:36.175427: val_loss -0.8747 
2025-12-08 22:52:36.180800: Pseudo dice [0.9201, 0.9509, 0.9505] 
2025-12-08 22:52:36.186806: Epoch time: 138.01 s 
2025-12-08 22:52:36.889045:  
2025-12-08 22:52:36.889045: Epoch 902 
2025-12-08 22:52:36.905158: Current learning rate: 0.00124 
2025-12-08 22:54:54.796586: train_loss -0.8591 
2025-12-08 22:54:54.796586: val_loss -0.8848 
2025-12-08 22:54:54.807936: Pseudo dice [0.9287, 0.9556, 0.9522] 
2025-12-08 22:54:54.815944: Epoch time: 137.91 s 
2025-12-08 22:54:55.437339:  
2025-12-08 22:54:55.437339: Epoch 903 
2025-12-08 22:54:55.453102: Current learning rate: 0.00122 
2025-12-08 22:57:13.640755: train_loss -0.8582 
2025-12-08 22:57:13.640755: val_loss -0.8817 
2025-12-08 22:57:13.650427: Pseudo dice [0.9277, 0.9578, 0.9521] 
2025-12-08 22:57:13.656440: Epoch time: 138.2 s 
2025-12-08 22:57:14.422769:  
2025-12-08 22:57:14.422769: Epoch 904 
2025-12-08 22:57:14.441635: Current learning rate: 0.00121 
2025-12-08 22:59:32.436190: train_loss -0.8566 
2025-12-08 22:59:32.436190: val_loss -0.8837 
2025-12-08 22:59:32.443238: Pseudo dice [0.9274, 0.9602, 0.9494] 
2025-12-08 22:59:32.449259: Epoch time: 138.01 s 
2025-12-08 22:59:33.249120:  
2025-12-08 22:59:33.249120: Epoch 905 
2025-12-08 22:59:33.249120: Current learning rate: 0.0012 
2025-12-08 23:01:51.368309: train_loss -0.8617 
2025-12-08 23:01:51.368309: val_loss -0.8718 
2025-12-08 23:01:51.380071: Pseudo dice [0.9181, 0.9512, 0.9537] 
2025-12-08 23:01:51.388081: Epoch time: 138.12 s 
2025-12-08 23:01:52.014668:  
2025-12-08 23:01:52.014668: Epoch 906 
2025-12-08 23:01:52.014668: Current learning rate: 0.00119 
2025-12-08 23:04:10.116211: train_loss -0.861 
2025-12-08 23:04:10.116211: val_loss -0.877 
2025-12-08 23:04:10.122217: Pseudo dice [0.921, 0.9551, 0.951] 
2025-12-08 23:04:10.129313: Epoch time: 138.1 s 
2025-12-08 23:04:10.811831:  
2025-12-08 23:04:10.827578: Epoch 907 
2025-12-08 23:04:10.827578: Current learning rate: 0.00118 
2025-12-08 23:06:28.966268: train_loss -0.8582 
2025-12-08 23:06:28.968009: val_loss -0.8812 
2025-12-08 23:06:28.974829: Pseudo dice [0.9264, 0.9615, 0.9494] 
2025-12-08 23:06:28.978833: Epoch time: 138.15 s 
2025-12-08 23:06:29.608177:  
2025-12-08 23:06:29.608177: Epoch 908 
2025-12-08 23:06:29.608177: Current learning rate: 0.00117 
2025-12-08 23:08:47.782441: train_loss -0.8607 
2025-12-08 23:08:47.782441: val_loss -0.8907 
2025-12-08 23:08:47.800372: Pseudo dice [0.9317, 0.959, 0.9561] 
2025-12-08 23:08:47.805387: Epoch time: 138.17 s 
2025-12-08 23:08:48.467901:  
2025-12-08 23:08:48.467901: Epoch 909 
2025-12-08 23:08:48.467901: Current learning rate: 0.00116 
2025-12-08 23:11:06.564006: train_loss -0.8595 
2025-12-08 23:11:06.565008: val_loss -0.8835 
2025-12-08 23:11:06.571022: Pseudo dice [0.9289, 0.9574, 0.9554] 
2025-12-08 23:11:06.577047: Epoch time: 138.1 s 
2025-12-08 23:11:07.265009:  
2025-12-08 23:11:07.265009: Epoch 910 
2025-12-08 23:11:07.265009: Current learning rate: 0.00115 
2025-12-08 23:13:25.530153: train_loss -0.858 
2025-12-08 23:13:25.530153: val_loss -0.8858 
2025-12-08 23:13:25.547807: Pseudo dice [0.9306, 0.9628, 0.9497] 
2025-12-08 23:13:25.547807: Epoch time: 138.27 s 
2025-12-08 23:13:26.344623:  
2025-12-08 23:13:26.344623: Epoch 911 
2025-12-08 23:13:26.344623: Current learning rate: 0.00113 
2025-12-08 23:15:44.509355: train_loss -0.8583 
2025-12-08 23:15:44.509355: val_loss -0.8912 
2025-12-08 23:15:44.517368: Pseudo dice [0.9337, 0.961, 0.9473] 
2025-12-08 23:15:44.523370: Epoch time: 138.16 s 
2025-12-08 23:15:45.209562:  
2025-12-08 23:15:45.209562: Epoch 912 
2025-12-08 23:15:45.209562: Current learning rate: 0.00112 
2025-12-08 23:18:03.229896: train_loss -0.8647 
2025-12-08 23:18:03.231898: val_loss -0.8835 
2025-12-08 23:18:03.239645: Pseudo dice [0.9281, 0.9571, 0.949] 
2025-12-08 23:18:03.243648: Epoch time: 138.02 s 
2025-12-08 23:18:03.983905:  
2025-12-08 23:18:03.983905: Epoch 913 
2025-12-08 23:18:04.001696: Current learning rate: 0.00111 
2025-12-08 23:20:22.108779: train_loss -0.8608 
2025-12-08 23:20:22.108779: val_loss -0.8902 
2025-12-08 23:20:22.118290: Pseudo dice [0.9302, 0.9596, 0.9555] 
2025-12-08 23:20:22.122294: Epoch time: 138.12 s 
2025-12-08 23:20:22.758726:  
2025-12-08 23:20:22.759738: Epoch 914 
2025-12-08 23:20:22.766513: Current learning rate: 0.0011 
2025-12-08 23:22:40.584112: train_loss -0.8621 
2025-12-08 23:22:40.586115: val_loss -0.8874 
2025-12-08 23:22:40.593861: Pseudo dice [0.9276, 0.9589, 0.9537] 
2025-12-08 23:22:40.599867: Epoch time: 137.83 s 
2025-12-08 23:22:41.232179:  
2025-12-08 23:22:41.232179: Epoch 915 
2025-12-08 23:22:41.233184: Current learning rate: 0.00109 
2025-12-08 23:24:59.337909: train_loss -0.86 
2025-12-08 23:24:59.339912: val_loss -0.8854 
2025-12-08 23:24:59.345658: Pseudo dice [0.9305, 0.9569, 0.9514] 
2025-12-08 23:24:59.351664: Epoch time: 138.11 s 
2025-12-08 23:24:59.968017:  
2025-12-08 23:24:59.968017: Epoch 916 
2025-12-08 23:24:59.983812: Current learning rate: 0.00108 
2025-12-08 23:27:18.297062: train_loss -0.8564 
2025-12-08 23:27:18.297062: val_loss -0.8716 
2025-12-08 23:27:18.304075: Pseudo dice [0.9211, 0.9512, 0.9451] 
2025-12-08 23:27:18.310076: Epoch time: 138.33 s 
2025-12-08 23:27:19.108407:  
2025-12-08 23:27:19.108407: Epoch 917 
2025-12-08 23:27:19.108407: Current learning rate: 0.00106 
2025-12-08 23:29:37.317205: train_loss -0.8618 
2025-12-08 23:29:37.317205: val_loss -0.8847 
2025-12-08 23:29:37.325213: Pseudo dice [0.931, 0.958, 0.9469] 
2025-12-08 23:29:37.330716: Epoch time: 138.21 s 
2025-12-08 23:29:38.015276:  
2025-12-08 23:29:38.015276: Epoch 918 
2025-12-08 23:29:38.022293: Current learning rate: 0.00105 
2025-12-08 23:31:55.987942: train_loss -0.8651 
2025-12-08 23:31:55.987942: val_loss -0.8799 
2025-12-08 23:31:55.999693: Pseudo dice [0.9269, 0.9578, 0.9473] 
2025-12-08 23:31:56.011711: Epoch time: 137.97 s 
2025-12-08 23:31:56.648056:  
2025-12-08 23:31:56.648056: Epoch 919 
2025-12-08 23:31:56.655580: Current learning rate: 0.00104 
2025-12-08 23:34:14.614665: train_loss -0.8643 
2025-12-08 23:34:14.614665: val_loss -0.8836 
2025-12-08 23:34:14.622673: Pseudo dice [0.9287, 0.956, 0.9518] 
2025-12-08 23:34:14.628290: Epoch time: 137.97 s 
2025-12-08 23:34:15.252282:  
2025-12-08 23:34:15.253282: Epoch 920 
2025-12-08 23:34:15.258828: Current learning rate: 0.00103 
2025-12-08 23:36:33.295356: train_loss -0.8654 
2025-12-08 23:36:33.295356: val_loss -0.8828 
2025-12-08 23:36:33.304069: Pseudo dice [0.9267, 0.9576, 0.954] 
2025-12-08 23:36:33.308873: Epoch time: 138.04 s 
2025-12-08 23:36:33.967107:  
2025-12-08 23:36:33.967107: Epoch 921 
2025-12-08 23:36:33.982939: Current learning rate: 0.00102 
2025-12-08 23:38:52.155399: train_loss -0.859 
2025-12-08 23:38:52.155399: val_loss -0.8824 
2025-12-08 23:38:52.167423: Pseudo dice [0.927, 0.9572, 0.951] 
2025-12-08 23:38:52.175170: Epoch time: 138.19 s 
2025-12-08 23:38:52.795760:  
2025-12-08 23:38:52.795760: Epoch 922 
2025-12-08 23:38:52.811668: Current learning rate: 0.00101 
2025-12-08 23:41:12.357891: train_loss -0.8637 
2025-12-08 23:41:12.357891: val_loss -0.8775 
2025-12-08 23:41:12.364308: Pseudo dice [0.925, 0.9566, 0.9495] 
2025-12-08 23:41:12.368819: Epoch time: 139.56 s 
2025-12-08 23:41:12.991977:  
2025-12-08 23:41:12.991977: Epoch 923 
2025-12-08 23:41:12.997108: Current learning rate: 0.001 
2025-12-08 23:43:31.474879: train_loss -0.8646 
2025-12-08 23:43:31.474879: val_loss -0.8865 
2025-12-08 23:43:31.484891: Pseudo dice [0.931, 0.96, 0.9514] 
2025-12-08 23:43:31.490636: Epoch time: 138.5 s 
2025-12-08 23:43:32.295345:  
2025-12-08 23:43:32.295345: Epoch 924 
2025-12-08 23:43:32.295345: Current learning rate: 0.00098 
2025-12-08 23:45:50.639628: train_loss -0.866 
2025-12-08 23:45:50.639628: val_loss -0.8926 
2025-12-08 23:45:50.647376: Pseudo dice [0.934, 0.9597, 0.9518] 
2025-12-08 23:45:50.653839: Epoch time: 138.34 s 
2025-12-08 23:45:51.396692:  
2025-12-08 23:45:51.396692: Epoch 925 
2025-12-08 23:45:51.404704: Current learning rate: 0.00097 
2025-12-08 23:48:09.797849: train_loss -0.8641 
2025-12-08 23:48:09.797849: val_loss -0.8894 
2025-12-08 23:48:09.797849: Pseudo dice [0.9326, 0.9621, 0.9511] 
2025-12-08 23:48:09.807821: Epoch time: 138.4 s 
2025-12-08 23:48:10.433750:  
2025-12-08 23:48:10.433750: Epoch 926 
2025-12-08 23:48:10.433750: Current learning rate: 0.00096 
2025-12-08 23:50:28.875886: train_loss -0.8646 
2025-12-08 23:50:28.875886: val_loss -0.8941 
2025-12-08 23:50:28.881891: Pseudo dice [0.9339, 0.9636, 0.9516] 
2025-12-08 23:50:28.889260: Epoch time: 138.44 s 
2025-12-08 23:50:28.895266: Yayy! New best EMA pseudo Dice: 0.9463 
2025-12-08 23:50:29.798206:  
2025-12-08 23:50:29.798206: Epoch 927 
2025-12-08 23:50:29.804480: Current learning rate: 0.00095 
2025-12-08 23:52:47.961868: train_loss -0.8594 
2025-12-08 23:52:47.961868: val_loss -0.8813 
2025-12-08 23:52:47.977778: Pseudo dice [0.9236, 0.9567, 0.9502] 
2025-12-08 23:52:47.977778: Epoch time: 138.17 s 
2025-12-08 23:52:48.838809:  
2025-12-08 23:52:48.838809: Epoch 928 
2025-12-08 23:52:48.838809: Current learning rate: 0.00094 
2025-12-08 23:55:06.899708: train_loss -0.8655 
2025-12-08 23:55:06.899708: val_loss -0.887 
2025-12-08 23:55:06.899708: Pseudo dice [0.9289, 0.9589, 0.9506] 
2025-12-08 23:55:06.915591: Epoch time: 138.06 s 
2025-12-08 23:55:07.532890:  
2025-12-08 23:55:07.532890: Epoch 929 
2025-12-08 23:55:07.532890: Current learning rate: 0.00092 
2025-12-08 23:57:25.828827: train_loss -0.8551 
2025-12-08 23:57:25.828827: val_loss -0.8833 
2025-12-08 23:57:25.838576: Pseudo dice [0.929, 0.9584, 0.9497] 
2025-12-08 23:57:25.842580: Epoch time: 138.3 s 
2025-12-08 23:57:26.470056:  
2025-12-08 23:57:26.470056: Epoch 930 
2025-12-08 23:57:26.470056: Current learning rate: 0.00091 
2025-12-08 23:59:44.581079: train_loss -0.8614 
2025-12-08 23:59:44.581079: val_loss -0.8825 
2025-12-08 23:59:44.588994: Pseudo dice [0.9282, 0.9602, 0.952] 
2025-12-08 23:59:44.595001: Epoch time: 138.11 s 
2025-12-08 23:59:45.569155:  
2025-12-08 23:59:45.569155: Epoch 931 
2025-12-08 23:59:45.586920: Current learning rate: 0.0009 
2025-12-09 00:02:03.747560: train_loss -0.8663 
2025-12-09 00:02:03.747560: val_loss -0.8894 
2025-12-09 00:02:03.763267: Pseudo dice [0.931, 0.9641, 0.9516] 
2025-12-09 00:02:03.763267: Epoch time: 138.18 s 
2025-12-09 00:02:03.763267: Yayy! New best EMA pseudo Dice: 0.9464 
2025-12-09 00:02:04.761514:  
2025-12-09 00:02:04.761514: Epoch 932 
2025-12-09 00:02:04.761514: Current learning rate: 0.00089 
2025-12-09 00:04:22.904267: train_loss -0.8637 
2025-12-09 00:04:22.906269: val_loss -0.8758 
2025-12-09 00:04:22.906269: Pseudo dice [0.9248, 0.9537, 0.9526] 
2025-12-09 00:04:22.916707: Epoch time: 138.16 s 
2025-12-09 00:04:23.540768:  
2025-12-09 00:04:23.540768: Epoch 933 
2025-12-09 00:04:23.540768: Current learning rate: 0.00088 
2025-12-09 00:06:41.677257: train_loss -0.863 
2025-12-09 00:06:41.677257: val_loss -0.884 
2025-12-09 00:06:41.685265: Pseudo dice [0.9287, 0.959, 0.9534] 
2025-12-09 00:06:41.691009: Epoch time: 138.14 s 
2025-12-09 00:06:42.495827:  
2025-12-09 00:06:42.495827: Epoch 934 
2025-12-09 00:06:42.495827: Current learning rate: 0.00087 
2025-12-09 00:09:00.511299: train_loss -0.8664 
2025-12-09 00:09:00.511299: val_loss -0.8878 
2025-12-09 00:09:00.529116: Pseudo dice [0.9308, 0.9612, 0.9498] 
2025-12-09 00:09:00.535122: Epoch time: 138.02 s 
2025-12-09 00:09:01.253980:  
2025-12-09 00:09:01.253980: Epoch 935 
2025-12-09 00:09:01.270051: Current learning rate: 0.00085 
2025-12-09 00:11:19.373273: train_loss -0.8651 
2025-12-09 00:11:19.375276: val_loss -0.8794 
2025-12-09 00:11:19.381283: Pseudo dice [0.9217, 0.957, 0.9553] 
2025-12-09 00:11:19.385287: Epoch time: 138.12 s 
2025-12-09 00:11:20.020909:  
2025-12-09 00:11:20.021912: Epoch 936 
2025-12-09 00:11:20.021912: Current learning rate: 0.00084 
2025-12-09 00:13:38.175034: train_loss -0.8598 
2025-12-09 00:13:38.175034: val_loss -0.8856 
2025-12-09 00:13:38.191150: Pseudo dice [0.9302, 0.9595, 0.9489] 
2025-12-09 00:13:38.191150: Epoch time: 138.16 s 
2025-12-09 00:13:39.204703:  
2025-12-09 00:13:39.204703: Epoch 937 
2025-12-09 00:13:39.204703: Current learning rate: 0.00083 
2025-12-09 00:15:57.221310: train_loss -0.8633 
2025-12-09 00:15:57.221310: val_loss -0.8824 
2025-12-09 00:15:57.221310: Pseudo dice [0.9272, 0.9573, 0.9496] 
2025-12-09 00:15:57.221310: Epoch time: 138.02 s 
2025-12-09 00:15:57.863778:  
2025-12-09 00:15:57.863778: Epoch 938 
2025-12-09 00:15:57.868090: Current learning rate: 0.00082 
2025-12-09 00:18:16.194149: train_loss -0.8671 
2025-12-09 00:18:16.194149: val_loss -0.8855 
2025-12-09 00:18:16.207900: Pseudo dice [0.932, 0.9599, 0.9442] 
2025-12-09 00:18:16.207900: Epoch time: 138.33 s 
2025-12-09 00:18:16.842175:  
2025-12-09 00:18:16.842175: Epoch 939 
2025-12-09 00:18:16.842175: Current learning rate: 0.00081 
2025-12-09 00:20:35.744829: train_loss -0.864 
2025-12-09 00:20:35.744829: val_loss -0.8803 
2025-12-09 00:20:35.744829: Pseudo dice [0.927, 0.953, 0.9521] 
2025-12-09 00:20:35.760588: Epoch time: 138.9 s 
2025-12-09 00:20:36.552299:  
2025-12-09 00:20:36.552299: Epoch 940 
2025-12-09 00:20:36.552299: Current learning rate: 0.00079 
2025-12-09 00:22:55.125354: train_loss -0.8628 
2025-12-09 00:22:55.125354: val_loss -0.8739 
2025-12-09 00:22:55.133100: Pseudo dice [0.9185, 0.953, 0.9553] 
2025-12-09 00:22:55.138898: Epoch time: 138.59 s 
2025-12-09 00:22:55.831434:  
2025-12-09 00:22:55.831434: Epoch 941 
2025-12-09 00:22:55.846762: Current learning rate: 0.00078 
2025-12-09 00:25:14.514328: train_loss -0.8619 
2025-12-09 00:25:14.514328: val_loss -0.8742 
2025-12-09 00:25:14.521967: Pseudo dice [0.9191, 0.9534, 0.951] 
2025-12-09 00:25:14.529975: Epoch time: 138.68 s 
2025-12-09 00:25:15.229328:  
2025-12-09 00:25:15.229328: Epoch 942 
2025-12-09 00:25:15.229328: Current learning rate: 0.00077 
2025-12-09 00:27:33.639635: train_loss -0.8634 
2025-12-09 00:27:33.639635: val_loss -0.8848 
2025-12-09 00:27:33.639635: Pseudo dice [0.9255, 0.9591, 0.9521] 
2025-12-09 00:27:33.659510: Epoch time: 138.41 s 
2025-12-09 00:27:34.492669:  
2025-12-09 00:27:34.508582: Epoch 943 
2025-12-09 00:27:34.514591: Current learning rate: 0.00076 
2025-12-09 00:29:52.860782: train_loss -0.8605 
2025-12-09 00:29:52.860782: val_loss -0.8753 
2025-12-09 00:29:52.876546: Pseudo dice [0.9225, 0.956, 0.947] 
2025-12-09 00:29:52.876546: Epoch time: 138.37 s 
2025-12-09 00:29:53.515744:  
2025-12-09 00:29:53.515744: Epoch 944 
2025-12-09 00:29:53.515744: Current learning rate: 0.00075 
2025-12-09 00:32:11.615592: train_loss -0.8606 
2025-12-09 00:32:11.615592: val_loss -0.8898 
2025-12-09 00:32:11.615592: Pseudo dice [0.9296, 0.9614, 0.958] 
2025-12-09 00:32:11.631644: Epoch time: 138.1 s 
2025-12-09 00:32:12.262644:  
2025-12-09 00:32:12.262644: Epoch 945 
2025-12-09 00:32:12.262644: Current learning rate: 0.00074 
2025-12-09 00:34:30.539233: train_loss -0.8648 
2025-12-09 00:34:30.539233: val_loss -0.8897 
2025-12-09 00:34:30.546257: Pseudo dice [0.9316, 0.9555, 0.9553] 
2025-12-09 00:34:30.550475: Epoch time: 138.28 s 
2025-12-09 00:34:31.180989:  
2025-12-09 00:34:31.182991: Epoch 946 
2025-12-09 00:34:31.187928: Current learning rate: 0.00072 
2025-12-09 00:36:49.151145: train_loss -0.8601 
2025-12-09 00:36:49.151145: val_loss -0.8814 
2025-12-09 00:36:49.170823: Pseudo dice [0.9291, 0.9557, 0.9525] 
2025-12-09 00:36:49.178832: Epoch time: 137.97 s 
2025-12-09 00:36:49.809514:  
2025-12-09 00:36:49.811516: Epoch 947 
2025-12-09 00:36:49.817551: Current learning rate: 0.00071 
2025-12-09 00:39:07.989095: train_loss -0.8619 
2025-12-09 00:39:07.989095: val_loss -0.8903 
2025-12-09 00:39:07.989095: Pseudo dice [0.9319, 0.9603, 0.9518] 
2025-12-09 00:39:08.004878: Epoch time: 138.18 s 
2025-12-09 00:39:08.628475:  
2025-12-09 00:39:08.628475: Epoch 948 
2025-12-09 00:39:08.628475: Current learning rate: 0.0007 
2025-12-09 00:41:26.635899: train_loss -0.8655 
2025-12-09 00:41:26.635899: val_loss -0.8798 
2025-12-09 00:41:26.643907: Pseudo dice [0.9246, 0.9542, 0.9531] 
2025-12-09 00:41:26.649913: Epoch time: 138.01 s 
2025-12-09 00:41:27.295447:  
2025-12-09 00:41:27.297450: Epoch 949 
2025-12-09 00:41:27.297450: Current learning rate: 0.00069 
2025-12-09 00:43:45.249300: train_loss -0.8662 
2025-12-09 00:43:45.249300: val_loss -0.8795 
2025-12-09 00:43:45.259310: Pseudo dice [0.9253, 0.9543, 0.9488] 
2025-12-09 00:43:45.265055: Epoch time: 137.95 s 
2025-12-09 00:43:46.405988:  
2025-12-09 00:43:46.407990: Epoch 950 
2025-12-09 00:43:46.414438: Current learning rate: 0.00067 
2025-12-09 00:46:04.558399: train_loss -0.8659 
2025-12-09 00:46:04.558399: val_loss -0.8762 
2025-12-09 00:46:04.566364: Pseudo dice [0.921, 0.9525, 0.951] 
2025-12-09 00:46:04.572370: Epoch time: 138.15 s 
2025-12-09 00:46:05.240777:  
2025-12-09 00:46:05.240777: Epoch 951 
2025-12-09 00:46:05.240777: Current learning rate: 0.00066 
2025-12-09 00:48:23.652069: train_loss -0.863 
2025-12-09 00:48:23.654071: val_loss -0.881 
2025-12-09 00:48:23.659577: Pseudo dice [0.9242, 0.9544, 0.9544] 
2025-12-09 00:48:23.659577: Epoch time: 138.41 s 
2025-12-09 00:48:24.307471:  
2025-12-09 00:48:24.307471: Epoch 952 
2025-12-09 00:48:24.323316: Current learning rate: 0.00065 
2025-12-09 00:50:42.407940: train_loss -0.8602 
2025-12-09 00:50:42.409942: val_loss -0.8828 
2025-12-09 00:50:42.415507: Pseudo dice [0.9266, 0.9568, 0.9534] 
2025-12-09 00:50:42.421512: Epoch time: 138.1 s 
2025-12-09 00:50:43.084547:  
2025-12-09 00:50:43.084547: Epoch 953 
2025-12-09 00:50:43.096294: Current learning rate: 0.00064 
2025-12-09 00:53:01.278290: train_loss -0.8608 
2025-12-09 00:53:01.278290: val_loss -0.8875 
2025-12-09 00:53:01.288038: Pseudo dice [0.9301, 0.9565, 0.9592] 
2025-12-09 00:53:01.292042: Epoch time: 138.19 s 
2025-12-09 00:53:02.010962:  
2025-12-09 00:53:02.010962: Epoch 954 
2025-12-09 00:53:02.026595: Current learning rate: 0.00063 
2025-12-09 00:55:20.077012: train_loss -0.8644 
2025-12-09 00:55:20.077012: val_loss -0.8822 
2025-12-09 00:55:20.092705: Pseudo dice [0.9266, 0.9582, 0.9539] 
2025-12-09 00:55:20.092705: Epoch time: 138.07 s 
2025-12-09 00:55:20.798968:  
2025-12-09 00:55:20.798968: Epoch 955 
2025-12-09 00:55:20.803137: Current learning rate: 0.00061 
2025-12-09 00:57:38.984826: train_loss -0.8656 
2025-12-09 00:57:38.984826: val_loss -0.8819 
2025-12-09 00:57:38.994449: Pseudo dice [0.9287, 0.9571, 0.9491] 
2025-12-09 00:57:39.002457: Epoch time: 138.19 s 
2025-12-09 00:57:39.892729:  
2025-12-09 00:57:39.892729: Epoch 956 
2025-12-09 00:57:39.892729: Current learning rate: 0.0006 
2025-12-09 00:59:58.071404: train_loss -0.8603 
2025-12-09 00:59:58.071404: val_loss -0.8862 
2025-12-09 00:59:58.085416: Pseudo dice [0.9279, 0.9565, 0.9524] 
2025-12-09 00:59:58.091020: Epoch time: 138.18 s 
2025-12-09 00:59:58.719701:  
2025-12-09 00:59:58.719701: Epoch 957 
2025-12-09 00:59:58.735532: Current learning rate: 0.00059 
2025-12-09 01:02:16.957267: train_loss -0.8643 
2025-12-09 01:02:16.972902: val_loss -0.885 
2025-12-09 01:02:16.978910: Pseudo dice [0.9301, 0.9585, 0.9503] 
2025-12-09 01:02:16.984916: Epoch time: 138.24 s 
2025-12-09 01:02:17.619654:  
2025-12-09 01:02:17.619654: Epoch 958 
2025-12-09 01:02:17.619654: Current learning rate: 0.00058 
2025-12-09 01:04:35.755251: train_loss -0.8652 
2025-12-09 01:04:35.757253: val_loss -0.8845 
2025-12-09 01:04:35.764808: Pseudo dice [0.9273, 0.9579, 0.9528] 
2025-12-09 01:04:35.770814: Epoch time: 138.14 s 
2025-12-09 01:04:36.498950:  
2025-12-09 01:04:36.498950: Epoch 959 
2025-12-09 01:04:36.505442: Current learning rate: 0.00056 
2025-12-09 01:06:54.695382: train_loss -0.8645 
2025-12-09 01:06:54.695382: val_loss -0.8847 
2025-12-09 01:06:54.695382: Pseudo dice [0.9288, 0.9594, 0.9541] 
2025-12-09 01:06:54.707583: Epoch time: 138.2 s 
2025-12-09 01:06:55.337204:  
2025-12-09 01:06:55.337204: Epoch 960 
2025-12-09 01:06:55.337204: Current learning rate: 0.00055 
2025-12-09 01:09:13.858275: train_loss -0.8634 
2025-12-09 01:09:13.860277: val_loss -0.8915 
2025-12-09 01:09:13.862279: Pseudo dice [0.9342, 0.9598, 0.9548] 
2025-12-09 01:09:13.862279: Epoch time: 138.52 s 
2025-12-09 01:09:14.621254:  
2025-12-09 01:09:14.621254: Epoch 961 
2025-12-09 01:09:14.621254: Current learning rate: 0.00054 
2025-12-09 01:11:32.862940: train_loss -0.8607 
2025-12-09 01:11:32.862940: val_loss -0.8803 
2025-12-09 01:11:32.862940: Pseudo dice [0.9255, 0.9584, 0.9511] 
2025-12-09 01:11:32.878955: Epoch time: 138.24 s 
2025-12-09 01:11:33.512436:  
2025-12-09 01:11:33.512436: Epoch 962 
2025-12-09 01:11:33.512436: Current learning rate: 0.00053 
2025-12-09 01:13:51.594019: train_loss -0.8654 
2025-12-09 01:13:51.594019: val_loss -0.8851 
2025-12-09 01:13:51.609855: Pseudo dice [0.9314, 0.9564, 0.9477] 
2025-12-09 01:13:51.609855: Epoch time: 138.08 s 
2025-12-09 01:13:52.416860:  
2025-12-09 01:13:52.416860: Epoch 963 
2025-12-09 01:13:52.432760: Current learning rate: 0.00051 
2025-12-09 01:16:10.649755: train_loss -0.864 
2025-12-09 01:16:10.649755: val_loss -0.8841 
2025-12-09 01:16:10.665553: Pseudo dice [0.9272, 0.9602, 0.9503] 
2025-12-09 01:16:10.669557: Epoch time: 138.23 s 
2025-12-09 01:16:11.305384:  
2025-12-09 01:16:11.307389: Epoch 964 
2025-12-09 01:16:11.314831: Current learning rate: 0.0005 
2025-12-09 01:18:29.386487: train_loss -0.8616 
2025-12-09 01:18:29.388228: val_loss -0.8833 
2025-12-09 01:18:29.388228: Pseudo dice [0.93, 0.9581, 0.9526] 
2025-12-09 01:18:29.401474: Epoch time: 138.08 s 
2025-12-09 01:18:30.097550:  
2025-12-09 01:18:30.097550: Epoch 965 
2025-12-09 01:18:30.097550: Current learning rate: 0.00049 
2025-12-09 01:20:48.279490: train_loss -0.8656 
2025-12-09 01:20:48.279490: val_loss -0.883 
2025-12-09 01:20:48.293246: Pseudo dice [0.9264, 0.9606, 0.9478] 
2025-12-09 01:20:48.300995: Epoch time: 138.18 s 
2025-12-09 01:20:48.931604:  
2025-12-09 01:20:48.931604: Epoch 966 
2025-12-09 01:20:48.947270: Current learning rate: 0.00048 
2025-12-09 01:23:07.049186: train_loss -0.8659 
2025-12-09 01:23:07.049186: val_loss -0.8913 
2025-12-09 01:23:07.056933: Pseudo dice [0.9331, 0.9608, 0.9506] 
2025-12-09 01:23:07.064479: Epoch time: 138.12 s 
2025-12-09 01:23:07.802176:  
2025-12-09 01:23:07.802176: Epoch 967 
2025-12-09 01:23:07.802176: Current learning rate: 0.00046 
2025-12-09 01:25:25.862397: train_loss -0.8677 
2025-12-09 01:25:25.864398: val_loss -0.8843 
2025-12-09 01:25:25.870404: Pseudo dice [0.9261, 0.9565, 0.9521] 
2025-12-09 01:25:25.877412: Epoch time: 138.06 s 
2025-12-09 01:25:26.567099:  
2025-12-09 01:25:26.567099: Epoch 968 
2025-12-09 01:25:26.567099: Current learning rate: 0.00045 
2025-12-09 01:27:44.668184: train_loss -0.8645 
2025-12-09 01:27:44.670187: val_loss -0.8844 
2025-12-09 01:27:44.677935: Pseudo dice [0.9284, 0.9582, 0.9485] 
2025-12-09 01:27:44.682157: Epoch time: 138.11 s 
2025-12-09 01:27:45.532036:  
2025-12-09 01:27:45.532036: Epoch 969 
2025-12-09 01:27:45.532036: Current learning rate: 0.00044 
2025-12-09 01:30:03.694713: train_loss -0.8636 
2025-12-09 01:30:03.694713: val_loss -0.8784 
2025-12-09 01:30:03.694713: Pseudo dice [0.922, 0.9575, 0.9535] 
2025-12-09 01:30:03.710473: Epoch time: 138.18 s 
2025-12-09 01:30:04.392874:  
2025-12-09 01:30:04.392874: Epoch 970 
2025-12-09 01:30:04.408733: Current learning rate: 0.00043 
2025-12-09 01:32:22.729078: train_loss -0.8597 
2025-12-09 01:32:22.729078: val_loss -0.8875 
2025-12-09 01:32:22.739089: Pseudo dice [0.93, 0.9588, 0.955] 
2025-12-09 01:32:22.741091: Epoch time: 138.34 s 
2025-12-09 01:32:23.476565:  
2025-12-09 01:32:23.476565: Epoch 971 
2025-12-09 01:32:23.476565: Current learning rate: 0.00041 
2025-12-09 01:34:41.579323: train_loss -0.8634 
2025-12-09 01:34:41.579323: val_loss -0.8851 
2025-12-09 01:34:41.587331: Pseudo dice [0.929, 0.9595, 0.9517] 
2025-12-09 01:34:41.592813: Epoch time: 138.1 s 
2025-12-09 01:34:42.288915:  
2025-12-09 01:34:42.288915: Epoch 972 
2025-12-09 01:34:42.306998: Current learning rate: 0.0004 
2025-12-09 01:37:00.478932: train_loss -0.8634 
2025-12-09 01:37:00.478932: val_loss -0.8842 
2025-12-09 01:37:00.494721: Pseudo dice [0.9262, 0.9599, 0.9526] 
2025-12-09 01:37:00.494721: Epoch time: 138.19 s 
2025-12-09 01:37:01.207094:  
2025-12-09 01:37:01.207094: Epoch 973 
2025-12-09 01:37:01.223079: Current learning rate: 0.00039 
2025-12-09 01:39:19.627141: train_loss -0.8657 
2025-12-09 01:39:19.634888: val_loss -0.8892 
2025-12-09 01:39:19.640894: Pseudo dice [0.9302, 0.9607, 0.9543] 
2025-12-09 01:39:19.646900: Epoch time: 138.42 s 
2025-12-09 01:39:20.271695:  
2025-12-09 01:39:20.271695: Epoch 974 
2025-12-09 01:39:20.287609: Current learning rate: 0.00037 
2025-12-09 01:41:38.321416: train_loss -0.8645 
2025-12-09 01:41:38.321416: val_loss -0.8838 
2025-12-09 01:41:38.337166: Pseudo dice [0.9291, 0.9596, 0.9488] 
2025-12-09 01:41:38.337166: Epoch time: 138.05 s 
2025-12-09 01:41:39.129686:  
2025-12-09 01:41:39.145750: Epoch 975 
2025-12-09 01:41:39.145750: Current learning rate: 0.00036 
2025-12-09 01:43:57.420134: train_loss -0.8616 
2025-12-09 01:43:57.420134: val_loss -0.8872 
2025-12-09 01:43:57.435943: Pseudo dice [0.9289, 0.9576, 0.953] 
2025-12-09 01:43:57.440474: Epoch time: 138.29 s 
2025-12-09 01:43:58.150448:  
2025-12-09 01:43:58.150448: Epoch 976 
2025-12-09 01:43:58.166267: Current learning rate: 0.00035 
2025-12-09 01:46:16.406887: train_loss -0.8606 
2025-12-09 01:46:16.406887: val_loss -0.8971 
2025-12-09 01:46:16.422758: Pseudo dice [0.9366, 0.9638, 0.9549] 
2025-12-09 01:46:16.424760: Epoch time: 138.26 s 
2025-12-09 01:46:16.430976: Yayy! New best EMA pseudo Dice: 0.9468 
2025-12-09 01:46:17.390983:  
2025-12-09 01:46:17.390983: Epoch 977 
2025-12-09 01:46:17.406730: Current learning rate: 0.00034 
2025-12-09 01:48:35.605344: train_loss -0.8655 
2025-12-09 01:48:35.605344: val_loss -0.8892 
2025-12-09 01:48:35.613089: Pseudo dice [0.9327, 0.9629, 0.9482] 
2025-12-09 01:48:35.613089: Epoch time: 138.21 s 
2025-12-09 01:48:35.621944: Yayy! New best EMA pseudo Dice: 0.9469 
2025-12-09 01:48:36.623237:  
2025-12-09 01:48:36.623237: Epoch 978 
2025-12-09 01:48:36.639202: Current learning rate: 0.00032 
2025-12-09 01:50:54.869846: train_loss -0.8614 
2025-12-09 01:50:54.871848: val_loss -0.8886 
2025-12-09 01:50:54.879596: Pseudo dice [0.9313, 0.9583, 0.9514] 
2025-12-09 01:50:54.887605: Epoch time: 138.25 s 
2025-12-09 01:50:54.893351: Yayy! New best EMA pseudo Dice: 0.9469 
2025-12-09 01:50:55.823470:  
2025-12-09 01:50:55.823470: Epoch 979 
2025-12-09 01:50:55.841502: Current learning rate: 0.00031 
2025-12-09 01:53:14.038652: train_loss -0.8684 
2025-12-09 01:53:14.038652: val_loss -0.8924 
2025-12-09 01:53:14.042658: Pseudo dice [0.9344, 0.9618, 0.9537] 
2025-12-09 01:53:14.049202: Epoch time: 138.22 s 
2025-12-09 01:53:14.058419: Yayy! New best EMA pseudo Dice: 0.9472 
2025-12-09 01:53:15.230993:  
2025-12-09 01:53:15.230993: Epoch 980 
2025-12-09 01:53:15.230993: Current learning rate: 0.0003 
2025-12-09 01:55:33.594475: train_loss -0.8619 
2025-12-09 01:55:33.594475: val_loss -0.8923 
2025-12-09 01:55:33.612240: Pseudo dice [0.9336, 0.9598, 0.9545] 
2025-12-09 01:55:33.612240: Epoch time: 138.36 s 
2025-12-09 01:55:33.626110: Yayy! New best EMA pseudo Dice: 0.9474 
2025-12-09 01:55:34.547577:  
2025-12-09 01:55:34.547577: Epoch 981 
2025-12-09 01:55:34.547577: Current learning rate: 0.00028 
2025-12-09 01:57:52.868595: train_loss -0.8649 
2025-12-09 01:57:52.868595: val_loss -0.8866 
2025-12-09 01:57:52.884368: Pseudo dice [0.928, 0.9586, 0.9529] 
2025-12-09 01:57:52.884368: Epoch time: 138.32 s 
2025-12-09 01:57:53.567270:  
2025-12-09 01:57:53.567270: Epoch 982 
2025-12-09 01:57:53.567270: Current learning rate: 0.00027 
2025-12-09 02:00:11.860437: train_loss -0.8639 
2025-12-09 02:00:11.862439: val_loss -0.8811 
2025-12-09 02:00:11.867587: Pseudo dice [0.9248, 0.9565, 0.9526] 
2025-12-09 02:00:11.872750: Epoch time: 138.29 s 
2025-12-09 02:00:12.609561:  
2025-12-09 02:00:12.609561: Epoch 983 
2025-12-09 02:00:12.625496: Current learning rate: 0.00026 
2025-12-09 02:02:30.793948: train_loss -0.8661 
2025-12-09 02:02:30.793948: val_loss -0.885 
2025-12-09 02:02:30.793948: Pseudo dice [0.9284, 0.962, 0.9508] 
2025-12-09 02:02:30.809686: Epoch time: 138.18 s 
2025-12-09 02:02:31.475857:  
2025-12-09 02:02:31.475857: Epoch 984 
2025-12-09 02:02:31.491630: Current learning rate: 0.00024 
2025-12-09 02:04:49.883636: train_loss -0.8562 
2025-12-09 02:04:49.883636: val_loss -0.8827 
2025-12-09 02:04:49.899409: Pseudo dice [0.9242, 0.9534, 0.9555] 
2025-12-09 02:04:49.899409: Epoch time: 138.41 s 
2025-12-09 02:04:50.616789:  
2025-12-09 02:04:50.616789: Epoch 985 
2025-12-09 02:04:50.616789: Current learning rate: 0.00023 
2025-12-09 02:07:08.865412: train_loss -0.866 
2025-12-09 02:07:08.865412: val_loss -0.8907 
2025-12-09 02:07:08.873179: Pseudo dice [0.9312, 0.9588, 0.9569] 
2025-12-09 02:07:08.881446: Epoch time: 138.25 s 
2025-12-09 02:07:09.567440:  
2025-12-09 02:07:09.567440: Epoch 986 
2025-12-09 02:07:09.585062: Current learning rate: 0.00021 
2025-12-09 02:09:27.925254: train_loss -0.8646 
2025-12-09 02:09:27.925254: val_loss -0.8779 
2025-12-09 02:09:27.927256: Pseudo dice [0.923, 0.9559, 0.9507] 
2025-12-09 02:09:27.935135: Epoch time: 138.36 s 
2025-12-09 02:09:28.844705:  
2025-12-09 02:09:28.844705: Epoch 987 
2025-12-09 02:09:28.860594: Current learning rate: 0.0002 
2025-12-09 02:11:47.059606: train_loss -0.8686 
2025-12-09 02:11:47.059606: val_loss -0.8871 
2025-12-09 02:11:47.065350: Pseudo dice [0.9316, 0.9597, 0.9486] 
2025-12-09 02:11:47.069172: Epoch time: 138.21 s 
2025-12-09 02:11:47.694001:  
2025-12-09 02:11:47.694001: Epoch 988 
2025-12-09 02:11:47.709911: Current learning rate: 0.00019 
2025-12-09 02:14:05.961917: train_loss -0.8617 
2025-12-09 02:14:05.961917: val_loss -0.8821 
2025-12-09 02:14:05.977945: Pseudo dice [0.9267, 0.959, 0.9509] 
2025-12-09 02:14:05.977945: Epoch time: 138.27 s 
2025-12-09 02:14:06.770595:  
2025-12-09 02:14:06.770595: Epoch 989 
2025-12-09 02:14:06.770595: Current learning rate: 0.00017 
2025-12-09 02:16:24.882771: train_loss -0.8636 
2025-12-09 02:16:24.882771: val_loss -0.883 
2025-12-09 02:16:24.898553: Pseudo dice [0.9285, 0.9587, 0.9478] 
2025-12-09 02:16:24.902525: Epoch time: 138.11 s 
2025-12-09 02:16:25.545879:  
2025-12-09 02:16:25.545879: Epoch 990 
2025-12-09 02:16:25.545879: Current learning rate: 0.00016 
2025-12-09 02:18:43.854167: train_loss -0.8622 
2025-12-09 02:18:43.854167: val_loss -0.8911 
2025-12-09 02:18:43.869926: Pseudo dice [0.934, 0.9606, 0.9545] 
2025-12-09 02:18:43.869926: Epoch time: 138.31 s 
2025-12-09 02:18:44.595631:  
2025-12-09 02:18:44.595631: Epoch 991 
2025-12-09 02:18:44.598637: Current learning rate: 0.00014 
2025-12-09 02:21:02.719771: train_loss -0.8668 
2025-12-09 02:21:02.719771: val_loss -0.8909 
2025-12-09 02:21:02.719771: Pseudo dice [0.9321, 0.9624, 0.9555] 
2025-12-09 02:21:02.735515: Epoch time: 138.13 s 
2025-12-09 02:21:03.467211:  
2025-12-09 02:21:03.467211: Epoch 992 
2025-12-09 02:21:03.481219: Current learning rate: 0.00013 
2025-12-09 02:23:21.878032: train_loss -0.8651 
2025-12-09 02:23:21.878032: val_loss -0.8922 
2025-12-09 02:23:21.889797: Pseudo dice [0.9334, 0.9602, 0.9488] 
2025-12-09 02:23:21.898426: Epoch time: 138.41 s 
2025-12-09 02:23:22.697762:  
2025-12-09 02:23:22.697762: Epoch 993 
2025-12-09 02:23:22.697762: Current learning rate: 0.00011 
2025-12-09 02:25:40.839727: train_loss -0.8682 
2025-12-09 02:25:40.839727: val_loss -0.8969 
2025-12-09 02:25:40.855485: Pseudo dice [0.9369, 0.9623, 0.9564] 
2025-12-09 02:25:40.855485: Epoch time: 138.14 s 
2025-12-09 02:25:40.871516: Yayy! New best EMA pseudo Dice: 0.9476 
2025-12-09 02:25:41.760688:  
2025-12-09 02:25:41.760688: Epoch 994 
2025-12-09 02:25:41.777892: Current learning rate: 0.0001 
2025-12-09 02:28:00.041387: train_loss -0.8618 
2025-12-09 02:28:00.041387: val_loss -0.8913 
2025-12-09 02:28:00.041387: Pseudo dice [0.9336, 0.9615, 0.954] 
2025-12-09 02:28:00.055396: Epoch time: 138.28 s 
2025-12-09 02:28:00.055396: Yayy! New best EMA pseudo Dice: 0.9478 
2025-12-09 02:28:01.196252:  
2025-12-09 02:28:01.196252: Epoch 995 
2025-12-09 02:28:01.204263: Current learning rate: 8e-05 
2025-12-09 02:30:19.399535: train_loss -0.8672 
2025-12-09 02:30:19.399535: val_loss -0.8823 
2025-12-09 02:30:19.407468: Pseudo dice [0.9281, 0.9583, 0.9505] 
2025-12-09 02:30:19.407468: Epoch time: 138.21 s 
2025-12-09 02:30:20.145894:  
2025-12-09 02:30:20.145894: Epoch 996 
2025-12-09 02:30:20.152395: Current learning rate: 7e-05 
2025-12-09 02:32:38.283765: train_loss -0.8677 
2025-12-09 02:32:38.283765: val_loss -0.8786 
2025-12-09 02:32:38.291015: Pseudo dice [0.9223, 0.9523, 0.9543] 
2025-12-09 02:32:38.298761: Epoch time: 138.14 s 
2025-12-09 02:32:39.008296:  
2025-12-09 02:32:39.008296: Epoch 997 
2025-12-09 02:32:39.008296: Current learning rate: 5e-05 
2025-12-09 02:34:57.088151: train_loss -0.8654 
2025-12-09 02:34:57.088151: val_loss -0.8792 
2025-12-09 02:34:57.096159: Pseudo dice [0.9234, 0.9565, 0.9514] 
2025-12-09 02:34:57.103905: Epoch time: 138.08 s 
2025-12-09 02:34:57.893020:  
2025-12-09 02:34:57.893020: Epoch 998 
2025-12-09 02:34:57.909064: Current learning rate: 4e-05 
2025-12-09 02:37:16.282831: train_loss -0.8659 
2025-12-09 02:37:16.282831: val_loss -0.8798 
2025-12-09 02:37:16.293190: Pseudo dice [0.925, 0.9536, 0.9517] 
2025-12-09 02:37:16.298934: Epoch time: 138.39 s 
2025-12-09 02:37:17.027145:  
2025-12-09 02:37:17.027145: Epoch 999 
2025-12-09 02:37:17.027145: Current learning rate: 2e-05 
2025-12-09 02:39:35.339341: train_loss -0.8659 
2025-12-09 02:39:35.341343: val_loss -0.8836 
2025-12-09 02:39:35.347397: Pseudo dice [0.9251, 0.958, 0.9542] 
2025-12-09 02:39:35.347397: Epoch time: 138.31 s 
2025-12-09 02:39:36.421947: Training done. 
2025-12-09 02:39:36.707715: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-09 02:39:36.713725: The split file contains 5 splits. 
2025-12-09 02:39:36.752995: Desired fold for training: 0 
2025-12-09 02:39:36.786520: This split has 400 training and 100 validation cases. 
2025-12-09 02:39:36.804286: predicting OAS30014_MR_d0196_9 
2025-12-09 02:39:36.958697: OAS30014_MR_d0196_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:39:58.746167: predicting OAS30017_MR_d0054_1 
2025-12-09 02:39:58.746167: OAS30017_MR_d0054_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:40:16.451824: predicting OAS30017_MR_d0054_10 
2025-12-09 02:40:16.467570: OAS30017_MR_d0054_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:40:34.147182: predicting OAS30017_MR_d0054_9 
2025-12-09 02:40:34.169172: OAS30017_MR_d0054_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:40:51.941931: predicting OAS30025_MR_d0210_7 
2025-12-09 02:40:51.952480: OAS30025_MR_d0210_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:41:09.690891: predicting OAS30025_MR_d0210_8 
2025-12-09 02:41:09.710557: OAS30025_MR_d0210_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:41:27.399452: predicting OAS30036_MR_d0059_3 
2025-12-09 02:41:27.423056: OAS30036_MR_d0059_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:41:45.127167: predicting OAS30039_MR_d1203_1 
2025-12-09 02:41:45.142930: OAS30039_MR_d1203_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:42:02.818247: predicting OAS30039_MR_d1203_10 
2025-12-09 02:42:02.840054: OAS30039_MR_d1203_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:42:20.569011: predicting OAS30039_MR_d1203_8 
2025-12-09 02:42:20.578493: OAS30039_MR_d1203_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:42:38.287601: predicting OAS30052_MR_d0693_2 
2025-12-09 02:42:38.299641: OAS30052_MR_d0693_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:42:55.996156: predicting OAS30052_MR_d0693_5 
2025-12-09 02:42:56.016531: OAS30052_MR_d0693_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:43:13.673009: predicting OAS30052_MR_d0693_6 
2025-12-09 02:43:13.695706: OAS30052_MR_d0693_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:43:31.414482: predicting OAS30078_MR_d0210_6 
2025-12-09 02:43:31.436475: OAS30078_MR_d0210_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:43:49.117414: predicting OAS30078_MR_d0210_8 
2025-12-09 02:43:49.127428: OAS30078_MR_d0210_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:44:06.836894: predicting OAS30083_MR_d0465_1 
2025-12-09 02:44:06.848567: OAS30083_MR_d0465_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:44:24.511685: predicting OAS30087_MR_d0260_5 
2025-12-09 02:44:24.523513: OAS30087_MR_d0260_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:44:42.184021: predicting OAS30099_MR_d0032_1 
2025-12-09 02:44:42.193348: OAS30099_MR_d0032_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:44:59.885038: predicting OAS30099_MR_d0032_7 
2025-12-09 02:44:59.905079: OAS30099_MR_d0032_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:45:17.593966: predicting OAS30099_MR_d0032_9 
2025-12-09 02:45:17.609995: OAS30099_MR_d0032_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:45:35.275320: predicting OAS30102_MR_d0024_1 
2025-12-09 02:45:35.284915: OAS30102_MR_d0024_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:45:52.958901: predicting OAS30102_MR_d0024_10 
2025-12-09 02:45:52.968498: OAS30102_MR_d0024_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:46:10.679825: predicting OAS30102_MR_d0024_3 
2025-12-09 02:46:10.690679: OAS30102_MR_d0024_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:46:28.415468: predicting OAS30104_MR_d0328_1 
2025-12-09 02:46:28.425479: OAS30104_MR_d0328_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:46:46.099731: predicting OAS30104_MR_d0328_5 
2025-12-09 02:46:46.110172: OAS30104_MR_d0328_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:47:03.823339: predicting OAS30107_MR_d0387_3 
2025-12-09 02:47:03.832535: OAS30107_MR_d0387_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:47:21.562269: predicting OAS30125_MR_d0201_1 
2025-12-09 02:47:21.572635: OAS30125_MR_d0201_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:47:39.250517: predicting OAS30125_MR_d0201_4 
2025-12-09 02:47:39.259403: OAS30125_MR_d0201_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:47:56.933176: predicting OAS30125_MR_d0201_5 
2025-12-09 02:47:56.952409: OAS30125_MR_d0201_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:48:14.668004: predicting OAS30127_MR_d0098_4 
2025-12-09 02:48:14.679119: OAS30127_MR_d0098_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:48:32.346652: predicting OAS30127_MR_d0098_8 
2025-12-09 02:48:32.357560: OAS30127_MR_d0098_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:48:50.073815: predicting OAS30134_MR_d0080_1 
2025-12-09 02:48:50.083683: OAS30134_MR_d0080_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:49:07.801308: predicting OAS30134_MR_d0080_4 
2025-12-09 02:49:07.814556: OAS30134_MR_d0080_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:49:25.501059: predicting OAS30134_MR_d0080_9 
2025-12-09 02:49:25.516108: OAS30134_MR_d0080_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:49:43.227242: predicting OAS30140_MR_d0172_3 
2025-12-09 02:49:43.239622: OAS30140_MR_d0172_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:50:00.957093: predicting OAS30147_MR_d0048_5 
2025-12-09 02:50:00.978920: OAS30147_MR_d0048_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:50:18.674383: predicting OAS30165_MR_d1763_1 
2025-12-09 02:50:18.692338: OAS30165_MR_d1763_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:50:36.349209: predicting OAS30165_MR_d1763_3 
2025-12-09 02:50:36.373179: OAS30165_MR_d1763_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:50:54.071485: predicting OAS30165_MR_d1763_4 
2025-12-09 02:50:54.083168: OAS30165_MR_d1763_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:51:11.778953: predicting OAS30165_MR_d1763_8 
2025-12-09 02:51:11.796936: OAS30165_MR_d1763_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:51:29.480866: predicting OAS30167_MR_d0111_10 
2025-12-09 02:51:29.496012: OAS30167_MR_d0111_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:51:47.201452: predicting OAS30167_MR_d0111_6 
2025-12-09 02:51:47.223147: OAS30167_MR_d0111_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:52:04.960795: predicting OAS30176_MR_d0000_3 
2025-12-09 02:52:04.971182: OAS30176_MR_d0000_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:52:22.647094: predicting OAS30195_MR_d1596_6 
2025-12-09 02:52:22.659155: OAS30195_MR_d1596_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:52:40.319597: predicting OAS30226_MR_d0183_1 
2025-12-09 02:52:40.342119: OAS30226_MR_d0183_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:52:58.008246: predicting OAS30226_MR_d0183_10 
2025-12-09 02:52:58.024188: OAS30226_MR_d0183_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:53:15.725749: predicting OAS30238_MR_d0037_1 
2025-12-09 02:53:15.738021: OAS30238_MR_d0037_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:53:33.424500: predicting OAS30238_MR_d0037_10 
2025-12-09 02:53:33.436773: OAS30238_MR_d0037_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:53:51.119259: predicting OAS30238_MR_d0037_4 
2025-12-09 02:53:51.144859: OAS30238_MR_d0037_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:54:08.852646: predicting OAS30250_MR_d0389_5 
2025-12-09 02:54:08.875051: OAS30250_MR_d0389_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:54:26.566837: predicting OAS30274_MR_d3332_10 
2025-12-09 02:54:26.586530: OAS30274_MR_d3332_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:54:44.272654: predicting OAS30274_MR_d3332_2 
2025-12-09 02:54:44.296249: OAS30274_MR_d3332_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:55:01.984726: predicting OAS30274_MR_d3332_4 
2025-12-09 02:55:01.994468: OAS30274_MR_d3332_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:55:19.661209: predicting OAS30292_MR_d0165_10 
2025-12-09 02:55:19.677269: OAS30292_MR_d0165_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:55:37.352799: predicting OAS30292_MR_d0165_3 
2025-12-09 02:55:37.368347: OAS30292_MR_d0165_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:55:55.033191: predicting OAS30292_MR_d0165_9 
2025-12-09 02:55:55.042764: OAS30292_MR_d0165_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:56:12.708555: predicting OAS30297_MR_d1712_2 
2025-12-09 02:56:12.717768: OAS30297_MR_d1712_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:56:30.434258: predicting OAS30297_MR_d1712_5 
2025-12-09 02:56:30.443326: OAS30297_MR_d1712_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:56:48.114841: predicting OAS30297_MR_d1712_8 
2025-12-09 02:56:48.124856: OAS30297_MR_d1712_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:57:05.801759: predicting OAS30297_MR_d1712_9 
2025-12-09 02:57:05.816847: OAS30297_MR_d1712_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:57:23.525357: predicting OAS30300_MR_d0100_3 
2025-12-09 02:57:23.537528: OAS30300_MR_d0100_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:57:41.264589: predicting OAS30300_MR_d0100_4 
2025-12-09 02:57:41.274297: OAS30300_MR_d0100_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:57:58.972664: predicting OAS30302_MR_d0262_1 
2025-12-09 02:57:58.980417: OAS30302_MR_d0262_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:58:16.658774: predicting OAS30302_MR_d0262_3 
2025-12-09 02:58:16.669575: OAS30302_MR_d0262_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:58:34.324687: predicting OAS30306_MR_d0028_2 
2025-12-09 02:58:34.342397: OAS30306_MR_d0028_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:58:52.040785: predicting OAS30321_MR_d3003_2 
2025-12-09 02:58:52.050913: OAS30321_MR_d3003_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:59:09.753227: predicting OAS30325_MR_d0032_2 
2025-12-09 02:59:09.774864: OAS30325_MR_d0032_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:59:27.504108: predicting OAS30343_MR_d4178_2 
2025-12-09 02:59:27.523606: OAS30343_MR_d4178_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 02:59:45.213475: predicting OAS30343_MR_d4178_6 
2025-12-09 02:59:45.233810: OAS30343_MR_d4178_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:00:02.922451: predicting OAS30349_MR_d0699_10 
2025-12-09 03:00:02.937356: OAS30349_MR_d0699_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:00:20.635502: predicting OAS30349_MR_d0699_2 
2025-12-09 03:00:20.657226: OAS30349_MR_d0699_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:00:38.363477: predicting OAS30349_MR_d0699_3 
2025-12-09 03:00:38.374452: OAS30349_MR_d0699_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:00:56.074534: predicting OAS30349_MR_d0699_5 
2025-12-09 03:00:56.080540: OAS30349_MR_d0699_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:01:13.807286: predicting OAS30349_MR_d0699_7 
2025-12-09 03:01:13.821149: OAS30349_MR_d0699_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:01:31.540524: predicting OAS30350_MR_d0018_2 
2025-12-09 03:01:31.550373: OAS30350_MR_d0018_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:01:49.260570: predicting OAS30352_MR_d0099_10 
2025-12-09 03:01:49.280241: OAS30352_MR_d0099_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:02:06.984650: predicting OAS30354_MR_d0056_10 
2025-12-09 03:02:07.004657: OAS30354_MR_d0056_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:02:24.729280: predicting OAS30354_MR_d0056_3 
2025-12-09 03:02:24.734508: OAS30354_MR_d0056_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:02:42.397912: predicting OAS30354_MR_d0056_5 
2025-12-09 03:02:42.408187: OAS30354_MR_d0056_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:03:00.097838: predicting OAS30355_MR_d0048_1 
2025-12-09 03:03:00.107090: OAS30355_MR_d0048_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:03:17.825193: predicting OAS30355_MR_d0048_7 
2025-12-09 03:03:17.835208: OAS30355_MR_d0048_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:03:35.542667: predicting OAS30355_MR_d0048_8 
2025-12-09 03:03:35.554377: OAS30355_MR_d0048_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:03:53.239689: predicting OAS30361_MR_d1457_1 
2025-12-09 03:03:53.261682: OAS30361_MR_d1457_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:04:10.946823: predicting OAS30361_MR_d1457_4 
2025-12-09 03:04:10.966559: OAS30361_MR_d1457_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:04:28.656093: predicting OAS30361_MR_d1457_8 
2025-12-09 03:04:28.670427: OAS30361_MR_d1457_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:04:46.365697: predicting OAS30369_MR_d4058_1 
2025-12-09 03:04:46.376242: OAS30369_MR_d4058_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:05:04.079599: predicting OAS30371_MR_d0338_6 
2025-12-09 03:05:04.087613: OAS30371_MR_d0338_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:05:21.779699: predicting OAS30373_MR_d1211_10 
2025-12-09 03:05:21.795347: OAS30373_MR_d1211_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:05:39.535772: predicting OAS30373_MR_d1211_2 
2025-12-09 03:05:39.548678: OAS30373_MR_d1211_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:05:57.254274: predicting OAS30373_MR_d1211_9 
2025-12-09 03:05:57.278089: OAS30373_MR_d1211_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:06:14.990406: predicting OAS30379_MR_d2106_1 
2025-12-09 03:06:15.008123: OAS30379_MR_d2106_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:06:32.709626: predicting OAS30379_MR_d2106_10 
2025-12-09 03:06:32.727318: OAS30379_MR_d2106_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:06:50.425219: predicting OAS30379_MR_d2106_4 
2025-12-09 03:06:50.440092: OAS30379_MR_d2106_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:07:08.142959: predicting OAS30379_MR_d2106_6 
2025-12-09 03:07:08.158762: OAS30379_MR_d2106_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:07:25.858183: predicting OAS30379_MR_d2106_9 
2025-12-09 03:07:25.871461: OAS30379_MR_d2106_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:07:43.561249: predicting OAS30380_MR_d3446_4 
2025-12-09 03:07:43.570802: OAS30380_MR_d3446_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:08:01.243198: predicting OAS30383_MR_d0134_1 
2025-12-09 03:08:01.260804: OAS30383_MR_d0134_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:08:18.927143: predicting OAS30383_MR_d0134_10 
2025-12-09 03:08:18.939142: OAS30383_MR_d0134_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:08:36.650287: predicting OAS30388_MR_d0073_6 
2025-12-09 03:08:36.662050: OAS30388_MR_d0073_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:08:54.386204: predicting OAS30388_MR_d0073_7 
2025-12-09 03:08:54.399407: OAS30388_MR_d0073_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-09 03:09:37.678043: Validation complete 
2025-12-09 03:09:37.678043: Mean Validation Dice:  0.9385947886337376 
