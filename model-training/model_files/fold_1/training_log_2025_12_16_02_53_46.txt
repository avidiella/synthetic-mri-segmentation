
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-12-16 02:53:46.199408: do_dummy_2d_data_aug: False 
2025-12-16 02:53:46.199408: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-16 02:53:46.199408: The split file contains 5 splits. 
2025-12-16 02:53:46.199408: Desired fold for training: 1 
2025-12-16 02:53:46.199408: This split has 400 training and 100 validation cases. 
2025-12-16 02:54:18.777400: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [202, 202, 202], 'spacing': [1.2667700813876164, 1.2667700813876164, 1.2667700813876164], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset500_MRI', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [256, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0000001192092896, 'mean': 0.422696590423584, 'median': 0.4194243550300598, 'min': 0.0027002037968486547, 'percentile_00_5': 0.05628390982747078, 'percentile_99_5': 0.8565635681152344, 'std': 0.19347868859767914}}} 
 
2025-12-16 02:54:18.793147: unpacking dataset... 
2025-12-16 02:54:19.337305: unpacking done... 
2025-12-16 02:54:19.343313: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-12-16 02:54:19.378188:  
2025-12-16 02:54:19.378188: Epoch 0 
2025-12-16 02:54:19.378188: Current learning rate: 0.01 
2025-12-16 02:56:46.864900: train_loss 0.1324 
2025-12-16 02:56:46.864900: val_loss 0.0009 
2025-12-16 02:56:46.866903: Pseudo dice [0.521, 0.5617, 0.2047] 
2025-12-16 02:56:46.866903: Epoch time: 147.5 s 
2025-12-16 02:56:46.866903: Yayy! New best EMA pseudo Dice: 0.4291 
2025-12-16 02:56:47.881575:  
2025-12-16 02:56:47.881575: Epoch 1 
2025-12-16 02:56:47.881575: Current learning rate: 0.00999 
2025-12-16 02:59:05.779346: train_loss -0.0663 
2025-12-16 02:59:05.781348: val_loss -0.1588 
2025-12-16 02:59:05.781348: Pseudo dice [0.5946, 0.6073, 0.3849] 
2025-12-16 02:59:05.783351: Epoch time: 137.9 s 
2025-12-16 02:59:05.783351: Yayy! New best EMA pseudo Dice: 0.4391 
2025-12-16 02:59:06.818069:  
2025-12-16 02:59:06.818069: Epoch 2 
2025-12-16 02:59:06.818069: Current learning rate: 0.00998 
2025-12-16 03:01:24.552033: train_loss -0.1533 
2025-12-16 03:01:24.552033: val_loss -0.2177 
2025-12-16 03:01:24.552033: Pseudo dice [0.6011, 0.632, 0.4591] 
2025-12-16 03:01:24.552033: Epoch time: 137.74 s 
2025-12-16 03:01:24.552033: Yayy! New best EMA pseudo Dice: 0.4516 
2025-12-16 03:01:25.494250:  
2025-12-16 03:01:25.494250: Epoch 3 
2025-12-16 03:01:25.494250: Current learning rate: 0.00997 
2025-12-16 03:03:43.397291: train_loss -0.2238 
2025-12-16 03:03:43.397291: val_loss -0.2634 
2025-12-16 03:03:43.399293: Pseudo dice [0.6319, 0.6585, 0.5158] 
2025-12-16 03:03:43.399293: Epoch time: 137.91 s 
2025-12-16 03:03:43.399293: Yayy! New best EMA pseudo Dice: 0.4667 
2025-12-16 03:03:44.470751:  
2025-12-16 03:03:44.470751: Epoch 4 
2025-12-16 03:03:44.470751: Current learning rate: 0.00996 
2025-12-16 03:06:02.161813: train_loss -0.2643 
2025-12-16 03:06:02.161813: val_loss -0.3039 
2025-12-16 03:06:02.161813: Pseudo dice [0.6369, 0.7034, 0.5541] 
2025-12-16 03:06:02.161813: Epoch time: 137.69 s 
2025-12-16 03:06:02.161813: Yayy! New best EMA pseudo Dice: 0.4831 
2025-12-16 03:06:03.091055:  
2025-12-16 03:06:03.091055: Epoch 5 
2025-12-16 03:06:03.091055: Current learning rate: 0.00995 
2025-12-16 03:08:20.935762: train_loss -0.3389 
2025-12-16 03:08:20.935762: val_loss -0.3868 
2025-12-16 03:08:20.935762: Pseudo dice [0.6862, 0.7456, 0.593] 
2025-12-16 03:08:20.935762: Epoch time: 137.85 s 
2025-12-16 03:08:20.935762: Yayy! New best EMA pseudo Dice: 0.5023 
2025-12-16 03:08:21.812753:  
2025-12-16 03:08:21.812753: Epoch 6 
2025-12-16 03:08:21.812753: Current learning rate: 0.00995 
2025-12-16 03:10:40.415144: train_loss -0.3965 
2025-12-16 03:10:40.417147: val_loss -0.3925 
2025-12-16 03:10:40.419150: Pseudo dice [0.6982, 0.7601, 0.6057] 
2025-12-16 03:10:40.419150: Epoch time: 138.6 s 
2025-12-16 03:10:40.419150: Yayy! New best EMA pseudo Dice: 0.5209 
2025-12-16 03:10:41.485706:  
2025-12-16 03:10:41.485706: Epoch 7 
2025-12-16 03:10:41.485706: Current learning rate: 0.00994 
2025-12-16 03:12:59.310319: train_loss -0.4342 
2025-12-16 03:12:59.325987: val_loss -0.4591 
2025-12-16 03:12:59.327849: Pseudo dice [0.7297, 0.7986, 0.6494] 
2025-12-16 03:12:59.327849: Epoch time: 137.83 s 
2025-12-16 03:12:59.327849: Yayy! New best EMA pseudo Dice: 0.5414 
2025-12-16 03:13:00.398220:  
2025-12-16 03:13:00.398220: Epoch 8 
2025-12-16 03:13:00.398220: Current learning rate: 0.00993 
2025-12-16 03:15:18.300085: train_loss -0.4829 
2025-12-16 03:15:18.300085: val_loss -0.5115 
2025-12-16 03:15:18.300085: Pseudo dice [0.7729, 0.8152, 0.6881] 
2025-12-16 03:15:18.300085: Epoch time: 137.9 s 
2025-12-16 03:15:18.315936: Yayy! New best EMA pseudo Dice: 0.5631 
2025-12-16 03:15:19.223984:  
2025-12-16 03:15:19.223984: Epoch 9 
2025-12-16 03:15:19.223984: Current learning rate: 0.00992 
2025-12-16 03:17:36.990010: train_loss -0.5154 
2025-12-16 03:17:36.990010: val_loss -0.5261 
2025-12-16 03:17:36.991750: Pseudo dice [0.7709, 0.8353, 0.7021] 
2025-12-16 03:17:36.991750: Epoch time: 137.77 s 
2025-12-16 03:17:36.991750: Yayy! New best EMA pseudo Dice: 0.5838 
2025-12-16 03:17:38.045633:  
2025-12-16 03:17:38.045633: Epoch 10 
2025-12-16 03:17:38.049297: Current learning rate: 0.00991 
2025-12-16 03:19:55.929363: train_loss -0.5444 
2025-12-16 03:19:55.929363: val_loss -0.5362 
2025-12-16 03:19:55.940712: Pseudo dice [0.7612, 0.8415, 0.6963] 
2025-12-16 03:19:55.940712: Epoch time: 137.88 s 
2025-12-16 03:19:55.940712: Yayy! New best EMA pseudo Dice: 0.602 
2025-12-16 03:19:56.835324:  
2025-12-16 03:19:56.837326: Epoch 11 
2025-12-16 03:19:56.837326: Current learning rate: 0.0099 
2025-12-16 03:22:14.797796: train_loss -0.5535 
2025-12-16 03:22:14.797796: val_loss -0.5881 
2025-12-16 03:22:14.797796: Pseudo dice [0.8059, 0.8606, 0.7283] 
2025-12-16 03:22:14.802252: Epoch time: 137.96 s 
2025-12-16 03:22:14.802252: Yayy! New best EMA pseudo Dice: 0.6216 
2025-12-16 03:22:15.705709:  
2025-12-16 03:22:15.707450: Epoch 12 
2025-12-16 03:22:15.707450: Current learning rate: 0.00989 
2025-12-16 03:24:33.587930: train_loss -0.581 
2025-12-16 03:24:33.587930: val_loss -0.5923 
2025-12-16 03:24:33.587930: Pseudo dice [0.8074, 0.8679, 0.7414] 
2025-12-16 03:24:33.598868: Epoch time: 137.88 s 
2025-12-16 03:24:33.598868: Yayy! New best EMA pseudo Dice: 0.64 
2025-12-16 03:24:34.690760:  
2025-12-16 03:24:34.690760: Epoch 13 
2025-12-16 03:24:34.690760: Current learning rate: 0.00988 
2025-12-16 03:26:52.416308: train_loss -0.5643 
2025-12-16 03:26:52.416308: val_loss -0.5939 
2025-12-16 03:26:52.416308: Pseudo dice [0.8027, 0.8618, 0.7472] 
2025-12-16 03:26:52.416308: Epoch time: 137.73 s 
2025-12-16 03:26:52.425809: Yayy! New best EMA pseudo Dice: 0.6564 
2025-12-16 03:26:53.500653:  
2025-12-16 03:26:53.500653: Epoch 14 
2025-12-16 03:26:53.500653: Current learning rate: 0.00987 
2025-12-16 03:29:11.491453: train_loss -0.5793 
2025-12-16 03:29:11.493455: val_loss -0.6072 
2025-12-16 03:29:11.493455: Pseudo dice [0.8182, 0.8768, 0.7396] 
2025-12-16 03:29:11.493455: Epoch time: 137.99 s 
2025-12-16 03:29:11.493455: Yayy! New best EMA pseudo Dice: 0.6719 
2025-12-16 03:29:12.411987:  
2025-12-16 03:29:12.411987: Epoch 15 
2025-12-16 03:29:12.411987: Current learning rate: 0.00986 
2025-12-16 03:31:30.202300: train_loss -0.6047 
2025-12-16 03:31:30.202300: val_loss -0.6177 
2025-12-16 03:31:30.204302: Pseudo dice [0.8045, 0.858, 0.7974] 
2025-12-16 03:31:30.204302: Epoch time: 137.79 s 
2025-12-16 03:31:30.206304: Yayy! New best EMA pseudo Dice: 0.6867 
2025-12-16 03:31:31.270834:  
2025-12-16 03:31:31.270834: Epoch 16 
2025-12-16 03:31:31.270834: Current learning rate: 0.00986 
2025-12-16 03:33:49.123510: train_loss -0.6234 
2025-12-16 03:33:49.123510: val_loss -0.6317 
2025-12-16 03:33:49.123510: Pseudo dice [0.8177, 0.8732, 0.7781] 
2025-12-16 03:33:49.123510: Epoch time: 137.85 s 
2025-12-16 03:33:49.123510: Yayy! New best EMA pseudo Dice: 0.7004 
2025-12-16 03:33:50.055535:  
2025-12-16 03:33:50.055535: Epoch 17 
2025-12-16 03:33:50.055535: Current learning rate: 0.00985 
2025-12-16 03:36:07.962632: train_loss -0.6334 
2025-12-16 03:36:07.964634: val_loss -0.6217 
2025-12-16 03:36:07.964634: Pseudo dice [0.8075, 0.8651, 0.7991] 
2025-12-16 03:36:07.966637: Epoch time: 137.91 s 
2025-12-16 03:36:07.966637: Yayy! New best EMA pseudo Dice: 0.7127 
2025-12-16 03:36:08.889738:  
2025-12-16 03:36:08.891740: Epoch 18 
2025-12-16 03:36:08.891740: Current learning rate: 0.00984 
2025-12-16 03:38:26.814190: train_loss -0.6479 
2025-12-16 03:38:26.814190: val_loss -0.6543 
2025-12-16 03:38:26.816193: Pseudo dice [0.8334, 0.8905, 0.7991] 
2025-12-16 03:38:26.816193: Epoch time: 137.92 s 
2025-12-16 03:38:26.818195: Yayy! New best EMA pseudo Dice: 0.7255 
2025-12-16 03:38:28.006310:  
2025-12-16 03:38:28.006310: Epoch 19 
2025-12-16 03:38:28.019678: Current learning rate: 0.00983 
2025-12-16 03:40:45.784899: train_loss -0.6506 
2025-12-16 03:40:45.784899: val_loss -0.6687 
2025-12-16 03:40:45.784899: Pseudo dice [0.8387, 0.8889, 0.8048] 
2025-12-16 03:40:45.784899: Epoch time: 137.78 s 
2025-12-16 03:40:45.784899: Yayy! New best EMA pseudo Dice: 0.7374 
2025-12-16 03:40:46.715650:  
2025-12-16 03:40:46.715650: Epoch 20 
2025-12-16 03:40:46.715650: Current learning rate: 0.00982 
2025-12-16 03:43:04.752820: train_loss -0.6656 
2025-12-16 03:43:04.752820: val_loss -0.6827 
2025-12-16 03:43:04.752820: Pseudo dice [0.8536, 0.8966, 0.8117] 
2025-12-16 03:43:04.752820: Epoch time: 138.04 s 
2025-12-16 03:43:04.752820: Yayy! New best EMA pseudo Dice: 0.7491 
2025-12-16 03:43:05.671366:  
2025-12-16 03:43:05.671366: Epoch 21 
2025-12-16 03:43:05.671366: Current learning rate: 0.00981 
2025-12-16 03:45:23.753887: train_loss -0.6708 
2025-12-16 03:45:23.753887: val_loss -0.6754 
2025-12-16 03:45:23.753887: Pseudo dice [0.8415, 0.895, 0.8319] 
2025-12-16 03:45:23.753887: Epoch time: 138.08 s 
2025-12-16 03:45:23.753887: Yayy! New best EMA pseudo Dice: 0.7598 
2025-12-16 03:45:24.835936:  
2025-12-16 03:45:24.835936: Epoch 22 
2025-12-16 03:45:24.835936: Current learning rate: 0.0098 
2025-12-16 03:47:42.818131: train_loss -0.6618 
2025-12-16 03:47:42.820133: val_loss -0.6791 
2025-12-16 03:47:42.820133: Pseudo dice [0.8495, 0.9016, 0.814] 
2025-12-16 03:47:42.820133: Epoch time: 137.98 s 
2025-12-16 03:47:42.820133: Yayy! New best EMA pseudo Dice: 0.7693 
2025-12-16 03:47:43.707495:  
2025-12-16 03:47:43.707495: Epoch 23 
2025-12-16 03:47:43.707495: Current learning rate: 0.00979 
2025-12-16 03:50:01.600580: train_loss -0.6753 
2025-12-16 03:50:01.600580: val_loss -0.6878 
2025-12-16 03:50:01.602583: Pseudo dice [0.8453, 0.8927, 0.8341] 
2025-12-16 03:50:01.602583: Epoch time: 137.89 s 
2025-12-16 03:50:01.602583: Yayy! New best EMA pseudo Dice: 0.7781 
2025-12-16 03:50:02.465817:  
2025-12-16 03:50:02.465817: Epoch 24 
2025-12-16 03:50:02.465817: Current learning rate: 0.00978 
2025-12-16 03:52:20.395366: train_loss -0.6849 
2025-12-16 03:52:20.395366: val_loss -0.7024 
2025-12-16 03:52:20.395366: Pseudo dice [0.8578, 0.9041, 0.8431] 
2025-12-16 03:52:20.395366: Epoch time: 137.93 s 
2025-12-16 03:52:20.398922: Yayy! New best EMA pseudo Dice: 0.7871 
2025-12-16 03:52:21.555968:  
2025-12-16 03:52:21.555968: Epoch 25 
2025-12-16 03:52:21.555968: Current learning rate: 0.00977 
2025-12-16 03:54:39.530111: train_loss -0.6904 
2025-12-16 03:54:39.530111: val_loss -0.6975 
2025-12-16 03:54:39.530111: Pseudo dice [0.8452, 0.9023, 0.8351] 
2025-12-16 03:54:39.530111: Epoch time: 137.97 s 
2025-12-16 03:54:39.545796: Yayy! New best EMA pseudo Dice: 0.7945 
2025-12-16 03:54:40.403024:  
2025-12-16 03:54:40.403024: Epoch 26 
2025-12-16 03:54:40.403024: Current learning rate: 0.00977 
2025-12-16 03:56:58.289611: train_loss -0.699 
2025-12-16 03:56:58.291613: val_loss -0.7162 
2025-12-16 03:56:58.293615: Pseudo dice [0.8618, 0.9112, 0.85] 
2025-12-16 03:56:58.293615: Epoch time: 137.89 s 
2025-12-16 03:56:58.295618: Yayy! New best EMA pseudo Dice: 0.8025 
2025-12-16 03:56:59.165680:  
2025-12-16 03:56:59.167683: Epoch 27 
2025-12-16 03:56:59.167683: Current learning rate: 0.00976 
2025-12-16 03:59:17.105994: train_loss -0.6938 
2025-12-16 03:59:17.105994: val_loss -0.7138 
2025-12-16 03:59:17.105994: Pseudo dice [0.8601, 0.9084, 0.8349] 
2025-12-16 03:59:17.105994: Epoch time: 137.94 s 
2025-12-16 03:59:17.105994: Yayy! New best EMA pseudo Dice: 0.809 
2025-12-16 03:59:18.084361:  
2025-12-16 03:59:18.084361: Epoch 28 
2025-12-16 03:59:18.084361: Current learning rate: 0.00975 
2025-12-16 04:01:36.120235: train_loss -0.7018 
2025-12-16 04:01:36.120235: val_loss -0.703 
2025-12-16 04:01:36.120235: Pseudo dice [0.8504, 0.8997, 0.8399] 
2025-12-16 04:01:36.120235: Epoch time: 138.04 s 
2025-12-16 04:01:36.120235: Yayy! New best EMA pseudo Dice: 0.8144 
2025-12-16 04:01:37.008708:  
2025-12-16 04:01:37.010449: Epoch 29 
2025-12-16 04:01:37.010449: Current learning rate: 0.00974 
2025-12-16 04:03:54.887595: train_loss -0.7032 
2025-12-16 04:03:54.887595: val_loss -0.711 
2025-12-16 04:03:54.889598: Pseudo dice [0.8412, 0.9053, 0.8561] 
2025-12-16 04:03:54.891602: Epoch time: 137.88 s 
2025-12-16 04:03:54.891602: Yayy! New best EMA pseudo Dice: 0.8197 
2025-12-16 04:03:55.781666:  
2025-12-16 04:03:55.781666: Epoch 30 
2025-12-16 04:03:55.781666: Current learning rate: 0.00973 
2025-12-16 04:06:13.671409: train_loss -0.7186 
2025-12-16 04:06:13.671409: val_loss -0.7308 
2025-12-16 04:06:13.671409: Pseudo dice [0.8642, 0.9175, 0.8524] 
2025-12-16 04:06:13.671409: Epoch time: 137.89 s 
2025-12-16 04:06:13.671409: Yayy! New best EMA pseudo Dice: 0.8256 
2025-12-16 04:06:14.933607:  
2025-12-16 04:06:14.933607: Epoch 31 
2025-12-16 04:06:14.933607: Current learning rate: 0.00972 
2025-12-16 04:08:32.813566: train_loss -0.7202 
2025-12-16 04:08:32.813566: val_loss -0.7372 
2025-12-16 04:08:32.815569: Pseudo dice [0.8618, 0.9136, 0.8692] 
2025-12-16 04:08:32.817572: Epoch time: 137.88 s 
2025-12-16 04:08:32.817572: Yayy! New best EMA pseudo Dice: 0.8312 
2025-12-16 04:08:33.711154:  
2025-12-16 04:08:33.713156: Epoch 32 
2025-12-16 04:08:33.713156: Current learning rate: 0.00971 
2025-12-16 04:10:52.530124: train_loss -0.7295 
2025-12-16 04:10:52.545881: val_loss -0.7225 
2025-12-16 04:10:52.545881: Pseudo dice [0.8664, 0.9132, 0.8362] 
2025-12-16 04:10:52.545881: Epoch time: 138.82 s 
2025-12-16 04:10:52.545881: Yayy! New best EMA pseudo Dice: 0.8352 
2025-12-16 04:10:53.439636:  
2025-12-16 04:10:53.439636: Epoch 33 
2025-12-16 04:10:53.455651: Current learning rate: 0.0097 
2025-12-16 04:13:11.298946: train_loss -0.7274 
2025-12-16 04:13:11.298946: val_loss -0.7336 
2025-12-16 04:13:11.300948: Pseudo dice [0.86, 0.908, 0.8646] 
2025-12-16 04:13:11.302951: Epoch time: 137.86 s 
2025-12-16 04:13:11.302951: Yayy! New best EMA pseudo Dice: 0.8395 
2025-12-16 04:13:12.290410:  
2025-12-16 04:13:12.290410: Epoch 34 
2025-12-16 04:13:12.306531: Current learning rate: 0.00969 
2025-12-16 04:15:30.356715: train_loss -0.7303 
2025-12-16 04:15:30.356715: val_loss -0.7401 
2025-12-16 04:15:30.358717: Pseudo dice [0.8671, 0.919, 0.8569] 
2025-12-16 04:15:30.360718: Epoch time: 138.07 s 
2025-12-16 04:15:30.360718: Yayy! New best EMA pseudo Dice: 0.8436 
2025-12-16 04:15:31.248782:  
2025-12-16 04:15:31.248782: Epoch 35 
2025-12-16 04:15:31.248782: Current learning rate: 0.00968 
2025-12-16 04:17:49.247996: train_loss -0.7374 
2025-12-16 04:17:49.247996: val_loss -0.7534 
2025-12-16 04:17:49.249736: Pseudo dice [0.8761, 0.919, 0.8606] 
2025-12-16 04:17:49.251739: Epoch time: 138.0 s 
2025-12-16 04:17:49.251739: Yayy! New best EMA pseudo Dice: 0.8478 
2025-12-16 04:17:50.295619:  
2025-12-16 04:17:50.295619: Epoch 36 
2025-12-16 04:17:50.295619: Current learning rate: 0.00968 
2025-12-16 04:20:08.368108: train_loss -0.7362 
2025-12-16 04:20:08.370110: val_loss -0.7293 
2025-12-16 04:20:08.371850: Pseudo dice [0.8638, 0.9158, 0.8576] 
2025-12-16 04:20:08.371850: Epoch time: 138.07 s 
2025-12-16 04:20:08.371850: Yayy! New best EMA pseudo Dice: 0.8509 
2025-12-16 04:20:09.290222:  
2025-12-16 04:20:09.290222: Epoch 37 
2025-12-16 04:20:09.290222: Current learning rate: 0.00967 
2025-12-16 04:22:27.392654: train_loss -0.7423 
2025-12-16 04:22:27.392654: val_loss -0.7414 
2025-12-16 04:22:27.408758: Pseudo dice [0.8725, 0.917, 0.8583] 
2025-12-16 04:22:27.408758: Epoch time: 138.1 s 
2025-12-16 04:22:27.408758: Yayy! New best EMA pseudo Dice: 0.8541 
2025-12-16 04:22:28.316015:  
2025-12-16 04:22:28.316015: Epoch 38 
2025-12-16 04:22:28.316015: Current learning rate: 0.00966 
2025-12-16 04:24:46.340600: train_loss -0.7386 
2025-12-16 04:24:46.340600: val_loss -0.7456 
2025-12-16 04:24:46.340600: Pseudo dice [0.8654, 0.9199, 0.8714] 
2025-12-16 04:24:46.340600: Epoch time: 138.03 s 
2025-12-16 04:24:46.340600: Yayy! New best EMA pseudo Dice: 0.8572 
2025-12-16 04:24:47.229631:  
2025-12-16 04:24:47.229631: Epoch 39 
2025-12-16 04:24:47.229631: Current learning rate: 0.00965 
2025-12-16 04:27:05.130792: train_loss -0.7416 
2025-12-16 04:27:05.130792: val_loss -0.7533 
2025-12-16 04:27:05.130792: Pseudo dice [0.8746, 0.9143, 0.8784] 
2025-12-16 04:27:05.130792: Epoch time: 137.9 s 
2025-12-16 04:27:05.130792: Yayy! New best EMA pseudo Dice: 0.8604 
2025-12-16 04:27:06.060648:  
2025-12-16 04:27:06.060648: Epoch 40 
2025-12-16 04:27:06.060648: Current learning rate: 0.00964 
2025-12-16 04:29:23.857627: train_loss -0.7482 
2025-12-16 04:29:23.859629: val_loss -0.7542 
2025-12-16 04:29:23.861631: Pseudo dice [0.8804, 0.9209, 0.8539] 
2025-12-16 04:29:23.861631: Epoch time: 137.8 s 
2025-12-16 04:29:23.861631: Yayy! New best EMA pseudo Dice: 0.8629 
2025-12-16 04:29:24.766719:  
2025-12-16 04:29:24.766719: Epoch 41 
2025-12-16 04:29:24.766719: Current learning rate: 0.00963 
2025-12-16 04:31:42.775482: train_loss -0.7436 
2025-12-16 04:31:42.775482: val_loss -0.7678 
2025-12-16 04:31:42.777484: Pseudo dice [0.889, 0.923, 0.865] 
2025-12-16 04:31:42.777484: Epoch time: 138.01 s 
2025-12-16 04:31:42.779224: Yayy! New best EMA pseudo Dice: 0.8658 
2025-12-16 04:31:43.840773:  
2025-12-16 04:31:43.840773: Epoch 42 
2025-12-16 04:31:43.840773: Current learning rate: 0.00962 
2025-12-16 04:34:01.823817: train_loss -0.745 
2025-12-16 04:34:01.825821: val_loss -0.7314 
2025-12-16 04:34:01.825821: Pseudo dice [0.8527, 0.9015, 0.8646] 
2025-12-16 04:34:01.825821: Epoch time: 137.99 s 
2025-12-16 04:34:01.825821: Yayy! New best EMA pseudo Dice: 0.8665 
2025-12-16 04:34:02.712060:  
2025-12-16 04:34:02.712060: Epoch 43 
2025-12-16 04:34:02.712060: Current learning rate: 0.00961 
2025-12-16 04:36:20.608635: train_loss -0.7549 
2025-12-16 04:36:20.608635: val_loss -0.7765 
2025-12-16 04:36:20.610636: Pseudo dice [0.889, 0.9269, 0.8631] 
2025-12-16 04:36:20.610636: Epoch time: 137.9 s 
2025-12-16 04:36:20.613143: Yayy! New best EMA pseudo Dice: 0.8692 
2025-12-16 04:36:21.503424:  
2025-12-16 04:36:21.505164: Epoch 44 
2025-12-16 04:36:21.505164: Current learning rate: 0.0096 
2025-12-16 04:38:39.366693: train_loss -0.7686 
2025-12-16 04:38:39.366693: val_loss -0.7654 
2025-12-16 04:38:39.368695: Pseudo dice [0.8729, 0.9201, 0.8768] 
2025-12-16 04:38:39.370698: Epoch time: 137.86 s 
2025-12-16 04:38:39.370698: Yayy! New best EMA pseudo Dice: 0.8713 
2025-12-16 04:38:40.249074:  
2025-12-16 04:38:40.249074: Epoch 45 
2025-12-16 04:38:40.249074: Current learning rate: 0.00959 
2025-12-16 04:40:58.273391: train_loss -0.7646 
2025-12-16 04:40:58.273391: val_loss -0.7761 
2025-12-16 04:40:58.273391: Pseudo dice [0.883, 0.9287, 0.8799] 
2025-12-16 04:40:58.273391: Epoch time: 138.02 s 
2025-12-16 04:40:58.273391: Yayy! New best EMA pseudo Dice: 0.8739 
2025-12-16 04:40:59.194070:  
2025-12-16 04:40:59.194070: Epoch 46 
2025-12-16 04:40:59.194070: Current learning rate: 0.00959 
2025-12-16 04:43:17.286612: train_loss -0.7598 
2025-12-16 04:43:17.286612: val_loss -0.7677 
2025-12-16 04:43:17.286612: Pseudo dice [0.8786, 0.9312, 0.8724] 
2025-12-16 04:43:17.286612: Epoch time: 138.09 s 
2025-12-16 04:43:17.286612: Yayy! New best EMA pseudo Dice: 0.8759 
2025-12-16 04:43:18.180067:  
2025-12-16 04:43:18.180067: Epoch 47 
2025-12-16 04:43:18.180067: Current learning rate: 0.00958 
2025-12-16 04:45:36.116207: train_loss -0.7636 
2025-12-16 04:45:36.116207: val_loss -0.7428 
2025-12-16 04:45:36.120212: Pseudo dice [0.8634, 0.916, 0.8578] 
2025-12-16 04:45:36.122215: Epoch time: 137.94 s 
2025-12-16 04:45:36.124218: Yayy! New best EMA pseudo Dice: 0.8762 
2025-12-16 04:45:37.170884:  
2025-12-16 04:45:37.170884: Epoch 48 
2025-12-16 04:45:37.170884: Current learning rate: 0.00957 
2025-12-16 04:47:55.032303: train_loss -0.7621 
2025-12-16 04:47:55.032303: val_loss -0.776 
2025-12-16 04:47:55.032303: Pseudo dice [0.8799, 0.9263, 0.8721] 
2025-12-16 04:47:55.036304: Epoch time: 137.86 s 
2025-12-16 04:47:55.036304: Yayy! New best EMA pseudo Dice: 0.8779 
2025-12-16 04:47:55.959119:  
2025-12-16 04:47:55.959119: Epoch 49 
2025-12-16 04:47:55.959119: Current learning rate: 0.00956 
2025-12-16 04:50:13.932590: train_loss -0.7672 
2025-12-16 04:50:13.932590: val_loss -0.777 
2025-12-16 04:50:13.948369: Pseudo dice [0.8891, 0.9322, 0.8656] 
2025-12-16 04:50:13.948369: Epoch time: 137.98 s 
2025-12-16 04:50:14.185639: Yayy! New best EMA pseudo Dice: 0.8796 
2025-12-16 04:50:15.076454:  
2025-12-16 04:50:15.076454: Epoch 50 
2025-12-16 04:50:15.078456: Current learning rate: 0.00955 
2025-12-16 04:52:32.914865: train_loss -0.7728 
2025-12-16 04:52:32.930785: val_loss -0.7653 
2025-12-16 04:52:32.930785: Pseudo dice [0.8743, 0.9183, 0.8715] 
2025-12-16 04:52:32.930785: Epoch time: 137.84 s 
2025-12-16 04:52:32.930785: Yayy! New best EMA pseudo Dice: 0.8805 
2025-12-16 04:52:33.818604:  
2025-12-16 04:52:33.818604: Epoch 51 
2025-12-16 04:52:33.818604: Current learning rate: 0.00954 
2025-12-16 04:54:51.851911: train_loss -0.7752 
2025-12-16 04:54:51.853915: val_loss -0.7793 
2025-12-16 04:54:51.853915: Pseudo dice [0.8811, 0.9299, 0.8787] 
2025-12-16 04:54:51.855655: Epoch time: 138.03 s 
2025-12-16 04:54:51.855655: Yayy! New best EMA pseudo Dice: 0.8821 
2025-12-16 04:54:52.767600:  
2025-12-16 04:54:52.767600: Epoch 52 
2025-12-16 04:54:52.767600: Current learning rate: 0.00953 
2025-12-16 04:57:10.906337: train_loss -0.7768 
2025-12-16 04:57:10.906337: val_loss -0.7705 
2025-12-16 04:57:10.906337: Pseudo dice [0.8712, 0.9223, 0.8894] 
2025-12-16 04:57:10.906337: Epoch time: 138.14 s 
2025-12-16 04:57:10.906337: Yayy! New best EMA pseudo Dice: 0.8833 
2025-12-16 04:57:11.795083:  
2025-12-16 04:57:11.795083: Epoch 53 
2025-12-16 04:57:11.795083: Current learning rate: 0.00952 
2025-12-16 04:59:29.760453: train_loss -0.765 
2025-12-16 04:59:29.760453: val_loss -0.7934 
2025-12-16 04:59:29.762194: Pseudo dice [0.8962, 0.9345, 0.8786] 
2025-12-16 04:59:29.762194: Epoch time: 137.97 s 
2025-12-16 04:59:29.762194: Yayy! New best EMA pseudo Dice: 0.8853 
2025-12-16 04:59:30.651361:  
2025-12-16 04:59:30.651361: Epoch 54 
2025-12-16 04:59:30.651361: Current learning rate: 0.00951 
2025-12-16 05:01:48.532446: train_loss -0.7774 
2025-12-16 05:01:48.535434: val_loss -0.7806 
2025-12-16 05:01:48.537438: Pseudo dice [0.8888, 0.9241, 0.8832] 
2025-12-16 05:01:48.539441: Epoch time: 137.88 s 
2025-12-16 05:01:48.539441: Yayy! New best EMA pseudo Dice: 0.8866 
2025-12-16 05:01:49.439443:  
2025-12-16 05:01:49.439443: Epoch 55 
2025-12-16 05:01:49.439443: Current learning rate: 0.0095 
2025-12-16 05:04:07.328993: train_loss -0.7722 
2025-12-16 05:04:07.330996: val_loss -0.7728 
2025-12-16 05:04:07.332999: Pseudo dice [0.8777, 0.9205, 0.8747] 
2025-12-16 05:04:07.335002: Epoch time: 137.89 s 
2025-12-16 05:04:07.336746: Yayy! New best EMA pseudo Dice: 0.8871 
2025-12-16 05:04:08.284328:  
2025-12-16 05:04:08.284328: Epoch 56 
2025-12-16 05:04:08.284328: Current learning rate: 0.00949 
2025-12-16 05:06:26.151141: train_loss -0.7626 
2025-12-16 05:06:26.153143: val_loss -0.7826 
2025-12-16 05:06:26.153143: Pseudo dice [0.8828, 0.9328, 0.8879] 
2025-12-16 05:06:26.153143: Epoch time: 137.87 s 
2025-12-16 05:06:26.153143: Yayy! New best EMA pseudo Dice: 0.8885 
2025-12-16 05:06:27.033497:  
2025-12-16 05:06:27.033497: Epoch 57 
2025-12-16 05:06:27.033497: Current learning rate: 0.00949 
2025-12-16 05:08:45.082974: train_loss -0.7691 
2025-12-16 05:08:45.082974: val_loss -0.7669 
2025-12-16 05:08:45.082974: Pseudo dice [0.8761, 0.9255, 0.8787] 
2025-12-16 05:08:45.082974: Epoch time: 138.05 s 
2025-12-16 05:08:45.092657: Yayy! New best EMA pseudo Dice: 0.889 
2025-12-16 05:08:46.014063:  
2025-12-16 05:08:46.014063: Epoch 58 
2025-12-16 05:08:46.014063: Current learning rate: 0.00948 
2025-12-16 05:11:04.729937: train_loss -0.7634 
2025-12-16 05:11:04.729937: val_loss -0.7728 
2025-12-16 05:11:04.729937: Pseudo dice [0.8758, 0.925, 0.8808] 
2025-12-16 05:11:04.734283: Epoch time: 138.72 s 
2025-12-16 05:11:04.734283: Yayy! New best EMA pseudo Dice: 0.8895 
2025-12-16 05:11:05.621921:  
2025-12-16 05:11:05.621921: Epoch 59 
2025-12-16 05:11:05.624739: Current learning rate: 0.00947 
2025-12-16 05:13:23.432786: train_loss -0.7366 
2025-12-16 05:13:23.432786: val_loss -0.7537 
2025-12-16 05:13:23.434788: Pseudo dice [0.8714, 0.916, 0.8686] 
2025-12-16 05:13:23.434788: Epoch time: 137.81 s 
2025-12-16 05:13:24.231301:  
2025-12-16 05:13:24.231301: Epoch 60 
2025-12-16 05:13:24.231301: Current learning rate: 0.00946 
2025-12-16 05:15:42.284155: train_loss -0.7513 
2025-12-16 05:15:42.286157: val_loss -0.7756 
2025-12-16 05:15:42.286157: Pseudo dice [0.886, 0.9296, 0.8684] 
2025-12-16 05:15:42.286157: Epoch time: 138.05 s 
2025-12-16 05:15:42.289479: Yayy! New best EMA pseudo Dice: 0.8896 
2025-12-16 05:15:43.183263:  
2025-12-16 05:15:43.183263: Epoch 61 
2025-12-16 05:15:43.183263: Current learning rate: 0.00945 
2025-12-16 05:18:00.962498: train_loss -0.7645 
2025-12-16 05:18:00.962498: val_loss -0.7774 
2025-12-16 05:18:00.962498: Pseudo dice [0.8868, 0.9289, 0.8732] 
2025-12-16 05:18:00.962498: Epoch time: 137.78 s 
2025-12-16 05:18:00.973812: Yayy! New best EMA pseudo Dice: 0.8903 
2025-12-16 05:18:01.860464:  
2025-12-16 05:18:01.860464: Epoch 62 
2025-12-16 05:18:01.860464: Current learning rate: 0.00944 
2025-12-16 05:20:19.722506: train_loss -0.7801 
2025-12-16 05:20:19.722506: val_loss -0.7951 
2025-12-16 05:20:19.722506: Pseudo dice [0.8929, 0.9319, 0.882] 
2025-12-16 05:20:19.730125: Epoch time: 137.86 s 
2025-12-16 05:20:19.730125: Yayy! New best EMA pseudo Dice: 0.8915 
2025-12-16 05:20:20.628532:  
2025-12-16 05:20:20.628532: Epoch 63 
2025-12-16 05:20:20.628532: Current learning rate: 0.00943 
2025-12-16 05:22:38.657552: train_loss -0.7775 
2025-12-16 05:22:38.657552: val_loss -0.7924 
2025-12-16 05:22:38.657552: Pseudo dice [0.8883, 0.9296, 0.8926] 
2025-12-16 05:22:38.657552: Epoch time: 138.03 s 
2025-12-16 05:22:38.669829: Yayy! New best EMA pseudo Dice: 0.8927 
2025-12-16 05:22:39.579349:  
2025-12-16 05:22:39.579349: Epoch 64 
2025-12-16 05:22:39.579349: Current learning rate: 0.00942 
2025-12-16 05:24:57.483163: train_loss -0.7835 
2025-12-16 05:24:57.483163: val_loss -0.7945 
2025-12-16 05:24:57.483163: Pseudo dice [0.8913, 0.9341, 0.8872] 
2025-12-16 05:24:57.483163: Epoch time: 137.91 s 
2025-12-16 05:24:57.483163: Yayy! New best EMA pseudo Dice: 0.8938 
2025-12-16 05:24:58.384354:  
2025-12-16 05:24:58.386357: Epoch 65 
2025-12-16 05:24:58.386357: Current learning rate: 0.00941 
2025-12-16 05:27:16.457556: train_loss -0.7752 
2025-12-16 05:27:16.457556: val_loss -0.7664 
2025-12-16 05:27:16.459296: Pseudo dice [0.8713, 0.9148, 0.8832] 
2025-12-16 05:27:16.461299: Epoch time: 138.07 s 
2025-12-16 05:27:17.275554:  
2025-12-16 05:27:17.275554: Epoch 66 
2025-12-16 05:27:17.275554: Current learning rate: 0.0094 
2025-12-16 05:29:35.075014: train_loss -0.7774 
2025-12-16 05:29:35.075014: val_loss -0.7821 
2025-12-16 05:29:35.075014: Pseudo dice [0.8762, 0.9247, 0.8903] 
2025-12-16 05:29:35.075014: Epoch time: 137.8 s 
2025-12-16 05:29:35.729534:  
2025-12-16 05:29:35.731536: Epoch 67 
2025-12-16 05:29:35.731536: Current learning rate: 0.00939 
2025-12-16 05:31:53.748152: train_loss -0.7845 
2025-12-16 05:31:53.748152: val_loss -0.8126 
2025-12-16 05:31:53.748152: Pseudo dice [0.9003, 0.939, 0.8885] 
2025-12-16 05:31:53.748152: Epoch time: 138.02 s 
2025-12-16 05:31:53.748152: Yayy! New best EMA pseudo Dice: 0.8953 
2025-12-16 05:31:54.619756:  
2025-12-16 05:31:54.619756: Epoch 68 
2025-12-16 05:31:54.619756: Current learning rate: 0.00939 
2025-12-16 05:34:12.466573: train_loss -0.7946 
2025-12-16 05:34:12.466573: val_loss -0.7996 
2025-12-16 05:34:12.466573: Pseudo dice [0.8951, 0.9342, 0.8846] 
2025-12-16 05:34:12.466573: Epoch time: 137.85 s 
2025-12-16 05:34:12.466573: Yayy! New best EMA pseudo Dice: 0.8963 
2025-12-16 05:34:13.368963:  
2025-12-16 05:34:13.370966: Epoch 69 
2025-12-16 05:34:13.370966: Current learning rate: 0.00938 
2025-12-16 05:36:31.215481: train_loss -0.7943 
2025-12-16 05:36:31.215481: val_loss -0.8137 
2025-12-16 05:36:31.217483: Pseudo dice [0.9016, 0.9408, 0.901] 
2025-12-16 05:36:31.219485: Epoch time: 137.85 s 
2025-12-16 05:36:31.219485: Yayy! New best EMA pseudo Dice: 0.8981 
2025-12-16 05:36:32.156308:  
2025-12-16 05:36:32.159922: Epoch 70 
2025-12-16 05:36:32.159922: Current learning rate: 0.00937 
2025-12-16 05:38:49.918176: train_loss -0.7952 
2025-12-16 05:38:49.918176: val_loss -0.8062 
2025-12-16 05:38:49.918176: Pseudo dice [0.9006, 0.9398, 0.9007] 
2025-12-16 05:38:49.928228: Epoch time: 137.76 s 
2025-12-16 05:38:49.930231: Yayy! New best EMA pseudo Dice: 0.8996 
2025-12-16 05:38:50.818488:  
2025-12-16 05:38:50.820896: Epoch 71 
2025-12-16 05:38:50.820896: Current learning rate: 0.00936 
2025-12-16 05:41:08.745566: train_loss -0.8005 
2025-12-16 05:41:08.747567: val_loss -0.7917 
2025-12-16 05:41:08.749387: Pseudo dice [0.8867, 0.9277, 0.8864] 
2025-12-16 05:41:08.749387: Epoch time: 137.93 s 
2025-12-16 05:41:08.751390: Yayy! New best EMA pseudo Dice: 0.8997 
2025-12-16 05:41:09.838476:  
2025-12-16 05:41:09.838476: Epoch 72 
2025-12-16 05:41:09.838476: Current learning rate: 0.00935 
2025-12-16 05:43:27.766435: train_loss -0.7981 
2025-12-16 05:43:27.766435: val_loss -0.7956 
2025-12-16 05:43:27.768437: Pseudo dice [0.8844, 0.9313, 0.9025] 
2025-12-16 05:43:27.770439: Epoch time: 137.93 s 
2025-12-16 05:43:27.772180: Yayy! New best EMA pseudo Dice: 0.9003 
2025-12-16 05:43:28.683681:  
2025-12-16 05:43:28.683681: Epoch 73 
2025-12-16 05:43:28.683681: Current learning rate: 0.00934 
2025-12-16 05:45:46.932826: train_loss -0.7862 
2025-12-16 05:45:46.934829: val_loss -0.8106 
2025-12-16 05:45:46.934829: Pseudo dice [0.8985, 0.9389, 0.9022] 
2025-12-16 05:45:46.934829: Epoch time: 138.25 s 
2025-12-16 05:45:46.940061: Yayy! New best EMA pseudo Dice: 0.9016 
2025-12-16 05:45:47.845033:  
2025-12-16 05:45:47.845033: Epoch 74 
2025-12-16 05:45:47.845033: Current learning rate: 0.00933 
2025-12-16 05:48:05.784727: train_loss -0.7865 
2025-12-16 05:48:05.784727: val_loss -0.8153 
2025-12-16 05:48:05.787260: Pseudo dice [0.9022, 0.9426, 0.9029] 
2025-12-16 05:48:05.787260: Epoch time: 137.94 s 
2025-12-16 05:48:05.787260: Yayy! New best EMA pseudo Dice: 0.9031 
2025-12-16 05:48:06.683159:  
2025-12-16 05:48:06.683159: Epoch 75 
2025-12-16 05:48:06.685671: Current learning rate: 0.00932 
2025-12-16 05:50:24.540187: train_loss -0.79 
2025-12-16 05:50:24.540187: val_loss -0.7972 
2025-12-16 05:50:24.542189: Pseudo dice [0.8903, 0.9299, 0.8807] 
2025-12-16 05:50:24.542189: Epoch time: 137.86 s 
2025-12-16 05:50:25.284940:  
2025-12-16 05:50:25.284940: Epoch 76 
2025-12-16 05:50:25.284940: Current learning rate: 0.00931 
2025-12-16 05:52:43.447507: train_loss -0.7972 
2025-12-16 05:52:43.449248: val_loss -0.8065 
2025-12-16 05:52:43.451251: Pseudo dice [0.8941, 0.9358, 0.8993] 
2025-12-16 05:52:43.451251: Epoch time: 138.16 s 
2025-12-16 05:52:43.453253: Yayy! New best EMA pseudo Dice: 0.9035 
2025-12-16 05:52:44.354001:  
2025-12-16 05:52:44.354001: Epoch 77 
2025-12-16 05:52:44.354001: Current learning rate: 0.0093 
2025-12-16 05:55:02.313652: train_loss -0.7957 
2025-12-16 05:55:02.313652: val_loss -0.7985 
2025-12-16 05:55:02.317572: Pseudo dice [0.8881, 0.9278, 0.9028] 
2025-12-16 05:55:02.317572: Epoch time: 137.96 s 
2025-12-16 05:55:02.317572: Yayy! New best EMA pseudo Dice: 0.9038 
2025-12-16 05:55:03.377017:  
2025-12-16 05:55:03.377017: Epoch 78 
2025-12-16 05:55:03.393023: Current learning rate: 0.0093 
2025-12-16 05:57:21.332628: train_loss -0.7933 
2025-12-16 05:57:21.332628: val_loss -0.83 
2025-12-16 05:57:21.335219: Pseudo dice [0.9154, 0.9463, 0.8987] 
2025-12-16 05:57:21.335219: Epoch time: 137.96 s 
2025-12-16 05:57:21.337221: Yayy! New best EMA pseudo Dice: 0.9054 
2025-12-16 05:57:22.314346:  
2025-12-16 05:57:22.314346: Epoch 79 
2025-12-16 05:57:22.314346: Current learning rate: 0.00929 
2025-12-16 05:59:40.372844: train_loss -0.7905 
2025-12-16 05:59:40.372844: val_loss -0.7922 
2025-12-16 05:59:40.372844: Pseudo dice [0.8891, 0.9254, 0.8833] 
2025-12-16 05:59:40.372844: Epoch time: 138.06 s 
2025-12-16 05:59:41.023784:  
2025-12-16 05:59:41.037812: Epoch 80 
2025-12-16 05:59:41.037812: Current learning rate: 0.00928 
2025-12-16 06:01:58.858962: train_loss -0.793 
2025-12-16 06:01:58.858962: val_loss -0.8111 
2025-12-16 06:01:58.860964: Pseudo dice [0.9022, 0.9404, 0.895] 
2025-12-16 06:01:58.862966: Epoch time: 137.84 s 
2025-12-16 06:01:58.862966: Yayy! New best EMA pseudo Dice: 0.9056 
2025-12-16 06:01:59.777862:  
2025-12-16 06:01:59.777862: Epoch 81 
2025-12-16 06:01:59.777862: Current learning rate: 0.00927 
2025-12-16 06:04:17.763553: train_loss -0.7992 
2025-12-16 06:04:17.763553: val_loss -0.8107 
2025-12-16 06:04:17.765555: Pseudo dice [0.8955, 0.9357, 0.8961] 
2025-12-16 06:04:17.767557: Epoch time: 137.99 s 
2025-12-16 06:04:17.769559: Yayy! New best EMA pseudo Dice: 0.9059 
2025-12-16 06:04:18.747092:  
2025-12-16 06:04:18.763211: Epoch 82 
2025-12-16 06:04:18.763211: Current learning rate: 0.00926 
2025-12-16 06:06:36.783101: train_loss -0.8024 
2025-12-16 06:06:36.783101: val_loss -0.8026 
2025-12-16 06:06:36.783101: Pseudo dice [0.8917, 0.9368, 0.891] 
2025-12-16 06:06:36.783101: Epoch time: 138.04 s 
2025-12-16 06:06:36.783101: Yayy! New best EMA pseudo Dice: 0.906 
2025-12-16 06:06:37.658737:  
2025-12-16 06:06:37.658737: Epoch 83 
2025-12-16 06:06:37.658737: Current learning rate: 0.00925 
2025-12-16 06:08:55.658219: train_loss -0.8023 
2025-12-16 06:08:55.658219: val_loss -0.8165 
2025-12-16 06:08:55.662224: Pseudo dice [0.8991, 0.9384, 0.9027] 
2025-12-16 06:08:55.662224: Epoch time: 138.0 s 
2025-12-16 06:08:55.664227: Yayy! New best EMA pseudo Dice: 0.9067 
2025-12-16 06:08:56.724125:  
2025-12-16 06:08:56.726500: Epoch 84 
2025-12-16 06:08:56.726500: Current learning rate: 0.00924 
2025-12-16 06:11:15.405712: train_loss -0.7946 
2025-12-16 06:11:15.405712: val_loss -0.8038 
2025-12-16 06:11:15.405712: Pseudo dice [0.8946, 0.935, 0.8999] 
2025-12-16 06:11:15.405712: Epoch time: 138.68 s 
2025-12-16 06:11:15.405712: Yayy! New best EMA pseudo Dice: 0.907 
2025-12-16 06:11:16.304983:  
2025-12-16 06:11:16.304983: Epoch 85 
2025-12-16 06:11:16.304983: Current learning rate: 0.00923 
2025-12-16 06:13:34.316675: train_loss -0.8011 
2025-12-16 06:13:34.318416: val_loss -0.8233 
2025-12-16 06:13:34.318416: Pseudo dice [0.9086, 0.9446, 0.901] 
2025-12-16 06:13:34.318416: Epoch time: 138.01 s 
2025-12-16 06:13:34.318416: Yayy! New best EMA pseudo Dice: 0.9081 
2025-12-16 06:13:35.205317:  
2025-12-16 06:13:35.205317: Epoch 86 
2025-12-16 06:13:35.221072: Current learning rate: 0.00922 
2025-12-16 06:15:53.075864: train_loss -0.801 
2025-12-16 06:15:53.075864: val_loss -0.8168 
2025-12-16 06:15:53.075864: Pseudo dice [0.8979, 0.9389, 0.9081] 
2025-12-16 06:15:53.088405: Epoch time: 137.87 s 
2025-12-16 06:15:53.090408: Yayy! New best EMA pseudo Dice: 0.9088 
2025-12-16 06:15:53.958930:  
2025-12-16 06:15:53.958930: Epoch 87 
2025-12-16 06:15:53.973459: Current learning rate: 0.00921 
2025-12-16 06:18:11.879557: train_loss -0.8049 
2025-12-16 06:18:11.881562: val_loss -0.8222 
2025-12-16 06:18:11.883564: Pseudo dice [0.9027, 0.9398, 0.8975] 
2025-12-16 06:18:11.883564: Epoch time: 137.92 s 
2025-12-16 06:18:11.883564: Yayy! New best EMA pseudo Dice: 0.9093 
2025-12-16 06:18:12.791945:  
2025-12-16 06:18:12.791945: Epoch 88 
2025-12-16 06:18:12.791945: Current learning rate: 0.0092 
2025-12-16 06:20:30.768612: train_loss -0.8016 
2025-12-16 06:20:30.768612: val_loss -0.8195 
2025-12-16 06:20:30.768612: Pseudo dice [0.8976, 0.9372, 0.905] 
2025-12-16 06:20:30.768612: Epoch time: 137.99 s 
2025-12-16 06:20:30.768612: Yayy! New best EMA pseudo Dice: 0.9097 
2025-12-16 06:20:31.640877:  
2025-12-16 06:20:31.640877: Epoch 89 
2025-12-16 06:20:31.640877: Current learning rate: 0.0092 
2025-12-16 06:22:49.693232: train_loss -0.7986 
2025-12-16 06:22:49.693232: val_loss -0.8104 
2025-12-16 06:22:49.695234: Pseudo dice [0.9028, 0.9382, 0.893] 
2025-12-16 06:22:49.697236: Epoch time: 138.05 s 
2025-12-16 06:22:49.698976: Yayy! New best EMA pseudo Dice: 0.9098 
2025-12-16 06:22:50.756917:  
2025-12-16 06:22:50.756917: Epoch 90 
2025-12-16 06:22:50.756917: Current learning rate: 0.00919 
2025-12-16 06:25:08.601519: train_loss -0.7966 
2025-12-16 06:25:08.601519: val_loss -0.7974 
2025-12-16 06:25:08.603521: Pseudo dice [0.8832, 0.9302, 0.9052] 
2025-12-16 06:25:08.603521: Epoch time: 137.84 s 
2025-12-16 06:25:09.233560:  
2025-12-16 06:25:09.233560: Epoch 91 
2025-12-16 06:25:09.233560: Current learning rate: 0.00918 
2025-12-16 06:27:27.380934: train_loss -0.7996 
2025-12-16 06:27:27.380934: val_loss -0.8089 
2025-12-16 06:27:27.380934: Pseudo dice [0.8974, 0.9375, 0.8939] 
2025-12-16 06:27:27.396945: Epoch time: 138.15 s 
2025-12-16 06:27:27.999871:  
2025-12-16 06:27:27.999871: Epoch 92 
2025-12-16 06:27:27.999871: Current learning rate: 0.00917 
2025-12-16 06:29:45.873798: train_loss -0.7939 
2025-12-16 06:29:45.873798: val_loss -0.8236 
2025-12-16 06:29:45.877803: Pseudo dice [0.9026, 0.9402, 0.913] 
2025-12-16 06:29:45.877803: Epoch time: 137.87 s 
2025-12-16 06:29:45.879804: Yayy! New best EMA pseudo Dice: 0.9104 
2025-12-16 06:29:46.722537:  
2025-12-16 06:29:46.722537: Epoch 93 
2025-12-16 06:29:46.722537: Current learning rate: 0.00916 
2025-12-16 06:32:04.729845: train_loss -0.7969 
2025-12-16 06:32:04.729845: val_loss -0.8183 
2025-12-16 06:32:04.729845: Pseudo dice [0.903, 0.9411, 0.9053] 
2025-12-16 06:32:04.729845: Epoch time: 138.01 s 
2025-12-16 06:32:04.729845: Yayy! New best EMA pseudo Dice: 0.911 
2025-12-16 06:32:05.695252:  
2025-12-16 06:32:05.695252: Epoch 94 
2025-12-16 06:32:05.695252: Current learning rate: 0.00915 
2025-12-16 06:34:23.549925: train_loss -0.7943 
2025-12-16 06:34:23.549925: val_loss -0.8041 
2025-12-16 06:34:23.549925: Pseudo dice [0.893, 0.9309, 0.8977] 
2025-12-16 06:34:23.549925: Epoch time: 137.85 s 
2025-12-16 06:34:24.168117:  
2025-12-16 06:34:24.168117: Epoch 95 
2025-12-16 06:34:24.168117: Current learning rate: 0.00914 
2025-12-16 06:36:42.114124: train_loss -0.8082 
2025-12-16 06:36:42.116126: val_loss -0.8081 
2025-12-16 06:36:42.117866: Pseudo dice [0.8935, 0.9322, 0.9055] 
2025-12-16 06:36:42.117866: Epoch time: 137.95 s 
2025-12-16 06:36:42.904596:  
2025-12-16 06:36:42.904596: Epoch 96 
2025-12-16 06:36:42.904596: Current learning rate: 0.00913 
2025-12-16 06:39:00.841005: train_loss -0.8077 
2025-12-16 06:39:00.841005: val_loss -0.8038 
2025-12-16 06:39:00.841005: Pseudo dice [0.8903, 0.9335, 0.9013] 
2025-12-16 06:39:00.856769: Epoch time: 137.94 s 
2025-12-16 06:39:01.587850:  
2025-12-16 06:39:01.587850: Epoch 97 
2025-12-16 06:39:01.587850: Current learning rate: 0.00912 
2025-12-16 06:41:19.696202: train_loss -0.809 
2025-12-16 06:41:19.696202: val_loss -0.8321 
2025-12-16 06:41:19.698205: Pseudo dice [0.9099, 0.9499, 0.9036] 
2025-12-16 06:41:19.698205: Epoch time: 138.11 s 
2025-12-16 06:41:19.698205: Yayy! New best EMA pseudo Dice: 0.9114 
2025-12-16 06:41:20.559130:  
2025-12-16 06:41:20.559130: Epoch 98 
2025-12-16 06:41:20.559130: Current learning rate: 0.00911 
2025-12-16 06:43:38.588167: train_loss -0.8028 
2025-12-16 06:43:38.588167: val_loss -0.8205 
2025-12-16 06:43:38.588167: Pseudo dice [0.9072, 0.9423, 0.9062] 
2025-12-16 06:43:38.588167: Epoch time: 138.03 s 
2025-12-16 06:43:38.588167: Yayy! New best EMA pseudo Dice: 0.9122 
2025-12-16 06:43:39.473575:  
2025-12-16 06:43:39.475395: Epoch 99 
2025-12-16 06:43:39.475395: Current learning rate: 0.0091 
2025-12-16 06:45:57.572548: train_loss -0.8016 
2025-12-16 06:45:57.572548: val_loss -0.827 
2025-12-16 06:45:57.574552: Pseudo dice [0.9134, 0.9432, 0.8954] 
2025-12-16 06:45:57.576555: Epoch time: 138.1 s 
2025-12-16 06:45:57.834612: Yayy! New best EMA pseudo Dice: 0.9127 
2025-12-16 06:45:58.838291:  
2025-12-16 06:45:58.850825: Epoch 100 
2025-12-16 06:45:58.850825: Current learning rate: 0.0091 
2025-12-16 06:48:16.792234: train_loss -0.8058 
2025-12-16 06:48:16.794237: val_loss -0.8197 
2025-12-16 06:48:16.796072: Pseudo dice [0.8997, 0.9423, 0.8992] 
2025-12-16 06:48:16.796072: Epoch time: 137.95 s 
2025-12-16 06:48:16.798075: Yayy! New best EMA pseudo Dice: 0.9128 
2025-12-16 06:48:17.677306:  
2025-12-16 06:48:17.679117: Epoch 101 
2025-12-16 06:48:17.680859: Current learning rate: 0.00909 
2025-12-16 06:50:35.817964: train_loss -0.811 
2025-12-16 06:50:35.817964: val_loss -0.823 
2025-12-16 06:50:35.819967: Pseudo dice [0.9038, 0.9424, 0.9027] 
2025-12-16 06:50:35.821968: Epoch time: 138.14 s 
2025-12-16 06:50:35.821968: Yayy! New best EMA pseudo Dice: 0.9131 
2025-12-16 06:50:36.715034:  
2025-12-16 06:50:36.715034: Epoch 102 
2025-12-16 06:50:36.715034: Current learning rate: 0.00908 
2025-12-16 06:52:54.601068: train_loss -0.8065 
2025-12-16 06:52:54.601068: val_loss -0.831 
2025-12-16 06:52:54.617066: Pseudo dice [0.9102, 0.9436, 0.9018] 
2025-12-16 06:52:54.617066: Epoch time: 137.89 s 
2025-12-16 06:52:54.617066: Yayy! New best EMA pseudo Dice: 0.9137 
2025-12-16 06:52:55.756529:  
2025-12-16 06:52:55.758392: Epoch 103 
2025-12-16 06:52:55.758392: Current learning rate: 0.00907 
2025-12-16 06:55:13.708247: train_loss -0.8058 
2025-12-16 06:55:13.708247: val_loss -0.8217 
2025-12-16 06:55:13.710251: Pseudo dice [0.9053, 0.9436, 0.8982] 
2025-12-16 06:55:13.712254: Epoch time: 137.95 s 
2025-12-16 06:55:13.712254: Yayy! New best EMA pseudo Dice: 0.9139 
2025-12-16 06:55:14.613018:  
2025-12-16 06:55:14.613018: Epoch 104 
2025-12-16 06:55:14.613018: Current learning rate: 0.00906 
2025-12-16 06:57:32.670336: train_loss -0.8033 
2025-12-16 06:57:32.670336: val_loss -0.8251 
2025-12-16 06:57:32.674340: Pseudo dice [0.9046, 0.9413, 0.9037] 
2025-12-16 06:57:32.674340: Epoch time: 138.06 s 
2025-12-16 06:57:32.676342: Yayy! New best EMA pseudo Dice: 0.9141 
2025-12-16 06:57:33.575412:  
2025-12-16 06:57:33.575412: Epoch 105 
2025-12-16 06:57:33.575412: Current learning rate: 0.00905 
2025-12-16 06:59:51.438244: train_loss -0.8161 
2025-12-16 06:59:51.438244: val_loss -0.8184 
2025-12-16 06:59:51.438244: Pseudo dice [0.8967, 0.9375, 0.9066] 
2025-12-16 06:59:51.443752: Epoch time: 137.86 s 
2025-12-16 06:59:52.228300:  
2025-12-16 06:59:52.228300: Epoch 106 
2025-12-16 06:59:52.228300: Current learning rate: 0.00904 
2025-12-16 07:02:10.282017: train_loss -0.8084 
2025-12-16 07:02:10.282017: val_loss -0.8112 
2025-12-16 07:02:10.284020: Pseudo dice [0.8961, 0.9329, 0.9068] 
2025-12-16 07:02:10.286021: Epoch time: 138.07 s 
2025-12-16 07:02:10.925228:  
2025-12-16 07:02:10.925228: Epoch 107 
2025-12-16 07:02:10.925228: Current learning rate: 0.00903 
2025-12-16 07:04:28.899063: train_loss -0.8097 
2025-12-16 07:04:28.899063: val_loss -0.831 
2025-12-16 07:04:28.899063: Pseudo dice [0.9094, 0.9498, 0.9041] 
2025-12-16 07:04:28.914800: Epoch time: 137.97 s 
2025-12-16 07:04:28.914800: Yayy! New best EMA pseudo Dice: 0.9146 
2025-12-16 07:04:29.771517:  
2025-12-16 07:04:29.771517: Epoch 108 
2025-12-16 07:04:29.771517: Current learning rate: 0.00902 
2025-12-16 07:06:47.723268: train_loss -0.8118 
2025-12-16 07:06:47.723268: val_loss -0.821 
2025-12-16 07:06:47.723268: Pseudo dice [0.9034, 0.9406, 0.9067] 
2025-12-16 07:06:47.736795: Epoch time: 137.97 s 
2025-12-16 07:06:47.738799: Yayy! New best EMA pseudo Dice: 0.9148 
2025-12-16 07:06:48.966311:  
2025-12-16 07:06:48.968314: Epoch 109 
2025-12-16 07:06:48.970318: Current learning rate: 0.00901 
2025-12-16 07:09:06.990718: train_loss -0.8096 
2025-12-16 07:09:06.990718: val_loss -0.8326 
2025-12-16 07:09:06.990718: Pseudo dice [0.9052, 0.9431, 0.9142] 
2025-12-16 07:09:06.990718: Epoch time: 138.02 s 
2025-12-16 07:09:06.990718: Yayy! New best EMA pseudo Dice: 0.9154 
2025-12-16 07:09:07.861807:  
2025-12-16 07:09:07.861807: Epoch 110 
2025-12-16 07:09:07.877668: Current learning rate: 0.009 
2025-12-16 07:11:26.476675: train_loss -0.8163 
2025-12-16 07:11:26.476675: val_loss -0.8232 
2025-12-16 07:11:26.480679: Pseudo dice [0.9037, 0.9408, 0.897] 
2025-12-16 07:11:26.482681: Epoch time: 138.61 s 
2025-12-16 07:11:27.123350:  
2025-12-16 07:11:27.123350: Epoch 111 
2025-12-16 07:11:27.123350: Current learning rate: 0.009 
2025-12-16 07:13:45.053591: train_loss -0.8124 
2025-12-16 07:13:45.053591: val_loss -0.82 
2025-12-16 07:13:45.055593: Pseudo dice [0.9019, 0.9404, 0.8946] 
2025-12-16 07:13:45.057595: Epoch time: 137.93 s 
2025-12-16 07:13:45.770086:  
2025-12-16 07:13:45.770086: Epoch 112 
2025-12-16 07:13:45.770086: Current learning rate: 0.00899 
2025-12-16 07:16:03.878836: train_loss -0.8139 
2025-12-16 07:16:03.894652: val_loss -0.8194 
2025-12-16 07:16:03.896442: Pseudo dice [0.9016, 0.9414, 0.9043] 
2025-12-16 07:16:03.898445: Epoch time: 138.11 s 
2025-12-16 07:16:04.526295:  
2025-12-16 07:16:04.526295: Epoch 113 
2025-12-16 07:16:04.526295: Current learning rate: 0.00898 
2025-12-16 07:18:22.493658: train_loss -0.8136 
2025-12-16 07:18:22.493658: val_loss -0.8242 
2025-12-16 07:18:22.503704: Pseudo dice [0.905, 0.9417, 0.9019] 
2025-12-16 07:18:22.503704: Epoch time: 137.97 s 
2025-12-16 07:18:23.123390:  
2025-12-16 07:18:23.123390: Epoch 114 
2025-12-16 07:18:23.123390: Current learning rate: 0.00897 
2025-12-16 07:20:41.032346: train_loss -0.8151 
2025-12-16 07:20:41.032346: val_loss -0.8339 
2025-12-16 07:20:41.032346: Pseudo dice [0.9064, 0.9475, 0.9095] 
2025-12-16 07:20:41.037366: Epoch time: 137.91 s 
2025-12-16 07:20:41.037366: Yayy! New best EMA pseudo Dice: 0.9158 
2025-12-16 07:20:42.252425:  
2025-12-16 07:20:42.252425: Epoch 115 
2025-12-16 07:20:42.252425: Current learning rate: 0.00896 
2025-12-16 07:23:00.158074: train_loss -0.8098 
2025-12-16 07:23:00.160077: val_loss -0.8272 
2025-12-16 07:23:00.160077: Pseudo dice [0.9106, 0.9449, 0.8999] 
2025-12-16 07:23:00.160077: Epoch time: 137.92 s 
2025-12-16 07:23:00.160077: Yayy! New best EMA pseudo Dice: 0.916 
2025-12-16 07:23:01.056574:  
2025-12-16 07:23:01.056574: Epoch 116 
2025-12-16 07:23:01.056574: Current learning rate: 0.00895 
2025-12-16 07:25:18.940677: train_loss -0.8095 
2025-12-16 07:25:18.940677: val_loss -0.8229 
2025-12-16 07:25:18.942679: Pseudo dice [0.9052, 0.9436, 0.8986] 
2025-12-16 07:25:18.944419: Epoch time: 137.89 s 
2025-12-16 07:25:19.572071:  
2025-12-16 07:25:19.572071: Epoch 117 
2025-12-16 07:25:19.572071: Current learning rate: 0.00894 
2025-12-16 07:27:37.613979: train_loss -0.8092 
2025-12-16 07:27:37.613979: val_loss -0.8239 
2025-12-16 07:27:37.613979: Pseudo dice [0.9028, 0.9413, 0.9094] 
2025-12-16 07:27:37.613979: Epoch time: 138.04 s 
2025-12-16 07:27:37.613979: Yayy! New best EMA pseudo Dice: 0.9162 
2025-12-16 07:27:38.591943:  
2025-12-16 07:27:38.591943: Epoch 118 
2025-12-16 07:27:38.591943: Current learning rate: 0.00893 
2025-12-16 07:29:56.429544: train_loss -0.8218 
2025-12-16 07:29:56.429544: val_loss -0.8395 
2025-12-16 07:29:56.429544: Pseudo dice [0.918, 0.948, 0.9088] 
2025-12-16 07:29:56.429544: Epoch time: 137.84 s 
2025-12-16 07:29:56.429544: Yayy! New best EMA pseudo Dice: 0.9171 
2025-12-16 07:29:57.318383:  
2025-12-16 07:29:57.318383: Epoch 119 
2025-12-16 07:29:57.318383: Current learning rate: 0.00892 
2025-12-16 07:32:15.538294: train_loss -0.8164 
2025-12-16 07:32:15.554067: val_loss -0.8398 
2025-12-16 07:32:15.554067: Pseudo dice [0.9143, 0.9484, 0.9057] 
2025-12-16 07:32:15.554067: Epoch time: 138.24 s 
2025-12-16 07:32:15.554067: Yayy! New best EMA pseudo Dice: 0.9176 
2025-12-16 07:32:16.456086:  
2025-12-16 07:32:16.457826: Epoch 120 
2025-12-16 07:32:16.457826: Current learning rate: 0.00891 
2025-12-16 07:34:34.463506: train_loss -0.8161 
2025-12-16 07:34:34.479173: val_loss -0.8296 
2025-12-16 07:34:34.479173: Pseudo dice [0.9074, 0.9415, 0.9035] 
2025-12-16 07:34:34.479173: Epoch time: 138.01 s 
2025-12-16 07:34:35.401632:  
2025-12-16 07:34:35.401632: Epoch 121 
2025-12-16 07:34:35.401632: Current learning rate: 0.0089 
2025-12-16 07:36:53.453721: train_loss -0.8051 
2025-12-16 07:36:53.455724: val_loss -0.8268 
2025-12-16 07:36:53.457726: Pseudo dice [0.9052, 0.9472, 0.9087] 
2025-12-16 07:36:53.459727: Epoch time: 138.05 s 
2025-12-16 07:36:53.461729: Yayy! New best EMA pseudo Dice: 0.9179 
2025-12-16 07:36:54.355407:  
2025-12-16 07:36:54.357409: Epoch 122 
2025-12-16 07:36:54.357409: Current learning rate: 0.00889 
2025-12-16 07:39:12.146041: train_loss -0.8122 
2025-12-16 07:39:12.146041: val_loss -0.8291 
2025-12-16 07:39:12.146041: Pseudo dice [0.905, 0.9407, 0.9145] 
2025-12-16 07:39:12.146041: Epoch time: 137.79 s 
2025-12-16 07:39:12.146041: Yayy! New best EMA pseudo Dice: 0.9181 
2025-12-16 07:39:13.042765:  
2025-12-16 07:39:13.042765: Epoch 123 
2025-12-16 07:39:13.042765: Current learning rate: 0.00889 
2025-12-16 07:41:31.117325: train_loss -0.8113 
2025-12-16 07:41:31.117325: val_loss -0.8091 
2025-12-16 07:41:31.117325: Pseudo dice [0.893, 0.9346, 0.9038] 
2025-12-16 07:41:31.117325: Epoch time: 138.08 s 
2025-12-16 07:41:31.858912:  
2025-12-16 07:41:31.858912: Epoch 124 
2025-12-16 07:41:31.874723: Current learning rate: 0.00888 
2025-12-16 07:43:49.915825: train_loss -0.8158 
2025-12-16 07:43:49.917827: val_loss -0.8246 
2025-12-16 07:43:49.917827: Pseudo dice [0.9048, 0.9409, 0.91] 
2025-12-16 07:43:49.917827: Epoch time: 138.06 s 
2025-12-16 07:43:50.544592:  
2025-12-16 07:43:50.544592: Epoch 125 
2025-12-16 07:43:50.544592: Current learning rate: 0.00887 
2025-12-16 07:46:08.526284: train_loss -0.8162 
2025-12-16 07:46:08.526284: val_loss -0.8419 
2025-12-16 07:46:08.526284: Pseudo dice [0.9121, 0.9468, 0.9142] 
2025-12-16 07:46:08.526284: Epoch time: 137.99 s 
2025-12-16 07:46:08.526284: Yayy! New best EMA pseudo Dice: 0.9182 
2025-12-16 07:46:09.395917:  
2025-12-16 07:46:09.395917: Epoch 126 
2025-12-16 07:46:09.395917: Current learning rate: 0.00886 
2025-12-16 07:48:27.312660: train_loss -0.8139 
2025-12-16 07:48:27.314663: val_loss -0.83 
2025-12-16 07:48:27.314663: Pseudo dice [0.9068, 0.946, 0.9037] 
2025-12-16 07:48:27.314663: Epoch time: 137.92 s 
2025-12-16 07:48:27.314663: Yayy! New best EMA pseudo Dice: 0.9182 
2025-12-16 07:48:28.527623:  
2025-12-16 07:48:28.543591: Epoch 127 
2025-12-16 07:48:28.543591: Current learning rate: 0.00885 
2025-12-16 07:50:46.399028: train_loss -0.8142 
2025-12-16 07:50:46.399028: val_loss -0.8448 
2025-12-16 07:50:46.399028: Pseudo dice [0.9169, 0.9461, 0.9106] 
2025-12-16 07:50:46.399028: Epoch time: 137.87 s 
2025-12-16 07:50:46.399028: Yayy! New best EMA pseudo Dice: 0.9189 
2025-12-16 07:50:47.284914:  
2025-12-16 07:50:47.284914: Epoch 128 
2025-12-16 07:50:47.300993: Current learning rate: 0.00884 
2025-12-16 07:53:05.236288: train_loss -0.819 
2025-12-16 07:53:05.238291: val_loss -0.8364 
2025-12-16 07:53:05.240292: Pseudo dice [0.9077, 0.9436, 0.9242] 
2025-12-16 07:53:05.242294: Epoch time: 137.95 s 
2025-12-16 07:53:05.244297: Yayy! New best EMA pseudo Dice: 0.9195 
2025-12-16 07:53:06.128640:  
2025-12-16 07:53:06.144431: Epoch 129 
2025-12-16 07:53:06.144431: Current learning rate: 0.00883 
2025-12-16 07:55:23.938346: train_loss -0.8144 
2025-12-16 07:55:23.938346: val_loss -0.8246 
2025-12-16 07:55:23.938346: Pseudo dice [0.9031, 0.9402, 0.9072] 
2025-12-16 07:55:23.938346: Epoch time: 137.81 s 
2025-12-16 07:55:24.688314:  
2025-12-16 07:55:24.688314: Epoch 130 
2025-12-16 07:55:24.690318: Current learning rate: 0.00882 
2025-12-16 07:57:42.620835: train_loss -0.8084 
2025-12-16 07:57:42.620835: val_loss -0.8145 
2025-12-16 07:57:42.620835: Pseudo dice [0.9003, 0.9407, 0.8989] 
2025-12-16 07:57:42.620835: Epoch time: 137.93 s 
2025-12-16 07:57:43.270276:  
2025-12-16 07:57:43.270276: Epoch 131 
2025-12-16 07:57:43.286261: Current learning rate: 0.00881 
2025-12-16 08:00:02.445165: train_loss -0.8148 
2025-12-16 08:00:02.445165: val_loss -0.833 
2025-12-16 08:00:02.445165: Pseudo dice [0.9065, 0.944, 0.9079] 
2025-12-16 08:00:02.460949: Epoch time: 139.17 s 
2025-12-16 08:00:03.087065:  
2025-12-16 08:00:03.087065: Epoch 132 
2025-12-16 08:00:03.087065: Current learning rate: 0.0088 
2025-12-16 08:02:21.230690: train_loss -0.8133 
2025-12-16 08:02:21.230690: val_loss -0.8285 
2025-12-16 08:02:21.230690: Pseudo dice [0.9088, 0.9455, 0.895] 
2025-12-16 08:02:21.230690: Epoch time: 138.14 s 
2025-12-16 08:02:22.220348:  
2025-12-16 08:02:22.220348: Epoch 133 
2025-12-16 08:02:22.220348: Current learning rate: 0.00879 
2025-12-16 08:04:40.420774: train_loss -0.8046 
2025-12-16 08:04:40.420774: val_loss -0.8304 
2025-12-16 08:04:40.422777: Pseudo dice [0.9138, 0.9431, 0.9035] 
2025-12-16 08:04:40.422777: Epoch time: 138.2 s 
2025-12-16 08:04:41.043418:  
2025-12-16 08:04:41.043418: Epoch 134 
2025-12-16 08:04:41.043418: Current learning rate: 0.00879 
2025-12-16 08:06:59.039310: train_loss -0.8166 
2025-12-16 08:06:59.055130: val_loss -0.8249 
2025-12-16 08:06:59.057077: Pseudo dice [0.9066, 0.9387, 0.9106] 
2025-12-16 08:06:59.057077: Epoch time: 138.0 s 
2025-12-16 08:06:59.694614:  
2025-12-16 08:06:59.694614: Epoch 135 
2025-12-16 08:06:59.694614: Current learning rate: 0.00878 
2025-12-16 08:09:17.910825: train_loss -0.8119 
2025-12-16 08:09:17.910825: val_loss -0.821 
2025-12-16 08:09:17.926459: Pseudo dice [0.8961, 0.942, 0.916] 
2025-12-16 08:09:17.928351: Epoch time: 138.22 s 
2025-12-16 08:09:18.660184:  
2025-12-16 08:09:18.660184: Epoch 136 
2025-12-16 08:09:18.660184: Current learning rate: 0.00877 
2025-12-16 08:11:36.774931: train_loss -0.8157 
2025-12-16 08:11:36.774931: val_loss -0.8306 
2025-12-16 08:11:36.774931: Pseudo dice [0.906, 0.9442, 0.8988] 
2025-12-16 08:11:36.774931: Epoch time: 138.11 s 
2025-12-16 08:11:37.440377:  
2025-12-16 08:11:37.440377: Epoch 137 
2025-12-16 08:11:37.440377: Current learning rate: 0.00876 
2025-12-16 08:13:55.415548: train_loss -0.8138 
2025-12-16 08:13:55.417551: val_loss -0.826 
2025-12-16 08:13:55.421557: Pseudo dice [0.9063, 0.9425, 0.9153] 
2025-12-16 08:13:55.423559: Epoch time: 137.98 s 
2025-12-16 08:13:56.063657:  
2025-12-16 08:13:56.063657: Epoch 138 
2025-12-16 08:13:56.063657: Current learning rate: 0.00875 
2025-12-16 08:16:14.005322: train_loss -0.8118 
2025-12-16 08:16:14.005322: val_loss -0.8417 
2025-12-16 08:16:14.005322: Pseudo dice [0.9164, 0.9432, 0.9221] 
2025-12-16 08:16:14.005322: Epoch time: 137.94 s 
2025-12-16 08:16:14.005322: Yayy! New best EMA pseudo Dice: 0.9195 
2025-12-16 08:16:15.209779:  
2025-12-16 08:16:15.209779: Epoch 139 
2025-12-16 08:16:15.209779: Current learning rate: 0.00874 
2025-12-16 08:18:33.059963: train_loss -0.7745 
2025-12-16 08:18:33.059963: val_loss -0.7778 
2025-12-16 08:18:33.059963: Pseudo dice [0.8859, 0.9272, 0.8741] 
2025-12-16 08:18:33.059963: Epoch time: 137.85 s 
2025-12-16 08:18:33.709684:  
2025-12-16 08:18:33.709684: Epoch 140 
2025-12-16 08:18:33.709684: Current learning rate: 0.00873 
2025-12-16 08:20:51.647556: train_loss -0.7958 
2025-12-16 08:20:51.649558: val_loss -0.8079 
2025-12-16 08:20:51.651560: Pseudo dice [0.8911, 0.9325, 0.9125] 
2025-12-16 08:20:51.653562: Epoch time: 137.95 s 
2025-12-16 08:20:52.292313:  
2025-12-16 08:20:52.292313: Epoch 141 
2025-12-16 08:20:52.292313: Current learning rate: 0.00872 
2025-12-16 08:23:10.292566: train_loss -0.7971 
2025-12-16 08:23:10.292566: val_loss -0.7909 
2025-12-16 08:23:10.294568: Pseudo dice [0.887, 0.9345, 0.8883] 
2025-12-16 08:23:10.294568: Epoch time: 138.0 s 
2025-12-16 08:23:11.112309:  
2025-12-16 08:23:11.112309: Epoch 142 
2025-12-16 08:23:11.112309: Current learning rate: 0.00871 
2025-12-16 08:25:28.852893: train_loss -0.8033 
2025-12-16 08:25:28.855161: val_loss -0.8299 
2025-12-16 08:25:28.857163: Pseudo dice [0.9162, 0.9479, 0.9005] 
2025-12-16 08:25:28.857163: Epoch time: 137.74 s 
2025-12-16 08:25:29.499963:  
2025-12-16 08:25:29.499963: Epoch 143 
2025-12-16 08:25:29.499963: Current learning rate: 0.0087 
2025-12-16 08:27:47.603652: train_loss -0.8068 
2025-12-16 08:27:47.603652: val_loss -0.8187 
2025-12-16 08:27:47.607660: Pseudo dice [0.9045, 0.939, 0.8956] 
2025-12-16 08:27:47.609663: Epoch time: 138.1 s 
2025-12-16 08:27:48.254272:  
2025-12-16 08:27:48.254272: Epoch 144 
2025-12-16 08:27:48.254272: Current learning rate: 0.00869 
2025-12-16 08:30:06.207587: train_loss -0.8103 
2025-12-16 08:30:06.207587: val_loss -0.8294 
2025-12-16 08:30:06.211330: Pseudo dice [0.9045, 0.943, 0.9165] 
2025-12-16 08:30:06.213171: Epoch time: 137.95 s 
2025-12-16 08:30:07.097632:  
2025-12-16 08:30:07.097632: Epoch 145 
2025-12-16 08:30:07.097632: Current learning rate: 0.00868 
2025-12-16 08:32:24.971073: train_loss -0.8124 
2025-12-16 08:32:24.973075: val_loss -0.838 
2025-12-16 08:32:24.975077: Pseudo dice [0.9181, 0.9473, 0.9138] 
2025-12-16 08:32:24.976818: Epoch time: 137.87 s 
2025-12-16 08:32:25.626074:  
2025-12-16 08:32:25.626074: Epoch 146 
2025-12-16 08:32:25.626074: Current learning rate: 0.00868 
2025-12-16 08:34:43.546978: train_loss -0.8146 
2025-12-16 08:34:43.546978: val_loss -0.8251 
2025-12-16 08:34:43.548980: Pseudo dice [0.9044, 0.9441, 0.9088] 
2025-12-16 08:34:43.548980: Epoch time: 137.92 s 
2025-12-16 08:34:44.193823:  
2025-12-16 08:34:44.193823: Epoch 147 
2025-12-16 08:34:44.193823: Current learning rate: 0.00867 
2025-12-16 08:37:02.006536: train_loss -0.8084 
2025-12-16 08:37:02.008538: val_loss -0.8267 
2025-12-16 08:37:02.012543: Pseudo dice [0.9015, 0.9428, 0.9069] 
2025-12-16 08:37:02.016553: Epoch time: 137.83 s 
2025-12-16 08:37:02.652684:  
2025-12-16 08:37:02.652684: Epoch 148 
2025-12-16 08:37:02.652684: Current learning rate: 0.00866 
2025-12-16 08:39:20.392180: train_loss -0.8124 
2025-12-16 08:39:20.392180: val_loss -0.8313 
2025-12-16 08:39:20.392180: Pseudo dice [0.9119, 0.9496, 0.9025] 
2025-12-16 08:39:20.407961: Epoch time: 137.74 s 
2025-12-16 08:39:21.040771:  
2025-12-16 08:39:21.040771: Epoch 149 
2025-12-16 08:39:21.040771: Current learning rate: 0.00865 
2025-12-16 08:41:39.086846: train_loss -0.8159 
2025-12-16 08:41:39.088848: val_loss -0.8337 
2025-12-16 08:41:39.092595: Pseudo dice [0.9125, 0.9453, 0.9078] 
2025-12-16 08:41:39.094597: Epoch time: 138.05 s 
2025-12-16 08:41:40.071059:  
2025-12-16 08:41:40.071059: Epoch 150 
2025-12-16 08:41:40.071059: Current learning rate: 0.00864 
2025-12-16 08:43:58.207414: train_loss -0.8167 
2025-12-16 08:43:58.209416: val_loss -0.8345 
2025-12-16 08:43:58.211418: Pseudo dice [0.9106, 0.9443, 0.9048] 
2025-12-16 08:43:58.211418: Epoch time: 138.14 s 
2025-12-16 08:43:59.025797:  
2025-12-16 08:43:59.025797: Epoch 151 
2025-12-16 08:43:59.025797: Current learning rate: 0.00863 
2025-12-16 08:46:17.073371: train_loss -0.8188 
2025-12-16 08:46:17.075373: val_loss -0.8369 
2025-12-16 08:46:17.077375: Pseudo dice [0.9096, 0.9462, 0.9099] 
2025-12-16 08:46:17.077375: Epoch time: 138.05 s 
2025-12-16 08:46:17.727559:  
2025-12-16 08:46:17.727559: Epoch 152 
2025-12-16 08:46:17.727559: Current learning rate: 0.00862 
2025-12-16 08:48:35.613771: train_loss -0.8188 
2025-12-16 08:48:35.615777: val_loss -0.8381 
2025-12-16 08:48:35.617518: Pseudo dice [0.9075, 0.9455, 0.9215] 
2025-12-16 08:48:35.619521: Epoch time: 137.89 s 
2025-12-16 08:48:36.441549:  
2025-12-16 08:48:36.441549: Epoch 153 
2025-12-16 08:48:36.441549: Current learning rate: 0.00861 
2025-12-16 08:50:54.463149: train_loss -0.8205 
2025-12-16 08:50:54.463149: val_loss -0.8433 
2025-12-16 08:50:54.468743: Pseudo dice [0.9191, 0.9524, 0.9025] 
2025-12-16 08:50:54.470744: Epoch time: 138.04 s 
2025-12-16 08:50:54.470744: Yayy! New best EMA pseudo Dice: 0.9199 
2025-12-16 08:50:55.347893:  
2025-12-16 08:50:55.347893: Epoch 154 
2025-12-16 08:50:55.347893: Current learning rate: 0.0086 
2025-12-16 08:53:13.145121: train_loss -0.818 
2025-12-16 08:53:13.145121: val_loss -0.8308 
2025-12-16 08:53:13.147123: Pseudo dice [0.9084, 0.936, 0.9116] 
2025-12-16 08:53:13.150359: Epoch time: 137.8 s 
2025-12-16 08:53:13.805763:  
2025-12-16 08:53:13.805763: Epoch 155 
2025-12-16 08:53:13.805763: Current learning rate: 0.00859 
2025-12-16 08:55:31.881943: train_loss -0.8201 
2025-12-16 08:55:31.881943: val_loss -0.852 
2025-12-16 08:55:31.885948: Pseudo dice [0.9224, 0.9534, 0.9166] 
2025-12-16 08:55:31.889691: Epoch time: 138.08 s 
2025-12-16 08:55:31.891693: Yayy! New best EMA pseudo Dice: 0.9208 
2025-12-16 08:55:32.998777:  
2025-12-16 08:55:32.998777: Epoch 156 
2025-12-16 08:55:32.998777: Current learning rate: 0.00858 
2025-12-16 08:57:50.879634: train_loss -0.8192 
2025-12-16 08:57:50.881376: val_loss -0.8483 
2025-12-16 08:57:50.885385: Pseudo dice [0.9172, 0.9521, 0.9183] 
2025-12-16 08:57:50.887387: Epoch time: 137.88 s 
2025-12-16 08:57:50.889389: Yayy! New best EMA pseudo Dice: 0.9217 
2025-12-16 08:57:51.979815:  
2025-12-16 08:57:51.979815: Epoch 157 
2025-12-16 08:57:51.979815: Current learning rate: 0.00858 
2025-12-16 09:00:09.865686: train_loss -0.8278 
2025-12-16 09:00:09.881608: val_loss -0.847 
2025-12-16 09:00:09.881608: Pseudo dice [0.9179, 0.9491, 0.9175] 
2025-12-16 09:00:09.881608: Epoch time: 137.89 s 
2025-12-16 09:00:09.887039: Yayy! New best EMA pseudo Dice: 0.9223 
2025-12-16 09:00:10.811819:  
2025-12-16 09:00:10.811819: Epoch 158 
2025-12-16 09:00:10.811819: Current learning rate: 0.00857 
2025-12-16 09:02:28.794671: train_loss -0.8242 
2025-12-16 09:02:28.794671: val_loss -0.8245 
2025-12-16 09:02:28.794671: Pseudo dice [0.9029, 0.9408, 0.9011] 
2025-12-16 09:02:28.808901: Epoch time: 137.98 s 
2025-12-16 09:02:29.606963:  
2025-12-16 09:02:29.606963: Epoch 159 
2025-12-16 09:02:29.606963: Current learning rate: 0.00856 
2025-12-16 09:04:47.723097: train_loss -0.8199 
2025-12-16 09:04:47.723097: val_loss -0.8334 
2025-12-16 09:04:47.725100: Pseudo dice [0.9071, 0.9459, 0.9111] 
2025-12-16 09:04:47.725100: Epoch time: 138.12 s 
2025-12-16 09:04:48.392933:  
2025-12-16 09:04:48.392933: Epoch 160 
2025-12-16 09:04:48.392933: Current learning rate: 0.00855 
2025-12-16 09:07:06.375530: train_loss -0.8246 
2025-12-16 09:07:06.391251: val_loss -0.8374 
2025-12-16 09:07:06.393306: Pseudo dice [0.9075, 0.9394, 0.918] 
2025-12-16 09:07:06.393306: Epoch time: 137.98 s 
2025-12-16 09:07:07.042664:  
2025-12-16 09:07:07.042664: Epoch 161 
2025-12-16 09:07:07.042664: Current learning rate: 0.00854 
2025-12-16 09:09:25.180270: train_loss -0.8301 
2025-12-16 09:09:25.180270: val_loss -0.8406 
2025-12-16 09:09:25.184015: Pseudo dice [0.9099, 0.9445, 0.9144] 
2025-12-16 09:09:25.186018: Epoch time: 138.14 s 
2025-12-16 09:09:26.192772:  
2025-12-16 09:09:26.192772: Epoch 162 
2025-12-16 09:09:26.196778: Current learning rate: 0.00853 
2025-12-16 09:11:44.314291: train_loss -0.8275 
2025-12-16 09:11:44.314291: val_loss -0.8367 
2025-12-16 09:11:44.314291: Pseudo dice [0.9065, 0.9474, 0.9121] 
2025-12-16 09:11:44.314291: Epoch time: 138.12 s 
2025-12-16 09:11:44.949655:  
2025-12-16 09:11:44.949655: Epoch 163 
2025-12-16 09:11:44.965695: Current learning rate: 0.00852 
2025-12-16 09:14:02.993183: train_loss -0.8249 
2025-12-16 09:14:02.993183: val_loss -0.8533 
2025-12-16 09:14:02.993183: Pseudo dice [0.9171, 0.9513, 0.9223] 
2025-12-16 09:14:02.993183: Epoch time: 138.04 s 
2025-12-16 09:14:02.993183: Yayy! New best EMA pseudo Dice: 0.9226 
2025-12-16 09:14:03.881413:  
2025-12-16 09:14:03.881413: Epoch 164 
2025-12-16 09:14:03.881413: Current learning rate: 0.00851 
2025-12-16 09:16:21.877011: train_loss -0.8256 
2025-12-16 09:16:21.877011: val_loss -0.8366 
2025-12-16 09:16:21.879015: Pseudo dice [0.908, 0.9454, 0.9271] 
2025-12-16 09:16:21.881018: Epoch time: 138.0 s 
2025-12-16 09:16:21.882759: Yayy! New best EMA pseudo Dice: 0.923 
2025-12-16 09:16:22.973123:  
2025-12-16 09:16:22.973123: Epoch 165 
2025-12-16 09:16:22.973123: Current learning rate: 0.0085 
2025-12-16 09:18:40.889887: train_loss -0.8152 
2025-12-16 09:18:40.889887: val_loss -0.8389 
2025-12-16 09:18:40.893630: Pseudo dice [0.9163, 0.9456, 0.912] 
2025-12-16 09:18:40.893630: Epoch time: 137.92 s 
2025-12-16 09:18:40.893630: Yayy! New best EMA pseudo Dice: 0.9232 
2025-12-16 09:18:41.812716:  
2025-12-16 09:18:41.812716: Epoch 166 
2025-12-16 09:18:41.812716: Current learning rate: 0.00849 
2025-12-16 09:20:59.798169: train_loss -0.821 
2025-12-16 09:20:59.800172: val_loss -0.8444 
2025-12-16 09:20:59.802173: Pseudo dice [0.9102, 0.9484, 0.9312] 
2025-12-16 09:20:59.804175: Epoch time: 137.99 s 
2025-12-16 09:20:59.806178: Yayy! New best EMA pseudo Dice: 0.9239 
2025-12-16 09:21:00.730867:  
2025-12-16 09:21:00.730867: Epoch 167 
2025-12-16 09:21:00.730867: Current learning rate: 0.00848 
2025-12-16 09:23:18.700394: train_loss -0.8227 
2025-12-16 09:23:18.700394: val_loss -0.8565 
2025-12-16 09:23:18.704398: Pseudo dice [0.9235, 0.9575, 0.9201] 
2025-12-16 09:23:18.704398: Epoch time: 137.97 s 
2025-12-16 09:23:18.704398: Yayy! New best EMA pseudo Dice: 0.9248 
2025-12-16 09:23:19.955060:  
2025-12-16 09:23:19.955060: Epoch 168 
2025-12-16 09:23:19.955060: Current learning rate: 0.00847 
2025-12-16 09:25:37.930491: train_loss -0.8211 
2025-12-16 09:25:37.930491: val_loss -0.8063 
2025-12-16 09:25:37.932492: Pseudo dice [0.8935, 0.9389, 0.9066] 
2025-12-16 09:25:37.934494: Epoch time: 137.98 s 
2025-12-16 09:25:38.588709:  
2025-12-16 09:25:38.588709: Epoch 169 
2025-12-16 09:25:38.596265: Current learning rate: 0.00847 
2025-12-16 09:27:56.490700: train_loss -0.8148 
2025-12-16 09:27:56.490700: val_loss -0.8323 
2025-12-16 09:27:56.493688: Pseudo dice [0.9098, 0.9485, 0.9132] 
2025-12-16 09:27:56.495691: Epoch time: 137.9 s 
2025-12-16 09:27:57.149137:  
2025-12-16 09:27:57.149137: Epoch 170 
2025-12-16 09:27:57.154075: Current learning rate: 0.00846 
2025-12-16 09:30:14.917004: train_loss -0.8084 
2025-12-16 09:30:14.917004: val_loss -0.8388 
2025-12-16 09:30:14.920509: Pseudo dice [0.9114, 0.9438, 0.9199] 
2025-12-16 09:30:14.922511: Epoch time: 137.77 s 
2025-12-16 09:30:15.707001:  
2025-12-16 09:30:15.707001: Epoch 171 
2025-12-16 09:30:15.712379: Current learning rate: 0.00845 
2025-12-16 09:32:33.781558: train_loss -0.8201 
2025-12-16 09:32:33.781558: val_loss -0.8394 
2025-12-16 09:32:33.797327: Pseudo dice [0.9116, 0.9487, 0.9236] 
2025-12-16 09:32:33.797327: Epoch time: 138.07 s 
2025-12-16 09:32:34.432767:  
2025-12-16 09:32:34.432767: Epoch 172 
2025-12-16 09:32:34.444613: Current learning rate: 0.00844 
2025-12-16 09:34:52.489471: train_loss -0.824 
2025-12-16 09:34:52.491212: val_loss -0.8497 
2025-12-16 09:34:52.493215: Pseudo dice [0.9213, 0.9509, 0.9123] 
2025-12-16 09:34:52.493215: Epoch time: 138.06 s 
2025-12-16 09:34:53.139836:  
2025-12-16 09:34:53.139836: Epoch 173 
2025-12-16 09:34:53.155694: Current learning rate: 0.00843 
2025-12-16 09:37:11.382997: train_loss -0.8243 
2025-12-16 09:37:11.384998: val_loss -0.8381 
2025-12-16 09:37:11.387001: Pseudo dice [0.9046, 0.9423, 0.9194] 
2025-12-16 09:37:11.389003: Epoch time: 138.24 s 
2025-12-16 09:37:12.324250:  
2025-12-16 09:37:12.324250: Epoch 174 
2025-12-16 09:37:12.324250: Current learning rate: 0.00842 
2025-12-16 09:39:30.199776: train_loss -0.8182 
2025-12-16 09:39:30.199776: val_loss -0.8371 
2025-12-16 09:39:30.199776: Pseudo dice [0.9103, 0.9471, 0.912] 
2025-12-16 09:39:30.199776: Epoch time: 137.88 s 
2025-12-16 09:39:30.863528:  
2025-12-16 09:39:30.863528: Epoch 175 
2025-12-16 09:39:30.863528: Current learning rate: 0.00841 
2025-12-16 09:41:48.960871: train_loss -0.8213 
2025-12-16 09:41:48.960871: val_loss -0.8345 
2025-12-16 09:41:48.963245: Pseudo dice [0.9051, 0.9417, 0.9235] 
2025-12-16 09:41:48.965248: Epoch time: 138.1 s 
2025-12-16 09:41:49.608570:  
2025-12-16 09:41:49.608570: Epoch 176 
2025-12-16 09:41:49.624251: Current learning rate: 0.0084 
2025-12-16 09:44:07.619451: train_loss -0.8276 
2025-12-16 09:44:07.619451: val_loss -0.8405 
2025-12-16 09:44:07.621454: Pseudo dice [0.9107, 0.9501, 0.9158] 
2025-12-16 09:44:07.623456: Epoch time: 138.01 s 
2025-12-16 09:44:08.408533:  
2025-12-16 09:44:08.408533: Epoch 177 
2025-12-16 09:44:08.424614: Current learning rate: 0.00839 
2025-12-16 09:46:26.320095: train_loss -0.8264 
2025-12-16 09:46:26.333909: val_loss -0.8323 
2025-12-16 09:46:26.335792: Pseudo dice [0.9083, 0.9424, 0.907] 
2025-12-16 09:46:26.337794: Epoch time: 137.91 s 
2025-12-16 09:46:26.984305:  
2025-12-16 09:46:26.984305: Epoch 178 
2025-12-16 09:46:26.989915: Current learning rate: 0.00838 
2025-12-16 09:48:44.852975: train_loss -0.8263 
2025-12-16 09:48:44.852975: val_loss -0.8403 
2025-12-16 09:48:44.852975: Pseudo dice [0.9131, 0.9437, 0.9246] 
2025-12-16 09:48:44.852975: Epoch time: 137.87 s 
2025-12-16 09:48:45.500901:  
2025-12-16 09:48:45.516643: Epoch 179 
2025-12-16 09:48:45.516643: Current learning rate: 0.00837 
2025-12-16 09:51:03.446881: train_loss -0.8289 
2025-12-16 09:51:03.446881: val_loss -0.8355 
2025-12-16 09:51:03.462735: Pseudo dice [0.9077, 0.9481, 0.9195] 
2025-12-16 09:51:03.462735: Epoch time: 137.95 s 
2025-12-16 09:51:04.286434:  
2025-12-16 09:51:04.286434: Epoch 180 
2025-12-16 09:51:04.286434: Current learning rate: 0.00836 
2025-12-16 09:53:22.164889: train_loss -0.8286 
2025-12-16 09:53:22.164889: val_loss -0.8426 
2025-12-16 09:53:22.166891: Pseudo dice [0.9138, 0.9502, 0.9123] 
2025-12-16 09:53:22.168893: Epoch time: 137.88 s 
2025-12-16 09:53:22.823304:  
2025-12-16 09:53:22.823304: Epoch 181 
2025-12-16 09:53:22.823304: Current learning rate: 0.00836 
2025-12-16 09:55:40.751195: train_loss -0.8331 
2025-12-16 09:55:40.751195: val_loss -0.8387 
2025-12-16 09:55:40.751195: Pseudo dice [0.9087, 0.9455, 0.923] 
2025-12-16 09:55:40.751195: Epoch time: 137.94 s 
2025-12-16 09:55:41.416953:  
2025-12-16 09:55:41.416953: Epoch 182 
2025-12-16 09:55:41.416953: Current learning rate: 0.00835 
2025-12-16 09:57:59.177516: train_loss -0.8245 
2025-12-16 09:57:59.177516: val_loss -0.8435 
2025-12-16 09:57:59.181440: Pseudo dice [0.9101, 0.9478, 0.9182] 
2025-12-16 09:57:59.183441: Epoch time: 137.76 s 
2025-12-16 09:57:59.841945:  
2025-12-16 09:57:59.841945: Epoch 183 
2025-12-16 09:57:59.841945: Current learning rate: 0.00834 
2025-12-16 10:00:17.741603: train_loss -0.8296 
2025-12-16 10:00:17.743605: val_loss -0.8375 
2025-12-16 10:00:17.747996: Pseudo dice [0.9095, 0.9445, 0.9157] 
2025-12-16 10:00:17.750002: Epoch time: 137.92 s 
2025-12-16 10:00:18.398878:  
2025-12-16 10:00:18.412897: Epoch 184 
2025-12-16 10:00:18.412897: Current learning rate: 0.00833 
2025-12-16 10:02:36.281253: train_loss -0.8301 
2025-12-16 10:02:36.281253: val_loss -0.8434 
2025-12-16 10:02:36.281253: Pseudo dice [0.909, 0.9469, 0.9258] 
2025-12-16 10:02:36.281253: Epoch time: 137.88 s 
2025-12-16 10:02:36.995447:  
2025-12-16 10:02:36.995447: Epoch 185 
2025-12-16 10:02:36.995447: Current learning rate: 0.00832 
2025-12-16 10:04:55.067536: train_loss -0.8267 
2025-12-16 10:04:55.067536: val_loss -0.8301 
2025-12-16 10:04:55.067536: Pseudo dice [0.9071, 0.9417, 0.9049] 
2025-12-16 10:04:55.067536: Epoch time: 138.07 s 
2025-12-16 10:04:55.717058:  
2025-12-16 10:04:55.717058: Epoch 186 
2025-12-16 10:04:55.717058: Current learning rate: 0.00831 
2025-12-16 10:07:13.810108: train_loss -0.8199 
2025-12-16 10:07:13.810108: val_loss -0.8465 
2025-12-16 10:07:13.810108: Pseudo dice [0.9132, 0.9518, 0.9178] 
2025-12-16 10:07:13.810108: Epoch time: 138.09 s 
2025-12-16 10:07:14.631314:  
2025-12-16 10:07:14.631314: Epoch 187 
2025-12-16 10:07:14.631314: Current learning rate: 0.0083 
2025-12-16 10:09:32.812096: train_loss -0.8216 
2025-12-16 10:09:32.814098: val_loss -0.8393 
2025-12-16 10:09:32.816100: Pseudo dice [0.904, 0.9466, 0.9116] 
2025-12-16 10:09:32.819843: Epoch time: 138.18 s 
2025-12-16 10:09:33.501024:  
2025-12-16 10:09:33.501024: Epoch 188 
2025-12-16 10:09:33.517123: Current learning rate: 0.00829 
2025-12-16 10:11:51.691409: train_loss -0.8294 
2025-12-16 10:11:51.691409: val_loss -0.8518 
2025-12-16 10:11:51.691409: Pseudo dice [0.9175, 0.9491, 0.92] 
2025-12-16 10:11:51.691409: Epoch time: 138.19 s 
2025-12-16 10:11:52.340409:  
2025-12-16 10:11:52.340409: Epoch 189 
2025-12-16 10:11:52.356097: Current learning rate: 0.00828 
2025-12-16 10:14:10.450679: train_loss -0.8353 
2025-12-16 10:14:10.450679: val_loss -0.8489 
2025-12-16 10:14:10.453793: Pseudo dice [0.9129, 0.9515, 0.9301] 
2025-12-16 10:14:10.455795: Epoch time: 138.11 s 
2025-12-16 10:14:10.459799: Yayy! New best EMA pseudo Dice: 0.9252 
2025-12-16 10:14:11.337190:  
2025-12-16 10:14:11.337190: Epoch 190 
2025-12-16 10:14:11.337190: Current learning rate: 0.00827 
2025-12-16 10:16:29.223527: train_loss -0.8324 
2025-12-16 10:16:29.223527: val_loss -0.8427 
2025-12-16 10:16:29.239261: Pseudo dice [0.9126, 0.9492, 0.9217] 
2025-12-16 10:16:29.239261: Epoch time: 137.89 s 
2025-12-16 10:16:29.239261: Yayy! New best EMA pseudo Dice: 0.9255 
2025-12-16 10:16:30.223144:  
2025-12-16 10:16:30.223144: Epoch 191 
2025-12-16 10:16:30.223144: Current learning rate: 0.00826 
2025-12-16 10:18:48.248619: train_loss -0.8313 
2025-12-16 10:18:48.248619: val_loss -0.8475 
2025-12-16 10:18:48.248619: Pseudo dice [0.9127, 0.9483, 0.9266] 
2025-12-16 10:18:48.248619: Epoch time: 138.04 s 
2025-12-16 10:18:48.248619: Yayy! New best EMA pseudo Dice: 0.9258 
2025-12-16 10:18:49.171018:  
2025-12-16 10:18:49.185028: Epoch 192 
2025-12-16 10:18:49.185028: Current learning rate: 0.00825 
2025-12-16 10:21:07.211937: train_loss -0.8305 
2025-12-16 10:21:07.211937: val_loss -0.8483 
2025-12-16 10:21:07.211937: Pseudo dice [0.917, 0.9461, 0.9214] 
2025-12-16 10:21:07.227693: Epoch time: 138.04 s 
2025-12-16 10:21:07.227693: Yayy! New best EMA pseudo Dice: 0.9261 
2025-12-16 10:21:08.322987:  
2025-12-16 10:21:08.322987: Epoch 193 
2025-12-16 10:21:08.338900: Current learning rate: 0.00824 
2025-12-16 10:23:26.473074: train_loss -0.8349 
2025-12-16 10:23:26.473074: val_loss -0.851 
2025-12-16 10:23:26.486822: Pseudo dice [0.9144, 0.9469, 0.9273] 
2025-12-16 10:23:26.486822: Epoch time: 138.15 s 
2025-12-16 10:23:26.486822: Yayy! New best EMA pseudo Dice: 0.9264 
2025-12-16 10:23:27.406866:  
2025-12-16 10:23:27.406866: Epoch 194 
2025-12-16 10:23:27.406866: Current learning rate: 0.00824 
2025-12-16 10:25:45.288596: train_loss -0.8294 
2025-12-16 10:25:45.288596: val_loss -0.8555 
2025-12-16 10:25:45.288596: Pseudo dice [0.9199, 0.9537, 0.9229] 
2025-12-16 10:25:45.288596: Epoch time: 137.88 s 
2025-12-16 10:25:45.288596: Yayy! New best EMA pseudo Dice: 0.927 
2025-12-16 10:25:46.207489:  
2025-12-16 10:25:46.207489: Epoch 195 
2025-12-16 10:25:46.207489: Current learning rate: 0.00823 
2025-12-16 10:28:04.206743: train_loss -0.8294 
2025-12-16 10:28:04.206743: val_loss -0.8407 
2025-12-16 10:28:04.210748: Pseudo dice [0.9108, 0.9441, 0.9103] 
2025-12-16 10:28:04.212750: Epoch time: 138.0 s 
2025-12-16 10:28:04.873764:  
2025-12-16 10:28:04.873764: Epoch 196 
2025-12-16 10:28:04.873764: Current learning rate: 0.00822 
2025-12-16 10:30:22.783882: train_loss -0.8307 
2025-12-16 10:30:22.783882: val_loss -0.841 
2025-12-16 10:30:22.783882: Pseudo dice [0.9093, 0.9494, 0.9236] 
2025-12-16 10:30:22.783882: Epoch time: 137.91 s 
2025-12-16 10:30:23.525552:  
2025-12-16 10:30:23.525552: Epoch 197 
2025-12-16 10:30:23.525552: Current learning rate: 0.00821 
2025-12-16 10:32:41.292562: train_loss -0.8294 
2025-12-16 10:32:41.292562: val_loss -0.8519 
2025-12-16 10:32:41.292562: Pseudo dice [0.9179, 0.9539, 0.9152] 
2025-12-16 10:32:41.292562: Epoch time: 137.77 s 
2025-12-16 10:32:42.100820:  
2025-12-16 10:32:42.100820: Epoch 198 
2025-12-16 10:32:42.116611: Current learning rate: 0.0082 
2025-12-16 10:35:00.010622: train_loss -0.8331 
2025-12-16 10:35:00.010622: val_loss -0.8551 
2025-12-16 10:35:00.010622: Pseudo dice [0.9198, 0.9522, 0.919] 
2025-12-16 10:35:00.010622: Epoch time: 137.91 s 
2025-12-16 10:35:00.010622: Yayy! New best EMA pseudo Dice: 0.9272 
2025-12-16 10:35:00.902721:  
2025-12-16 10:35:00.904723: Epoch 199 
2025-12-16 10:35:00.906849: Current learning rate: 0.00819 
2025-12-16 10:37:18.763352: train_loss -0.8338 
2025-12-16 10:37:18.765354: val_loss -0.8526 
2025-12-16 10:37:18.767356: Pseudo dice [0.919, 0.9518, 0.9217] 
2025-12-16 10:37:18.769358: Epoch time: 137.86 s 
2025-12-16 10:37:19.026463: Yayy! New best EMA pseudo Dice: 0.9275 
2025-12-16 10:37:20.127155:  
2025-12-16 10:37:20.127155: Epoch 200 
2025-12-16 10:37:20.129257: Current learning rate: 0.00818 
2025-12-16 10:39:37.963537: train_loss -0.8316 
2025-12-16 10:39:37.963537: val_loss -0.8459 
2025-12-16 10:39:37.970422: Pseudo dice [0.9124, 0.9494, 0.9172] 
2025-12-16 10:39:37.972424: Epoch time: 137.84 s 
2025-12-16 10:39:38.627895:  
2025-12-16 10:39:38.627895: Epoch 201 
2025-12-16 10:39:38.627895: Current learning rate: 0.00817 
2025-12-16 10:41:56.555402: train_loss -0.8312 
2025-12-16 10:41:56.555402: val_loss -0.8346 
2025-12-16 10:41:56.557405: Pseudo dice [0.9029, 0.9378, 0.9273] 
2025-12-16 10:41:56.562904: Epoch time: 137.93 s 
2025-12-16 10:41:57.217003:  
2025-12-16 10:41:57.217003: Epoch 202 
2025-12-16 10:41:57.217003: Current learning rate: 0.00816 
2025-12-16 10:44:16.714457: train_loss -0.8354 
2025-12-16 10:44:16.714457: val_loss -0.8519 
2025-12-16 10:44:16.718951: Pseudo dice [0.9188, 0.9533, 0.9188] 
2025-12-16 10:44:16.720954: Epoch time: 139.5 s 
2025-12-16 10:44:17.402208:  
2025-12-16 10:44:17.402208: Epoch 203 
2025-12-16 10:44:17.402208: Current learning rate: 0.00815 
2025-12-16 10:46:37.050549: train_loss -0.8299 
2025-12-16 10:46:37.050549: val_loss -0.8518 
2025-12-16 10:46:37.050549: Pseudo dice [0.9163, 0.9501, 0.9265] 
2025-12-16 10:46:37.050549: Epoch time: 139.65 s 
2025-12-16 10:46:37.061811: Yayy! New best EMA pseudo Dice: 0.9276 
2025-12-16 10:46:38.118531:  
2025-12-16 10:46:38.118531: Epoch 204 
2025-12-16 10:46:38.118531: Current learning rate: 0.00814 
2025-12-16 10:48:56.018219: train_loss -0.8343 
2025-12-16 10:48:56.020224: val_loss -0.8579 
2025-12-16 10:48:56.024237: Pseudo dice [0.9224, 0.9576, 0.9139] 
2025-12-16 10:48:56.026239: Epoch time: 137.9 s 
2025-12-16 10:48:56.027980: Yayy! New best EMA pseudo Dice: 0.928 
2025-12-16 10:48:56.943422:  
2025-12-16 10:48:56.943422: Epoch 205 
2025-12-16 10:48:56.943422: Current learning rate: 0.00813 
2025-12-16 10:51:14.909730: train_loss -0.8295 
2025-12-16 10:51:14.909730: val_loss -0.8497 
2025-12-16 10:51:14.909730: Pseudo dice [0.9146, 0.9478, 0.9198] 
2025-12-16 10:51:14.909730: Epoch time: 137.97 s 
2025-12-16 10:51:15.535568:  
2025-12-16 10:51:15.535568: Epoch 206 
2025-12-16 10:51:15.535568: Current learning rate: 0.00813 
2025-12-16 10:53:33.586471: train_loss -0.8307 
2025-12-16 10:53:33.586471: val_loss -0.861 
2025-12-16 10:53:33.588474: Pseudo dice [0.924, 0.9564, 0.9121] 
2025-12-16 10:53:33.588474: Epoch time: 138.05 s 
2025-12-16 10:53:33.594805: Yayy! New best EMA pseudo Dice: 0.9282 
2025-12-16 10:53:34.482681:  
2025-12-16 10:53:34.482681: Epoch 207 
2025-12-16 10:53:34.482681: Current learning rate: 0.00812 
2025-12-16 10:55:52.553198: train_loss -0.8333 
2025-12-16 10:55:52.555199: val_loss -0.8416 
2025-12-16 10:55:52.557201: Pseudo dice [0.916, 0.9442, 0.9138] 
2025-12-16 10:55:52.558941: Epoch time: 138.07 s 
2025-12-16 10:55:53.190536:  
2025-12-16 10:55:53.190536: Epoch 208 
2025-12-16 10:55:53.190536: Current learning rate: 0.00811 
2025-12-16 10:58:11.284456: train_loss -0.8283 
2025-12-16 10:58:11.284456: val_loss -0.8431 
2025-12-16 10:58:11.284456: Pseudo dice [0.9105, 0.9482, 0.9189] 
2025-12-16 10:58:11.288900: Epoch time: 138.09 s 
2025-12-16 10:58:11.907638:  
2025-12-16 10:58:11.907638: Epoch 209 
2025-12-16 10:58:11.907638: Current learning rate: 0.0081 
2025-12-16 11:00:29.824456: train_loss -0.8327 
2025-12-16 11:00:29.824456: val_loss -0.8541 
2025-12-16 11:00:29.831514: Pseudo dice [0.914, 0.9461, 0.9348] 
2025-12-16 11:00:29.834081: Epoch time: 137.92 s 
2025-12-16 11:00:30.626452:  
2025-12-16 11:00:30.626452: Epoch 210 
2025-12-16 11:00:30.626452: Current learning rate: 0.00809 
2025-12-16 11:02:48.619218: train_loss -0.8277 
2025-12-16 11:02:48.619218: val_loss -0.8403 
2025-12-16 11:02:48.623222: Pseudo dice [0.9082, 0.9463, 0.9173] 
2025-12-16 11:02:48.625224: Epoch time: 137.99 s 
2025-12-16 11:02:49.254083:  
2025-12-16 11:02:49.254083: Epoch 211 
2025-12-16 11:02:49.257828: Current learning rate: 0.00808 
2025-12-16 11:05:07.290141: train_loss -0.8343 
2025-12-16 11:05:07.290141: val_loss -0.8534 
2025-12-16 11:05:07.295147: Pseudo dice [0.918, 0.9532, 0.9225] 
2025-12-16 11:05:07.297149: Epoch time: 138.04 s 
2025-12-16 11:05:07.930880:  
2025-12-16 11:05:07.930880: Epoch 212 
2025-12-16 11:05:07.930880: Current learning rate: 0.00807 
2025-12-16 11:07:25.968099: train_loss -0.8202 
2025-12-16 11:07:25.968099: val_loss -0.8528 
2025-12-16 11:07:25.984046: Pseudo dice [0.9156, 0.9521, 0.9275] 
2025-12-16 11:07:25.984046: Epoch time: 138.04 s 
2025-12-16 11:07:25.984046: Yayy! New best EMA pseudo Dice: 0.9284 
2025-12-16 11:07:26.864779:  
2025-12-16 11:07:26.864779: Epoch 213 
2025-12-16 11:07:26.864779: Current learning rate: 0.00806 
2025-12-16 11:09:45.335214: train_loss -0.8311 
2025-12-16 11:09:45.350923: val_loss -0.8423 
2025-12-16 11:09:45.350923: Pseudo dice [0.9077, 0.948, 0.9186] 
2025-12-16 11:09:45.350923: Epoch time: 138.47 s 
2025-12-16 11:09:45.969582:  
2025-12-16 11:09:45.969582: Epoch 214 
2025-12-16 11:09:45.969582: Current learning rate: 0.00805 
2025-12-16 11:12:04.300150: train_loss -0.8286 
2025-12-16 11:12:04.300150: val_loss -0.8269 
2025-12-16 11:12:04.304154: Pseudo dice [0.8997, 0.9364, 0.9091] 
2025-12-16 11:12:04.306156: Epoch time: 138.33 s 
2025-12-16 11:12:04.948822:  
2025-12-16 11:12:04.948822: Epoch 215 
2025-12-16 11:12:04.948822: Current learning rate: 0.00804 
2025-12-16 11:14:22.908002: train_loss -0.8287 
2025-12-16 11:14:22.908002: val_loss -0.8261 
2025-12-16 11:14:22.908002: Pseudo dice [0.899, 0.9393, 0.906] 
2025-12-16 11:14:22.908002: Epoch time: 137.96 s 
2025-12-16 11:14:23.708010:  
2025-12-16 11:14:23.708010: Epoch 216 
2025-12-16 11:14:23.708010: Current learning rate: 0.00803 
2025-12-16 11:16:41.755986: train_loss -0.8321 
2025-12-16 11:16:41.757727: val_loss -0.8425 
2025-12-16 11:16:41.759729: Pseudo dice [0.9155, 0.9457, 0.9228] 
2025-12-16 11:16:41.763734: Epoch time: 138.05 s 
2025-12-16 11:16:42.391367:  
2025-12-16 11:16:42.391367: Epoch 217 
2025-12-16 11:16:42.391367: Current learning rate: 0.00802 
2025-12-16 11:19:00.387583: train_loss -0.8298 
2025-12-16 11:19:00.387583: val_loss -0.8421 
2025-12-16 11:19:00.387583: Pseudo dice [0.9061, 0.9468, 0.9239] 
2025-12-16 11:19:00.400463: Epoch time: 138.0 s 
2025-12-16 11:19:01.039875:  
2025-12-16 11:19:01.039875: Epoch 218 
2025-12-16 11:19:01.039875: Current learning rate: 0.00801 
2025-12-16 11:21:19.004887: train_loss -0.8339 
2025-12-16 11:21:19.004887: val_loss -0.847 
2025-12-16 11:21:19.006889: Pseudo dice [0.9112, 0.9499, 0.9269] 
2025-12-16 11:21:19.010893: Epoch time: 137.97 s 
2025-12-16 11:21:19.643876:  
2025-12-16 11:21:19.645878: Epoch 219 
2025-12-16 11:21:19.648625: Current learning rate: 0.00801 
2025-12-16 11:23:37.676148: train_loss -0.8315 
2025-12-16 11:23:37.676148: val_loss -0.8465 
2025-12-16 11:23:37.678151: Pseudo dice [0.9163, 0.949, 0.9155] 
2025-12-16 11:23:37.678151: Epoch time: 138.03 s 
2025-12-16 11:23:38.333202:  
2025-12-16 11:23:38.333202: Epoch 220 
2025-12-16 11:23:38.333202: Current learning rate: 0.008 
2025-12-16 11:25:56.492593: train_loss -0.8265 
2025-12-16 11:25:56.494595: val_loss -0.8435 
2025-12-16 11:25:56.496597: Pseudo dice [0.9101, 0.9501, 0.9226] 
2025-12-16 11:25:56.498599: Epoch time: 138.16 s 
2025-12-16 11:25:57.135141:  
2025-12-16 11:25:57.135141: Epoch 221 
2025-12-16 11:25:57.135141: Current learning rate: 0.00799 
2025-12-16 11:28:15.001089: train_loss -0.8293 
2025-12-16 11:28:15.001089: val_loss -0.841 
2025-12-16 11:28:15.001089: Pseudo dice [0.9105, 0.9443, 0.9175] 
2025-12-16 11:28:15.001089: Epoch time: 137.87 s 
2025-12-16 11:28:15.632859:  
2025-12-16 11:28:15.632859: Epoch 222 
2025-12-16 11:28:15.632859: Current learning rate: 0.00798 
2025-12-16 11:30:33.765129: train_loss -0.8286 
2025-12-16 11:30:33.765129: val_loss -0.8549 
2025-12-16 11:30:33.769133: Pseudo dice [0.9179, 0.9524, 0.9318] 
2025-12-16 11:30:33.769133: Epoch time: 138.13 s 
2025-12-16 11:30:34.578800:  
2025-12-16 11:30:34.578800: Epoch 223 
2025-12-16 11:30:34.589061: Current learning rate: 0.00797 
2025-12-16 11:32:52.403569: train_loss -0.8356 
2025-12-16 11:32:52.403569: val_loss -0.8437 
2025-12-16 11:32:52.403569: Pseudo dice [0.9115, 0.9445, 0.9207] 
2025-12-16 11:32:52.417233: Epoch time: 137.82 s 
2025-12-16 11:32:53.035771:  
2025-12-16 11:32:53.035771: Epoch 224 
2025-12-16 11:32:53.051722: Current learning rate: 0.00796 
2025-12-16 11:35:10.934595: train_loss -0.8349 
2025-12-16 11:35:10.934595: val_loss -0.8608 
2025-12-16 11:35:10.934595: Pseudo dice [0.9291, 0.9566, 0.9199] 
2025-12-16 11:35:10.934595: Epoch time: 137.9 s 
2025-12-16 11:35:11.553732:  
2025-12-16 11:35:11.553732: Epoch 225 
2025-12-16 11:35:11.571584: Current learning rate: 0.00795 
2025-12-16 11:37:29.475529: train_loss -0.8384 
2025-12-16 11:37:29.479533: val_loss -0.8455 
2025-12-16 11:37:29.479533: Pseudo dice [0.9091, 0.9408, 0.9315] 
2025-12-16 11:37:29.483021: Epoch time: 137.92 s 
2025-12-16 11:37:30.096676:  
2025-12-16 11:37:30.096676: Epoch 226 
2025-12-16 11:37:30.112606: Current learning rate: 0.00794 
2025-12-16 11:39:47.987831: train_loss -0.8322 
2025-12-16 11:39:48.001883: val_loss -0.8584 
2025-12-16 11:39:48.003886: Pseudo dice [0.9208, 0.9529, 0.9238] 
2025-12-16 11:39:48.005889: Epoch time: 137.89 s 
2025-12-16 11:39:48.808910:  
2025-12-16 11:39:48.808910: Epoch 227 
2025-12-16 11:39:48.808910: Current learning rate: 0.00793 
2025-12-16 11:42:06.835869: train_loss -0.8392 
2025-12-16 11:42:06.835869: val_loss -0.8587 
2025-12-16 11:42:06.835869: Pseudo dice [0.921, 0.9542, 0.9242] 
2025-12-16 11:42:06.851419: Epoch time: 138.03 s 
2025-12-16 11:42:06.851419: Yayy! New best EMA pseudo Dice: 0.9286 
2025-12-16 11:42:07.710111:  
2025-12-16 11:42:07.712113: Epoch 228 
2025-12-16 11:42:07.712113: Current learning rate: 0.00792 
2025-12-16 11:44:25.793665: train_loss -0.8356 
2025-12-16 11:44:25.795668: val_loss -0.8627 
2025-12-16 11:44:25.797706: Pseudo dice [0.9244, 0.9528, 0.9296] 
2025-12-16 11:44:25.799708: Epoch time: 138.08 s 
2025-12-16 11:44:25.801710: Yayy! New best EMA pseudo Dice: 0.9293 
2025-12-16 11:44:26.868684:  
2025-12-16 11:44:26.868684: Epoch 229 
2025-12-16 11:44:26.868684: Current learning rate: 0.00791 
2025-12-16 11:46:44.744298: train_loss -0.8304 
2025-12-16 11:46:44.744298: val_loss -0.8387 
2025-12-16 11:46:44.744298: Pseudo dice [0.9093, 0.9431, 0.9206] 
2025-12-16 11:46:44.744298: Epoch time: 137.88 s 
2025-12-16 11:46:45.517439:  
2025-12-16 11:46:45.517439: Epoch 230 
2025-12-16 11:46:45.517439: Current learning rate: 0.0079 
2025-12-16 11:49:03.448052: train_loss -0.8337 
2025-12-16 11:49:03.449795: val_loss -0.8493 
2025-12-16 11:49:03.455812: Pseudo dice [0.9145, 0.9512, 0.9189] 
2025-12-16 11:49:03.457814: Epoch time: 137.93 s 
2025-12-16 11:49:04.088300:  
2025-12-16 11:49:04.088300: Epoch 231 
2025-12-16 11:49:04.092306: Current learning rate: 0.00789 
2025-12-16 11:51:21.937022: train_loss -0.8336 
2025-12-16 11:51:21.937022: val_loss -0.8588 
2025-12-16 11:51:21.941028: Pseudo dice [0.9203, 0.9546, 0.9219] 
2025-12-16 11:51:21.943030: Epoch time: 137.85 s 
2025-12-16 11:51:22.562615:  
2025-12-16 11:51:22.562615: Epoch 232 
2025-12-16 11:51:22.562615: Current learning rate: 0.00789 
2025-12-16 11:53:40.678890: train_loss -0.8177 
2025-12-16 11:53:40.680893: val_loss -0.8284 
2025-12-16 11:53:40.683610: Pseudo dice [0.9081, 0.944, 0.89] 
2025-12-16 11:53:40.685488: Epoch time: 138.12 s 
2025-12-16 11:53:41.394250:  
2025-12-16 11:53:41.394250: Epoch 233 
2025-12-16 11:53:41.394250: Current learning rate: 0.00788 
2025-12-16 11:55:59.426661: train_loss -0.8198 
2025-12-16 11:55:59.426661: val_loss -0.8345 
2025-12-16 11:55:59.426661: Pseudo dice [0.9037, 0.9439, 0.92] 
2025-12-16 11:55:59.426661: Epoch time: 138.03 s 
2025-12-16 11:56:00.044883:  
2025-12-16 11:56:00.044883: Epoch 234 
2025-12-16 11:56:00.044883: Current learning rate: 0.00787 
2025-12-16 11:58:18.118201: train_loss -0.8281 
2025-12-16 11:58:18.118201: val_loss -0.8439 
2025-12-16 11:58:18.118201: Pseudo dice [0.9183, 0.9474, 0.9026] 
2025-12-16 11:58:18.118201: Epoch time: 138.09 s 
2025-12-16 11:58:18.738576:  
2025-12-16 11:58:18.738576: Epoch 235 
2025-12-16 11:58:18.738576: Current learning rate: 0.00786 
2025-12-16 12:00:36.650623: train_loss -0.8304 
2025-12-16 12:00:36.650623: val_loss -0.8455 
2025-12-16 12:00:36.650623: Pseudo dice [0.9138, 0.9472, 0.9191] 
2025-12-16 12:00:36.650623: Epoch time: 137.91 s 
2025-12-16 12:00:37.569366:  
2025-12-16 12:00:37.569366: Epoch 236 
2025-12-16 12:00:37.569366: Current learning rate: 0.00785 
2025-12-16 12:02:55.555220: train_loss -0.8339 
2025-12-16 12:02:55.557223: val_loss -0.8528 
2025-12-16 12:02:55.559225: Pseudo dice [0.9202, 0.9483, 0.9195] 
2025-12-16 12:02:55.563229: Epoch time: 137.99 s 
2025-12-16 12:02:56.211781:  
2025-12-16 12:02:56.211781: Epoch 237 
2025-12-16 12:02:56.211781: Current learning rate: 0.00784 
2025-12-16 12:05:14.197168: train_loss -0.8305 
2025-12-16 12:05:14.197168: val_loss -0.8491 
2025-12-16 12:05:14.201171: Pseudo dice [0.9136, 0.9479, 0.9255] 
2025-12-16 12:05:14.203676: Epoch time: 137.99 s 
2025-12-16 12:05:14.830482:  
2025-12-16 12:05:14.830482: Epoch 238 
2025-12-16 12:05:14.830482: Current learning rate: 0.00783 
2025-12-16 12:07:32.844026: train_loss -0.8161 
2025-12-16 12:07:32.844026: val_loss -0.8455 
2025-12-16 12:07:32.849032: Pseudo dice [0.9131, 0.9488, 0.9274] 
2025-12-16 12:07:32.851034: Epoch time: 138.01 s 
2025-12-16 12:07:33.472010:  
2025-12-16 12:07:33.472010: Epoch 239 
2025-12-16 12:07:33.475361: Current learning rate: 0.00782 
2025-12-16 12:09:51.942196: train_loss -0.823 
2025-12-16 12:09:51.944198: val_loss -0.843 
2025-12-16 12:09:51.946200: Pseudo dice [0.9158, 0.9465, 0.9096] 
2025-12-16 12:09:51.950034: Epoch time: 138.47 s 
2025-12-16 12:09:52.578795:  
2025-12-16 12:09:52.578795: Epoch 240 
2025-12-16 12:09:52.580797: Current learning rate: 0.00781 
2025-12-16 12:12:10.667344: train_loss -0.8249 
2025-12-16 12:12:10.667344: val_loss -0.8407 
2025-12-16 12:12:10.670318: Pseudo dice [0.9093, 0.9462, 0.9209] 
2025-12-16 12:12:10.673322: Epoch time: 138.09 s 
2025-12-16 12:12:11.306232:  
2025-12-16 12:12:11.306232: Epoch 241 
2025-12-16 12:12:11.306232: Current learning rate: 0.0078 
2025-12-16 12:14:29.414619: train_loss -0.8276 
2025-12-16 12:14:29.414619: val_loss -0.8476 
2025-12-16 12:14:29.418622: Pseudo dice [0.9088, 0.9457, 0.9264] 
2025-12-16 12:14:29.420624: Epoch time: 138.11 s 
2025-12-16 12:14:30.084801:  
2025-12-16 12:14:30.084801: Epoch 242 
2025-12-16 12:14:30.084801: Current learning rate: 0.00779 
2025-12-16 12:16:47.976641: train_loss -0.8337 
2025-12-16 12:16:47.976641: val_loss -0.8517 
2025-12-16 12:16:47.976641: Pseudo dice [0.9147, 0.9475, 0.9293] 
2025-12-16 12:16:47.976641: Epoch time: 137.89 s 
2025-12-16 12:16:48.780125:  
2025-12-16 12:16:48.780125: Epoch 243 
2025-12-16 12:16:48.780125: Current learning rate: 0.00778 
2025-12-16 12:19:06.576393: train_loss -0.8308 
2025-12-16 12:19:06.576393: val_loss -0.84 
2025-12-16 12:19:06.580397: Pseudo dice [0.9081, 0.9467, 0.9112] 
2025-12-16 12:19:06.582138: Epoch time: 137.8 s 
2025-12-16 12:19:07.201005:  
2025-12-16 12:19:07.201005: Epoch 244 
2025-12-16 12:19:07.201005: Current learning rate: 0.00777 
2025-12-16 12:21:25.234280: train_loss -0.8359 
2025-12-16 12:21:25.234280: val_loss -0.8568 
2025-12-16 12:21:25.236288: Pseudo dice [0.9205, 0.9533, 0.9186] 
2025-12-16 12:21:25.236288: Epoch time: 138.03 s 
2025-12-16 12:21:25.866504:  
2025-12-16 12:21:25.866504: Epoch 245 
2025-12-16 12:21:25.866504: Current learning rate: 0.00777 
2025-12-16 12:23:44.025345: train_loss -0.8362 
2025-12-16 12:23:44.025345: val_loss -0.8573 
2025-12-16 12:23:44.029089: Pseudo dice [0.9209, 0.952, 0.9159] 
2025-12-16 12:23:44.029089: Epoch time: 138.16 s 
2025-12-16 12:23:44.661607:  
2025-12-16 12:23:44.661607: Epoch 246 
2025-12-16 12:23:44.661607: Current learning rate: 0.00776 
2025-12-16 12:26:02.493044: train_loss -0.8371 
2025-12-16 12:26:02.493044: val_loss -0.8429 
2025-12-16 12:26:02.497052: Pseudo dice [0.912, 0.9471, 0.9178] 
2025-12-16 12:26:02.499685: Epoch time: 137.83 s 
2025-12-16 12:26:03.117564:  
2025-12-16 12:26:03.117564: Epoch 247 
2025-12-16 12:26:03.133669: Current learning rate: 0.00775 
2025-12-16 12:28:21.019683: train_loss -0.8378 
2025-12-16 12:28:21.021685: val_loss -0.8427 
2025-12-16 12:28:21.023687: Pseudo dice [0.9124, 0.9474, 0.9169] 
2025-12-16 12:28:21.027691: Epoch time: 137.9 s 
2025-12-16 12:28:21.652651:  
2025-12-16 12:28:21.652651: Epoch 248 
2025-12-16 12:28:21.652651: Current learning rate: 0.00774 
2025-12-16 12:30:39.533468: train_loss -0.8292 
2025-12-16 12:30:39.533468: val_loss -0.8411 
2025-12-16 12:30:39.533468: Pseudo dice [0.9086, 0.9486, 0.9096] 
2025-12-16 12:30:39.533468: Epoch time: 137.88 s 
2025-12-16 12:30:40.356647:  
2025-12-16 12:30:40.356647: Epoch 249 
2025-12-16 12:30:40.356647: Current learning rate: 0.00773 
2025-12-16 12:32:58.180074: train_loss -0.8332 
2025-12-16 12:32:58.180074: val_loss -0.8598 
2025-12-16 12:32:58.180074: Pseudo dice [0.9194, 0.9528, 0.9308] 
2025-12-16 12:32:58.180074: Epoch time: 137.82 s 
2025-12-16 12:32:59.099537:  
2025-12-16 12:32:59.099537: Epoch 250 
2025-12-16 12:32:59.099537: Current learning rate: 0.00772 
2025-12-16 12:35:17.068311: train_loss -0.8353 
2025-12-16 12:35:17.068311: val_loss -0.8608 
2025-12-16 12:35:17.074040: Pseudo dice [0.9185, 0.9519, 0.9271] 
2025-12-16 12:35:17.076042: Epoch time: 137.97 s 
2025-12-16 12:35:17.684935:  
2025-12-16 12:35:17.684935: Epoch 251 
2025-12-16 12:35:17.684935: Current learning rate: 0.00771 
2025-12-16 12:37:35.778282: train_loss -0.8229 
2025-12-16 12:37:35.778282: val_loss -0.8269 
2025-12-16 12:37:35.778282: Pseudo dice [0.9002, 0.9366, 0.9074] 
2025-12-16 12:37:35.778282: Epoch time: 138.09 s 
2025-12-16 12:37:36.395031:  
2025-12-16 12:37:36.395031: Epoch 252 
2025-12-16 12:37:36.395031: Current learning rate: 0.0077 
2025-12-16 12:39:54.487101: train_loss -0.8176 
2025-12-16 12:39:54.487101: val_loss -0.8609 
2025-12-16 12:39:54.487101: Pseudo dice [0.9228, 0.9583, 0.9271] 
2025-12-16 12:39:54.487101: Epoch time: 138.09 s 
2025-12-16 12:39:55.261377:  
2025-12-16 12:39:55.261377: Epoch 253 
2025-12-16 12:39:55.261377: Current learning rate: 0.00769 
2025-12-16 12:42:13.335876: train_loss -0.8257 
2025-12-16 12:42:13.335876: val_loss -0.845 
2025-12-16 12:42:13.339880: Pseudo dice [0.9146, 0.9512, 0.9228] 
2025-12-16 12:42:13.342884: Epoch time: 138.07 s 
2025-12-16 12:42:13.975221:  
2025-12-16 12:42:13.975221: Epoch 254 
2025-12-16 12:42:13.975221: Current learning rate: 0.00768 
2025-12-16 12:44:32.037352: train_loss -0.826 
2025-12-16 12:44:32.053103: val_loss -0.8575 
2025-12-16 12:44:32.053103: Pseudo dice [0.9207, 0.9528, 0.9292] 
2025-12-16 12:44:32.053103: Epoch time: 138.06 s 
2025-12-16 12:44:32.845178:  
2025-12-16 12:44:32.845178: Epoch 255 
2025-12-16 12:44:32.845178: Current learning rate: 0.00767 
2025-12-16 12:46:50.823747: train_loss -0.8316 
2025-12-16 12:46:50.823747: val_loss -0.8463 
2025-12-16 12:46:50.823747: Pseudo dice [0.9178, 0.95, 0.9169] 
2025-12-16 12:46:50.839385: Epoch time: 137.99 s 
2025-12-16 12:46:51.554149:  
2025-12-16 12:46:51.554149: Epoch 256 
2025-12-16 12:46:51.554149: Current learning rate: 0.00766 
2025-12-16 12:49:09.353668: train_loss -0.8314 
2025-12-16 12:49:09.355670: val_loss -0.8585 
2025-12-16 12:49:09.357672: Pseudo dice [0.9157, 0.9508, 0.9364] 
2025-12-16 12:49:09.357672: Epoch time: 137.8 s 
2025-12-16 12:49:09.984352:  
2025-12-16 12:49:09.984352: Epoch 257 
2025-12-16 12:49:10.000242: Current learning rate: 0.00765 
2025-12-16 12:51:27.952257: train_loss -0.8336 
2025-12-16 12:51:27.952257: val_loss -0.855 
2025-12-16 12:51:27.956003: Pseudo dice [0.9153, 0.9526, 0.9355] 
2025-12-16 12:51:27.958005: Epoch time: 137.97 s 
2025-12-16 12:51:27.958005: Yayy! New best EMA pseudo Dice: 0.9295 
2025-12-16 12:51:28.828033:  
2025-12-16 12:51:28.828033: Epoch 258 
2025-12-16 12:51:28.828033: Current learning rate: 0.00764 
2025-12-16 12:53:46.722689: train_loss -0.8348 
2025-12-16 12:53:46.722689: val_loss -0.8548 
2025-12-16 12:53:46.722689: Pseudo dice [0.9213, 0.95, 0.926] 
2025-12-16 12:53:46.722689: Epoch time: 137.89 s 
2025-12-16 12:53:46.722689: Yayy! New best EMA pseudo Dice: 0.9298 
2025-12-16 12:53:47.765576:  
2025-12-16 12:53:47.765576: Epoch 259 
2025-12-16 12:53:47.765576: Current learning rate: 0.00764 
2025-12-16 12:56:05.871234: train_loss -0.8369 
2025-12-16 12:56:05.873235: val_loss -0.8516 
2025-12-16 12:56:05.873235: Pseudo dice [0.9115, 0.9452, 0.9323] 
2025-12-16 12:56:05.873235: Epoch time: 138.11 s 
2025-12-16 12:56:06.491220:  
2025-12-16 12:56:06.491220: Epoch 260 
2025-12-16 12:56:06.491220: Current learning rate: 0.00763 
2025-12-16 12:58:24.459063: train_loss -0.8386 
2025-12-16 12:58:24.459063: val_loss -0.8625 
2025-12-16 12:58:24.461066: Pseudo dice [0.9227, 0.9561, 0.9224] 
2025-12-16 12:58:24.464808: Epoch time: 137.97 s 
2025-12-16 12:58:24.466810: Yayy! New best EMA pseudo Dice: 0.9302 
2025-12-16 12:58:25.532539:  
2025-12-16 12:58:25.532539: Epoch 261 
2025-12-16 12:58:25.532539: Current learning rate: 0.00762 
2025-12-16 13:00:43.540227: train_loss -0.8395 
2025-12-16 13:00:43.540227: val_loss -0.8639 
2025-12-16 13:00:43.544231: Pseudo dice [0.9238, 0.9555, 0.9246] 
2025-12-16 13:00:43.546233: Epoch time: 138.01 s 
2025-12-16 13:00:43.550237: Yayy! New best EMA pseudo Dice: 0.9306 
2025-12-16 13:00:44.584657:  
2025-12-16 13:00:44.584657: Epoch 262 
2025-12-16 13:00:44.584657: Current learning rate: 0.00761 
2025-12-16 13:03:02.493730: train_loss -0.8333 
2025-12-16 13:03:02.495732: val_loss -0.8524 
2025-12-16 13:03:02.503486: Pseudo dice [0.9188, 0.9504, 0.917] 
2025-12-16 13:03:02.505489: Epoch time: 137.91 s 
2025-12-16 13:03:03.135616:  
2025-12-16 13:03:03.135616: Epoch 263 
2025-12-16 13:03:03.135616: Current learning rate: 0.0076 
2025-12-16 13:05:21.262272: train_loss -0.8351 
2025-12-16 13:05:21.264274: val_loss -0.8484 
2025-12-16 13:05:21.264274: Pseudo dice [0.9142, 0.9489, 0.9223] 
2025-12-16 13:05:21.268426: Epoch time: 138.13 s 
2025-12-16 13:05:21.896380:  
2025-12-16 13:05:21.896380: Epoch 264 
2025-12-16 13:05:21.896380: Current learning rate: 0.00759 
2025-12-16 13:07:39.727717: train_loss -0.8082 
2025-12-16 13:07:39.729457: val_loss -0.8181 
2025-12-16 13:07:39.733462: Pseudo dice [0.9007, 0.9396, 0.9177] 
2025-12-16 13:07:39.735464: Epoch time: 137.83 s 
2025-12-16 13:07:40.363475:  
2025-12-16 13:07:40.363475: Epoch 265 
2025-12-16 13:07:40.363475: Current learning rate: 0.00758 
2025-12-16 13:09:58.588528: train_loss -0.8091 
2025-12-16 13:09:58.588528: val_loss -0.8369 
2025-12-16 13:09:58.590530: Pseudo dice [0.9088, 0.9448, 0.9219] 
2025-12-16 13:09:58.593032: Epoch time: 138.23 s 
2025-12-16 13:09:59.213868:  
2025-12-16 13:09:59.213868: Epoch 266 
2025-12-16 13:09:59.213868: Current learning rate: 0.00757 
2025-12-16 13:12:17.207084: train_loss -0.8234 
2025-12-16 13:12:17.209086: val_loss -0.8495 
2025-12-16 13:12:17.213089: Pseudo dice [0.9169, 0.9518, 0.9259] 
2025-12-16 13:12:17.215091: Epoch time: 137.99 s 
2025-12-16 13:12:17.838947:  
2025-12-16 13:12:17.838947: Epoch 267 
2025-12-16 13:12:17.838947: Current learning rate: 0.00756 
2025-12-16 13:14:35.810217: train_loss -0.8315 
2025-12-16 13:14:35.810217: val_loss -0.8434 
2025-12-16 13:14:35.815054: Pseudo dice [0.9157, 0.9471, 0.9126] 
2025-12-16 13:14:35.817056: Epoch time: 137.97 s 
2025-12-16 13:14:36.615347:  
2025-12-16 13:14:36.615347: Epoch 268 
2025-12-16 13:14:36.615347: Current learning rate: 0.00755 
2025-12-16 13:16:54.536474: train_loss -0.8249 
2025-12-16 13:16:54.536474: val_loss -0.7922 
2025-12-16 13:16:54.550294: Pseudo dice [0.8954, 0.9341, 0.8854] 
2025-12-16 13:16:54.550294: Epoch time: 137.92 s 
2025-12-16 13:16:55.181619:  
2025-12-16 13:16:55.181619: Epoch 269 
2025-12-16 13:16:55.181619: Current learning rate: 0.00754 
2025-12-16 13:19:13.120633: train_loss -0.8207 
2025-12-16 13:19:13.122636: val_loss -0.8358 
2025-12-16 13:19:13.126639: Pseudo dice [0.9069, 0.9439, 0.9104] 
2025-12-16 13:19:13.128641: Epoch time: 137.94 s 
2025-12-16 13:19:13.795821:  
2025-12-16 13:19:13.795821: Epoch 270 
2025-12-16 13:19:13.795821: Current learning rate: 0.00753 
2025-12-16 13:21:31.930283: train_loss -0.8307 
2025-12-16 13:21:31.930283: val_loss -0.8546 
2025-12-16 13:21:31.934287: Pseudo dice [0.9242, 0.9544, 0.918] 
2025-12-16 13:21:31.936289: Epoch time: 138.15 s 
2025-12-16 13:21:32.560452:  
2025-12-16 13:21:32.560452: Epoch 271 
2025-12-16 13:21:32.560452: Current learning rate: 0.00752 
2025-12-16 13:23:50.386999: train_loss -0.8312 
2025-12-16 13:23:50.386999: val_loss -0.8504 
2025-12-16 13:23:50.389001: Pseudo dice [0.9145, 0.9507, 0.9209] 
2025-12-16 13:23:50.389001: Epoch time: 137.83 s 
2025-12-16 13:23:51.011505:  
2025-12-16 13:23:51.011505: Epoch 272 
2025-12-16 13:23:51.027280: Current learning rate: 0.00751 
2025-12-16 13:26:09.132943: train_loss -0.8381 
2025-12-16 13:26:09.132943: val_loss -0.8609 
2025-12-16 13:26:09.132943: Pseudo dice [0.9235, 0.9512, 0.9315] 
2025-12-16 13:26:09.132943: Epoch time: 138.12 s 
2025-12-16 13:26:09.766534:  
2025-12-16 13:26:09.766534: Epoch 273 
2025-12-16 13:26:09.766534: Current learning rate: 0.00751 
2025-12-16 13:28:27.670045: train_loss -0.8346 
2025-12-16 13:28:27.670045: val_loss -0.8565 
2025-12-16 13:28:27.670045: Pseudo dice [0.9133, 0.9494, 0.9386] 
2025-12-16 13:28:27.670045: Epoch time: 137.9 s 
2025-12-16 13:28:28.462194:  
2025-12-16 13:28:28.462194: Epoch 274 
2025-12-16 13:28:28.478274: Current learning rate: 0.0075 
2025-12-16 13:30:46.607992: train_loss -0.8351 
2025-12-16 13:30:46.609994: val_loss -0.8476 
2025-12-16 13:30:46.613736: Pseudo dice [0.9127, 0.947, 0.9189] 
2025-12-16 13:30:46.615737: Epoch time: 138.15 s 
2025-12-16 13:30:47.238204:  
2025-12-16 13:30:47.238204: Epoch 275 
2025-12-16 13:30:47.238204: Current learning rate: 0.00749 
2025-12-16 13:33:05.271841: train_loss -0.8346 
2025-12-16 13:33:05.271841: val_loss -0.8562 
2025-12-16 13:33:05.287689: Pseudo dice [0.9184, 0.9552, 0.9238] 
2025-12-16 13:33:05.287689: Epoch time: 138.03 s 
2025-12-16 13:33:06.000401:  
2025-12-16 13:33:06.000401: Epoch 276 
2025-12-16 13:33:06.000401: Current learning rate: 0.00748 
2025-12-16 13:35:23.896566: train_loss -0.8403 
2025-12-16 13:35:23.896566: val_loss -0.8599 
2025-12-16 13:35:23.898381: Pseudo dice [0.9209, 0.9532, 0.9317] 
2025-12-16 13:35:23.901805: Epoch time: 137.9 s 
2025-12-16 13:35:24.530998:  
2025-12-16 13:35:24.530998: Epoch 277 
2025-12-16 13:35:24.530998: Current learning rate: 0.00747 
2025-12-16 13:37:42.490875: train_loss -0.8382 
2025-12-16 13:37:42.490875: val_loss -0.8518 
2025-12-16 13:37:42.494617: Pseudo dice [0.9149, 0.9479, 0.926] 
2025-12-16 13:37:42.496619: Epoch time: 137.96 s 
2025-12-16 13:37:43.115216:  
2025-12-16 13:37:43.115216: Epoch 278 
2025-12-16 13:37:43.131001: Current learning rate: 0.00746 
2025-12-16 13:40:00.917869: train_loss -0.8258 
2025-12-16 13:40:00.917869: val_loss -0.8464 
2025-12-16 13:40:00.933627: Pseudo dice [0.9174, 0.9536, 0.9139] 
2025-12-16 13:40:00.933627: Epoch time: 137.8 s 
2025-12-16 13:40:01.678714:  
2025-12-16 13:40:01.678714: Epoch 279 
2025-12-16 13:40:01.678714: Current learning rate: 0.00745 
2025-12-16 13:42:19.526969: train_loss -0.8191 
2025-12-16 13:42:19.528971: val_loss -0.8424 
2025-12-16 13:42:19.530973: Pseudo dice [0.9162, 0.9501, 0.9046] 
2025-12-16 13:42:19.532975: Epoch time: 137.85 s 
2025-12-16 13:42:20.313725:  
2025-12-16 13:42:20.313725: Epoch 280 
2025-12-16 13:42:20.313725: Current learning rate: 0.00744 
2025-12-16 13:44:38.240517: train_loss -0.821 
2025-12-16 13:44:38.240517: val_loss -0.8508 
2025-12-16 13:44:38.240517: Pseudo dice [0.9148, 0.949, 0.9261] 
2025-12-16 13:44:38.256261: Epoch time: 137.93 s 
2025-12-16 13:44:38.874468:  
2025-12-16 13:44:38.874468: Epoch 281 
2025-12-16 13:44:38.874468: Current learning rate: 0.00743 
2025-12-16 13:46:56.735304: train_loss -0.8321 
2025-12-16 13:46:56.735304: val_loss -0.8502 
2025-12-16 13:46:56.739309: Pseudo dice [0.9166, 0.9523, 0.918] 
2025-12-16 13:46:56.741311: Epoch time: 137.86 s 
2025-12-16 13:46:57.560270:  
2025-12-16 13:46:57.560270: Epoch 282 
2025-12-16 13:46:57.560270: Current learning rate: 0.00742 
2025-12-16 13:49:15.360062: train_loss -0.8328 
2025-12-16 13:49:15.360062: val_loss -0.8517 
2025-12-16 13:49:15.369801: Pseudo dice [0.9154, 0.948, 0.9245] 
2025-12-16 13:49:15.369801: Epoch time: 137.8 s 
2025-12-16 13:49:15.994339:  
2025-12-16 13:49:15.994339: Epoch 283 
2025-12-16 13:49:16.010116: Current learning rate: 0.00741 
2025-12-16 13:51:33.927567: train_loss -0.8395 
2025-12-16 13:51:33.927567: val_loss -0.8555 
2025-12-16 13:51:33.931571: Pseudo dice [0.9149, 0.9505, 0.9292] 
2025-12-16 13:51:33.933311: Epoch time: 137.93 s 
2025-12-16 13:51:34.588991:  
2025-12-16 13:51:34.588991: Epoch 284 
2025-12-16 13:51:34.604935: Current learning rate: 0.0074 
2025-12-16 13:53:52.656670: train_loss -0.8343 
2025-12-16 13:53:52.656670: val_loss -0.8551 
2025-12-16 13:53:52.656670: Pseudo dice [0.9152, 0.9515, 0.9242] 
2025-12-16 13:53:52.656670: Epoch time: 138.07 s 
2025-12-16 13:53:53.287755:  
2025-12-16 13:53:53.287755: Epoch 285 
2025-12-16 13:53:53.287755: Current learning rate: 0.00739 
2025-12-16 13:56:11.362836: train_loss -0.841 
2025-12-16 13:56:11.364839: val_loss -0.8628 
2025-12-16 13:56:11.368843: Pseudo dice [0.9235, 0.9526, 0.9215] 
2025-12-16 13:56:11.370845: Epoch time: 138.08 s 
2025-12-16 13:56:11.993433:  
2025-12-16 13:56:11.993433: Epoch 286 
2025-12-16 13:56:12.009234: Current learning rate: 0.00738 
2025-12-16 13:58:29.988450: train_loss -0.845 
2025-12-16 13:58:29.988450: val_loss -0.8522 
2025-12-16 13:58:29.988450: Pseudo dice [0.9141, 0.9492, 0.9208] 
2025-12-16 13:58:29.988450: Epoch time: 138.0 s 
2025-12-16 13:58:30.797929:  
2025-12-16 13:58:30.797929: Epoch 287 
2025-12-16 13:58:30.797929: Current learning rate: 0.00738 
2025-12-16 14:00:49.547004: train_loss -0.8404 
2025-12-16 14:00:49.547004: val_loss -0.8556 
2025-12-16 14:00:49.547004: Pseudo dice [0.9201, 0.9516, 0.9298] 
2025-12-16 14:00:49.547004: Epoch time: 138.75 s 
2025-12-16 14:00:50.179596:  
2025-12-16 14:00:50.179596: Epoch 288 
2025-12-16 14:00:50.179596: Current learning rate: 0.00737 
2025-12-16 14:03:08.517884: train_loss -0.8444 
2025-12-16 14:03:08.517884: val_loss -0.8696 
2025-12-16 14:03:08.517884: Pseudo dice [0.922, 0.9529, 0.9454] 
2025-12-16 14:03:08.517884: Epoch time: 138.34 s 
2025-12-16 14:03:08.517884: Yayy! New best EMA pseudo Dice: 0.9308 
2025-12-16 14:03:09.406077:  
2025-12-16 14:03:09.406077: Epoch 289 
2025-12-16 14:03:09.406077: Current learning rate: 0.00736 
2025-12-16 14:05:27.753197: train_loss -0.8379 
2025-12-16 14:05:27.753197: val_loss -0.8435 
2025-12-16 14:05:27.769014: Pseudo dice [0.9129, 0.9429, 0.9091] 
2025-12-16 14:05:27.769014: Epoch time: 138.35 s 
2025-12-16 14:05:28.404309:  
2025-12-16 14:05:28.404309: Epoch 290 
2025-12-16 14:05:28.404309: Current learning rate: 0.00735 
2025-12-16 14:07:46.755280: train_loss -0.8478 
2025-12-16 14:07:46.755280: val_loss -0.844 
2025-12-16 14:07:46.761028: Pseudo dice [0.9088, 0.9379, 0.9321] 
2025-12-16 14:07:46.764990: Epoch time: 138.37 s 
2025-12-16 14:07:47.409121:  
2025-12-16 14:07:47.409121: Epoch 291 
2025-12-16 14:07:47.409121: Current learning rate: 0.00734 
2025-12-16 14:10:06.168989: train_loss -0.8432 
2025-12-16 14:10:06.168989: val_loss -0.8709 
2025-12-16 14:10:06.173939: Pseudo dice [0.9256, 0.9563, 0.931] 
2025-12-16 14:10:06.176944: Epoch time: 138.76 s 
2025-12-16 14:10:06.818124:  
2025-12-16 14:10:06.818124: Epoch 292 
2025-12-16 14:10:06.818124: Current learning rate: 0.00733 
2025-12-16 14:12:25.020449: train_loss -0.8409 
2025-12-16 14:12:25.020449: val_loss -0.848 
2025-12-16 14:12:25.024191: Pseudo dice [0.9153, 0.942, 0.9238] 
2025-12-16 14:12:25.027318: Epoch time: 138.2 s 
2025-12-16 14:12:25.830955:  
2025-12-16 14:12:25.830955: Epoch 293 
2025-12-16 14:12:25.830955: Current learning rate: 0.00732 
2025-12-16 14:14:43.732345: train_loss -0.838 
2025-12-16 14:14:43.732345: val_loss -0.8611 
2025-12-16 14:14:43.732345: Pseudo dice [0.9207, 0.952, 0.93] 
2025-12-16 14:14:43.732345: Epoch time: 137.9 s 
2025-12-16 14:14:44.491348:  
2025-12-16 14:14:44.491348: Epoch 294 
2025-12-16 14:14:44.491348: Current learning rate: 0.00731 
2025-12-16 14:17:02.476585: train_loss -0.8417 
2025-12-16 14:17:02.478587: val_loss -0.8609 
2025-12-16 14:17:02.480588: Pseudo dice [0.924, 0.9539, 0.9162] 
2025-12-16 14:17:02.480588: Epoch time: 137.99 s 
2025-12-16 14:17:03.129117:  
2025-12-16 14:17:03.129117: Epoch 295 
2025-12-16 14:17:03.131120: Current learning rate: 0.0073 
2025-12-16 14:19:21.051135: train_loss -0.842 
2025-12-16 14:19:21.051135: val_loss -0.8497 
2025-12-16 14:19:21.051135: Pseudo dice [0.9135, 0.9517, 0.9176] 
2025-12-16 14:19:21.051135: Epoch time: 137.92 s 
2025-12-16 14:19:21.702225:  
2025-12-16 14:19:21.702225: Epoch 296 
2025-12-16 14:19:21.704295: Current learning rate: 0.00729 
2025-12-16 14:21:39.543249: train_loss -0.8413 
2025-12-16 14:21:39.543249: val_loss -0.8555 
2025-12-16 14:21:39.559107: Pseudo dice [0.9188, 0.9507, 0.9307] 
2025-12-16 14:21:39.562608: Epoch time: 137.84 s 
2025-12-16 14:21:40.208998:  
2025-12-16 14:21:40.208998: Epoch 297 
2025-12-16 14:21:40.208998: Current learning rate: 0.00728 
2025-12-16 14:23:58.070627: train_loss -0.8368 
2025-12-16 14:23:58.070627: val_loss -0.8553 
2025-12-16 14:23:58.074952: Pseudo dice [0.9134, 0.9522, 0.9307] 
2025-12-16 14:23:58.076954: Epoch time: 137.88 s 
2025-12-16 14:23:58.737370:  
2025-12-16 14:23:58.737370: Epoch 298 
2025-12-16 14:23:58.753302: Current learning rate: 0.00727 
2025-12-16 14:26:16.791432: train_loss -0.8382 
2025-12-16 14:26:16.793434: val_loss -0.8606 
2025-12-16 14:26:16.797438: Pseudo dice [0.9198, 0.9543, 0.9293] 
2025-12-16 14:26:16.799440: Epoch time: 138.05 s 
2025-12-16 14:26:16.803445: Yayy! New best EMA pseudo Dice: 0.9311 
2025-12-16 14:26:17.861441:  
2025-12-16 14:26:17.861441: Epoch 299 
2025-12-16 14:26:17.861441: Current learning rate: 0.00726 
2025-12-16 14:28:35.893511: train_loss -0.8095 
2025-12-16 14:28:35.893511: val_loss -0.8096 
2025-12-16 14:28:35.898499: Pseudo dice [0.8957, 0.9383, 0.9017] 
2025-12-16 14:28:35.900501: Epoch time: 138.03 s 
2025-12-16 14:28:36.779014:  
2025-12-16 14:28:36.779014: Epoch 300 
2025-12-16 14:28:36.779014: Current learning rate: 0.00725 
2025-12-16 14:30:54.869938: train_loss -0.7917 
2025-12-16 14:30:54.869938: val_loss -0.8101 
2025-12-16 14:30:54.873943: Pseudo dice [0.9003, 0.9285, 0.9156] 
2025-12-16 14:30:54.875945: Epoch time: 138.09 s 
2025-12-16 14:30:55.512069:  
2025-12-16 14:30:55.512069: Epoch 301 
2025-12-16 14:30:55.512069: Current learning rate: 0.00724 
2025-12-16 14:33:13.507470: train_loss -0.8023 
2025-12-16 14:33:13.507470: val_loss -0.8485 
2025-12-16 14:33:13.511482: Pseudo dice [0.9185, 0.9472, 0.9199] 
2025-12-16 14:33:13.515487: Epoch time: 138.0 s 
2025-12-16 14:33:14.186645:  
2025-12-16 14:33:14.202437: Epoch 302 
2025-12-16 14:33:14.202437: Current learning rate: 0.00724 
2025-12-16 14:35:32.183456: train_loss -0.8261 
2025-12-16 14:35:32.185459: val_loss -0.8536 
2025-12-16 14:35:32.187462: Pseudo dice [0.9196, 0.9549, 0.9216] 
2025-12-16 14:35:32.191467: Epoch time: 138.0 s 
2025-12-16 14:35:32.830057:  
2025-12-16 14:35:32.830057: Epoch 303 
2025-12-16 14:35:32.830057: Current learning rate: 0.00723 
2025-12-16 14:37:50.784102: train_loss -0.8262 
2025-12-16 14:37:50.784102: val_loss -0.8484 
2025-12-16 14:37:50.789689: Pseudo dice [0.915, 0.953, 0.9178] 
2025-12-16 14:37:50.791691: Epoch time: 137.95 s 
2025-12-16 14:37:51.593725:  
2025-12-16 14:37:51.593725: Epoch 304 
2025-12-16 14:37:51.593725: Current learning rate: 0.00722 
2025-12-16 14:40:09.383492: train_loss -0.8235 
2025-12-16 14:40:09.387446: val_loss -0.8315 
2025-12-16 14:40:09.389449: Pseudo dice [0.9111, 0.9424, 0.9083] 
2025-12-16 14:40:09.393996: Epoch time: 137.79 s 
2025-12-16 14:40:10.050041:  
2025-12-16 14:40:10.050041: Epoch 305 
2025-12-16 14:40:10.050041: Current learning rate: 0.00721 
2025-12-16 14:42:27.805526: train_loss -0.8014 
2025-12-16 14:42:27.805526: val_loss -0.8388 
2025-12-16 14:42:27.821381: Pseudo dice [0.9132, 0.9467, 0.9155] 
2025-12-16 14:42:27.821381: Epoch time: 137.76 s 
2025-12-16 14:42:28.450001:  
2025-12-16 14:42:28.450001: Epoch 306 
2025-12-16 14:42:28.450001: Current learning rate: 0.0072 
2025-12-16 14:44:46.521214: train_loss -0.8197 
2025-12-16 14:44:46.521214: val_loss -0.8344 
2025-12-16 14:44:46.523216: Pseudo dice [0.9058, 0.9454, 0.9121] 
2025-12-16 14:44:46.527222: Epoch time: 138.07 s 
2025-12-16 14:44:47.170465:  
2025-12-16 14:44:47.170465: Epoch 307 
2025-12-16 14:44:47.173556: Current learning rate: 0.00719 
2025-12-16 14:47:05.092702: train_loss -0.8261 
2025-12-16 14:47:05.092702: val_loss -0.8338 
2025-12-16 14:47:05.092702: Pseudo dice [0.904, 0.9385, 0.9155] 
2025-12-16 14:47:05.102821: Epoch time: 137.92 s 
2025-12-16 14:47:05.868974:  
2025-12-16 14:47:05.868974: Epoch 308 
2025-12-16 14:47:05.868974: Current learning rate: 0.00718 
2025-12-16 14:49:23.829606: train_loss -0.8267 
2025-12-16 14:49:23.831612: val_loss -0.8591 
2025-12-16 14:49:23.836623: Pseudo dice [0.9239, 0.9539, 0.9146] 
2025-12-16 14:49:23.839528: Epoch time: 137.96 s 
2025-12-16 14:49:24.470594:  
2025-12-16 14:49:24.470594: Epoch 309 
2025-12-16 14:49:24.470594: Current learning rate: 0.00717 
2025-12-16 14:51:42.366717: train_loss -0.8338 
2025-12-16 14:51:42.368720: val_loss -0.8496 
2025-12-16 14:51:42.372465: Pseudo dice [0.9191, 0.9522, 0.919] 
2025-12-16 14:51:42.376470: Epoch time: 137.9 s 
2025-12-16 14:51:43.004965:  
2025-12-16 14:51:43.004965: Epoch 310 
2025-12-16 14:51:43.020902: Current learning rate: 0.00716 
2025-12-16 14:54:00.947766: train_loss -0.8379 
2025-12-16 14:54:00.949769: val_loss -0.8584 
2025-12-16 14:54:00.953774: Pseudo dice [0.9183, 0.952, 0.932] 
2025-12-16 14:54:00.957782: Epoch time: 137.94 s 
2025-12-16 14:54:01.863410:  
2025-12-16 14:54:01.863410: Epoch 311 
2025-12-16 14:54:01.877366: Current learning rate: 0.00715 
2025-12-16 14:56:19.816128: train_loss -0.8331 
2025-12-16 14:56:19.816128: val_loss -0.852 
2025-12-16 14:56:19.832160: Pseudo dice [0.915, 0.95, 0.9162] 
2025-12-16 14:56:19.836109: Epoch time: 137.95 s 
2025-12-16 14:56:20.464346:  
2025-12-16 14:56:20.464346: Epoch 312 
2025-12-16 14:56:20.464346: Current learning rate: 0.00714 
2025-12-16 14:58:38.302219: train_loss -0.8363 
2025-12-16 14:58:38.302219: val_loss -0.8539 
2025-12-16 14:58:38.302219: Pseudo dice [0.9162, 0.9483, 0.927] 
2025-12-16 14:58:38.302219: Epoch time: 137.84 s 
2025-12-16 14:58:38.951956:  
2025-12-16 14:58:38.951956: Epoch 313 
2025-12-16 14:58:38.951956: Current learning rate: 0.00713 
2025-12-16 15:00:56.891766: train_loss -0.84 
2025-12-16 15:00:56.891766: val_loss -0.8534 
2025-12-16 15:00:56.897510: Pseudo dice [0.9207, 0.9516, 0.9114] 
2025-12-16 15:00:56.899512: Epoch time: 137.94 s 
2025-12-16 15:00:57.641506:  
2025-12-16 15:00:57.657204: Epoch 314 
2025-12-16 15:00:57.659208: Current learning rate: 0.00712 
2025-12-16 15:03:15.484257: train_loss -0.8357 
2025-12-16 15:03:15.484257: val_loss -0.8546 
2025-12-16 15:03:15.485999: Pseudo dice [0.9175, 0.9524, 0.9338] 
2025-12-16 15:03:15.485999: Epoch time: 137.84 s 
2025-12-16 15:03:16.182079:  
2025-12-16 15:03:16.182079: Epoch 315 
2025-12-16 15:03:16.182079: Current learning rate: 0.00711 
2025-12-16 15:05:34.196690: train_loss -0.833 
2025-12-16 15:05:34.196690: val_loss -0.8542 
2025-12-16 15:05:34.200695: Pseudo dice [0.919, 0.9515, 0.9209] 
2025-12-16 15:05:34.202697: Epoch time: 138.01 s 
2025-12-16 15:05:34.842271:  
2025-12-16 15:05:34.842271: Epoch 316 
2025-12-16 15:05:34.842271: Current learning rate: 0.0071 
2025-12-16 15:07:52.788648: train_loss -0.8385 
2025-12-16 15:07:52.788648: val_loss -0.8502 
2025-12-16 15:07:52.788648: Pseudo dice [0.9158, 0.9451, 0.9228] 
2025-12-16 15:07:52.788648: Epoch time: 137.95 s 
2025-12-16 15:07:53.596341:  
2025-12-16 15:07:53.596341: Epoch 317 
2025-12-16 15:07:53.602446: Current learning rate: 0.0071 
2025-12-16 15:10:12.072904: train_loss -0.8332 
2025-12-16 15:10:12.072904: val_loss -0.8578 
2025-12-16 15:10:12.088153: Pseudo dice [0.9195, 0.9531, 0.9241] 
2025-12-16 15:10:12.090156: Epoch time: 138.48 s 
2025-12-16 15:10:12.717241:  
2025-12-16 15:10:12.717241: Epoch 318 
2025-12-16 15:10:12.717241: Current learning rate: 0.00709 
2025-12-16 15:12:31.184583: train_loss -0.8404 
2025-12-16 15:12:31.184583: val_loss -0.8709 
2025-12-16 15:12:31.184583: Pseudo dice [0.9259, 0.9534, 0.9395] 
2025-12-16 15:12:31.195888: Epoch time: 138.47 s 
2025-12-16 15:12:31.851629:  
2025-12-16 15:12:31.851629: Epoch 319 
2025-12-16 15:12:31.861345: Current learning rate: 0.00708 
2025-12-16 15:14:49.837965: train_loss -0.8475 
2025-12-16 15:14:49.837965: val_loss -0.8512 
2025-12-16 15:14:49.854087: Pseudo dice [0.913, 0.9485, 0.925] 
2025-12-16 15:14:49.854087: Epoch time: 137.99 s 
2025-12-16 15:14:50.488766:  
2025-12-16 15:14:50.488766: Epoch 320 
2025-12-16 15:14:50.505813: Current learning rate: 0.00707 
2025-12-16 15:17:08.444637: train_loss -0.8441 
2025-12-16 15:17:08.444637: val_loss -0.8679 
2025-12-16 15:17:08.448643: Pseudo dice [0.9251, 0.958, 0.9327] 
2025-12-16 15:17:08.452387: Epoch time: 137.96 s 
2025-12-16 15:17:09.101655:  
2025-12-16 15:17:09.101655: Epoch 321 
2025-12-16 15:17:09.101655: Current learning rate: 0.00706 
2025-12-16 15:19:27.032730: train_loss -0.8438 
2025-12-16 15:19:27.034732: val_loss -0.8603 
2025-12-16 15:19:27.038737: Pseudo dice [0.924, 0.9544, 0.9206] 
2025-12-16 15:19:27.040740: Epoch time: 137.93 s 
2025-12-16 15:19:27.668708:  
2025-12-16 15:19:27.684730: Epoch 322 
2025-12-16 15:19:27.684730: Current learning rate: 0.00705 
2025-12-16 15:21:45.563630: train_loss -0.839 
2025-12-16 15:21:45.565632: val_loss -0.8598 
2025-12-16 15:21:45.567635: Pseudo dice [0.9206, 0.9507, 0.9271] 
2025-12-16 15:21:45.571640: Epoch time: 137.89 s 
2025-12-16 15:21:45.573692: Yayy! New best EMA pseudo Dice: 0.9312 
2025-12-16 15:21:46.640234:  
2025-12-16 15:21:46.642237: Epoch 323 
2025-12-16 15:21:46.642237: Current learning rate: 0.00704 
2025-12-16 15:24:04.753661: train_loss -0.8353 
2025-12-16 15:24:04.753661: val_loss -0.8597 
2025-12-16 15:24:04.761276: Pseudo dice [0.9236, 0.9541, 0.9262] 
2025-12-16 15:24:04.763278: Epoch time: 138.11 s 
2025-12-16 15:24:04.767282: Yayy! New best EMA pseudo Dice: 0.9315 
2025-12-16 15:24:05.660927:  
2025-12-16 15:24:05.660927: Epoch 324 
2025-12-16 15:24:05.667064: Current learning rate: 0.00703 
2025-12-16 15:26:23.635105: train_loss -0.8402 
2025-12-16 15:26:23.635105: val_loss -0.8573 
2025-12-16 15:26:23.641081: Pseudo dice [0.9234, 0.9518, 0.9202] 
2025-12-16 15:26:23.641081: Epoch time: 137.97 s 
2025-12-16 15:26:23.646790: Yayy! New best EMA pseudo Dice: 0.9315 
2025-12-16 15:26:24.537761:  
2025-12-16 15:26:24.537761: Epoch 325 
2025-12-16 15:26:24.537761: Current learning rate: 0.00702 
2025-12-16 15:28:42.316420: train_loss -0.8446 
2025-12-16 15:28:42.316420: val_loss -0.8633 
2025-12-16 15:28:42.325417: Pseudo dice [0.9244, 0.9562, 0.9233] 
2025-12-16 15:28:42.325417: Epoch time: 137.78 s 
2025-12-16 15:28:42.325417: Yayy! New best EMA pseudo Dice: 0.9319 
2025-12-16 15:28:43.230325:  
2025-12-16 15:28:43.230325: Epoch 326 
2025-12-16 15:28:43.230325: Current learning rate: 0.00701 
2025-12-16 15:31:01.237316: train_loss -0.841 
2025-12-16 15:31:01.237316: val_loss -0.8696 
2025-12-16 15:31:01.241320: Pseudo dice [0.9262, 0.9552, 0.9321] 
2025-12-16 15:31:01.245324: Epoch time: 138.01 s 
2025-12-16 15:31:01.249328: Yayy! New best EMA pseudo Dice: 0.9325 
2025-12-16 15:31:02.162196:  
2025-12-16 15:31:02.162196: Epoch 327 
2025-12-16 15:31:02.162196: Current learning rate: 0.007 
2025-12-16 15:33:20.393430: train_loss -0.8401 
2025-12-16 15:33:20.393430: val_loss -0.8661 
2025-12-16 15:33:20.393430: Pseudo dice [0.9249, 0.9552, 0.9303] 
2025-12-16 15:33:20.393430: Epoch time: 138.23 s 
2025-12-16 15:33:20.393430: Yayy! New best EMA pseudo Dice: 0.9329 
2025-12-16 15:33:21.491601:  
2025-12-16 15:33:21.491601: Epoch 328 
2025-12-16 15:33:21.491601: Current learning rate: 0.00699 
2025-12-16 15:35:39.604518: train_loss -0.8415 
2025-12-16 15:35:39.604518: val_loss -0.8631 
2025-12-16 15:35:39.610264: Pseudo dice [0.9215, 0.9523, 0.9327] 
2025-12-16 15:35:39.612153: Epoch time: 138.11 s 
2025-12-16 15:35:39.616157: Yayy! New best EMA pseudo Dice: 0.9331 
2025-12-16 15:35:40.522240:  
2025-12-16 15:35:40.522240: Epoch 329 
2025-12-16 15:35:40.522240: Current learning rate: 0.00698 
2025-12-16 15:37:58.603568: train_loss -0.8411 
2025-12-16 15:37:58.603568: val_loss -0.8689 
2025-12-16 15:37:58.607311: Pseudo dice [0.9253, 0.959, 0.9269] 
2025-12-16 15:37:58.609313: Epoch time: 138.08 s 
2025-12-16 15:37:58.613317: Yayy! New best EMA pseudo Dice: 0.9335 
2025-12-16 15:37:59.522043:  
2025-12-16 15:37:59.522043: Epoch 330 
2025-12-16 15:37:59.522043: Current learning rate: 0.00697 
2025-12-16 15:40:17.306255: train_loss -0.8417 
2025-12-16 15:40:17.306255: val_loss -0.8571 
2025-12-16 15:40:17.314277: Pseudo dice [0.9185, 0.9521, 0.9269] 
2025-12-16 15:40:17.318290: Epoch time: 137.79 s 
2025-12-16 15:40:17.990074:  
2025-12-16 15:40:17.990074: Epoch 331 
2025-12-16 15:40:17.990074: Current learning rate: 0.00696 
2025-12-16 15:42:35.849999: train_loss -0.837 
2025-12-16 15:42:35.849999: val_loss -0.867 
2025-12-16 15:42:35.855503: Pseudo dice [0.9219, 0.9577, 0.9311] 
2025-12-16 15:42:35.857506: Epoch time: 137.86 s 
2025-12-16 15:42:35.861509: Yayy! New best EMA pseudo Dice: 0.9338 
2025-12-16 15:42:36.768193:  
2025-12-16 15:42:36.768193: Epoch 332 
2025-12-16 15:42:36.784121: Current learning rate: 0.00696 
2025-12-16 15:44:54.746033: train_loss -0.8402 
2025-12-16 15:44:54.748036: val_loss -0.851 
2025-12-16 15:44:54.750039: Pseudo dice [0.9156, 0.9522, 0.9208] 
2025-12-16 15:44:54.752042: Epoch time: 137.98 s 
2025-12-16 15:44:55.384390:  
2025-12-16 15:44:55.384390: Epoch 333 
2025-12-16 15:44:55.384390: Current learning rate: 0.00695 
2025-12-16 15:47:13.244583: train_loss -0.8432 
2025-12-16 15:47:13.244583: val_loss -0.8736 
2025-12-16 15:47:13.248589: Pseudo dice [0.9281, 0.9575, 0.932] 
2025-12-16 15:47:13.248589: Epoch time: 137.86 s 
2025-12-16 15:47:13.248589: Yayy! New best EMA pseudo Dice: 0.9339 
2025-12-16 15:47:14.359894:  
2025-12-16 15:47:14.359894: Epoch 334 
2025-12-16 15:47:14.359894: Current learning rate: 0.00694 
2025-12-16 15:49:32.307305: train_loss -0.8428 
2025-12-16 15:49:32.307305: val_loss -0.855 
2025-12-16 15:49:32.313050: Pseudo dice [0.9154, 0.9514, 0.9304] 
2025-12-16 15:49:32.315052: Epoch time: 137.96 s 
2025-12-16 15:49:32.961443:  
2025-12-16 15:49:32.961443: Epoch 335 
2025-12-16 15:49:32.977409: Current learning rate: 0.00693 
2025-12-16 15:51:51.098881: train_loss -0.8402 
2025-12-16 15:51:51.098881: val_loss -0.8538 
2025-12-16 15:51:51.100884: Pseudo dice [0.9191, 0.9501, 0.9156] 
2025-12-16 15:51:51.100884: Epoch time: 138.14 s 
2025-12-16 15:51:51.740039:  
2025-12-16 15:51:51.740039: Epoch 336 
2025-12-16 15:51:51.744152: Current learning rate: 0.00692 
2025-12-16 15:54:09.938270: train_loss -0.8329 
2025-12-16 15:54:09.938270: val_loss -0.8583 
2025-12-16 15:54:09.942289: Pseudo dice [0.9162, 0.9505, 0.9349] 
2025-12-16 15:54:09.942289: Epoch time: 138.2 s 
2025-12-16 15:54:10.583430:  
2025-12-16 15:54:10.583430: Epoch 337 
2025-12-16 15:54:10.585721: Current learning rate: 0.00691 
2025-12-16 15:56:28.508367: train_loss -0.8355 
2025-12-16 15:56:28.508367: val_loss -0.8567 
2025-12-16 15:56:28.515868: Pseudo dice [0.9195, 0.9501, 0.9249] 
2025-12-16 15:56:28.517871: Epoch time: 137.93 s 
2025-12-16 15:56:29.178795:  
2025-12-16 15:56:29.178795: Epoch 338 
2025-12-16 15:56:29.182915: Current learning rate: 0.0069 
2025-12-16 15:58:47.008585: train_loss -0.846 
2025-12-16 15:58:47.008585: val_loss -0.8701 
2025-12-16 15:58:47.008585: Pseudo dice [0.9287, 0.9592, 0.9272] 
2025-12-16 15:58:47.008585: Epoch time: 137.83 s 
2025-12-16 15:58:47.660354:  
2025-12-16 15:58:47.660354: Epoch 339 
2025-12-16 15:58:47.660354: Current learning rate: 0.00689 
2025-12-16 16:01:05.558041: train_loss -0.8368 
2025-12-16 16:01:05.560043: val_loss -0.8639 
2025-12-16 16:01:05.562045: Pseudo dice [0.9221, 0.9522, 0.9295] 
2025-12-16 16:01:05.565787: Epoch time: 137.9 s 
2025-12-16 16:01:06.482609:  
2025-12-16 16:01:06.482609: Epoch 340 
2025-12-16 16:01:06.482609: Current learning rate: 0.00688 
2025-12-16 16:03:24.487587: train_loss -0.8479 
2025-12-16 16:03:24.487587: val_loss -0.8531 
2025-12-16 16:03:24.493593: Pseudo dice [0.9118, 0.9483, 0.9301] 
2025-12-16 16:03:24.495595: Epoch time: 138.01 s 
2025-12-16 16:03:25.130353:  
2025-12-16 16:03:25.130353: Epoch 341 
2025-12-16 16:03:25.130353: Current learning rate: 0.00687 
2025-12-16 16:05:43.166049: train_loss -0.841 
2025-12-16 16:05:43.166049: val_loss -0.8552 
2025-12-16 16:05:43.166049: Pseudo dice [0.9178, 0.9474, 0.9248] 
2025-12-16 16:05:43.166049: Epoch time: 138.04 s 
2025-12-16 16:05:43.799685:  
2025-12-16 16:05:43.799685: Epoch 342 
2025-12-16 16:05:43.799685: Current learning rate: 0.00686 
2025-12-16 16:08:01.728302: train_loss -0.8437 
2025-12-16 16:08:01.728302: val_loss -0.875 
2025-12-16 16:08:01.732309: Pseudo dice [0.931, 0.9606, 0.9328] 
2025-12-16 16:08:01.734312: Epoch time: 137.93 s 
2025-12-16 16:08:02.565422:  
2025-12-16 16:08:02.565422: Epoch 343 
2025-12-16 16:08:02.565422: Current learning rate: 0.00685 
2025-12-16 16:10:21.444956: train_loss -0.8429 
2025-12-16 16:10:21.444956: val_loss -0.8661 
2025-12-16 16:10:21.460844: Pseudo dice [0.9238, 0.9516, 0.9356] 
2025-12-16 16:10:21.464850: Epoch time: 138.88 s 
2025-12-16 16:10:21.466853: Yayy! New best EMA pseudo Dice: 0.9342 
2025-12-16 16:10:22.353577:  
2025-12-16 16:10:22.355579: Epoch 344 
2025-12-16 16:10:22.358858: Current learning rate: 0.00684 
2025-12-16 16:12:40.082692: train_loss -0.8443 
2025-12-16 16:12:40.082692: val_loss -0.8635 
2025-12-16 16:12:40.082692: Pseudo dice [0.9224, 0.9538, 0.9216] 
2025-12-16 16:12:40.082692: Epoch time: 137.73 s 
2025-12-16 16:12:40.715704:  
2025-12-16 16:12:40.715704: Epoch 345 
2025-12-16 16:12:40.731724: Current learning rate: 0.00683 
2025-12-16 16:14:58.797804: train_loss -0.8467 
2025-12-16 16:14:58.797804: val_loss -0.864 
2025-12-16 16:14:58.797804: Pseudo dice [0.926, 0.9567, 0.9188] 
2025-12-16 16:14:58.797804: Epoch time: 138.08 s 
2025-12-16 16:14:59.700279:  
2025-12-16 16:14:59.700279: Epoch 346 
2025-12-16 16:14:59.716359: Current learning rate: 0.00682 
2025-12-16 16:17:17.660641: train_loss -0.8409 
2025-12-16 16:17:17.660641: val_loss -0.8646 
2025-12-16 16:17:17.660641: Pseudo dice [0.9284, 0.9573, 0.9271] 
2025-12-16 16:17:17.660641: Epoch time: 137.96 s 
2025-12-16 16:17:17.660641: Yayy! New best EMA pseudo Dice: 0.9344 
2025-12-16 16:17:18.550143:  
2025-12-16 16:17:18.550143: Epoch 347 
2025-12-16 16:17:18.550143: Current learning rate: 0.00681 
2025-12-16 16:19:36.355481: train_loss -0.8423 
2025-12-16 16:19:36.355481: val_loss -0.8598 
2025-12-16 16:19:36.363235: Pseudo dice [0.9174, 0.9545, 0.923] 
2025-12-16 16:19:36.367240: Epoch time: 137.81 s 
2025-12-16 16:19:37.014271:  
2025-12-16 16:19:37.014271: Epoch 348 
2025-12-16 16:19:37.014271: Current learning rate: 0.0068 
2025-12-16 16:21:55.023301: train_loss -0.8386 
2025-12-16 16:21:55.025302: val_loss -0.8515 
2025-12-16 16:21:55.031051: Pseudo dice [0.9136, 0.9505, 0.9201] 
2025-12-16 16:21:55.035058: Epoch time: 138.01 s 
2025-12-16 16:21:55.804775:  
2025-12-16 16:21:55.804775: Epoch 349 
2025-12-16 16:21:55.804775: Current learning rate: 0.0068 
2025-12-16 16:24:13.818401: train_loss -0.8382 
2025-12-16 16:24:13.818401: val_loss -0.8628 
2025-12-16 16:24:13.818401: Pseudo dice [0.9255, 0.9557, 0.9221] 
2025-12-16 16:24:13.834202: Epoch time: 138.01 s 
2025-12-16 16:24:14.708383:  
2025-12-16 16:24:14.708383: Epoch 350 
2025-12-16 16:24:14.708383: Current learning rate: 0.00679 
2025-12-16 16:26:32.570302: train_loss -0.8425 
2025-12-16 16:26:32.570302: val_loss -0.865 
2025-12-16 16:26:32.586276: Pseudo dice [0.9241, 0.9556, 0.9323] 
2025-12-16 16:26:32.588117: Epoch time: 137.86 s 
2025-12-16 16:26:33.234385:  
2025-12-16 16:26:33.234385: Epoch 351 
2025-12-16 16:26:33.234385: Current learning rate: 0.00678 
2025-12-16 16:28:51.195454: train_loss -0.8471 
2025-12-16 16:28:51.195454: val_loss -0.8531 
2025-12-16 16:28:51.199196: Pseudo dice [0.9114, 0.9485, 0.9318] 
2025-12-16 16:28:51.203200: Epoch time: 137.96 s 
2025-12-16 16:28:52.178189:  
2025-12-16 16:28:52.178189: Epoch 352 
2025-12-16 16:28:52.184231: Current learning rate: 0.00677 
2025-12-16 16:31:10.271085: train_loss -0.8381 
2025-12-16 16:31:10.271085: val_loss -0.8601 
2025-12-16 16:31:10.271085: Pseudo dice [0.9185, 0.9513, 0.9364] 
2025-12-16 16:31:10.289050: Epoch time: 138.09 s 
2025-12-16 16:31:10.936507:  
2025-12-16 16:31:10.936507: Epoch 353 
2025-12-16 16:31:10.936507: Current learning rate: 0.00676 
2025-12-16 16:33:28.927839: train_loss -0.8351 
2025-12-16 16:33:28.927839: val_loss -0.8585 
2025-12-16 16:33:28.931659: Pseudo dice [0.9174, 0.9542, 0.9371] 
2025-12-16 16:33:28.933661: Epoch time: 137.99 s 
2025-12-16 16:33:29.579475:  
2025-12-16 16:33:29.579475: Epoch 354 
2025-12-16 16:33:29.579475: Current learning rate: 0.00675 
2025-12-16 16:35:47.628822: train_loss -0.8337 
2025-12-16 16:35:47.628822: val_loss -0.8502 
2025-12-16 16:35:47.636574: Pseudo dice [0.9127, 0.9494, 0.9291] 
2025-12-16 16:35:47.640579: Epoch time: 138.05 s 
2025-12-16 16:35:48.420367:  
2025-12-16 16:35:48.420367: Epoch 355 
2025-12-16 16:35:48.420367: Current learning rate: 0.00674 
2025-12-16 16:38:06.266654: train_loss -0.8435 
2025-12-16 16:38:06.266654: val_loss -0.8478 
2025-12-16 16:38:06.282327: Pseudo dice [0.9109, 0.9478, 0.9232] 
2025-12-16 16:38:06.286332: Epoch time: 137.85 s 
2025-12-16 16:38:06.932170:  
2025-12-16 16:38:06.932170: Epoch 356 
2025-12-16 16:38:06.932170: Current learning rate: 0.00673 
2025-12-16 16:40:24.858468: train_loss -0.8434 
2025-12-16 16:40:24.858468: val_loss -0.8668 
2025-12-16 16:40:24.860470: Pseudo dice [0.9252, 0.9594, 0.9317] 
2025-12-16 16:40:24.860470: Epoch time: 137.93 s 
2025-12-16 16:40:25.657051:  
2025-12-16 16:40:25.657051: Epoch 357 
2025-12-16 16:40:25.671070: Current learning rate: 0.00672 
2025-12-16 16:42:43.574767: train_loss -0.8273 
2025-12-16 16:42:43.574767: val_loss -0.8451 
2025-12-16 16:42:43.574767: Pseudo dice [0.9103, 0.9483, 0.9211] 
2025-12-16 16:42:43.574767: Epoch time: 137.92 s 
2025-12-16 16:42:44.242331:  
2025-12-16 16:42:44.242331: Epoch 358 
2025-12-16 16:42:44.242331: Current learning rate: 0.00671 
2025-12-16 16:45:02.248922: train_loss -0.824 
2025-12-16 16:45:02.248922: val_loss -0.8395 
2025-12-16 16:45:02.264626: Pseudo dice [0.9141, 0.9515, 0.9118] 
2025-12-16 16:45:02.264626: Epoch time: 138.01 s 
2025-12-16 16:45:02.898663:  
2025-12-16 16:45:02.898663: Epoch 359 
2025-12-16 16:45:02.898663: Current learning rate: 0.0067 
2025-12-16 16:47:20.853943: train_loss -0.8339 
2025-12-16 16:47:20.855944: val_loss -0.8643 
2025-12-16 16:47:20.859688: Pseudo dice [0.9242, 0.9558, 0.9328] 
2025-12-16 16:47:20.861690: Epoch time: 137.96 s 
2025-12-16 16:47:21.508488:  
2025-12-16 16:47:21.508488: Epoch 360 
2025-12-16 16:47:21.508488: Current learning rate: 0.00669 
2025-12-16 16:49:39.285097: train_loss -0.8388 
2025-12-16 16:49:39.285097: val_loss -0.8613 
2025-12-16 16:49:39.289101: Pseudo dice [0.9243, 0.951, 0.9218] 
2025-12-16 16:49:39.293105: Epoch time: 137.78 s 
2025-12-16 16:49:39.951447:  
2025-12-16 16:49:39.951447: Epoch 361 
2025-12-16 16:49:39.951447: Current learning rate: 0.00668 
2025-12-16 16:51:57.969033: train_loss -0.8443 
2025-12-16 16:51:57.969033: val_loss -0.8727 
2025-12-16 16:51:57.975040: Pseudo dice [0.9285, 0.9612, 0.9271] 
2025-12-16 16:51:57.977042: Epoch time: 138.02 s 
2025-12-16 16:51:58.635065:  
2025-12-16 16:51:58.637068: Epoch 362 
2025-12-16 16:51:58.637068: Current learning rate: 0.00667 
2025-12-16 16:54:16.632699: train_loss -0.8445 
2025-12-16 16:54:16.632699: val_loss -0.8623 
2025-12-16 16:54:16.638204: Pseudo dice [0.9197, 0.9537, 0.9356] 
2025-12-16 16:54:16.642210: Epoch time: 138.0 s 
2025-12-16 16:54:17.291172:  
2025-12-16 16:54:17.291172: Epoch 363 
2025-12-16 16:54:17.291172: Current learning rate: 0.00666 
2025-12-16 16:56:35.335723: train_loss -0.8395 
2025-12-16 16:56:35.337463: val_loss -0.8613 
2025-12-16 16:56:35.341469: Pseudo dice [0.9175, 0.9514, 0.934] 
2025-12-16 16:56:35.345473: Epoch time: 138.05 s 
2025-12-16 16:56:36.170847:  
2025-12-16 16:56:36.170847: Epoch 364 
2025-12-16 16:56:36.172849: Current learning rate: 0.00665 
2025-12-16 16:58:54.140263: train_loss -0.8403 
2025-12-16 16:58:54.140263: val_loss -0.8567 
2025-12-16 16:58:54.144268: Pseudo dice [0.9173, 0.951, 0.9305] 
2025-12-16 16:58:54.148010: Epoch time: 137.97 s 
2025-12-16 16:58:54.783741:  
2025-12-16 16:58:54.783741: Epoch 365 
2025-12-16 16:58:54.783741: Current learning rate: 0.00665 
2025-12-16 17:01:12.870845: train_loss -0.8428 
2025-12-16 17:01:12.870845: val_loss -0.8677 
2025-12-16 17:01:12.874632: Pseudo dice [0.9259, 0.9559, 0.9319] 
2025-12-16 17:01:12.876635: Epoch time: 138.09 s 
2025-12-16 17:01:13.596764:  
2025-12-16 17:01:13.596764: Epoch 366 
2025-12-16 17:01:13.604032: Current learning rate: 0.00664 
2025-12-16 17:03:31.613278: train_loss -0.8467 
2025-12-16 17:03:31.613278: val_loss -0.8676 
2025-12-16 17:03:31.625650: Pseudo dice [0.9188, 0.953, 0.9432] 
2025-12-16 17:03:31.625650: Epoch time: 138.02 s 
2025-12-16 17:03:31.629360: Yayy! New best EMA pseudo Dice: 0.9345 
2025-12-16 17:03:32.516093:  
2025-12-16 17:03:32.516093: Epoch 367 
2025-12-16 17:03:32.529441: Current learning rate: 0.00663 
2025-12-16 17:05:50.632636: train_loss -0.8413 
2025-12-16 17:05:50.632636: val_loss -0.8581 
2025-12-16 17:05:50.638643: Pseudo dice [0.9221, 0.9513, 0.9259] 
2025-12-16 17:05:50.640645: Epoch time: 138.12 s 
2025-12-16 17:05:51.296766:  
2025-12-16 17:05:51.296766: Epoch 368 
2025-12-16 17:05:51.304564: Current learning rate: 0.00662 
2025-12-16 17:08:09.092430: train_loss -0.8405 
2025-12-16 17:08:09.092430: val_loss -0.8595 
2025-12-16 17:08:09.108133: Pseudo dice [0.9219, 0.9492, 0.9299] 
2025-12-16 17:08:09.108133: Epoch time: 137.8 s 
2025-12-16 17:08:09.886272:  
2025-12-16 17:08:09.886272: Epoch 369 
2025-12-16 17:08:09.902277: Current learning rate: 0.00661 
2025-12-16 17:10:28.446867: train_loss -0.8454 
2025-12-16 17:10:28.446867: val_loss -0.8692 
2025-12-16 17:10:28.452874: Pseudo dice [0.9244, 0.9568, 0.9303] 
2025-12-16 17:10:28.455878: Epoch time: 138.56 s 
2025-12-16 17:10:28.459882: Yayy! New best EMA pseudo Dice: 0.9346 
2025-12-16 17:10:29.352103:  
2025-12-16 17:10:29.352103: Epoch 370 
2025-12-16 17:10:29.352103: Current learning rate: 0.0066 
2025-12-16 17:12:47.428914: train_loss -0.8404 
2025-12-16 17:12:47.428914: val_loss -0.8723 
2025-12-16 17:12:47.428914: Pseudo dice [0.9265, 0.9595, 0.9365] 
2025-12-16 17:12:47.428914: Epoch time: 138.08 s 
2025-12-16 17:12:47.428914: Yayy! New best EMA pseudo Dice: 0.9352 
2025-12-16 17:12:48.356742:  
2025-12-16 17:12:48.356742: Epoch 371 
2025-12-16 17:12:48.356742: Current learning rate: 0.00659 
2025-12-16 17:15:06.382193: train_loss -0.8458 
2025-12-16 17:15:06.382193: val_loss -0.8568 
2025-12-16 17:15:06.386199: Pseudo dice [0.9169, 0.9514, 0.9331] 
2025-12-16 17:15:06.389943: Epoch time: 138.03 s 
2025-12-16 17:15:07.056344:  
2025-12-16 17:15:07.056344: Epoch 372 
2025-12-16 17:15:07.056344: Current learning rate: 0.00658 
2025-12-16 17:17:25.037724: train_loss -0.8377 
2025-12-16 17:17:25.037724: val_loss -0.8445 
2025-12-16 17:17:25.037724: Pseudo dice [0.9147, 0.9469, 0.9138] 
2025-12-16 17:17:25.037724: Epoch time: 137.98 s 
2025-12-16 17:17:25.693233:  
2025-12-16 17:17:25.693233: Epoch 373 
2025-12-16 17:17:25.696575: Current learning rate: 0.00657 
2025-12-16 17:19:43.669031: train_loss -0.8322 
2025-12-16 17:19:43.669031: val_loss -0.866 
2025-12-16 17:19:43.672773: Pseudo dice [0.9248, 0.9558, 0.9257] 
2025-12-16 17:19:43.672773: Epoch time: 137.98 s 
2025-12-16 17:19:44.321665:  
2025-12-16 17:19:44.321665: Epoch 374 
2025-12-16 17:19:44.321665: Current learning rate: 0.00656 
2025-12-16 17:22:02.365810: train_loss -0.8442 
2025-12-16 17:22:02.365810: val_loss -0.8607 
2025-12-16 17:22:02.367812: Pseudo dice [0.9216, 0.9541, 0.928] 
2025-12-16 17:22:02.367812: Epoch time: 138.04 s 
2025-12-16 17:22:03.372761:  
2025-12-16 17:22:03.372761: Epoch 375 
2025-12-16 17:22:03.372761: Current learning rate: 0.00655 
2025-12-16 17:24:21.375738: train_loss -0.8432 
2025-12-16 17:24:21.375738: val_loss -0.8647 
2025-12-16 17:24:21.391525: Pseudo dice [0.9238, 0.954, 0.9271] 
2025-12-16 17:24:21.391525: Epoch time: 138.02 s 
2025-12-16 17:24:22.040853:  
2025-12-16 17:24:22.040853: Epoch 376 
2025-12-16 17:24:22.056633: Current learning rate: 0.00654 
2025-12-16 17:26:39.872334: train_loss -0.8432 
2025-12-16 17:26:39.872334: val_loss -0.8585 
2025-12-16 17:26:39.885764: Pseudo dice [0.9154, 0.9492, 0.9323] 
2025-12-16 17:26:39.887994: Epoch time: 137.83 s 
2025-12-16 17:26:40.536620:  
2025-12-16 17:26:40.536620: Epoch 377 
2025-12-16 17:26:40.536620: Current learning rate: 0.00653 
2025-12-16 17:28:58.424927: train_loss -0.848 
2025-12-16 17:28:58.424927: val_loss -0.8652 
2025-12-16 17:28:58.430192: Pseudo dice [0.9222, 0.9529, 0.9329] 
2025-12-16 17:28:58.430192: Epoch time: 137.89 s 
2025-12-16 17:28:59.169821:  
2025-12-16 17:28:59.169821: Epoch 378 
2025-12-16 17:28:59.185524: Current learning rate: 0.00652 
2025-12-16 17:31:16.915413: train_loss -0.8489 
2025-12-16 17:31:16.915413: val_loss -0.8572 
2025-12-16 17:31:16.931251: Pseudo dice [0.919, 0.9524, 0.9276] 
2025-12-16 17:31:16.931251: Epoch time: 137.75 s 
2025-12-16 17:31:17.581385:  
2025-12-16 17:31:17.581385: Epoch 379 
2025-12-16 17:31:17.581385: Current learning rate: 0.00651 
2025-12-16 17:33:35.514497: train_loss -0.839 
2025-12-16 17:33:35.514497: val_loss -0.8384 
2025-12-16 17:33:35.518605: Pseudo dice [0.9118, 0.9481, 0.906] 
2025-12-16 17:33:35.522609: Epoch time: 137.93 s 
2025-12-16 17:33:36.162198:  
2025-12-16 17:33:36.162198: Epoch 380 
2025-12-16 17:33:36.173231: Current learning rate: 0.0065 
2025-12-16 17:35:54.095599: train_loss -0.827 
2025-12-16 17:35:54.095599: val_loss -0.8555 
2025-12-16 17:35:54.104471: Pseudo dice [0.9199, 0.9519, 0.9271] 
2025-12-16 17:35:54.108076: Epoch time: 137.93 s 
2025-12-16 17:35:54.953763:  
2025-12-16 17:35:54.955766: Epoch 381 
2025-12-16 17:35:54.958081: Current learning rate: 0.00649 
2025-12-16 17:38:13.068562: train_loss -0.8264 
2025-12-16 17:38:13.068562: val_loss -0.8456 
2025-12-16 17:38:13.079970: Pseudo dice [0.9115, 0.9529, 0.9214] 
2025-12-16 17:38:13.079970: Epoch time: 138.11 s 
2025-12-16 17:38:13.733804:  
2025-12-16 17:38:13.733804: Epoch 382 
2025-12-16 17:38:13.749869: Current learning rate: 0.00648 
2025-12-16 17:40:31.665272: train_loss -0.8131 
2025-12-16 17:40:31.667275: val_loss -0.8333 
2025-12-16 17:40:31.667275: Pseudo dice [0.9074, 0.944, 0.9063] 
2025-12-16 17:40:31.667275: Epoch time: 137.93 s 
2025-12-16 17:40:32.324940:  
2025-12-16 17:40:32.324940: Epoch 383 
2025-12-16 17:40:32.330174: Current learning rate: 0.00648 
2025-12-16 17:42:50.352076: train_loss -0.8082 
2025-12-16 17:42:50.352076: val_loss -0.8354 
2025-12-16 17:42:50.352076: Pseudo dice [0.9091, 0.9441, 0.9154] 
2025-12-16 17:42:50.352076: Epoch time: 138.03 s 
2025-12-16 17:42:51.001332:  
2025-12-16 17:42:51.001332: Epoch 384 
2025-12-16 17:42:51.001332: Current learning rate: 0.00647 
2025-12-16 17:45:08.959367: train_loss -0.8205 
2025-12-16 17:45:08.959367: val_loss -0.831 
2025-12-16 17:45:08.963372: Pseudo dice [0.9044, 0.9412, 0.9239] 
2025-12-16 17:45:08.965375: Epoch time: 137.96 s 
2025-12-16 17:45:09.619950:  
2025-12-16 17:45:09.619950: Epoch 385 
2025-12-16 17:45:09.619950: Current learning rate: 0.00646 
2025-12-16 17:47:27.790867: train_loss -0.8284 
2025-12-16 17:47:27.792870: val_loss -0.8402 
2025-12-16 17:47:27.796875: Pseudo dice [0.9106, 0.9445, 0.9127] 
2025-12-16 17:47:27.799722: Epoch time: 138.17 s 
2025-12-16 17:47:28.460668:  
2025-12-16 17:47:28.460668: Epoch 386 
2025-12-16 17:47:28.460668: Current learning rate: 0.00645 
2025-12-16 17:49:46.594386: train_loss -0.8353 
2025-12-16 17:49:46.594386: val_loss -0.8534 
2025-12-16 17:49:46.602155: Pseudo dice [0.9201, 0.9531, 0.9202] 
2025-12-16 17:49:46.602155: Epoch time: 138.13 s 
2025-12-16 17:49:47.434402:  
2025-12-16 17:49:47.434402: Epoch 387 
2025-12-16 17:49:47.442049: Current learning rate: 0.00644 
2025-12-16 17:52:05.435626: train_loss -0.8363 
2025-12-16 17:52:05.435626: val_loss -0.8549 
2025-12-16 17:52:05.451263: Pseudo dice [0.9109, 0.9499, 0.9338] 
2025-12-16 17:52:05.455270: Epoch time: 138.0 s 
2025-12-16 17:52:06.116159:  
2025-12-16 17:52:06.116159: Epoch 388 
2025-12-16 17:52:06.116159: Current learning rate: 0.00643 
2025-12-16 17:54:24.087033: train_loss -0.8349 
2025-12-16 17:54:24.087033: val_loss -0.8574 
2025-12-16 17:54:24.102815: Pseudo dice [0.9202, 0.9542, 0.9193] 
2025-12-16 17:54:24.102815: Epoch time: 137.99 s 
2025-12-16 17:54:24.768145:  
2025-12-16 17:54:24.768145: Epoch 389 
2025-12-16 17:54:24.768145: Current learning rate: 0.00642 
2025-12-16 17:56:42.749063: train_loss -0.845 
2025-12-16 17:56:42.751065: val_loss -0.869 
2025-12-16 17:56:42.753067: Pseudo dice [0.9274, 0.9529, 0.9301] 
2025-12-16 17:56:42.753067: Epoch time: 137.98 s 
2025-12-16 17:56:43.402102:  
2025-12-16 17:56:43.402102: Epoch 390 
2025-12-16 17:56:43.402102: Current learning rate: 0.00641 
2025-12-16 17:59:01.483034: train_loss -0.8418 
2025-12-16 17:59:01.485036: val_loss -0.8568 
2025-12-16 17:59:01.489042: Pseudo dice [0.9159, 0.9506, 0.9279] 
2025-12-16 17:59:01.493904: Epoch time: 138.08 s 
2025-12-16 17:59:02.141582:  
2025-12-16 17:59:02.141582: Epoch 391 
2025-12-16 17:59:02.157217: Current learning rate: 0.0064 
2025-12-16 18:01:20.278382: train_loss -0.8431 
2025-12-16 18:01:20.278382: val_loss -0.8578 
2025-12-16 18:01:20.296912: Pseudo dice [0.9215, 0.9513, 0.931] 
2025-12-16 18:01:20.298913: Epoch time: 138.14 s 
2025-12-16 18:01:20.943784:  
2025-12-16 18:01:20.943784: Epoch 392 
2025-12-16 18:01:20.943784: Current learning rate: 0.00639 
2025-12-16 18:03:39.132776: train_loss -0.8413 
2025-12-16 18:03:39.132776: val_loss -0.8594 
2025-12-16 18:03:39.140795: Pseudo dice [0.9184, 0.9503, 0.929] 
2025-12-16 18:03:39.146550: Epoch time: 138.19 s 
2025-12-16 18:03:39.970088:  
2025-12-16 18:03:39.970088: Epoch 393 
2025-12-16 18:03:39.975757: Current learning rate: 0.00638 
2025-12-16 18:05:57.874338: train_loss -0.8395 
2025-12-16 18:05:57.874338: val_loss -0.8645 
2025-12-16 18:05:57.879690: Pseudo dice [0.9246, 0.954, 0.9338] 
2025-12-16 18:05:57.879690: Epoch time: 137.9 s 
2025-12-16 18:05:58.542282:  
2025-12-16 18:05:58.542282: Epoch 394 
2025-12-16 18:05:58.548956: Current learning rate: 0.00637 
2025-12-16 18:08:16.534985: train_loss -0.8424 
2025-12-16 18:08:16.534985: val_loss -0.8621 
2025-12-16 18:08:16.540304: Pseudo dice [0.922, 0.9532, 0.9241] 
2025-12-16 18:08:16.544047: Epoch time: 137.99 s 
2025-12-16 18:08:17.223520:  
2025-12-16 18:08:17.223520: Epoch 395 
2025-12-16 18:08:17.241609: Current learning rate: 0.00636 
2025-12-16 18:10:35.660508: train_loss -0.8466 
2025-12-16 18:10:35.660508: val_loss -0.8644 
2025-12-16 18:10:35.660508: Pseudo dice [0.9195, 0.9489, 0.9309] 
2025-12-16 18:10:35.668419: Epoch time: 138.44 s 
2025-12-16 18:10:36.309067:  
2025-12-16 18:10:36.309067: Epoch 396 
2025-12-16 18:10:36.309067: Current learning rate: 0.00635 
2025-12-16 18:12:53.967327: train_loss -0.8407 
2025-12-16 18:12:53.967327: val_loss -0.8572 
2025-12-16 18:12:53.967327: Pseudo dice [0.9182, 0.9532, 0.9274] 
2025-12-16 18:12:53.967327: Epoch time: 137.66 s 
2025-12-16 18:12:54.617101:  
2025-12-16 18:12:54.617101: Epoch 397 
2025-12-16 18:12:54.617101: Current learning rate: 0.00634 
2025-12-16 18:15:12.592933: train_loss -0.8437 
2025-12-16 18:15:12.592933: val_loss -0.8503 
2025-12-16 18:15:12.596938: Pseudo dice [0.9118, 0.949, 0.9224] 
2025-12-16 18:15:12.598941: Epoch time: 137.98 s 
2025-12-16 18:15:13.376490:  
2025-12-16 18:15:13.376490: Epoch 398 
2025-12-16 18:15:13.376490: Current learning rate: 0.00633 
2025-12-16 18:17:31.189253: train_loss -0.8419 
2025-12-16 18:17:31.191255: val_loss -0.8719 
2025-12-16 18:17:31.195259: Pseudo dice [0.928, 0.9561, 0.9326] 
2025-12-16 18:17:31.197261: Epoch time: 137.81 s 
2025-12-16 18:17:32.017787:  
2025-12-16 18:17:32.017787: Epoch 399 
2025-12-16 18:17:32.017787: Current learning rate: 0.00632 
2025-12-16 18:19:49.892351: train_loss -0.8422 
2025-12-16 18:19:49.892351: val_loss -0.8622 
2025-12-16 18:19:49.908313: Pseudo dice [0.924, 0.9551, 0.9217] 
2025-12-16 18:19:49.908313: Epoch time: 137.87 s 
2025-12-16 18:19:50.806903:  
2025-12-16 18:19:50.806903: Epoch 400 
2025-12-16 18:19:50.806903: Current learning rate: 0.00631 
2025-12-16 18:22:08.719361: train_loss -0.8441 
2025-12-16 18:22:08.719361: val_loss -0.8694 
2025-12-16 18:22:08.719361: Pseudo dice [0.9264, 0.9549, 0.9293] 
2025-12-16 18:22:08.719361: Epoch time: 137.91 s 
2025-12-16 18:22:09.556558:  
2025-12-16 18:22:09.556558: Epoch 401 
2025-12-16 18:22:09.556558: Current learning rate: 0.0063 
2025-12-16 18:24:27.279963: train_loss -0.8414 
2025-12-16 18:24:27.279963: val_loss -0.8749 
2025-12-16 18:24:27.284659: Pseudo dice [0.9266, 0.9585, 0.9356] 
2025-12-16 18:24:27.288664: Epoch time: 137.72 s 
2025-12-16 18:24:27.955549:  
2025-12-16 18:24:27.955549: Epoch 402 
2025-12-16 18:24:27.957291: Current learning rate: 0.0063 
2025-12-16 18:26:45.964283: train_loss -0.8389 
2025-12-16 18:26:45.966284: val_loss -0.8523 
2025-12-16 18:26:45.970754: Pseudo dice [0.913, 0.9494, 0.9296] 
2025-12-16 18:26:45.974258: Epoch time: 138.01 s 
2025-12-16 18:26:46.638224:  
2025-12-16 18:26:46.638224: Epoch 403 
2025-12-16 18:26:46.638224: Current learning rate: 0.00629 
2025-12-16 18:29:04.696649: train_loss -0.8358 
2025-12-16 18:29:04.696649: val_loss -0.8621 
2025-12-16 18:29:04.699654: Pseudo dice [0.9257, 0.9555, 0.9288] 
2025-12-16 18:29:04.703659: Epoch time: 138.06 s 
2025-12-16 18:29:05.492182:  
2025-12-16 18:29:05.492182: Epoch 404 
2025-12-16 18:29:05.492182: Current learning rate: 0.00628 
2025-12-16 18:31:23.549634: train_loss -0.8357 
2025-12-16 18:31:23.549634: val_loss -0.8552 
2025-12-16 18:31:23.565466: Pseudo dice [0.9144, 0.9467, 0.9357] 
2025-12-16 18:31:23.571070: Epoch time: 138.07 s 
2025-12-16 18:31:24.229368:  
2025-12-16 18:31:24.229368: Epoch 405 
2025-12-16 18:31:24.229368: Current learning rate: 0.00627 
2025-12-16 18:33:42.154241: train_loss -0.8363 
2025-12-16 18:33:42.154241: val_loss -0.869 
2025-12-16 18:33:42.165328: Pseudo dice [0.9309, 0.9591, 0.9218] 
2025-12-16 18:33:42.167331: Epoch time: 137.92 s 
2025-12-16 18:33:42.818365:  
2025-12-16 18:33:42.818365: Epoch 406 
2025-12-16 18:33:42.818365: Current learning rate: 0.00626 
2025-12-16 18:36:00.696921: train_loss -0.8386 
2025-12-16 18:36:00.696921: val_loss -0.8654 
2025-12-16 18:36:00.703244: Pseudo dice [0.9222, 0.9541, 0.934] 
2025-12-16 18:36:00.705503: Epoch time: 137.88 s 
2025-12-16 18:36:01.487254:  
2025-12-16 18:36:01.487254: Epoch 407 
2025-12-16 18:36:01.505230: Current learning rate: 0.00625 
2025-12-16 18:38:19.477969: train_loss -0.8413 
2025-12-16 18:38:19.477969: val_loss -0.8527 
2025-12-16 18:38:19.482566: Pseudo dice [0.9144, 0.9459, 0.9301] 
2025-12-16 18:38:19.482566: Epoch time: 137.99 s 
2025-12-16 18:38:20.132692:  
2025-12-16 18:38:20.134695: Epoch 408 
2025-12-16 18:38:20.134695: Current learning rate: 0.00624 
2025-12-16 18:40:38.154932: train_loss -0.8413 
2025-12-16 18:40:38.154932: val_loss -0.8606 
2025-12-16 18:40:38.159507: Pseudo dice [0.9194, 0.9528, 0.9261] 
2025-12-16 18:40:38.159507: Epoch time: 138.02 s 
2025-12-16 18:40:38.813004:  
2025-12-16 18:40:38.813004: Epoch 409 
2025-12-16 18:40:38.816982: Current learning rate: 0.00623 
2025-12-16 18:42:56.796607: train_loss -0.8396 
2025-12-16 18:42:56.796607: val_loss -0.8597 
2025-12-16 18:42:56.796607: Pseudo dice [0.9208, 0.949, 0.9224] 
2025-12-16 18:42:56.807902: Epoch time: 137.99 s 
2025-12-16 18:42:57.742361:  
2025-12-16 18:42:57.742361: Epoch 410 
2025-12-16 18:42:57.742361: Current learning rate: 0.00622 
2025-12-16 18:45:15.856815: train_loss -0.8395 
2025-12-16 18:45:15.856815: val_loss -0.8659 
2025-12-16 18:45:15.856815: Pseudo dice [0.9217, 0.9582, 0.9289] 
2025-12-16 18:45:15.863183: Epoch time: 138.11 s 
2025-12-16 18:45:16.487565:  
2025-12-16 18:45:16.487565: Epoch 411 
2025-12-16 18:45:16.489568: Current learning rate: 0.00621 
2025-12-16 18:47:34.446537: train_loss -0.8411 
2025-12-16 18:47:34.446537: val_loss -0.858 
2025-12-16 18:47:34.450541: Pseudo dice [0.9154, 0.9522, 0.9321] 
2025-12-16 18:47:34.452281: Epoch time: 137.96 s 
2025-12-16 18:47:35.117638:  
2025-12-16 18:47:35.117638: Epoch 412 
2025-12-16 18:47:35.117638: Current learning rate: 0.0062 
2025-12-16 18:49:53.051076: train_loss -0.8454 
2025-12-16 18:49:53.051076: val_loss -0.8736 
2025-12-16 18:49:53.054936: Pseudo dice [0.9284, 0.9589, 0.9351] 
2025-12-16 18:49:53.058940: Epoch time: 137.94 s 
2025-12-16 18:49:53.687002:  
2025-12-16 18:49:53.687002: Epoch 413 
2025-12-16 18:49:53.687002: Current learning rate: 0.00619 
2025-12-16 18:52:11.454782: train_loss -0.8456 
2025-12-16 18:52:11.456784: val_loss -0.8605 
2025-12-16 18:52:11.460788: Pseudo dice [0.9185, 0.9579, 0.9305] 
2025-12-16 18:52:11.462790: Epoch time: 137.77 s 
2025-12-16 18:52:12.086541:  
2025-12-16 18:52:12.086541: Epoch 414 
2025-12-16 18:52:12.086541: Current learning rate: 0.00618 
2025-12-16 18:54:29.942279: train_loss -0.8492 
2025-12-16 18:54:29.942279: val_loss -0.8718 
2025-12-16 18:54:29.948026: Pseudo dice [0.9283, 0.9584, 0.93] 
2025-12-16 18:54:29.950028: Epoch time: 137.86 s 
2025-12-16 18:54:30.622512:  
2025-12-16 18:54:30.622512: Epoch 415 
2025-12-16 18:54:30.622512: Current learning rate: 0.00617 
2025-12-16 18:56:48.595593: train_loss -0.8415 
2025-12-16 18:56:48.595593: val_loss -0.8634 
2025-12-16 18:56:48.599597: Pseudo dice [0.9211, 0.9501, 0.9324] 
2025-12-16 18:56:48.603339: Epoch time: 137.97 s 
2025-12-16 18:56:49.235927:  
2025-12-16 18:56:49.235927: Epoch 416 
2025-12-16 18:56:49.235927: Current learning rate: 0.00616 
2025-12-16 18:59:07.281447: train_loss -0.8417 
2025-12-16 18:59:07.281447: val_loss -0.8661 
2025-12-16 18:59:07.287333: Pseudo dice [0.9225, 0.9532, 0.935] 
2025-12-16 18:59:07.291337: Epoch time: 138.05 s 
2025-12-16 18:59:08.105480:  
2025-12-16 18:59:08.105480: Epoch 417 
2025-12-16 18:59:08.105480: Current learning rate: 0.00615 
2025-12-16 19:01:26.117665: train_loss -0.8469 
2025-12-16 19:01:26.117665: val_loss -0.8748 
2025-12-16 19:01:26.117665: Pseudo dice [0.9284, 0.9562, 0.9326] 
2025-12-16 19:01:26.123727: Epoch time: 138.03 s 
2025-12-16 19:01:26.123727: Yayy! New best EMA pseudo Dice: 0.9355 
2025-12-16 19:01:27.001098:  
2025-12-16 19:01:27.001098: Epoch 418 
2025-12-16 19:01:27.004843: Current learning rate: 0.00614 
2025-12-16 19:03:44.898361: train_loss -0.8441 
2025-12-16 19:03:44.898361: val_loss -0.8801 
2025-12-16 19:03:44.898361: Pseudo dice [0.931, 0.9621, 0.9351] 
2025-12-16 19:03:44.898361: Epoch time: 137.9 s 
2025-12-16 19:03:44.898361: Yayy! New best EMA pseudo Dice: 0.9362 
2025-12-16 19:03:45.812279:  
2025-12-16 19:03:45.812279: Epoch 419 
2025-12-16 19:03:45.812279: Current learning rate: 0.00613 
2025-12-16 19:06:03.604110: train_loss -0.8506 
2025-12-16 19:06:03.606112: val_loss -0.8609 
2025-12-16 19:06:03.608113: Pseudo dice [0.9177, 0.9529, 0.9343] 
2025-12-16 19:06:03.612620: Epoch time: 137.79 s 
2025-12-16 19:06:04.229003:  
2025-12-16 19:06:04.229003: Epoch 420 
2025-12-16 19:06:04.244684: Current learning rate: 0.00612 
2025-12-16 19:08:22.158577: train_loss -0.8491 
2025-12-16 19:08:22.158577: val_loss -0.8716 
2025-12-16 19:08:22.158577: Pseudo dice [0.9241, 0.9594, 0.9376] 
2025-12-16 19:08:22.158577: Epoch time: 137.93 s 
2025-12-16 19:08:22.158577: Yayy! New best EMA pseudo Dice: 0.9365 
2025-12-16 19:08:23.092963:  
2025-12-16 19:08:23.092963: Epoch 421 
2025-12-16 19:08:23.092963: Current learning rate: 0.00612 
2025-12-16 19:10:41.775160: train_loss -0.8418 
2025-12-16 19:10:41.775160: val_loss -0.8614 
2025-12-16 19:10:41.783170: Pseudo dice [0.9171, 0.9511, 0.9363] 
2025-12-16 19:10:41.785171: Epoch time: 138.68 s 
2025-12-16 19:10:42.422434:  
2025-12-16 19:10:42.422434: Epoch 422 
2025-12-16 19:10:42.422434: Current learning rate: 0.00611 
2025-12-16 19:13:00.752432: train_loss -0.8451 
2025-12-16 19:13:00.752432: val_loss -0.8664 
2025-12-16 19:13:00.758439: Pseudo dice [0.9255, 0.9548, 0.9316] 
2025-12-16 19:13:00.762443: Epoch time: 138.33 s 
2025-12-16 19:13:01.556349:  
2025-12-16 19:13:01.556349: Epoch 423 
2025-12-16 19:13:01.572252: Current learning rate: 0.0061 
2025-12-16 19:15:21.103728: train_loss -0.8467 
2025-12-16 19:15:21.105730: val_loss -0.8656 
2025-12-16 19:15:21.109734: Pseudo dice [0.9228, 0.9551, 0.9307] 
2025-12-16 19:15:21.113477: Epoch time: 139.55 s 
2025-12-16 19:15:21.739836:  
2025-12-16 19:15:21.739836: Epoch 424 
2025-12-16 19:15:21.739836: Current learning rate: 0.00609 
2025-12-16 19:17:40.214980: train_loss -0.845 
2025-12-16 19:17:40.214980: val_loss -0.8616 
2025-12-16 19:17:40.220986: Pseudo dice [0.9221, 0.9542, 0.9252] 
2025-12-16 19:17:40.224728: Epoch time: 138.48 s 
2025-12-16 19:17:40.897086:  
2025-12-16 19:17:40.897086: Epoch 425 
2025-12-16 19:17:40.897086: Current learning rate: 0.00608 
2025-12-16 19:19:59.327404: train_loss -0.8417 
2025-12-16 19:19:59.327404: val_loss -0.8696 
2025-12-16 19:19:59.332411: Pseudo dice [0.923, 0.9565, 0.9266] 
2025-12-16 19:19:59.332411: Epoch time: 138.43 s 
2025-12-16 19:19:59.977972:  
2025-12-16 19:19:59.977972: Epoch 426 
2025-12-16 19:19:59.977972: Current learning rate: 0.00607 
2025-12-16 19:22:18.497241: train_loss -0.8438 
2025-12-16 19:22:18.499244: val_loss -0.8712 
2025-12-16 19:22:18.502957: Pseudo dice [0.9258, 0.9573, 0.9334] 
2025-12-16 19:22:18.502957: Epoch time: 138.52 s 
2025-12-16 19:22:19.132976:  
2025-12-16 19:22:19.132976: Epoch 427 
2025-12-16 19:22:19.132976: Current learning rate: 0.00606 
2025-12-16 19:24:37.801542: train_loss -0.8387 
2025-12-16 19:24:37.801542: val_loss -0.8567 
2025-12-16 19:24:37.815299: Pseudo dice [0.9165, 0.9495, 0.9317] 
2025-12-16 19:24:37.820801: Epoch time: 138.67 s 
2025-12-16 19:24:38.519576:  
2025-12-16 19:24:38.520579: Epoch 428 
2025-12-16 19:24:38.524434: Current learning rate: 0.00605 
2025-12-16 19:26:56.841174: train_loss -0.8444 
2025-12-16 19:26:56.841174: val_loss -0.8552 
2025-12-16 19:26:56.843176: Pseudo dice [0.9172, 0.9511, 0.9156] 
2025-12-16 19:26:56.843176: Epoch time: 138.32 s 
2025-12-16 19:26:57.646091:  
2025-12-16 19:26:57.646091: Epoch 429 
2025-12-16 19:26:57.661981: Current learning rate: 0.00604 
2025-12-16 19:29:15.729109: train_loss -0.844 
2025-12-16 19:29:15.729109: val_loss -0.8744 
2025-12-16 19:29:15.733113: Pseudo dice [0.9295, 0.956, 0.9368] 
2025-12-16 19:29:15.737118: Epoch time: 138.08 s 
2025-12-16 19:29:16.366930:  
2025-12-16 19:29:16.366930: Epoch 430 
2025-12-16 19:29:16.366930: Current learning rate: 0.00603 
2025-12-16 19:31:34.264107: train_loss -0.8481 
2025-12-16 19:31:34.264107: val_loss -0.873 
2025-12-16 19:31:34.279879: Pseudo dice [0.9258, 0.9596, 0.9321] 
2025-12-16 19:31:34.279879: Epoch time: 137.9 s 
2025-12-16 19:31:35.056462:  
2025-12-16 19:31:35.056462: Epoch 431 
2025-12-16 19:31:35.058721: Current learning rate: 0.00602 
2025-12-16 19:33:53.098221: train_loss -0.845 
2025-12-16 19:33:53.099223: val_loss -0.8726 
2025-12-16 19:33:53.099223: Pseudo dice [0.9235, 0.9563, 0.9366] 
2025-12-16 19:33:53.105001: Epoch time: 138.04 s 
2025-12-16 19:33:53.732644:  
2025-12-16 19:33:53.732644: Epoch 432 
2025-12-16 19:33:53.732644: Current learning rate: 0.00601 
2025-12-16 19:36:11.613399: train_loss -0.8497 
2025-12-16 19:36:11.613399: val_loss -0.8684 
2025-12-16 19:36:11.613399: Pseudo dice [0.9272, 0.9566, 0.9249] 
2025-12-16 19:36:11.627282: Epoch time: 137.88 s 
2025-12-16 19:36:12.244753:  
2025-12-16 19:36:12.244753: Epoch 433 
2025-12-16 19:36:12.260539: Current learning rate: 0.006 
2025-12-16 19:38:30.128240: train_loss -0.8485 
2025-12-16 19:38:30.128240: val_loss -0.8558 
2025-12-16 19:38:30.128240: Pseudo dice [0.9202, 0.9505, 0.9153] 
2025-12-16 19:38:30.128240: Epoch time: 137.88 s 
2025-12-16 19:38:30.761548:  
2025-12-16 19:38:30.761548: Epoch 434 
2025-12-16 19:38:30.761548: Current learning rate: 0.00599 
2025-12-16 19:40:48.991729: train_loss -0.8502 
2025-12-16 19:40:48.991729: val_loss -0.8669 
2025-12-16 19:40:48.991729: Pseudo dice [0.9268, 0.9531, 0.926] 
2025-12-16 19:40:48.991729: Epoch time: 138.23 s 
2025-12-16 19:40:49.624595:  
2025-12-16 19:40:49.624595: Epoch 435 
2025-12-16 19:40:49.640365: Current learning rate: 0.00598 
2025-12-16 19:43:07.669314: train_loss -0.8448 
2025-12-16 19:43:07.671316: val_loss -0.8585 
2025-12-16 19:43:07.675320: Pseudo dice [0.9154, 0.9515, 0.9362] 
2025-12-16 19:43:07.677323: Epoch time: 138.04 s 
2025-12-16 19:43:08.476622:  
2025-12-16 19:43:08.476622: Epoch 436 
2025-12-16 19:43:08.476622: Current learning rate: 0.00597 
2025-12-16 19:45:26.536670: train_loss -0.8464 
2025-12-16 19:45:26.536670: val_loss -0.8551 
2025-12-16 19:45:26.536670: Pseudo dice [0.9178, 0.946, 0.9271] 
2025-12-16 19:45:26.536670: Epoch time: 138.06 s 
2025-12-16 19:45:27.212769:  
2025-12-16 19:45:27.212769: Epoch 437 
2025-12-16 19:45:27.216280: Current learning rate: 0.00596 
2025-12-16 19:47:45.160871: train_loss -0.8455 
2025-12-16 19:47:45.160871: val_loss -0.8551 
2025-12-16 19:47:45.162873: Pseudo dice [0.9132, 0.9503, 0.9257] 
2025-12-16 19:47:45.162873: Epoch time: 137.95 s 
2025-12-16 19:47:45.788126:  
2025-12-16 19:47:45.788126: Epoch 438 
2025-12-16 19:47:45.788126: Current learning rate: 0.00595 
2025-12-16 19:50:03.734903: train_loss -0.8446 
2025-12-16 19:50:03.734903: val_loss -0.8582 
2025-12-16 19:50:03.734903: Pseudo dice [0.9182, 0.9522, 0.9266] 
2025-12-16 19:50:03.734903: Epoch time: 137.95 s 
2025-12-16 19:50:04.370886:  
2025-12-16 19:50:04.370886: Epoch 439 
2025-12-16 19:50:04.370886: Current learning rate: 0.00594 
2025-12-16 19:52:22.487235: train_loss -0.8441 
2025-12-16 19:52:22.489237: val_loss -0.8681 
2025-12-16 19:52:22.493241: Pseudo dice [0.9236, 0.9567, 0.9348] 
2025-12-16 19:52:22.496984: Epoch time: 138.12 s 
2025-12-16 19:52:23.132651:  
2025-12-16 19:52:23.132651: Epoch 440 
2025-12-16 19:52:23.132651: Current learning rate: 0.00593 
2025-12-16 19:54:41.218299: train_loss -0.8418 
2025-12-16 19:54:41.218299: val_loss -0.8654 
2025-12-16 19:54:41.218299: Pseudo dice [0.9233, 0.9584, 0.9299] 
2025-12-16 19:54:41.218299: Epoch time: 138.09 s 
2025-12-16 19:54:41.869401:  
2025-12-16 19:54:41.869401: Epoch 441 
2025-12-16 19:54:41.869401: Current learning rate: 0.00592 
2025-12-16 19:56:59.823715: train_loss -0.845 
2025-12-16 19:56:59.823715: val_loss -0.8573 
2025-12-16 19:56:59.823715: Pseudo dice [0.9178, 0.949, 0.9292] 
2025-12-16 19:56:59.823715: Epoch time: 137.95 s 
2025-12-16 19:57:00.617046:  
2025-12-16 19:57:00.617046: Epoch 442 
2025-12-16 19:57:00.617046: Current learning rate: 0.00592 
2025-12-16 19:59:18.529584: train_loss -0.8456 
2025-12-16 19:59:18.529584: val_loss -0.8669 
2025-12-16 19:59:18.529584: Pseudo dice [0.9245, 0.9524, 0.9293] 
2025-12-16 19:59:18.529584: Epoch time: 137.91 s 
2025-12-16 19:59:19.163188:  
2025-12-16 19:59:19.163188: Epoch 443 
2025-12-16 19:59:19.179052: Current learning rate: 0.00591 
2025-12-16 20:01:37.267950: train_loss -0.8489 
2025-12-16 20:01:37.267950: val_loss -0.8637 
2025-12-16 20:01:37.271692: Pseudo dice [0.9202, 0.9526, 0.9314] 
2025-12-16 20:01:37.271692: Epoch time: 138.1 s 
2025-12-16 20:01:37.888583:  
2025-12-16 20:01:37.888583: Epoch 444 
2025-12-16 20:01:37.904396: Current learning rate: 0.0059 
2025-12-16 20:03:55.995528: train_loss -0.8445 
2025-12-16 20:03:55.995528: val_loss -0.8561 
2025-12-16 20:03:55.999532: Pseudo dice [0.9123, 0.9449, 0.9312] 
2025-12-16 20:03:56.003536: Epoch time: 138.11 s 
2025-12-16 20:03:56.748378:  
2025-12-16 20:03:56.748378: Epoch 445 
2025-12-16 20:03:56.748378: Current learning rate: 0.00589 
2025-12-16 20:06:14.822788: train_loss -0.8484 
2025-12-16 20:06:14.822788: val_loss -0.8606 
2025-12-16 20:06:14.824529: Pseudo dice [0.9221, 0.9508, 0.9289] 
2025-12-16 20:06:14.824529: Epoch time: 138.09 s 
2025-12-16 20:06:15.460633:  
2025-12-16 20:06:15.460633: Epoch 446 
2025-12-16 20:06:15.462636: Current learning rate: 0.00588 
2025-12-16 20:08:33.403282: train_loss -0.8502 
2025-12-16 20:08:33.405285: val_loss -0.867 
2025-12-16 20:08:33.411014: Pseudo dice [0.9233, 0.9549, 0.9243] 
2025-12-16 20:08:33.415020: Epoch time: 137.94 s 
2025-12-16 20:08:34.044461:  
2025-12-16 20:08:34.044461: Epoch 447 
2025-12-16 20:08:34.044461: Current learning rate: 0.00587 
2025-12-16 20:10:52.914047: train_loss -0.8497 
2025-12-16 20:10:52.914047: val_loss -0.861 
2025-12-16 20:10:52.929921: Pseudo dice [0.9194, 0.9527, 0.9298] 
2025-12-16 20:10:52.929921: Epoch time: 138.87 s 
2025-12-16 20:10:53.611416:  
2025-12-16 20:10:53.611416: Epoch 448 
2025-12-16 20:10:53.611416: Current learning rate: 0.00586 
2025-12-16 20:13:11.640960: train_loss -0.8506 
2025-12-16 20:13:11.640960: val_loss -0.8604 
2025-12-16 20:13:11.644966: Pseudo dice [0.9185, 0.9521, 0.9283] 
2025-12-16 20:13:11.648709: Epoch time: 138.03 s 
2025-12-16 20:13:12.442876:  
2025-12-16 20:13:12.442876: Epoch 449 
2025-12-16 20:13:12.442876: Current learning rate: 0.00585 
2025-12-16 20:15:30.501364: train_loss -0.8452 
2025-12-16 20:15:30.501364: val_loss -0.863 
2025-12-16 20:15:30.507370: Pseudo dice [0.9202, 0.9522, 0.9287] 
2025-12-16 20:15:30.509372: Epoch time: 138.07 s 
2025-12-16 20:15:31.389742:  
2025-12-16 20:15:31.391744: Epoch 450 
2025-12-16 20:15:31.391744: Current learning rate: 0.00584 
2025-12-16 20:17:49.374163: train_loss -0.8368 
2025-12-16 20:17:49.374163: val_loss -0.8617 
2025-12-16 20:17:49.380172: Pseudo dice [0.9202, 0.9558, 0.9281] 
2025-12-16 20:17:49.382174: Epoch time: 137.98 s 
2025-12-16 20:17:50.140373:  
2025-12-16 20:17:50.140373: Epoch 451 
2025-12-16 20:17:50.141376: Current learning rate: 0.00583 
2025-12-16 20:20:08.242680: train_loss -0.8464 
2025-12-16 20:20:08.242680: val_loss -0.8621 
2025-12-16 20:20:08.246684: Pseudo dice [0.9155, 0.9528, 0.9317] 
2025-12-16 20:20:08.250688: Epoch time: 138.1 s 
2025-12-16 20:20:08.880311:  
2025-12-16 20:20:08.880311: Epoch 452 
2025-12-16 20:20:08.880311: Current learning rate: 0.00582 
2025-12-16 20:22:26.954685: train_loss -0.8451 
2025-12-16 20:22:26.954685: val_loss -0.8731 
2025-12-16 20:22:26.963671: Pseudo dice [0.9232, 0.9545, 0.9365] 
2025-12-16 20:22:26.965673: Epoch time: 138.08 s 
2025-12-16 20:22:27.590791:  
2025-12-16 20:22:27.590791: Epoch 453 
2025-12-16 20:22:27.590791: Current learning rate: 0.00581 
2025-12-16 20:24:45.699599: train_loss -0.8504 
2025-12-16 20:24:45.701602: val_loss -0.8543 
2025-12-16 20:24:45.704504: Pseudo dice [0.9145, 0.9459, 0.9296] 
2025-12-16 20:24:45.708510: Epoch time: 138.11 s 
2025-12-16 20:24:46.467828:  
2025-12-16 20:24:46.467828: Epoch 454 
2025-12-16 20:24:46.467828: Current learning rate: 0.0058 
2025-12-16 20:27:05.109702: train_loss -0.8467 
2025-12-16 20:27:05.109702: val_loss -0.874 
2025-12-16 20:27:05.115655: Pseudo dice [0.9285, 0.9569, 0.9341] 
2025-12-16 20:27:05.118663: Epoch time: 138.64 s 
2025-12-16 20:27:05.954666:  
2025-12-16 20:27:05.955671: Epoch 455 
2025-12-16 20:27:05.959650: Current learning rate: 0.00579 
2025-12-16 20:29:25.265375: train_loss -0.8445 
2025-12-16 20:29:25.265375: val_loss -0.8734 
2025-12-16 20:29:25.270876: Pseudo dice [0.9265, 0.9571, 0.9364] 
2025-12-16 20:29:25.272879: Epoch time: 139.31 s 
2025-12-16 20:29:25.882171:  
2025-12-16 20:29:25.882171: Epoch 456 
2025-12-16 20:29:25.898088: Current learning rate: 0.00578 
2025-12-16 20:31:44.392802: train_loss -0.8524 
2025-12-16 20:31:44.394804: val_loss -0.862 
2025-12-16 20:31:44.398808: Pseudo dice [0.9214, 0.9547, 0.9235] 
2025-12-16 20:31:44.402813: Epoch time: 138.51 s 
2025-12-16 20:31:45.023466:  
2025-12-16 20:31:45.023466: Epoch 457 
2025-12-16 20:31:45.023466: Current learning rate: 0.00577 
2025-12-16 20:34:03.411894: train_loss -0.8505 
2025-12-16 20:34:03.413896: val_loss -0.8604 
2025-12-16 20:34:03.417900: Pseudo dice [0.9211, 0.9519, 0.9242] 
2025-12-16 20:34:03.421904: Epoch time: 138.39 s 
2025-12-16 20:34:04.053124:  
2025-12-16 20:34:04.053124: Epoch 458 
2025-12-16 20:34:04.053124: Current learning rate: 0.00576 
2025-12-16 20:36:22.517487: train_loss -0.8456 
2025-12-16 20:36:22.517487: val_loss -0.8732 
2025-12-16 20:36:22.521492: Pseudo dice [0.9225, 0.9566, 0.9398] 
2025-12-16 20:36:22.525496: Epoch time: 138.47 s 
2025-12-16 20:36:23.134120:  
2025-12-16 20:36:23.134120: Epoch 459 
2025-12-16 20:36:23.134120: Current learning rate: 0.00575 
2025-12-16 20:38:41.519741: train_loss -0.8451 
2025-12-16 20:38:41.521744: val_loss -0.8631 
2025-12-16 20:38:41.530764: Pseudo dice [0.9216, 0.9549, 0.927] 
2025-12-16 20:38:41.534560: Epoch time: 138.39 s 
2025-12-16 20:38:42.157044:  
2025-12-16 20:38:42.157044: Epoch 460 
2025-12-16 20:38:42.157044: Current learning rate: 0.00574 
2025-12-16 20:41:00.019465: train_loss -0.8444 
2025-12-16 20:41:00.021468: val_loss -0.8658 
2025-12-16 20:41:00.023471: Pseudo dice [0.927, 0.9548, 0.9236] 
2025-12-16 20:41:00.027475: Epoch time: 137.86 s 
2025-12-16 20:41:00.654974:  
2025-12-16 20:41:00.656976: Epoch 461 
2025-12-16 20:41:00.656976: Current learning rate: 0.00573 
2025-12-16 20:43:18.688304: train_loss -0.8135 
2025-12-16 20:43:18.690307: val_loss -0.8282 
2025-12-16 20:43:18.690307: Pseudo dice [0.9042, 0.9422, 0.9158] 
2025-12-16 20:43:18.694699: Epoch time: 138.03 s 
2025-12-16 20:43:19.503662:  
2025-12-16 20:43:19.503662: Epoch 462 
2025-12-16 20:43:19.503662: Current learning rate: 0.00572 
2025-12-16 20:45:37.527626: train_loss -0.8144 
2025-12-16 20:45:37.527626: val_loss -0.8473 
2025-12-16 20:45:37.527626: Pseudo dice [0.9107, 0.9513, 0.9192] 
2025-12-16 20:45:37.527626: Epoch time: 138.03 s 
2025-12-16 20:45:38.154027:  
2025-12-16 20:45:38.154027: Epoch 463 
2025-12-16 20:45:38.156312: Current learning rate: 0.00571 
2025-12-16 20:47:56.125874: train_loss -0.8045 
2025-12-16 20:47:56.125874: val_loss -0.839 
2025-12-16 20:47:56.129878: Pseudo dice [0.9122, 0.9499, 0.9171] 
2025-12-16 20:47:56.133882: Epoch time: 137.97 s 
2025-12-16 20:47:56.759041:  
2025-12-16 20:47:56.759041: Epoch 464 
2025-12-16 20:47:56.759041: Current learning rate: 0.0057 
2025-12-16 20:50:14.633269: train_loss -0.8243 
2025-12-16 20:50:14.633269: val_loss -0.8616 
2025-12-16 20:50:14.639487: Pseudo dice [0.9269, 0.9525, 0.9268] 
2025-12-16 20:50:14.643491: Epoch time: 137.88 s 
2025-12-16 20:50:15.266062:  
2025-12-16 20:50:15.266062: Epoch 465 
2025-12-16 20:50:15.266062: Current learning rate: 0.0057 
2025-12-16 20:52:33.322645: train_loss -0.8274 
2025-12-16 20:52:33.324648: val_loss -0.8523 
2025-12-16 20:52:33.328654: Pseudo dice [0.9158, 0.9501, 0.9288] 
2025-12-16 20:52:33.332659: Epoch time: 138.06 s 
2025-12-16 20:52:34.020302:  
2025-12-16 20:52:34.020302: Epoch 466 
2025-12-16 20:52:34.020302: Current learning rate: 0.00569 
2025-12-16 20:54:51.934254: train_loss -0.8392 
2025-12-16 20:54:51.935995: val_loss -0.8549 
2025-12-16 20:54:51.946011: Pseudo dice [0.916, 0.9498, 0.9274] 
2025-12-16 20:54:51.951756: Epoch time: 137.91 s 
2025-12-16 20:54:52.569674:  
2025-12-16 20:54:52.569674: Epoch 467 
2025-12-16 20:54:52.569674: Current learning rate: 0.00568 
2025-12-16 20:57:10.593950: train_loss -0.8394 
2025-12-16 20:57:10.593950: val_loss -0.8634 
2025-12-16 20:57:10.601966: Pseudo dice [0.9244, 0.953, 0.9273] 
2025-12-16 20:57:10.605972: Epoch time: 138.02 s 
2025-12-16 20:57:11.386421:  
2025-12-16 20:57:11.386421: Epoch 468 
2025-12-16 20:57:11.386421: Current learning rate: 0.00567 
2025-12-16 20:59:29.328824: train_loss -0.8444 
2025-12-16 20:59:29.328824: val_loss -0.8631 
2025-12-16 20:59:29.328824: Pseudo dice [0.9223, 0.9555, 0.9269] 
2025-12-16 20:59:29.328824: Epoch time: 137.94 s 
2025-12-16 20:59:30.084284:  
2025-12-16 20:59:30.084284: Epoch 469 
2025-12-16 20:59:30.084284: Current learning rate: 0.00566 
2025-12-16 21:01:48.171266: train_loss -0.8445 
2025-12-16 21:01:48.173269: val_loss -0.8697 
2025-12-16 21:01:48.175508: Pseudo dice [0.9287, 0.9576, 0.9277] 
2025-12-16 21:01:48.175508: Epoch time: 138.09 s 
2025-12-16 21:01:48.792206:  
2025-12-16 21:01:48.792206: Epoch 470 
2025-12-16 21:01:48.792206: Current learning rate: 0.00565 
2025-12-16 21:04:06.889475: train_loss -0.8392 
2025-12-16 21:04:06.889475: val_loss -0.8662 
2025-12-16 21:04:06.907164: Pseudo dice [0.9263, 0.9557, 0.918] 
2025-12-16 21:04:06.909167: Epoch time: 138.1 s 
2025-12-16 21:04:07.538261:  
2025-12-16 21:04:07.538261: Epoch 471 
2025-12-16 21:04:07.538261: Current learning rate: 0.00564 
2025-12-16 21:06:25.558456: train_loss -0.8412 
2025-12-16 21:06:25.560458: val_loss -0.872 
2025-12-16 21:06:25.564462: Pseudo dice [0.9267, 0.9566, 0.9335] 
2025-12-16 21:06:25.570207: Epoch time: 138.02 s 
2025-12-16 21:06:26.335181:  
2025-12-16 21:06:26.335181: Epoch 472 
2025-12-16 21:06:26.335181: Current learning rate: 0.00563 
2025-12-16 21:08:44.404472: train_loss -0.8441 
2025-12-16 21:08:44.404472: val_loss -0.8655 
2025-12-16 21:08:44.420234: Pseudo dice [0.923, 0.9544, 0.9405] 
2025-12-16 21:08:44.420234: Epoch time: 138.07 s 
2025-12-16 21:08:45.048992:  
2025-12-16 21:08:45.048992: Epoch 473 
2025-12-16 21:08:45.048992: Current learning rate: 0.00562 
2025-12-16 21:11:03.337438: train_loss -0.8412 
2025-12-16 21:11:03.337438: val_loss -0.8566 
2025-12-16 21:11:03.343182: Pseudo dice [0.9186, 0.95, 0.9206] 
2025-12-16 21:11:03.347186: Epoch time: 138.29 s 
2025-12-16 21:11:04.005595:  
2025-12-16 21:11:04.005595: Epoch 474 
2025-12-16 21:11:04.021402: Current learning rate: 0.00561 
2025-12-16 21:13:21.958828: train_loss -0.8459 
2025-12-16 21:13:21.958828: val_loss -0.8678 
2025-12-16 21:13:21.964573: Pseudo dice [0.9257, 0.9569, 0.9267] 
2025-12-16 21:13:21.968578: Epoch time: 137.95 s 
2025-12-16 21:13:22.977116:  
2025-12-16 21:13:22.977116: Epoch 475 
2025-12-16 21:13:22.977116: Current learning rate: 0.0056 
2025-12-16 21:15:41.120329: train_loss -0.8451 
2025-12-16 21:15:41.120329: val_loss -0.8604 
2025-12-16 21:15:41.136193: Pseudo dice [0.9212, 0.9478, 0.9295] 
2025-12-16 21:15:41.136193: Epoch time: 138.15 s 
2025-12-16 21:15:41.752750:  
2025-12-16 21:15:41.752750: Epoch 476 
2025-12-16 21:15:41.752750: Current learning rate: 0.00559 
2025-12-16 21:17:59.741783: train_loss -0.8471 
2025-12-16 21:17:59.741783: val_loss -0.8723 
2025-12-16 21:17:59.757443: Pseudo dice [0.9307, 0.9589, 0.9271] 
2025-12-16 21:17:59.757443: Epoch time: 137.99 s 
2025-12-16 21:18:00.374003:  
2025-12-16 21:18:00.374003: Epoch 477 
2025-12-16 21:18:00.389815: Current learning rate: 0.00558 
2025-12-16 21:20:18.383543: train_loss -0.8472 
2025-12-16 21:20:18.385283: val_loss -0.8612 
2025-12-16 21:20:18.385283: Pseudo dice [0.92, 0.9519, 0.9272] 
2025-12-16 21:20:18.385283: Epoch time: 138.01 s 
2025-12-16 21:20:19.109971:  
2025-12-16 21:20:19.109971: Epoch 478 
2025-12-16 21:20:19.125755: Current learning rate: 0.00557 
2025-12-16 21:22:36.984832: train_loss -0.8439 
2025-12-16 21:22:36.984832: val_loss -0.851 
2025-12-16 21:22:36.984832: Pseudo dice [0.9205, 0.9474, 0.9184] 
2025-12-16 21:22:36.984832: Epoch time: 137.87 s 
2025-12-16 21:22:37.660295:  
2025-12-16 21:22:37.660295: Epoch 479 
2025-12-16 21:22:37.660295: Current learning rate: 0.00556 
2025-12-16 21:24:55.681529: train_loss -0.8472 
2025-12-16 21:24:55.681529: val_loss -0.8621 
2025-12-16 21:24:55.685533: Pseudo dice [0.9222, 0.953, 0.9307] 
2025-12-16 21:24:55.691031: Epoch time: 138.02 s 
2025-12-16 21:24:56.312411:  
2025-12-16 21:24:56.312411: Epoch 480 
2025-12-16 21:24:56.328296: Current learning rate: 0.00555 
2025-12-16 21:27:14.349971: train_loss -0.8322 
2025-12-16 21:27:14.349971: val_loss -0.8342 
2025-12-16 21:27:14.353974: Pseudo dice [0.9108, 0.9454, 0.9095] 
2025-12-16 21:27:14.357978: Epoch time: 138.04 s 
2025-12-16 21:27:15.137050:  
2025-12-16 21:27:15.137050: Epoch 481 
2025-12-16 21:27:15.145203: Current learning rate: 0.00554 
2025-12-16 21:29:32.983634: train_loss -0.8017 
2025-12-16 21:29:32.983634: val_loss -0.8253 
2025-12-16 21:29:32.987638: Pseudo dice [0.9026, 0.9443, 0.9112] 
2025-12-16 21:29:32.991642: Epoch time: 137.85 s 
2025-12-16 21:29:33.780982:  
2025-12-16 21:29:33.780982: Epoch 482 
2025-12-16 21:29:33.796938: Current learning rate: 0.00553 
2025-12-16 21:31:51.802152: train_loss -0.8157 
2025-12-16 21:31:51.802152: val_loss -0.8377 
2025-12-16 21:31:51.802152: Pseudo dice [0.9082, 0.9447, 0.9239] 
2025-12-16 21:31:51.817661: Epoch time: 138.02 s 
2025-12-16 21:31:52.437091:  
2025-12-16 21:31:52.437091: Epoch 483 
2025-12-16 21:31:52.453011: Current learning rate: 0.00552 
2025-12-16 21:34:10.384289: train_loss -0.8261 
2025-12-16 21:34:10.386030: val_loss -0.8517 
2025-12-16 21:34:10.387985: Pseudo dice [0.9145, 0.9514, 0.9244] 
2025-12-16 21:34:10.392651: Epoch time: 137.95 s 
2025-12-16 21:34:11.050450:  
2025-12-16 21:34:11.050450: Epoch 484 
2025-12-16 21:34:11.050450: Current learning rate: 0.00551 
2025-12-16 21:36:28.907433: train_loss -0.8446 
2025-12-16 21:36:28.907433: val_loss -0.8566 
2025-12-16 21:36:28.907433: Pseudo dice [0.9175, 0.9451, 0.937] 
2025-12-16 21:36:28.907433: Epoch time: 137.86 s 
2025-12-16 21:36:29.539602:  
2025-12-16 21:36:29.539602: Epoch 485 
2025-12-16 21:36:29.539602: Current learning rate: 0.0055 
2025-12-16 21:38:47.492053: train_loss -0.8282 
2025-12-16 21:38:47.492053: val_loss -0.8554 
2025-12-16 21:38:47.510116: Pseudo dice [0.9117, 0.9481, 0.9382] 
2025-12-16 21:38:47.514120: Epoch time: 137.95 s 
2025-12-16 21:38:48.141548:  
2025-12-16 21:38:48.141548: Epoch 486 
2025-12-16 21:38:48.141548: Current learning rate: 0.00549 
2025-12-16 21:41:06.194919: train_loss -0.8439 
2025-12-16 21:41:06.194919: val_loss -0.8698 
2025-12-16 21:41:06.200924: Pseudo dice [0.9231, 0.9524, 0.9412] 
2025-12-16 21:41:06.202665: Epoch time: 138.05 s 
2025-12-16 21:41:06.833265:  
2025-12-16 21:41:06.835267: Epoch 487 
2025-12-16 21:41:06.835267: Current learning rate: 0.00548 
2025-12-16 21:43:24.672453: train_loss -0.8413 
2025-12-16 21:43:24.672453: val_loss -0.8557 
2025-12-16 21:43:24.688529: Pseudo dice [0.9184, 0.9487, 0.9279] 
2025-12-16 21:43:24.691189: Epoch time: 137.84 s 
2025-12-16 21:43:25.478629:  
2025-12-16 21:43:25.478629: Epoch 488 
2025-12-16 21:43:25.488447: Current learning rate: 0.00547 
2025-12-16 21:45:43.554374: train_loss -0.8437 
2025-12-16 21:45:43.554374: val_loss -0.8635 
2025-12-16 21:45:43.560119: Pseudo dice [0.9218, 0.9571, 0.928] 
2025-12-16 21:45:43.568137: Epoch time: 138.08 s 
2025-12-16 21:45:44.253845:  
2025-12-16 21:45:44.253845: Epoch 489 
2025-12-16 21:45:44.253845: Current learning rate: 0.00546 
2025-12-16 21:48:02.176204: train_loss -0.8415 
2025-12-16 21:48:02.178206: val_loss -0.8689 
2025-12-16 21:48:02.182210: Pseudo dice [0.9245, 0.9553, 0.9326] 
2025-12-16 21:48:02.189960: Epoch time: 137.94 s 
2025-12-16 21:48:02.836333:  
2025-12-16 21:48:02.836333: Epoch 490 
2025-12-16 21:48:02.842005: Current learning rate: 0.00546 
2025-12-16 21:50:20.860263: train_loss -0.8433 
2025-12-16 21:50:20.860263: val_loss -0.8518 
2025-12-16 21:50:20.871592: Pseudo dice [0.9133, 0.9456, 0.9339] 
2025-12-16 21:50:20.871592: Epoch time: 138.02 s 
2025-12-16 21:50:21.534104:  
2025-12-16 21:50:21.534104: Epoch 491 
2025-12-16 21:50:21.534104: Current learning rate: 0.00545 
2025-12-16 21:52:39.462233: train_loss -0.8423 
2025-12-16 21:52:39.462233: val_loss -0.848 
2025-12-16 21:52:39.468241: Pseudo dice [0.9111, 0.9499, 0.9289] 
2025-12-16 21:52:39.472247: Epoch time: 137.92 s 
2025-12-16 21:52:40.115746:  
2025-12-16 21:52:40.115746: Epoch 492 
2025-12-16 21:52:40.131646: Current learning rate: 0.00544 
2025-12-16 21:54:58.081194: train_loss -0.8415 
2025-12-16 21:54:58.081194: val_loss -0.8598 
2025-12-16 21:54:58.087383: Pseudo dice [0.9205, 0.9527, 0.9244] 
2025-12-16 21:54:58.091609: Epoch time: 137.97 s 
2025-12-16 21:54:58.715506:  
2025-12-16 21:54:58.715506: Epoch 493 
2025-12-16 21:54:58.715506: Current learning rate: 0.00543 
2025-12-16 21:57:16.593784: train_loss -0.8452 
2025-12-16 21:57:16.593784: val_loss -0.8707 
2025-12-16 21:57:16.593784: Pseudo dice [0.9294, 0.9574, 0.9279] 
2025-12-16 21:57:16.593784: Epoch time: 137.88 s 
2025-12-16 21:57:17.386518:  
2025-12-16 21:57:17.386518: Epoch 494 
2025-12-16 21:57:17.386518: Current learning rate: 0.00542 
2025-12-16 21:59:35.154833: train_loss -0.8435 
2025-12-16 21:59:35.154833: val_loss -0.8662 
2025-12-16 21:59:35.160839: Pseudo dice [0.9247, 0.9549, 0.9373] 
2025-12-16 21:59:35.166588: Epoch time: 137.77 s 
2025-12-16 21:59:35.925518:  
2025-12-16 21:59:35.925518: Epoch 495 
2025-12-16 21:59:35.927521: Current learning rate: 0.00541 
2025-12-16 22:01:54.037618: train_loss -0.8343 
2025-12-16 22:01:54.037618: val_loss -0.8517 
2025-12-16 22:01:54.048522: Pseudo dice [0.916, 0.9501, 0.9266] 
2025-12-16 22:01:54.048522: Epoch time: 138.11 s 
2025-12-16 22:01:54.669915:  
2025-12-16 22:01:54.669915: Epoch 496 
2025-12-16 22:01:54.685652: Current learning rate: 0.0054 
2025-12-16 22:04:12.651016: train_loss -0.8395 
2025-12-16 22:04:12.651016: val_loss -0.8644 
2025-12-16 22:04:12.662595: Pseudo dice [0.9227, 0.9547, 0.9342] 
2025-12-16 22:04:12.668766: Epoch time: 137.98 s 
2025-12-16 22:04:13.285946:  
2025-12-16 22:04:13.285946: Epoch 497 
2025-12-16 22:04:13.285946: Current learning rate: 0.00539 
2025-12-16 22:06:31.242451: train_loss -0.8442 
2025-12-16 22:06:31.244193: val_loss -0.8622 
2025-12-16 22:06:31.248199: Pseudo dice [0.9156, 0.9525, 0.9383] 
2025-12-16 22:06:31.252205: Epoch time: 137.96 s 
2025-12-16 22:06:31.981857:  
2025-12-16 22:06:31.983860: Epoch 498 
2025-12-16 22:06:31.987462: Current learning rate: 0.00538 
2025-12-16 22:08:50.133425: train_loss -0.8427 
2025-12-16 22:08:50.133425: val_loss -0.8663 
2025-12-16 22:08:50.133425: Pseudo dice [0.9227, 0.9563, 0.9283] 
2025-12-16 22:08:50.133425: Epoch time: 138.15 s 
2025-12-16 22:08:50.781282:  
2025-12-16 22:08:50.781282: Epoch 499 
2025-12-16 22:08:50.785696: Current learning rate: 0.00537 
2025-12-16 22:11:09.058425: train_loss -0.8461 
2025-12-16 22:11:09.060427: val_loss -0.8694 
2025-12-16 22:11:09.064432: Pseudo dice [0.9271, 0.9559, 0.9338] 
2025-12-16 22:11:09.068435: Epoch time: 138.29 s 
2025-12-16 22:11:10.115057:  
2025-12-16 22:11:10.115057: Epoch 500 
2025-12-16 22:11:10.119488: Current learning rate: 0.00536 
2025-12-16 22:13:28.091738: train_loss -0.8433 
2025-12-16 22:13:28.091738: val_loss -0.8693 
2025-12-16 22:13:28.099487: Pseudo dice [0.9257, 0.9549, 0.9327] 
2025-12-16 22:13:28.103491: Epoch time: 137.98 s 
2025-12-16 22:13:28.848239:  
2025-12-16 22:13:28.848239: Epoch 501 
2025-12-16 22:13:28.848239: Current learning rate: 0.00535 
2025-12-16 22:15:46.835968: train_loss -0.8438 
2025-12-16 22:15:46.835968: val_loss -0.8671 
2025-12-16 22:15:46.843716: Pseudo dice [0.9253, 0.9561, 0.9314] 
2025-12-16 22:15:46.845681: Epoch time: 137.99 s 
2025-12-16 22:15:47.462445:  
2025-12-16 22:15:47.462445: Epoch 502 
2025-12-16 22:15:47.479676: Current learning rate: 0.00534 
2025-12-16 22:18:05.248397: train_loss -0.8458 
2025-12-16 22:18:05.248397: val_loss -0.8563 
2025-12-16 22:18:05.254403: Pseudo dice [0.9213, 0.9471, 0.9321] 
2025-12-16 22:18:05.258145: Epoch time: 137.79 s 
2025-12-16 22:18:05.892391:  
2025-12-16 22:18:05.892391: Epoch 503 
2025-12-16 22:18:05.892391: Current learning rate: 0.00533 
2025-12-16 22:20:23.730002: train_loss -0.8439 
2025-12-16 22:20:23.730002: val_loss -0.8727 
2025-12-16 22:20:23.736008: Pseudo dice [0.9262, 0.9548, 0.9334] 
2025-12-16 22:20:23.740013: Epoch time: 137.84 s 
2025-12-16 22:20:24.435225:  
2025-12-16 22:20:24.435225: Epoch 504 
2025-12-16 22:20:24.435225: Current learning rate: 0.00532 
2025-12-16 22:22:42.490448: train_loss -0.8432 
2025-12-16 22:22:42.490448: val_loss -0.8658 
2025-12-16 22:22:42.497950: Pseudo dice [0.9225, 0.9516, 0.9314] 
2025-12-16 22:22:42.501955: Epoch time: 138.07 s 
2025-12-16 22:22:43.118252:  
2025-12-16 22:22:43.134053: Epoch 505 
2025-12-16 22:22:43.134053: Current learning rate: 0.00531 
2025-12-16 22:25:01.242064: train_loss -0.8459 
2025-12-16 22:25:01.242064: val_loss -0.8631 
2025-12-16 22:25:01.246069: Pseudo dice [0.9182, 0.9513, 0.9304] 
2025-12-16 22:25:01.250072: Epoch time: 138.12 s 
2025-12-16 22:25:01.882929:  
2025-12-16 22:25:01.882929: Epoch 506 
2025-12-16 22:25:01.883933: Current learning rate: 0.0053 
2025-12-16 22:27:19.801040: train_loss -0.8507 
2025-12-16 22:27:19.801040: val_loss -0.8653 
2025-12-16 22:27:19.807046: Pseudo dice [0.9229, 0.9538, 0.9329] 
2025-12-16 22:27:19.809048: Epoch time: 137.92 s 
2025-12-16 22:27:20.628261:  
2025-12-16 22:27:20.628261: Epoch 507 
2025-12-16 22:27:20.628261: Current learning rate: 0.00529 
2025-12-16 22:29:38.588051: train_loss -0.8473 
2025-12-16 22:29:38.588051: val_loss -0.8709 
2025-12-16 22:29:38.593560: Pseudo dice [0.9264, 0.9532, 0.9358] 
2025-12-16 22:29:38.597564: Epoch time: 137.96 s 
2025-12-16 22:29:39.234393:  
2025-12-16 22:29:39.236395: Epoch 508 
2025-12-16 22:29:39.236395: Current learning rate: 0.00528 
2025-12-16 22:31:57.186723: train_loss -0.8474 
2025-12-16 22:31:57.188726: val_loss -0.8608 
2025-12-16 22:31:57.190729: Pseudo dice [0.9241, 0.9512, 0.9251] 
2025-12-16 22:31:57.198338: Epoch time: 137.95 s 
2025-12-16 22:31:57.831174:  
2025-12-16 22:31:57.831174: Epoch 509 
2025-12-16 22:31:57.831174: Current learning rate: 0.00527 
2025-12-16 22:34:15.756208: train_loss -0.8489 
2025-12-16 22:34:15.758210: val_loss -0.8808 
2025-12-16 22:34:15.761703: Pseudo dice [0.9332, 0.9591, 0.9358] 
2025-12-16 22:34:15.765707: Epoch time: 137.93 s 
2025-12-16 22:34:16.404130:  
2025-12-16 22:34:16.404130: Epoch 510 
2025-12-16 22:34:16.404130: Current learning rate: 0.00526 
2025-12-16 22:36:34.335037: train_loss -0.848 
2025-12-16 22:36:34.337039: val_loss -0.8695 
2025-12-16 22:36:34.340915: Pseudo dice [0.9262, 0.9561, 0.9328] 
2025-12-16 22:36:34.344919: Epoch time: 137.93 s 
2025-12-16 22:36:34.973929:  
2025-12-16 22:36:34.973929: Epoch 511 
2025-12-16 22:36:34.973929: Current learning rate: 0.00525 
2025-12-16 22:38:52.955019: train_loss -0.8508 
2025-12-16 22:38:52.955019: val_loss -0.8717 
2025-12-16 22:38:52.971014: Pseudo dice [0.9256, 0.9552, 0.9342] 
2025-12-16 22:38:52.971014: Epoch time: 137.98 s 
2025-12-16 22:38:53.637440:  
2025-12-16 22:38:53.637440: Epoch 512 
2025-12-16 22:38:53.637440: Current learning rate: 0.00524 
2025-12-16 22:41:11.618928: train_loss -0.8468 
2025-12-16 22:41:11.618928: val_loss -0.8581 
2025-12-16 22:41:11.622932: Pseudo dice [0.9156, 0.9527, 0.9307] 
2025-12-16 22:41:11.626936: Epoch time: 137.98 s 
2025-12-16 22:41:12.257987:  
2025-12-16 22:41:12.257987: Epoch 513 
2025-12-16 22:41:12.257987: Current learning rate: 0.00523 
2025-12-16 22:43:30.135499: train_loss -0.853 
2025-12-16 22:43:30.137502: val_loss -0.8654 
2025-12-16 22:43:30.137502: Pseudo dice [0.9181, 0.9503, 0.9344] 
2025-12-16 22:43:30.143986: Epoch time: 137.88 s 
2025-12-16 22:43:30.951734:  
2025-12-16 22:43:30.951734: Epoch 514 
2025-12-16 22:43:30.951734: Current learning rate: 0.00522 
2025-12-16 22:45:48.913779: train_loss -0.8494 
2025-12-16 22:45:48.913779: val_loss -0.8747 
2025-12-16 22:45:48.919786: Pseudo dice [0.9257, 0.959, 0.9338] 
2025-12-16 22:45:48.923791: Epoch time: 137.96 s 
2025-12-16 22:45:49.567534:  
2025-12-16 22:45:49.567534: Epoch 515 
2025-12-16 22:45:49.567534: Current learning rate: 0.00521 
2025-12-16 22:48:07.508243: train_loss -0.8491 
2025-12-16 22:48:07.510246: val_loss -0.8778 
2025-12-16 22:48:07.510246: Pseudo dice [0.9297, 0.9578, 0.9344] 
2025-12-16 22:48:07.518000: Epoch time: 137.94 s 
2025-12-16 22:48:07.518000: Yayy! New best EMA pseudo Dice: 0.9368 
2025-12-16 22:48:08.382491:  
2025-12-16 22:48:08.382491: Epoch 516 
2025-12-16 22:48:08.382491: Current learning rate: 0.0052 
2025-12-16 22:50:26.291947: train_loss -0.8529 
2025-12-16 22:50:26.291947: val_loss -0.8767 
2025-12-16 22:50:26.297692: Pseudo dice [0.9308, 0.9594, 0.9341] 
2025-12-16 22:50:26.297692: Epoch time: 137.91 s 
2025-12-16 22:50:26.303282: Yayy! New best EMA pseudo Dice: 0.9372 
2025-12-16 22:50:27.215556:  
2025-12-16 22:50:27.215556: Epoch 517 
2025-12-16 22:50:27.215556: Current learning rate: 0.00519 
2025-12-16 22:52:45.192095: train_loss -0.8523 
2025-12-16 22:52:45.192095: val_loss -0.8649 
2025-12-16 22:52:45.200107: Pseudo dice [0.9203, 0.9533, 0.9274] 
2025-12-16 22:52:45.206129: Epoch time: 137.98 s 
2025-12-16 22:52:45.842349:  
2025-12-16 22:52:45.842349: Epoch 518 
2025-12-16 22:52:45.858214: Current learning rate: 0.00518 
2025-12-16 22:55:03.798854: train_loss -0.85 
2025-12-16 22:55:03.798854: val_loss -0.8673 
2025-12-16 22:55:03.804456: Pseudo dice [0.9239, 0.9565, 0.9287] 
2025-12-16 22:55:03.804456: Epoch time: 137.96 s 
2025-12-16 22:55:04.436721:  
2025-12-16 22:55:04.436721: Epoch 519 
2025-12-16 22:55:04.436721: Current learning rate: 0.00518 
2025-12-16 22:57:22.455354: train_loss -0.8486 
2025-12-16 22:57:22.455354: val_loss -0.874 
2025-12-16 22:57:22.462366: Pseudo dice [0.9282, 0.9625, 0.9254] 
2025-12-16 22:57:22.466370: Epoch time: 138.02 s 
2025-12-16 22:57:23.268373:  
2025-12-16 22:57:23.268373: Epoch 520 
2025-12-16 22:57:23.268373: Current learning rate: 0.00517 
2025-12-16 22:59:41.492136: train_loss -0.8403 
2025-12-16 22:59:41.492136: val_loss -0.86 
2025-12-16 22:59:41.497330: Pseudo dice [0.9194, 0.9504, 0.9282] 
2025-12-16 22:59:41.501200: Epoch time: 138.22 s 
2025-12-16 22:59:42.225393:  
2025-12-16 22:59:42.225393: Epoch 521 
2025-12-16 22:59:42.227397: Current learning rate: 0.00516 
2025-12-16 23:02:00.265389: train_loss -0.8471 
2025-12-16 23:02:00.265389: val_loss -0.8701 
2025-12-16 23:02:00.265389: Pseudo dice [0.9244, 0.9545, 0.9355] 
2025-12-16 23:02:00.281038: Epoch time: 138.04 s 
2025-12-16 23:02:00.939689:  
2025-12-16 23:02:00.943236: Epoch 522 
2025-12-16 23:02:00.943236: Current learning rate: 0.00515 
2025-12-16 23:04:18.959757: train_loss -0.8401 
2025-12-16 23:04:18.961759: val_loss -0.8743 
2025-12-16 23:04:18.961759: Pseudo dice [0.9239, 0.9595, 0.9386] 
2025-12-16 23:04:18.961759: Epoch time: 138.02 s 
2025-12-16 23:04:19.627439:  
2025-12-16 23:04:19.627439: Epoch 523 
2025-12-16 23:04:19.627439: Current learning rate: 0.00514 
2025-12-16 23:06:37.642678: train_loss -0.8311 
2025-12-16 23:06:37.642678: val_loss -0.8337 
2025-12-16 23:06:37.642678: Pseudo dice [0.9018, 0.9386, 0.9172] 
2025-12-16 23:06:37.658430: Epoch time: 138.02 s 
2025-12-16 23:06:38.416097:  
2025-12-16 23:06:38.416097: Epoch 524 
2025-12-16 23:06:38.416097: Current learning rate: 0.00513 
2025-12-16 23:08:56.626466: train_loss -0.8326 
2025-12-16 23:08:56.628468: val_loss -0.872 
2025-12-16 23:08:56.633712: Pseudo dice [0.928, 0.9603, 0.9277] 
2025-12-16 23:08:56.633712: Epoch time: 138.21 s 
2025-12-16 23:08:57.276244:  
2025-12-16 23:08:57.276244: Epoch 525 
2025-12-16 23:08:57.279263: Current learning rate: 0.00512 
2025-12-16 23:11:15.609744: train_loss -0.8387 
2025-12-16 23:11:15.609744: val_loss -0.8549 
2025-12-16 23:11:15.611747: Pseudo dice [0.9148, 0.9511, 0.9347] 
2025-12-16 23:11:15.611747: Epoch time: 138.33 s 
2025-12-16 23:11:16.242721:  
2025-12-16 23:11:16.242721: Epoch 526 
2025-12-16 23:11:16.242721: Current learning rate: 0.00511 
2025-12-16 23:13:34.100958: train_loss -0.8466 
2025-12-16 23:13:34.100958: val_loss -0.8595 
2025-12-16 23:13:34.106966: Pseudo dice [0.92, 0.9516, 0.9287] 
2025-12-16 23:13:34.111973: Epoch time: 137.86 s 
2025-12-16 23:13:35.105134:  
2025-12-16 23:13:35.105134: Epoch 527 
2025-12-16 23:13:35.105134: Current learning rate: 0.0051 
2025-12-16 23:15:53.047938: train_loss -0.8448 
2025-12-16 23:15:53.047938: val_loss -0.8708 
2025-12-16 23:15:53.047938: Pseudo dice [0.9254, 0.9581, 0.9386] 
2025-12-16 23:15:53.063674: Epoch time: 137.94 s 
2025-12-16 23:15:53.681442:  
2025-12-16 23:15:53.681442: Epoch 528 
2025-12-16 23:15:53.681442: Current learning rate: 0.00509 
2025-12-16 23:18:11.623014: train_loss -0.8499 
2025-12-16 23:18:11.623014: val_loss -0.8573 
2025-12-16 23:18:11.638747: Pseudo dice [0.9162, 0.9505, 0.9242] 
2025-12-16 23:18:11.638747: Epoch time: 137.94 s 
2025-12-16 23:18:12.272194:  
2025-12-16 23:18:12.272194: Epoch 529 
2025-12-16 23:18:12.272194: Current learning rate: 0.00508 
2025-12-16 23:20:30.224138: train_loss -0.8446 
2025-12-16 23:20:30.224138: val_loss -0.8686 
2025-12-16 23:20:30.224138: Pseudo dice [0.9232, 0.9574, 0.9388] 
2025-12-16 23:20:30.224138: Epoch time: 137.95 s 
2025-12-16 23:20:30.967708:  
2025-12-16 23:20:30.967708: Epoch 530 
2025-12-16 23:20:30.967708: Current learning rate: 0.00507 
2025-12-16 23:22:49.083268: train_loss -0.846 
2025-12-16 23:22:49.083268: val_loss -0.8568 
2025-12-16 23:22:49.099187: Pseudo dice [0.9156, 0.9463, 0.9312] 
2025-12-16 23:22:49.104690: Epoch time: 138.12 s 
2025-12-16 23:22:49.741072:  
2025-12-16 23:22:49.741072: Epoch 531 
2025-12-16 23:22:49.741072: Current learning rate: 0.00506 
2025-12-16 23:25:07.645882: train_loss -0.8506 
2025-12-16 23:25:07.645882: val_loss -0.8622 
2025-12-16 23:25:07.650097: Pseudo dice [0.917, 0.9532, 0.9346] 
2025-12-16 23:25:07.650097: Epoch time: 137.9 s 
2025-12-16 23:25:08.278608:  
2025-12-16 23:25:08.278608: Epoch 532 
2025-12-16 23:25:08.278608: Current learning rate: 0.00505 
2025-12-16 23:27:26.276951: train_loss -0.8483 
2025-12-16 23:27:26.276951: val_loss -0.8666 
2025-12-16 23:27:26.282956: Pseudo dice [0.9267, 0.9567, 0.9244] 
2025-12-16 23:27:26.286589: Epoch time: 138.01 s 
2025-12-16 23:27:27.196351:  
2025-12-16 23:27:27.196351: Epoch 533 
2025-12-16 23:27:27.196351: Current learning rate: 0.00504 
2025-12-16 23:29:44.911436: train_loss -0.8477 
2025-12-16 23:29:44.911436: val_loss -0.8806 
2025-12-16 23:29:44.911436: Pseudo dice [0.934, 0.9605, 0.9319] 
2025-12-16 23:29:44.911436: Epoch time: 137.72 s 
2025-12-16 23:29:45.542774:  
2025-12-16 23:29:45.542774: Epoch 534 
2025-12-16 23:29:45.542774: Current learning rate: 0.00503 
2025-12-16 23:32:03.626071: train_loss -0.8532 
2025-12-16 23:32:03.628073: val_loss -0.8764 
2025-12-16 23:32:03.632205: Pseudo dice [0.927, 0.9557, 0.9462] 
2025-12-16 23:32:03.632205: Epoch time: 138.08 s 
2025-12-16 23:32:04.260896:  
2025-12-16 23:32:04.260896: Epoch 535 
2025-12-16 23:32:04.263562: Current learning rate: 0.00502 
2025-12-16 23:34:22.018298: train_loss -0.8478 
2025-12-16 23:34:22.018298: val_loss -0.8704 
2025-12-16 23:34:22.025306: Pseudo dice [0.9234, 0.9554, 0.9336] 
2025-12-16 23:34:22.029310: Epoch time: 137.76 s 
2025-12-16 23:34:22.661637:  
2025-12-16 23:34:22.661637: Epoch 536 
2025-12-16 23:34:22.661637: Current learning rate: 0.00501 
2025-12-16 23:36:40.695772: train_loss -0.8486 
2025-12-16 23:36:40.695772: val_loss -0.8712 
2025-12-16 23:36:40.701637: Pseudo dice [0.9256, 0.9589, 0.9341] 
2025-12-16 23:36:40.707382: Epoch time: 138.04 s 
2025-12-16 23:36:41.337382:  
2025-12-16 23:36:41.337382: Epoch 537 
2025-12-16 23:36:41.337382: Current learning rate: 0.005 
2025-12-16 23:38:59.205022: train_loss -0.846 
2025-12-16 23:38:59.205022: val_loss -0.8793 
2025-12-16 23:38:59.206763: Pseudo dice [0.9327, 0.9613, 0.9337] 
2025-12-16 23:38:59.214092: Epoch time: 137.87 s 
2025-12-16 23:38:59.218096: Yayy! New best EMA pseudo Dice: 0.9376 
2025-12-16 23:39:00.101050:  
2025-12-16 23:39:00.101050: Epoch 538 
2025-12-16 23:39:00.101050: Current learning rate: 0.00499 
2025-12-16 23:41:18.141097: train_loss -0.8446 
2025-12-16 23:41:18.141097: val_loss -0.8734 
2025-12-16 23:41:18.147416: Pseudo dice [0.926, 0.9568, 0.9343] 
2025-12-16 23:41:18.150420: Epoch time: 138.04 s 
2025-12-16 23:41:18.154263: Yayy! New best EMA pseudo Dice: 0.9377 
2025-12-16 23:41:19.253420:  
2025-12-16 23:41:19.253420: Epoch 539 
2025-12-16 23:41:19.259427: Current learning rate: 0.00498 
2025-12-16 23:43:37.111270: train_loss -0.8424 
2025-12-16 23:43:37.111270: val_loss -0.8534 
2025-12-16 23:43:37.117276: Pseudo dice [0.9147, 0.9469, 0.9214] 
2025-12-16 23:43:37.119278: Epoch time: 137.86 s 
2025-12-16 23:43:37.736912:  
2025-12-16 23:43:37.736912: Epoch 540 
2025-12-16 23:43:37.736912: Current learning rate: 0.00497 
2025-12-16 23:45:55.621509: train_loss -0.8458 
2025-12-16 23:45:55.621509: val_loss -0.8626 
2025-12-16 23:45:55.628577: Pseudo dice [0.9213, 0.9519, 0.93] 
2025-12-16 23:45:55.632581: Epoch time: 137.88 s 
2025-12-16 23:45:56.256287:  
2025-12-16 23:45:56.256287: Epoch 541 
2025-12-16 23:45:56.272010: Current learning rate: 0.00496 
2025-12-16 23:48:14.074400: train_loss -0.8515 
2025-12-16 23:48:14.074400: val_loss -0.8617 
2025-12-16 23:48:14.074400: Pseudo dice [0.9194, 0.9508, 0.9196] 
2025-12-16 23:48:14.090405: Epoch time: 137.82 s 
2025-12-16 23:48:14.709805:  
2025-12-16 23:48:14.709805: Epoch 542 
2025-12-16 23:48:14.709805: Current learning rate: 0.00495 
2025-12-16 23:50:32.586123: train_loss -0.8508 
2025-12-16 23:50:32.586123: val_loss -0.8694 
2025-12-16 23:50:32.591867: Pseudo dice [0.9264, 0.9555, 0.9267] 
2025-12-16 23:50:32.595871: Epoch time: 137.88 s 
2025-12-16 23:50:33.228677:  
2025-12-16 23:50:33.228677: Epoch 543 
2025-12-16 23:50:33.228677: Current learning rate: 0.00494 
2025-12-16 23:52:51.128171: train_loss -0.8497 
2025-12-16 23:52:51.130173: val_loss -0.8668 
2025-12-16 23:52:51.134177: Pseudo dice [0.9265, 0.9553, 0.9184] 
2025-12-16 23:52:51.138181: Epoch time: 137.9 s 
2025-12-16 23:52:51.805887:  
2025-12-16 23:52:51.805887: Epoch 544 
2025-12-16 23:52:51.805887: Current learning rate: 0.00493 
2025-12-16 23:55:09.813072: train_loss -0.8494 
2025-12-16 23:55:09.813072: val_loss -0.865 
2025-12-16 23:55:09.820129: Pseudo dice [0.9221, 0.9553, 0.9307] 
2025-12-16 23:55:09.824897: Epoch time: 138.01 s 
2025-12-16 23:55:10.627525:  
2025-12-16 23:55:10.627525: Epoch 545 
2025-12-16 23:55:10.627525: Current learning rate: 0.00492 
2025-12-16 23:57:28.482924: train_loss -0.8491 
2025-12-16 23:57:28.482924: val_loss -0.8702 
2025-12-16 23:57:28.489932: Pseudo dice [0.9258, 0.9579, 0.9254] 
2025-12-16 23:57:28.493936: Epoch time: 137.86 s 
2025-12-16 23:57:29.120295:  
2025-12-16 23:57:29.120295: Epoch 546 
2025-12-16 23:57:29.120295: Current learning rate: 0.00491 
2025-12-16 23:59:46.961279: train_loss -0.8523 
2025-12-16 23:59:46.963281: val_loss -0.8564 
2025-12-16 23:59:46.969289: Pseudo dice [0.9128, 0.95, 0.9301] 
2025-12-16 23:59:46.975035: Epoch time: 137.84 s 
2025-12-16 23:59:47.764292:  
2025-12-16 23:59:47.764292: Epoch 547 
2025-12-16 23:59:47.774510: Current learning rate: 0.0049 
2025-12-17 00:02:05.551368: train_loss -0.8551 
2025-12-17 00:02:05.551368: val_loss -0.877 
2025-12-17 00:02:05.561382: Pseudo dice [0.9292, 0.9604, 0.9303] 
2025-12-17 00:02:05.567129: Epoch time: 137.79 s 
2025-12-17 00:02:06.196535:  
2025-12-17 00:02:06.196535: Epoch 548 
2025-12-17 00:02:06.196535: Current learning rate: 0.00489 
2025-12-17 00:04:24.191232: train_loss -0.8489 
2025-12-17 00:04:24.191232: val_loss -0.8701 
2025-12-17 00:04:24.197078: Pseudo dice [0.928, 0.9552, 0.933] 
2025-12-17 00:04:24.201082: Epoch time: 137.99 s 
2025-12-17 00:04:24.829745:  
2025-12-17 00:04:24.829745: Epoch 549 
2025-12-17 00:04:24.829745: Current learning rate: 0.00488 
2025-12-17 00:06:42.741640: train_loss -0.8462 
2025-12-17 00:06:42.743642: val_loss -0.8781 
2025-12-17 00:06:42.749388: Pseudo dice [0.9297, 0.9567, 0.9411] 
2025-12-17 00:06:42.753393: Epoch time: 137.91 s 
2025-12-17 00:06:43.749096:  
2025-12-17 00:06:43.749096: Epoch 550 
2025-12-17 00:06:43.749096: Current learning rate: 0.00487 
2025-12-17 00:09:01.806283: train_loss -0.8483 
2025-12-17 00:09:01.808285: val_loss -0.86 
2025-12-17 00:09:01.810287: Pseudo dice [0.9197, 0.9481, 0.9312] 
2025-12-17 00:09:01.816379: Epoch time: 138.06 s 
2025-12-17 00:09:02.619255:  
2025-12-17 00:09:02.619255: Epoch 551 
2025-12-17 00:09:02.619255: Current learning rate: 0.00486 
2025-12-17 00:11:21.025829: train_loss -0.8465 
2025-12-17 00:11:21.027832: val_loss -0.8677 
2025-12-17 00:11:21.031837: Pseudo dice [0.9208, 0.9565, 0.9337] 
2025-12-17 00:11:21.035841: Epoch time: 138.41 s 
2025-12-17 00:11:21.655698:  
2025-12-17 00:11:21.671614: Epoch 552 
2025-12-17 00:11:21.675549: Current learning rate: 0.00485 
2025-12-17 00:13:39.767436: train_loss -0.849 
2025-12-17 00:13:39.767436: val_loss -0.8663 
2025-12-17 00:13:39.775202: Pseudo dice [0.9256, 0.9526, 0.9325] 
2025-12-17 00:13:39.777204: Epoch time: 138.11 s 
2025-12-17 00:13:40.573645:  
2025-12-17 00:13:40.573645: Epoch 553 
2025-12-17 00:13:40.573645: Current learning rate: 0.00484 
2025-12-17 00:15:58.535255: train_loss -0.847 
2025-12-17 00:15:58.537257: val_loss -0.8715 
2025-12-17 00:15:58.537257: Pseudo dice [0.9243, 0.9583, 0.9418] 
2025-12-17 00:15:58.537257: Epoch time: 137.97 s 
2025-12-17 00:15:59.171130:  
2025-12-17 00:15:59.171130: Epoch 554 
2025-12-17 00:15:59.175551: Current learning rate: 0.00484 
2025-12-17 00:18:17.124830: train_loss -0.8493 
2025-12-17 00:18:17.124830: val_loss -0.8716 
2025-12-17 00:18:17.129837: Pseudo dice [0.9311, 0.9548, 0.9334] 
2025-12-17 00:18:17.133666: Epoch time: 137.95 s 
2025-12-17 00:18:17.810056:  
2025-12-17 00:18:17.810056: Epoch 555 
2025-12-17 00:18:17.816064: Current learning rate: 0.00483 
2025-12-17 00:20:35.773886: train_loss -0.8504 
2025-12-17 00:20:35.775888: val_loss -0.8795 
2025-12-17 00:20:35.779894: Pseudo dice [0.9274, 0.9587, 0.9419] 
2025-12-17 00:20:35.781896: Epoch time: 137.97 s 
2025-12-17 00:20:35.781896: Yayy! New best EMA pseudo Dice: 0.9378 
2025-12-17 00:20:36.782190:  
2025-12-17 00:20:36.782190: Epoch 556 
2025-12-17 00:20:36.792039: Current learning rate: 0.00482 
2025-12-17 00:22:54.666601: train_loss -0.8492 
2025-12-17 00:22:54.670139: val_loss -0.8688 
2025-12-17 00:22:54.674994: Pseudo dice [0.9226, 0.9572, 0.9292] 
2025-12-17 00:22:54.676996: Epoch time: 137.88 s 
2025-12-17 00:22:55.317425:  
2025-12-17 00:22:55.317425: Epoch 557 
2025-12-17 00:22:55.317425: Current learning rate: 0.00481 
2025-12-17 00:25:13.298236: train_loss -0.8488 
2025-12-17 00:25:13.298236: val_loss -0.8666 
2025-12-17 00:25:13.314021: Pseudo dice [0.9184, 0.951, 0.9406] 
2025-12-17 00:25:13.314021: Epoch time: 137.98 s 
2025-12-17 00:25:14.107169:  
2025-12-17 00:25:14.107169: Epoch 558 
2025-12-17 00:25:14.107169: Current learning rate: 0.0048 
2025-12-17 00:27:32.054046: train_loss -0.8497 
2025-12-17 00:27:32.056049: val_loss -0.8675 
2025-12-17 00:27:32.060055: Pseudo dice [0.9217, 0.9514, 0.9376] 
2025-12-17 00:27:32.061796: Epoch time: 137.95 s 
2025-12-17 00:27:32.806911:  
2025-12-17 00:27:32.806911: Epoch 559 
2025-12-17 00:27:32.813166: Current learning rate: 0.00479 
2025-12-17 00:29:50.729719: train_loss -0.8539 
2025-12-17 00:29:50.729719: val_loss -0.8624 
2025-12-17 00:29:50.735465: Pseudo dice [0.9216, 0.952, 0.9315] 
2025-12-17 00:29:50.741471: Epoch time: 137.92 s 
2025-12-17 00:29:51.402236:  
2025-12-17 00:29:51.402236: Epoch 560 
2025-12-17 00:29:51.402236: Current learning rate: 0.00478 
2025-12-17 00:32:09.380013: train_loss -0.85 
2025-12-17 00:32:09.395811: val_loss -0.8786 
2025-12-17 00:32:09.399817: Pseudo dice [0.9318, 0.9574, 0.9349] 
2025-12-17 00:32:09.402122: Epoch time: 137.98 s 
2025-12-17 00:32:10.029626:  
2025-12-17 00:32:10.029626: Epoch 561 
2025-12-17 00:32:10.029626: Current learning rate: 0.00477 
2025-12-17 00:34:27.945403: train_loss -0.8491 
2025-12-17 00:34:27.945403: val_loss -0.8595 
2025-12-17 00:34:27.961118: Pseudo dice [0.9164, 0.9497, 0.937] 
2025-12-17 00:34:27.966423: Epoch time: 137.92 s 
2025-12-17 00:34:28.594382:  
2025-12-17 00:34:28.594382: Epoch 562 
2025-12-17 00:34:28.609781: Current learning rate: 0.00476 
2025-12-17 00:36:46.603366: train_loss -0.8528 
2025-12-17 00:36:46.603366: val_loss -0.8775 
2025-12-17 00:36:46.603366: Pseudo dice [0.9275, 0.9591, 0.9394] 
2025-12-17 00:36:46.619173: Epoch time: 138.01 s 
2025-12-17 00:36:46.622838: Yayy! New best EMA pseudo Dice: 0.9378 
2025-12-17 00:36:47.476973:  
2025-12-17 00:36:47.476973: Epoch 563 
2025-12-17 00:36:47.496258: Current learning rate: 0.00475 
2025-12-17 00:39:05.644304: train_loss -0.8532 
2025-12-17 00:39:05.644304: val_loss -0.8732 
2025-12-17 00:39:05.658163: Pseudo dice [0.9243, 0.9573, 0.9325] 
2025-12-17 00:39:05.660166: Epoch time: 138.17 s 
2025-12-17 00:39:05.660166: Yayy! New best EMA pseudo Dice: 0.9378 
2025-12-17 00:39:06.721900:  
2025-12-17 00:39:06.721900: Epoch 564 
2025-12-17 00:39:06.730046: Current learning rate: 0.00474 
2025-12-17 00:41:24.626337: train_loss -0.848 
2025-12-17 00:41:24.626337: val_loss -0.877 
2025-12-17 00:41:24.634086: Pseudo dice [0.9322, 0.963, 0.9244] 
2025-12-17 00:41:24.638093: Epoch time: 137.9 s 
2025-12-17 00:41:24.640096: Yayy! New best EMA pseudo Dice: 0.938 
2025-12-17 00:41:25.553245:  
2025-12-17 00:41:25.553245: Epoch 565 
2025-12-17 00:41:25.553245: Current learning rate: 0.00473 
2025-12-17 00:43:43.559346: train_loss -0.8518 
2025-12-17 00:43:43.561348: val_loss -0.8561 
2025-12-17 00:43:43.565888: Pseudo dice [0.9117, 0.9501, 0.9321] 
2025-12-17 00:43:43.571300: Epoch time: 138.01 s 
2025-12-17 00:43:44.211757:  
2025-12-17 00:43:44.211757: Epoch 566 
2025-12-17 00:43:44.211757: Current learning rate: 0.00472 
2025-12-17 00:46:02.195060: train_loss -0.8464 
2025-12-17 00:46:02.197062: val_loss -0.8855 
2025-12-17 00:46:02.203068: Pseudo dice [0.9316, 0.9583, 0.9458] 
2025-12-17 00:46:02.208818: Epoch time: 137.98 s 
2025-12-17 00:46:02.214835: Yayy! New best EMA pseudo Dice: 0.9381 
2025-12-17 00:46:03.167927:  
2025-12-17 00:46:03.167927: Epoch 567 
2025-12-17 00:46:03.171669: Current learning rate: 0.00471 
2025-12-17 00:48:21.043832: train_loss -0.8486 
2025-12-17 00:48:21.043832: val_loss -0.8638 
2025-12-17 00:48:21.050206: Pseudo dice [0.922, 0.9548, 0.9235] 
2025-12-17 00:48:21.050206: Epoch time: 137.88 s 
2025-12-17 00:48:21.667648:  
2025-12-17 00:48:21.667648: Epoch 568 
2025-12-17 00:48:21.683552: Current learning rate: 0.0047 
2025-12-17 00:50:39.798221: train_loss -0.8481 
2025-12-17 00:50:39.798221: val_loss -0.8704 
2025-12-17 00:50:39.806647: Pseudo dice [0.9271, 0.956, 0.9305] 
2025-12-17 00:50:39.810935: Epoch time: 138.13 s 
2025-12-17 00:50:40.432894:  
2025-12-17 00:50:40.432894: Epoch 569 
2025-12-17 00:50:40.448699: Current learning rate: 0.00469 
2025-12-17 00:52:58.401642: train_loss -0.8505 
2025-12-17 00:52:58.401642: val_loss -0.8711 
2025-12-17 00:52:58.401642: Pseudo dice [0.9268, 0.9584, 0.9293] 
2025-12-17 00:52:58.401642: Epoch time: 137.97 s 
2025-12-17 00:52:59.241240:  
2025-12-17 00:52:59.241240: Epoch 570 
2025-12-17 00:52:59.241240: Current learning rate: 0.00468 
2025-12-17 00:55:17.226207: train_loss -0.8485 
2025-12-17 00:55:17.226207: val_loss -0.8724 
2025-12-17 00:55:17.242176: Pseudo dice [0.9302, 0.9594, 0.9308] 
2025-12-17 00:55:17.248994: Epoch time: 138.0 s 
2025-12-17 00:55:17.876584:  
2025-12-17 00:55:17.876584: Epoch 571 
2025-12-17 00:55:17.876584: Current learning rate: 0.00467 
2025-12-17 00:57:35.924664: train_loss -0.8502 
2025-12-17 00:57:35.926667: val_loss -0.8674 
2025-12-17 00:57:35.931734: Pseudo dice [0.9209, 0.9548, 0.9279] 
2025-12-17 00:57:35.935738: Epoch time: 138.05 s 
2025-12-17 00:57:36.562647:  
2025-12-17 00:57:36.562647: Epoch 572 
2025-12-17 00:57:36.562647: Current learning rate: 0.00466 
2025-12-17 00:59:54.464628: train_loss -0.8531 
2025-12-17 00:59:54.466630: val_loss -0.8616 
2025-12-17 00:59:54.472375: Pseudo dice [0.92, 0.954, 0.9319] 
2025-12-17 00:59:54.476379: Epoch time: 137.9 s 
2025-12-17 00:59:55.104356:  
2025-12-17 00:59:55.104356: Epoch 573 
2025-12-17 00:59:55.120436: Current learning rate: 0.00465 
2025-12-17 01:02:13.100853: train_loss -0.8509 
2025-12-17 01:02:13.100853: val_loss -0.8667 
2025-12-17 01:02:13.116902: Pseudo dice [0.9262, 0.9553, 0.9271] 
2025-12-17 01:02:13.116902: Epoch time: 138.0 s 
2025-12-17 01:02:13.797668:  
2025-12-17 01:02:13.797668: Epoch 574 
2025-12-17 01:02:13.797668: Current learning rate: 0.00464 
2025-12-17 01:04:31.809324: train_loss -0.8526 
2025-12-17 01:04:31.809324: val_loss -0.8781 
2025-12-17 01:04:31.821999: Pseudo dice [0.9298, 0.9601, 0.9363] 
2025-12-17 01:04:31.825191: Epoch time: 138.01 s 
2025-12-17 01:04:32.459983:  
2025-12-17 01:04:32.459983: Epoch 575 
2025-12-17 01:04:32.478126: Current learning rate: 0.00463 
2025-12-17 01:06:50.475384: train_loss -0.8544 
2025-12-17 01:06:50.475384: val_loss -0.8659 
2025-12-17 01:06:50.481390: Pseudo dice [0.9202, 0.9495, 0.9382] 
2025-12-17 01:06:50.485395: Epoch time: 138.02 s 
2025-12-17 01:06:51.378602:  
2025-12-17 01:06:51.378602: Epoch 576 
2025-12-17 01:06:51.378602: Current learning rate: 0.00462 
2025-12-17 01:09:09.729863: train_loss -0.8517 
2025-12-17 01:09:09.729863: val_loss -0.8781 
2025-12-17 01:09:09.737422: Pseudo dice [0.9313, 0.9563, 0.932] 
2025-12-17 01:09:09.737422: Epoch time: 138.35 s 
2025-12-17 01:09:10.396080:  
2025-12-17 01:09:10.396080: Epoch 577 
2025-12-17 01:09:10.396080: Current learning rate: 0.00461 
2025-12-17 01:11:28.769387: train_loss -0.8472 
2025-12-17 01:11:28.769387: val_loss -0.8693 
2025-12-17 01:11:28.774375: Pseudo dice [0.9263, 0.9558, 0.9345] 
2025-12-17 01:11:28.777063: Epoch time: 138.37 s 
2025-12-17 01:11:29.404816:  
2025-12-17 01:11:29.404816: Epoch 578 
2025-12-17 01:11:29.415082: Current learning rate: 0.0046 
2025-12-17 01:13:47.522790: train_loss -0.8482 
2025-12-17 01:13:47.522790: val_loss -0.8695 
2025-12-17 01:13:47.530816: Pseudo dice [0.9228, 0.952, 0.9323] 
2025-12-17 01:13:47.534820: Epoch time: 138.12 s 
2025-12-17 01:13:48.303066:  
2025-12-17 01:13:48.303066: Epoch 579 
2025-12-17 01:13:48.303066: Current learning rate: 0.00459 
2025-12-17 01:16:06.265033: train_loss -0.8529 
2025-12-17 01:16:06.265033: val_loss -0.8601 
2025-12-17 01:16:06.266973: Pseudo dice [0.9249, 0.9517, 0.9251] 
2025-12-17 01:16:06.266973: Epoch time: 137.96 s 
2025-12-17 01:16:06.898795:  
2025-12-17 01:16:06.898795: Epoch 580 
2025-12-17 01:16:06.914565: Current learning rate: 0.00458 
2025-12-17 01:18:24.823357: train_loss -0.8498 
2025-12-17 01:18:24.825360: val_loss -0.8648 
2025-12-17 01:18:24.831371: Pseudo dice [0.9236, 0.9541, 0.9279] 
2025-12-17 01:18:24.837379: Epoch time: 137.92 s 
2025-12-17 01:18:25.472030:  
2025-12-17 01:18:25.472030: Epoch 581 
2025-12-17 01:18:25.480968: Current learning rate: 0.00457 
2025-12-17 01:20:43.455305: train_loss -0.8495 
2025-12-17 01:20:43.455305: val_loss -0.8582 
2025-12-17 01:20:43.471413: Pseudo dice [0.9179, 0.9515, 0.9315] 
2025-12-17 01:20:43.471413: Epoch time: 137.98 s 
2025-12-17 01:20:44.452224:  
2025-12-17 01:20:44.452224: Epoch 582 
2025-12-17 01:20:44.456896: Current learning rate: 0.00456 
2025-12-17 01:23:02.401942: train_loss -0.8512 
2025-12-17 01:23:02.401942: val_loss -0.8802 
2025-12-17 01:23:02.404927: Pseudo dice [0.9299, 0.9609, 0.942] 
2025-12-17 01:23:02.411781: Epoch time: 137.97 s 
2025-12-17 01:23:03.102813:  
2025-12-17 01:23:03.102813: Epoch 583 
2025-12-17 01:23:03.115786: Current learning rate: 0.00455 
2025-12-17 01:25:21.094128: train_loss -0.848 
2025-12-17 01:25:21.094128: val_loss -0.8716 
2025-12-17 01:25:21.110088: Pseudo dice [0.926, 0.9572, 0.9324] 
2025-12-17 01:25:21.110088: Epoch time: 137.99 s 
2025-12-17 01:25:21.744437:  
2025-12-17 01:25:21.744437: Epoch 584 
2025-12-17 01:25:21.744437: Current learning rate: 0.00454 
2025-12-17 01:27:39.720405: train_loss -0.8519 
2025-12-17 01:27:39.722406: val_loss -0.8619 
2025-12-17 01:27:39.726151: Pseudo dice [0.9218, 0.956, 0.9309] 
2025-12-17 01:27:39.730870: Epoch time: 137.98 s 
2025-12-17 01:27:40.497090:  
2025-12-17 01:27:40.499094: Epoch 585 
2025-12-17 01:27:40.502840: Current learning rate: 0.00453 
2025-12-17 01:29:58.543181: train_loss -0.8504 
2025-12-17 01:29:58.543181: val_loss -0.8743 
2025-12-17 01:29:58.545183: Pseudo dice [0.9228, 0.9558, 0.9416] 
2025-12-17 01:29:58.545183: Epoch time: 138.05 s 
2025-12-17 01:29:59.189007:  
2025-12-17 01:29:59.189007: Epoch 586 
2025-12-17 01:29:59.189007: Current learning rate: 0.00452 
2025-12-17 01:32:17.399182: train_loss -0.8515 
2025-12-17 01:32:17.399182: val_loss -0.8719 
2025-12-17 01:32:17.404929: Pseudo dice [0.9245, 0.9553, 0.933] 
2025-12-17 01:32:17.408933: Epoch time: 138.21 s 
2025-12-17 01:32:18.052118:  
2025-12-17 01:32:18.052118: Epoch 587 
2025-12-17 01:32:18.052118: Current learning rate: 0.00451 
2025-12-17 01:34:35.935807: train_loss -0.8494 
2025-12-17 01:34:35.935807: val_loss -0.8579 
2025-12-17 01:34:35.939552: Pseudo dice [0.9123, 0.9505, 0.9342] 
2025-12-17 01:34:35.939552: Epoch time: 137.88 s 
2025-12-17 01:34:36.890167:  
2025-12-17 01:34:36.890167: Epoch 588 
2025-12-17 01:34:36.890167: Current learning rate: 0.0045 
2025-12-17 01:36:54.730054: train_loss -0.8565 
2025-12-17 01:36:54.730054: val_loss -0.8757 
2025-12-17 01:36:54.745776: Pseudo dice [0.928, 0.9561, 0.9347] 
2025-12-17 01:36:54.745776: Epoch time: 137.84 s 
2025-12-17 01:36:55.383013:  
2025-12-17 01:36:55.383013: Epoch 589 
2025-12-17 01:36:55.398796: Current learning rate: 0.00449 
2025-12-17 01:39:13.364539: train_loss -0.8494 
2025-12-17 01:39:13.364539: val_loss -0.8839 
2025-12-17 01:39:13.364539: Pseudo dice [0.9327, 0.9571, 0.937] 
2025-12-17 01:39:13.380343: Epoch time: 137.98 s 
2025-12-17 01:39:14.015530:  
2025-12-17 01:39:14.015530: Epoch 590 
2025-12-17 01:39:14.015530: Current learning rate: 0.00448 
2025-12-17 01:41:32.137440: train_loss -0.8485 
2025-12-17 01:41:32.137440: val_loss -0.8752 
2025-12-17 01:41:32.141445: Pseudo dice [0.9238, 0.9582, 0.9365] 
2025-12-17 01:41:32.147190: Epoch time: 138.12 s 
2025-12-17 01:41:32.938691:  
2025-12-17 01:41:32.938691: Epoch 591 
2025-12-17 01:41:32.954578: Current learning rate: 0.00447 
2025-12-17 01:43:51.193350: train_loss -0.8437 
2025-12-17 01:43:51.195352: val_loss -0.8739 
2025-12-17 01:43:51.198466: Pseudo dice [0.9301, 0.958, 0.9337] 
2025-12-17 01:43:51.198466: Epoch time: 138.25 s 
2025-12-17 01:43:51.198466: Yayy! New best EMA pseudo Dice: 0.9383 
2025-12-17 01:43:52.090947:  
2025-12-17 01:43:52.090947: Epoch 592 
2025-12-17 01:43:52.090947: Current learning rate: 0.00446 
2025-12-17 01:46:10.076378: train_loss -0.8488 
2025-12-17 01:46:10.076378: val_loss -0.856 
2025-12-17 01:46:10.076378: Pseudo dice [0.9155, 0.9489, 0.9361] 
2025-12-17 01:46:10.076378: Epoch time: 137.99 s 
2025-12-17 01:46:10.710753:  
2025-12-17 01:46:10.710753: Epoch 593 
2025-12-17 01:46:10.726586: Current learning rate: 0.00445 
2025-12-17 01:48:28.593069: train_loss -0.8515 
2025-12-17 01:48:28.593069: val_loss -0.8643 
2025-12-17 01:48:28.599077: Pseudo dice [0.9256, 0.9507, 0.9247] 
2025-12-17 01:48:28.606912: Epoch time: 137.88 s 
2025-12-17 01:48:29.418196:  
2025-12-17 01:48:29.418196: Epoch 594 
2025-12-17 01:48:29.425089: Current learning rate: 0.00444 
2025-12-17 01:50:47.167241: train_loss -0.8438 
2025-12-17 01:50:47.169243: val_loss -0.8713 
2025-12-17 01:50:47.173247: Pseudo dice [0.9246, 0.9566, 0.9359] 
2025-12-17 01:50:47.177253: Epoch time: 137.75 s 
2025-12-17 01:50:47.820850:  
2025-12-17 01:50:47.820850: Epoch 595 
2025-12-17 01:50:47.820850: Current learning rate: 0.00443 
2025-12-17 01:53:05.820215: train_loss -0.8495 
2025-12-17 01:53:05.820215: val_loss -0.876 
2025-12-17 01:53:05.820215: Pseudo dice [0.9291, 0.9568, 0.937] 
2025-12-17 01:53:05.820215: Epoch time: 138.02 s 
2025-12-17 01:53:06.470138:  
2025-12-17 01:53:06.470138: Epoch 596 
2025-12-17 01:53:06.470138: Current learning rate: 0.00442 
2025-12-17 01:55:24.541516: train_loss -0.8507 
2025-12-17 01:55:24.541516: val_loss -0.8703 
2025-12-17 01:55:24.546350: Pseudo dice [0.9219, 0.9557, 0.9379] 
2025-12-17 01:55:24.549066: Epoch time: 138.07 s 
2025-12-17 01:55:25.175804:  
2025-12-17 01:55:25.175804: Epoch 597 
2025-12-17 01:55:25.189121: Current learning rate: 0.00441 
2025-12-17 01:57:43.203102: train_loss -0.8459 
2025-12-17 01:57:43.203102: val_loss -0.8848 
2025-12-17 01:57:43.217697: Pseudo dice [0.9331, 0.9649, 0.9385] 
2025-12-17 01:57:43.221202: Epoch time: 138.03 s 
2025-12-17 01:57:43.226177: Yayy! New best EMA pseudo Dice: 0.9387 
2025-12-17 01:57:44.105969:  
2025-12-17 01:57:44.105969: Epoch 598 
2025-12-17 01:57:44.121727: Current learning rate: 0.0044 
2025-12-17 02:00:02.023286: train_loss -0.8519 
2025-12-17 02:00:02.023286: val_loss -0.877 
2025-12-17 02:00:02.038980: Pseudo dice [0.9292, 0.9608, 0.9337] 
2025-12-17 02:00:02.044482: Epoch time: 137.92 s 
2025-12-17 02:00:02.048487: Yayy! New best EMA pseudo Dice: 0.939 
2025-12-17 02:00:03.017873:  
2025-12-17 02:00:03.017873: Epoch 599 
2025-12-17 02:00:03.017873: Current learning rate: 0.00439 
2025-12-17 02:02:20.985895: train_loss -0.8531 
2025-12-17 02:02:20.987897: val_loss -0.8568 
2025-12-17 02:02:20.989900: Pseudo dice [0.9174, 0.952, 0.9264] 
2025-12-17 02:02:20.995397: Epoch time: 137.97 s 
2025-12-17 02:02:22.050371:  
2025-12-17 02:02:22.050371: Epoch 600 
2025-12-17 02:02:22.050371: Current learning rate: 0.00438 
2025-12-17 02:04:40.097097: train_loss -0.8537 
2025-12-17 02:04:40.099099: val_loss -0.8524 
2025-12-17 02:04:40.103103: Pseudo dice [0.9165, 0.947, 0.9325] 
2025-12-17 02:04:40.108525: Epoch time: 138.05 s 
2025-12-17 02:04:40.745076:  
2025-12-17 02:04:40.745076: Epoch 601 
2025-12-17 02:04:40.761199: Current learning rate: 0.00437 
2025-12-17 02:06:58.910087: train_loss -0.851 
2025-12-17 02:06:58.910087: val_loss -0.8625 
2025-12-17 02:06:58.918096: Pseudo dice [0.9173, 0.9535, 0.9391] 
2025-12-17 02:06:58.922100: Epoch time: 138.17 s 
2025-12-17 02:06:59.563745:  
2025-12-17 02:06:59.563745: Epoch 602 
2025-12-17 02:06:59.563745: Current learning rate: 0.00436 
2025-12-17 02:09:17.706974: train_loss -0.8537 
2025-12-17 02:09:17.706974: val_loss -0.8662 
2025-12-17 02:09:17.710978: Pseudo dice [0.9177, 0.952, 0.9399] 
2025-12-17 02:09:17.714983: Epoch time: 138.15 s 
2025-12-17 02:09:18.366422:  
2025-12-17 02:09:18.366422: Epoch 603 
2025-12-17 02:09:18.366422: Current learning rate: 0.00435 
2025-12-17 02:11:36.531259: train_loss -0.8536 
2025-12-17 02:11:36.533261: val_loss -0.8709 
2025-12-17 02:11:36.539005: Pseudo dice [0.9241, 0.9572, 0.9283] 
2025-12-17 02:11:36.547015: Epoch time: 138.17 s 
2025-12-17 02:11:37.188267:  
2025-12-17 02:11:37.188267: Epoch 604 
2025-12-17 02:11:37.188267: Current learning rate: 0.00434 
2025-12-17 02:13:55.190045: train_loss -0.8553 
2025-12-17 02:13:55.190045: val_loss -0.8695 
2025-12-17 02:13:55.190045: Pseudo dice [0.9231, 0.9587, 0.9353] 
2025-12-17 02:13:55.190045: Epoch time: 138.0 s 
2025-12-17 02:13:55.862578:  
2025-12-17 02:13:55.862578: Epoch 605 
2025-12-17 02:13:55.862578: Current learning rate: 0.00433 
2025-12-17 02:16:14.118293: train_loss -0.8542 
2025-12-17 02:16:14.118293: val_loss -0.8723 
2025-12-17 02:16:14.122298: Pseudo dice [0.9229, 0.9534, 0.9363] 
2025-12-17 02:16:14.124038: Epoch time: 138.26 s 
2025-12-17 02:16:14.759933:  
2025-12-17 02:16:14.759933: Epoch 606 
2025-12-17 02:16:14.775939: Current learning rate: 0.00432 
2025-12-17 02:18:32.672380: train_loss -0.8509 
2025-12-17 02:18:32.674381: val_loss -0.8717 
2025-12-17 02:18:32.678385: Pseudo dice [0.9244, 0.9554, 0.9363] 
2025-12-17 02:18:32.682128: Epoch time: 137.91 s 
2025-12-17 02:18:33.316503:  
2025-12-17 02:18:33.316503: Epoch 607 
2025-12-17 02:18:33.316503: Current learning rate: 0.00431 
2025-12-17 02:20:51.299778: train_loss -0.8529 
2025-12-17 02:20:51.299778: val_loss -0.8687 
2025-12-17 02:20:51.302392: Pseudo dice [0.9221, 0.9562, 0.9313] 
2025-12-17 02:20:51.302392: Epoch time: 137.98 s 
2025-12-17 02:20:51.933538:  
2025-12-17 02:20:51.933538: Epoch 608 
2025-12-17 02:20:51.933538: Current learning rate: 0.0043 
2025-12-17 02:23:09.996652: train_loss -0.8547 
2025-12-17 02:23:09.998654: val_loss -0.8766 
2025-12-17 02:23:10.004161: Pseudo dice [0.9248, 0.9557, 0.9413] 
2025-12-17 02:23:10.010166: Epoch time: 138.06 s 
2025-12-17 02:23:10.645068:  
2025-12-17 02:23:10.645068: Epoch 609 
2025-12-17 02:23:10.660824: Current learning rate: 0.00429 
2025-12-17 02:25:28.606348: train_loss -0.851 
2025-12-17 02:25:28.609604: val_loss -0.8633 
2025-12-17 02:25:28.613488: Pseudo dice [0.918, 0.95, 0.9301] 
2025-12-17 02:25:28.619493: Epoch time: 137.96 s 
2025-12-17 02:25:29.264815:  
2025-12-17 02:25:29.264815: Epoch 610 
2025-12-17 02:25:29.264815: Current learning rate: 0.00429 
2025-12-17 02:27:47.267899: train_loss -0.8506 
2025-12-17 02:27:47.267899: val_loss -0.8513 
2025-12-17 02:27:47.267899: Pseudo dice [0.9108, 0.9532, 0.9339] 
2025-12-17 02:27:47.283850: Epoch time: 138.01 s 
2025-12-17 02:27:47.924708:  
2025-12-17 02:27:47.924708: Epoch 611 
2025-12-17 02:27:47.928517: Current learning rate: 0.00428 
2025-12-17 02:30:05.734025: train_loss -0.8362 
2025-12-17 02:30:05.734025: val_loss -0.8547 
2025-12-17 02:30:05.750007: Pseudo dice [0.9194, 0.9506, 0.9192] 
2025-12-17 02:30:05.755512: Epoch time: 137.81 s 
2025-12-17 02:30:06.565152:  
2025-12-17 02:30:06.565152: Epoch 612 
2025-12-17 02:30:06.571137: Current learning rate: 0.00427 
2025-12-17 02:32:24.536493: train_loss -0.8329 
2025-12-17 02:32:24.538495: val_loss -0.8588 
2025-12-17 02:32:24.544501: Pseudo dice [0.9232, 0.9531, 0.9302] 
2025-12-17 02:32:24.550508: Epoch time: 137.97 s 
2025-12-17 02:32:25.197386:  
2025-12-17 02:32:25.197386: Epoch 613 
2025-12-17 02:32:25.197386: Current learning rate: 0.00426 
2025-12-17 02:34:43.079106: train_loss -0.8472 
2025-12-17 02:34:43.079106: val_loss -0.8751 
2025-12-17 02:34:43.083111: Pseudo dice [0.9283, 0.9598, 0.9294] 
2025-12-17 02:34:43.087115: Epoch time: 137.9 s 
2025-12-17 02:34:43.839330:  
2025-12-17 02:34:43.839330: Epoch 614 
2025-12-17 02:34:43.855251: Current learning rate: 0.00425 
2025-12-17 02:37:01.801078: train_loss -0.8421 
2025-12-17 02:37:01.801078: val_loss -0.8588 
2025-12-17 02:37:01.801078: Pseudo dice [0.9169, 0.954, 0.9267] 
2025-12-17 02:37:01.801078: Epoch time: 137.96 s 
2025-12-17 02:37:02.437081:  
2025-12-17 02:37:02.452997: Epoch 615 
2025-12-17 02:37:02.452997: Current learning rate: 0.00424 
2025-12-17 02:39:20.410561: train_loss -0.8516 
2025-12-17 02:39:20.410561: val_loss -0.8697 
2025-12-17 02:39:20.418309: Pseudo dice [0.9231, 0.9533, 0.9315] 
2025-12-17 02:39:20.424317: Epoch time: 137.97 s 
2025-12-17 02:39:21.080973:  
2025-12-17 02:39:21.080973: Epoch 616 
2025-12-17 02:39:21.085032: Current learning rate: 0.00423 
2025-12-17 02:41:39.008240: train_loss -0.8516 
2025-12-17 02:41:39.008240: val_loss -0.8737 
2025-12-17 02:41:39.013744: Pseudo dice [0.9272, 0.9556, 0.9301] 
2025-12-17 02:41:39.017748: Epoch time: 137.93 s 
2025-12-17 02:41:39.779552:  
2025-12-17 02:41:39.795216: Epoch 617 
2025-12-17 02:41:39.795216: Current learning rate: 0.00422 
2025-12-17 02:43:57.815466: train_loss -0.853 
2025-12-17 02:43:57.815466: val_loss -0.8696 
2025-12-17 02:43:57.815466: Pseudo dice [0.9207, 0.9522, 0.9413] 
2025-12-17 02:43:57.823918: Epoch time: 138.04 s 
2025-12-17 02:43:58.657731:  
2025-12-17 02:43:58.657731: Epoch 618 
2025-12-17 02:43:58.673654: Current learning rate: 0.00421 
2025-12-17 02:46:16.546140: train_loss -0.85 
2025-12-17 02:46:16.546140: val_loss -0.8784 
2025-12-17 02:46:16.562124: Pseudo dice [0.9285, 0.9588, 0.9347] 
2025-12-17 02:46:16.562124: Epoch time: 137.89 s 
2025-12-17 02:46:17.214615:  
2025-12-17 02:46:17.214615: Epoch 619 
2025-12-17 02:46:17.214615: Current learning rate: 0.0042 
2025-12-17 02:48:35.072469: train_loss -0.8521 
2025-12-17 02:48:35.074470: val_loss -0.8774 
2025-12-17 02:48:35.078474: Pseudo dice [0.9305, 0.9581, 0.9353] 
2025-12-17 02:48:35.082405: Epoch time: 137.86 s 
2025-12-17 02:48:35.848099:  
2025-12-17 02:48:35.848099: Epoch 620 
2025-12-17 02:48:35.863852: Current learning rate: 0.00419 
2025-12-17 02:50:53.855551: train_loss -0.8547 
2025-12-17 02:50:53.857553: val_loss -0.873 
2025-12-17 02:50:53.863560: Pseudo dice [0.9222, 0.9527, 0.9411] 
2025-12-17 02:50:53.867564: Epoch time: 138.01 s 
2025-12-17 02:50:54.527857:  
2025-12-17 02:50:54.527857: Epoch 621 
2025-12-17 02:50:54.527857: Current learning rate: 0.00418 
2025-12-17 02:53:12.615321: train_loss -0.8524 
2025-12-17 02:53:12.615321: val_loss -0.8803 
2025-12-17 02:53:12.620670: Pseudo dice [0.9334, 0.9624, 0.933] 
2025-12-17 02:53:12.624674: Epoch time: 138.09 s 
2025-12-17 02:53:13.327668:  
2025-12-17 02:53:13.327668: Epoch 622 
2025-12-17 02:53:13.327668: Current learning rate: 0.00417 
2025-12-17 02:55:31.358751: train_loss -0.8537 
2025-12-17 02:55:31.360754: val_loss -0.8608 
2025-12-17 02:55:31.364366: Pseudo dice [0.9186, 0.949, 0.922] 
2025-12-17 02:55:31.368370: Epoch time: 138.03 s 
2025-12-17 02:55:32.134923:  
2025-12-17 02:55:32.134923: Epoch 623 
2025-12-17 02:55:32.134923: Current learning rate: 0.00416 
2025-12-17 02:57:50.079661: train_loss -0.8509 
2025-12-17 02:57:50.079661: val_loss -0.8663 
2025-12-17 02:57:50.079661: Pseudo dice [0.9178, 0.9546, 0.9315] 
2025-12-17 02:57:50.079661: Epoch time: 137.94 s 
2025-12-17 02:57:50.935086:  
2025-12-17 02:57:50.935086: Epoch 624 
2025-12-17 02:57:50.935086: Current learning rate: 0.00415 
2025-12-17 03:00:08.835399: train_loss -0.8514 
2025-12-17 03:00:08.837402: val_loss -0.871 
2025-12-17 03:00:08.841405: Pseudo dice [0.9185, 0.9574, 0.9454] 
2025-12-17 03:00:08.845409: Epoch time: 137.9 s 
2025-12-17 03:00:09.484222:  
2025-12-17 03:00:09.484222: Epoch 625 
2025-12-17 03:00:09.484222: Current learning rate: 0.00414 
2025-12-17 03:02:27.579864: train_loss -0.853 
2025-12-17 03:02:27.579864: val_loss -0.8709 
2025-12-17 03:02:27.583868: Pseudo dice [0.9255, 0.9551, 0.9378] 
2025-12-17 03:02:27.587677: Epoch time: 138.1 s 
2025-12-17 03:02:28.227738:  
2025-12-17 03:02:28.227738: Epoch 626 
2025-12-17 03:02:28.243536: Current learning rate: 0.00413 
2025-12-17 03:04:46.120181: train_loss -0.8523 
2025-12-17 03:04:46.120181: val_loss -0.8705 
2025-12-17 03:04:46.120181: Pseudo dice [0.9212, 0.955, 0.9435] 
2025-12-17 03:04:46.120181: Epoch time: 137.89 s 
2025-12-17 03:04:46.757991:  
2025-12-17 03:04:46.759732: Epoch 627 
2025-12-17 03:04:46.763662: Current learning rate: 0.00412 
2025-12-17 03:07:04.899273: train_loss -0.8487 
2025-12-17 03:07:04.899273: val_loss -0.8665 
2025-12-17 03:07:04.905017: Pseudo dice [0.9244, 0.9514, 0.929] 
2025-12-17 03:07:04.909022: Epoch time: 138.14 s 
2025-12-17 03:07:05.558505:  
2025-12-17 03:07:05.558505: Epoch 628 
2025-12-17 03:07:05.560509: Current learning rate: 0.00411 
2025-12-17 03:09:23.811800: train_loss -0.8486 
2025-12-17 03:09:23.811800: val_loss -0.8783 
2025-12-17 03:09:23.811800: Pseudo dice [0.9289, 0.9554, 0.9401] 
2025-12-17 03:09:23.811800: Epoch time: 138.25 s 
2025-12-17 03:09:24.473881:  
2025-12-17 03:09:24.473881: Epoch 629 
2025-12-17 03:09:24.473881: Current learning rate: 0.0041 
2025-12-17 03:11:42.520255: train_loss -0.8531 
2025-12-17 03:11:42.520255: val_loss -0.8683 
2025-12-17 03:11:42.520255: Pseudo dice [0.9233, 0.9565, 0.9332] 
2025-12-17 03:11:42.520255: Epoch time: 138.05 s 
2025-12-17 03:11:43.169255:  
2025-12-17 03:11:43.169255: Epoch 630 
2025-12-17 03:11:43.171257: Current learning rate: 0.00409 
2025-12-17 03:14:01.052418: train_loss -0.852 
2025-12-17 03:14:01.052418: val_loss -0.8652 
2025-12-17 03:14:01.056160: Pseudo dice [0.9207, 0.9517, 0.9343] 
2025-12-17 03:14:01.062721: Epoch time: 137.88 s 
2025-12-17 03:14:01.881317:  
2025-12-17 03:14:01.881317: Epoch 631 
2025-12-17 03:14:01.881317: Current learning rate: 0.00408 
2025-12-17 03:16:19.824701: train_loss -0.8511 
2025-12-17 03:16:19.824701: val_loss -0.869 
2025-12-17 03:16:19.830709: Pseudo dice [0.9285, 0.9549, 0.9291] 
2025-12-17 03:16:19.836291: Epoch time: 137.94 s 
2025-12-17 03:16:20.463186:  
2025-12-17 03:16:20.463186: Epoch 632 
2025-12-17 03:16:20.478975: Current learning rate: 0.00407 
2025-12-17 03:18:38.313350: train_loss -0.8571 
2025-12-17 03:18:38.313350: val_loss -0.8728 
2025-12-17 03:18:38.319356: Pseudo dice [0.9258, 0.9558, 0.935] 
2025-12-17 03:18:38.323359: Epoch time: 137.85 s 
2025-12-17 03:18:38.953073:  
2025-12-17 03:18:38.953073: Epoch 633 
2025-12-17 03:18:38.968830: Current learning rate: 0.00406 
2025-12-17 03:20:57.095095: train_loss -0.8497 
2025-12-17 03:20:57.095095: val_loss -0.8729 
2025-12-17 03:20:57.111147: Pseudo dice [0.9265, 0.9581, 0.9391] 
2025-12-17 03:20:57.111147: Epoch time: 138.14 s 
2025-12-17 03:20:57.808913:  
2025-12-17 03:20:57.808913: Epoch 634 
2025-12-17 03:20:57.808913: Current learning rate: 0.00405 
2025-12-17 03:23:15.658015: train_loss -0.8579 
2025-12-17 03:23:15.658015: val_loss -0.8743 
2025-12-17 03:23:15.664994: Pseudo dice [0.9254, 0.9577, 0.9367] 
2025-12-17 03:23:15.671000: Epoch time: 137.85 s 
2025-12-17 03:23:16.317063:  
2025-12-17 03:23:16.319066: Epoch 635 
2025-12-17 03:23:16.319066: Current learning rate: 0.00404 
2025-12-17 03:25:34.331852: train_loss -0.8518 
2025-12-17 03:25:34.331852: val_loss -0.8746 
2025-12-17 03:25:34.338446: Pseudo dice [0.9281, 0.9594, 0.9314] 
2025-12-17 03:25:34.338446: Epoch time: 138.01 s 
2025-12-17 03:25:34.979499:  
2025-12-17 03:25:34.979499: Epoch 636 
2025-12-17 03:25:34.983188: Current learning rate: 0.00403 
2025-12-17 03:27:52.914060: train_loss -0.8505 
2025-12-17 03:27:52.914060: val_loss -0.87 
2025-12-17 03:27:52.920070: Pseudo dice [0.925, 0.9546, 0.9401] 
2025-12-17 03:27:52.924074: Epoch time: 137.94 s 
2025-12-17 03:27:53.772425:  
2025-12-17 03:27:53.772425: Epoch 637 
2025-12-17 03:27:53.772425: Current learning rate: 0.00402 
2025-12-17 03:30:11.652548: train_loss -0.8507 
2025-12-17 03:30:11.652548: val_loss -0.8643 
2025-12-17 03:30:11.658554: Pseudo dice [0.9214, 0.9528, 0.9256] 
2025-12-17 03:30:11.658554: Epoch time: 137.88 s 
2025-12-17 03:30:12.308270:  
2025-12-17 03:30:12.308270: Epoch 638 
2025-12-17 03:30:12.308270: Current learning rate: 0.00401 
2025-12-17 03:32:30.422300: train_loss -0.853 
2025-12-17 03:32:30.424304: val_loss -0.8778 
2025-12-17 03:32:30.430311: Pseudo dice [0.9326, 0.9617, 0.9287] 
2025-12-17 03:32:30.432312: Epoch time: 138.12 s 
2025-12-17 03:32:31.079193:  
2025-12-17 03:32:31.079193: Epoch 639 
2025-12-17 03:32:31.079193: Current learning rate: 0.004 
2025-12-17 03:34:48.964612: train_loss -0.8583 
2025-12-17 03:34:48.964612: val_loss -0.8757 
2025-12-17 03:34:48.972277: Pseudo dice [0.9254, 0.9582, 0.9396] 
2025-12-17 03:34:48.978283: Epoch time: 137.89 s 
2025-12-17 03:34:49.795814:  
2025-12-17 03:34:49.795814: Epoch 640 
2025-12-17 03:34:49.795814: Current learning rate: 0.00399 
2025-12-17 03:37:07.583748: train_loss -0.8583 
2025-12-17 03:37:07.583748: val_loss -0.87 
2025-12-17 03:37:07.589136: Pseudo dice [0.924, 0.9555, 0.935] 
2025-12-17 03:37:07.594757: Epoch time: 137.79 s 
2025-12-17 03:37:08.239693:  
2025-12-17 03:37:08.239693: Epoch 641 
2025-12-17 03:37:08.239693: Current learning rate: 0.00398 
2025-12-17 03:39:26.101383: train_loss -0.8523 
2025-12-17 03:39:26.101383: val_loss -0.8733 
2025-12-17 03:39:26.107128: Pseudo dice [0.9274, 0.957, 0.9339] 
2025-12-17 03:39:26.111132: Epoch time: 137.86 s 
2025-12-17 03:39:26.750716:  
2025-12-17 03:39:26.750716: Epoch 642 
2025-12-17 03:39:26.766809: Current learning rate: 0.00397 
2025-12-17 03:41:44.871837: train_loss -0.8586 
2025-12-17 03:41:44.871837: val_loss -0.8697 
2025-12-17 03:41:44.885685: Pseudo dice [0.9273, 0.9547, 0.9313] 
2025-12-17 03:41:44.885685: Epoch time: 138.12 s 
2025-12-17 03:41:45.865872:  
2025-12-17 03:41:45.865872: Epoch 643 
2025-12-17 03:41:45.883504: Current learning rate: 0.00396 
2025-12-17 03:44:03.873284: train_loss -0.8576 
2025-12-17 03:44:03.873284: val_loss -0.8669 
2025-12-17 03:44:03.880345: Pseudo dice [0.9274, 0.9533, 0.9229] 
2025-12-17 03:44:03.886351: Epoch time: 138.01 s 
2025-12-17 03:44:04.522755:  
2025-12-17 03:44:04.522755: Epoch 644 
2025-12-17 03:44:04.522755: Current learning rate: 0.00395 
2025-12-17 03:46:22.576723: train_loss -0.8516 
2025-12-17 03:46:22.579197: val_loss -0.8729 
2025-12-17 03:46:22.584226: Pseudo dice [0.9264, 0.9553, 0.933] 
2025-12-17 03:46:22.588231: Epoch time: 138.05 s 
2025-12-17 03:46:23.242818:  
2025-12-17 03:46:23.242818: Epoch 645 
2025-12-17 03:46:23.242818: Current learning rate: 0.00394 
2025-12-17 03:48:41.294638: train_loss -0.8532 
2025-12-17 03:48:41.294638: val_loss -0.8755 
2025-12-17 03:48:41.302386: Pseudo dice [0.9257, 0.9594, 0.9371] 
2025-12-17 03:48:41.308393: Epoch time: 138.05 s 
2025-12-17 03:48:42.066164:  
2025-12-17 03:48:42.066164: Epoch 646 
2025-12-17 03:48:42.072140: Current learning rate: 0.00393 
2025-12-17 03:51:00.008419: train_loss -0.8599 
2025-12-17 03:51:00.010220: val_loss -0.8676 
2025-12-17 03:51:00.014225: Pseudo dice [0.9214, 0.9549, 0.9309] 
2025-12-17 03:51:00.020232: Epoch time: 137.94 s 
2025-12-17 03:51:00.666509:  
2025-12-17 03:51:00.666509: Epoch 647 
2025-12-17 03:51:00.666509: Current learning rate: 0.00392 
2025-12-17 03:53:18.594612: train_loss -0.8459 
2025-12-17 03:53:18.594612: val_loss -0.8706 
2025-12-17 03:53:18.613749: Pseudo dice [0.9238, 0.9565, 0.9377] 
2025-12-17 03:53:18.617752: Epoch time: 137.93 s 
2025-12-17 03:53:19.260684:  
2025-12-17 03:53:19.260684: Epoch 648 
2025-12-17 03:53:19.260684: Current learning rate: 0.00391 
2025-12-17 03:55:37.302595: train_loss -0.8529 
2025-12-17 03:55:37.304597: val_loss -0.8629 
2025-12-17 03:55:37.308601: Pseudo dice [0.9194, 0.9526, 0.9301] 
2025-12-17 03:55:37.314607: Epoch time: 138.04 s 
2025-12-17 03:55:38.060156:  
2025-12-17 03:55:38.060156: Epoch 649 
2025-12-17 03:55:38.075992: Current learning rate: 0.0039 
2025-12-17 03:57:56.055606: train_loss -0.851 
2025-12-17 03:57:56.071524: val_loss -0.8673 
2025-12-17 03:57:56.071524: Pseudo dice [0.9243, 0.9559, 0.9315] 
2025-12-17 03:57:56.071524: Epoch time: 138.0 s 
2025-12-17 03:57:57.197014:  
2025-12-17 03:57:57.197014: Epoch 650 
2025-12-17 03:57:57.197014: Current learning rate: 0.00389 
2025-12-17 04:00:15.206191: train_loss -0.8562 
2025-12-17 04:00:15.206191: val_loss -0.8768 
2025-12-17 04:00:15.210980: Pseudo dice [0.9304, 0.9591, 0.9333] 
2025-12-17 04:00:15.216987: Epoch time: 138.01 s 
2025-12-17 04:00:15.871228:  
2025-12-17 04:00:15.871228: Epoch 651 
2025-12-17 04:00:15.871228: Current learning rate: 0.00388 
2025-12-17 04:02:33.878583: train_loss -0.8481 
2025-12-17 04:02:33.880585: val_loss -0.8645 
2025-12-17 04:02:33.884588: Pseudo dice [0.9184, 0.9474, 0.9346] 
2025-12-17 04:02:33.890085: Epoch time: 138.01 s 
2025-12-17 04:02:34.722716:  
2025-12-17 04:02:34.722716: Epoch 652 
2025-12-17 04:02:34.728725: Current learning rate: 0.00387 
2025-12-17 04:04:52.815162: train_loss -0.8502 
2025-12-17 04:04:52.817165: val_loss -0.8698 
2025-12-17 04:04:52.817165: Pseudo dice [0.9231, 0.953, 0.9401] 
2025-12-17 04:04:52.817165: Epoch time: 138.09 s 
2025-12-17 04:04:53.459472:  
2025-12-17 04:04:53.459472: Epoch 653 
2025-12-17 04:04:53.463734: Current learning rate: 0.00386 
2025-12-17 04:07:11.614798: train_loss -0.8552 
2025-12-17 04:07:11.614798: val_loss -0.8742 
2025-12-17 04:07:11.630788: Pseudo dice [0.925, 0.9535, 0.9424] 
2025-12-17 04:07:11.632791: Epoch time: 138.16 s 
2025-12-17 04:07:12.283854:  
2025-12-17 04:07:12.283854: Epoch 654 
2025-12-17 04:07:12.283854: Current learning rate: 0.00385 
2025-12-17 04:09:30.682436: train_loss -0.8559 
2025-12-17 04:09:30.684438: val_loss -0.8739 
2025-12-17 04:09:30.690444: Pseudo dice [0.9253, 0.9582, 0.9291] 
2025-12-17 04:09:30.696451: Epoch time: 138.4 s 
2025-12-17 04:09:31.460246:  
2025-12-17 04:09:31.462248: Epoch 655 
2025-12-17 04:09:31.462248: Current learning rate: 0.00384 
2025-12-17 04:11:49.392292: train_loss -0.8577 
2025-12-17 04:11:49.394294: val_loss -0.8744 
2025-12-17 04:11:49.398298: Pseudo dice [0.9212, 0.9553, 0.9381] 
2025-12-17 04:11:49.404304: Epoch time: 137.93 s 
2025-12-17 04:11:50.213223:  
2025-12-17 04:11:50.213223: Epoch 656 
2025-12-17 04:11:50.213223: Current learning rate: 0.00383 
2025-12-17 04:14:08.270751: train_loss -0.8507 
2025-12-17 04:14:08.272710: val_loss -0.8748 
2025-12-17 04:14:08.278716: Pseudo dice [0.9259, 0.9574, 0.9362] 
2025-12-17 04:14:08.284696: Epoch time: 138.06 s 
2025-12-17 04:14:08.932776:  
2025-12-17 04:14:08.932776: Epoch 657 
2025-12-17 04:14:08.934779: Current learning rate: 0.00382 
2025-12-17 04:16:27.044936: train_loss -0.8482 
2025-12-17 04:16:27.044936: val_loss -0.8737 
2025-12-17 04:16:27.052945: Pseudo dice [0.9272, 0.9537, 0.9317] 
2025-12-17 04:16:27.058292: Epoch time: 138.11 s 
2025-12-17 04:16:27.851237:  
2025-12-17 04:16:27.851237: Epoch 658 
2025-12-17 04:16:27.867079: Current learning rate: 0.00381 
2025-12-17 04:18:45.720022: train_loss -0.8494 
2025-12-17 04:18:45.720022: val_loss -0.8778 
2025-12-17 04:18:45.726029: Pseudo dice [0.9291, 0.9606, 0.9303] 
2025-12-17 04:18:45.729034: Epoch time: 137.87 s 
2025-12-17 04:18:46.377110:  
2025-12-17 04:18:46.377110: Epoch 659 
2025-12-17 04:18:46.377110: Current learning rate: 0.0038 
2025-12-17 04:21:04.349470: train_loss -0.8529 
2025-12-17 04:21:04.349470: val_loss -0.8784 
2025-12-17 04:21:04.353966: Pseudo dice [0.9332, 0.9596, 0.9375] 
2025-12-17 04:21:04.359974: Epoch time: 137.99 s 
2025-12-17 04:21:05.001913:  
2025-12-17 04:21:05.001913: Epoch 660 
2025-12-17 04:21:05.001913: Current learning rate: 0.00379 
2025-12-17 04:23:22.881802: train_loss -0.8598 
2025-12-17 04:23:22.881802: val_loss -0.8723 
2025-12-17 04:23:22.891047: Pseudo dice [0.9256, 0.9589, 0.9367] 
2025-12-17 04:23:22.895051: Epoch time: 137.88 s 
2025-12-17 04:23:23.528756:  
2025-12-17 04:23:23.528756: Epoch 661 
2025-12-17 04:23:23.528756: Current learning rate: 0.00378 
2025-12-17 04:25:41.615592: train_loss -0.8541 
2025-12-17 04:25:41.615592: val_loss -0.8712 
2025-12-17 04:25:41.631411: Pseudo dice [0.9238, 0.9541, 0.9393] 
2025-12-17 04:25:41.633698: Epoch time: 138.09 s 
2025-12-17 04:25:42.451535:  
2025-12-17 04:25:42.451535: Epoch 662 
2025-12-17 04:25:42.451535: Current learning rate: 0.00377 
2025-12-17 04:28:00.464739: train_loss -0.8495 
2025-12-17 04:28:00.464739: val_loss -0.8688 
2025-12-17 04:28:00.471600: Pseudo dice [0.9217, 0.9536, 0.9281] 
2025-12-17 04:28:00.475605: Epoch time: 138.03 s 
2025-12-17 04:28:01.154447:  
2025-12-17 04:28:01.154447: Epoch 663 
2025-12-17 04:28:01.154447: Current learning rate: 0.00376 
2025-12-17 04:30:19.153574: train_loss -0.8517 
2025-12-17 04:30:19.153574: val_loss -0.8704 
2025-12-17 04:30:19.161240: Pseudo dice [0.9202, 0.953, 0.9412] 
2025-12-17 04:30:19.167246: Epoch time: 138.01 s 
2025-12-17 04:30:19.817813:  
2025-12-17 04:30:19.817813: Epoch 664 
2025-12-17 04:30:19.817813: Current learning rate: 0.00375 
2025-12-17 04:32:37.799442: train_loss -0.8534 
2025-12-17 04:32:37.799442: val_loss -0.8773 
2025-12-17 04:32:37.806264: Pseudo dice [0.9277, 0.96, 0.9333] 
2025-12-17 04:32:37.808266: Epoch time: 137.98 s 
2025-12-17 04:32:38.455046:  
2025-12-17 04:32:38.455046: Epoch 665 
2025-12-17 04:32:38.461075: Current learning rate: 0.00374 
2025-12-17 04:34:56.628524: train_loss -0.8513 
2025-12-17 04:34:56.630530: val_loss -0.8783 
2025-12-17 04:34:56.638188: Pseudo dice [0.9319, 0.9586, 0.9364] 
2025-12-17 04:34:56.644195: Epoch time: 138.17 s 
2025-12-17 04:34:56.647937: Yayy! New best EMA pseudo Dice: 0.939 
2025-12-17 04:34:57.581508:  
2025-12-17 04:34:57.581508: Epoch 666 
2025-12-17 04:34:57.581508: Current learning rate: 0.00373 
2025-12-17 04:37:15.670704: train_loss -0.8567 
2025-12-17 04:37:15.670704: val_loss -0.8723 
2025-12-17 04:37:15.678051: Pseudo dice [0.9217, 0.9549, 0.9371] 
2025-12-17 04:37:15.682056: Epoch time: 138.09 s 
2025-12-17 04:37:16.326495:  
2025-12-17 04:37:16.326495: Epoch 667 
2025-12-17 04:37:16.326495: Current learning rate: 0.00372 
2025-12-17 04:39:34.240799: train_loss -0.855 
2025-12-17 04:39:34.256736: val_loss -0.8806 
2025-12-17 04:39:34.260236: Pseudo dice [0.9282, 0.9594, 0.9388] 
2025-12-17 04:39:34.266243: Epoch time: 137.92 s 
2025-12-17 04:39:34.270247: Yayy! New best EMA pseudo Dice: 0.9392 
2025-12-17 04:39:35.372937:  
2025-12-17 04:39:35.372937: Epoch 668 
2025-12-17 04:39:35.372937: Current learning rate: 0.00371 
2025-12-17 04:41:53.503549: train_loss -0.8542 
2025-12-17 04:41:53.505552: val_loss -0.8766 
2025-12-17 04:41:53.509557: Pseudo dice [0.9269, 0.957, 0.9399] 
2025-12-17 04:41:53.515055: Epoch time: 138.13 s 
2025-12-17 04:41:53.519059: Yayy! New best EMA pseudo Dice: 0.9394 
2025-12-17 04:41:54.468998:  
2025-12-17 04:41:54.468998: Epoch 669 
2025-12-17 04:41:54.484892: Current learning rate: 0.0037 
2025-12-17 04:44:12.326876: train_loss -0.8583 
2025-12-17 04:44:12.326876: val_loss -0.8735 
2025-12-17 04:44:12.332621: Pseudo dice [0.9268, 0.9552, 0.9271] 
2025-12-17 04:44:12.339075: Epoch time: 137.86 s 
2025-12-17 04:44:12.991088:  
2025-12-17 04:44:12.991088: Epoch 670 
2025-12-17 04:44:12.993709: Current learning rate: 0.00369 
2025-12-17 04:46:30.944799: train_loss -0.8558 
2025-12-17 04:46:30.944799: val_loss -0.8771 
2025-12-17 04:46:30.944799: Pseudo dice [0.9285, 0.9598, 0.9309] 
2025-12-17 04:46:30.951228: Epoch time: 137.96 s 
2025-12-17 04:46:31.594728:  
2025-12-17 04:46:31.594728: Epoch 671 
2025-12-17 04:46:31.594728: Current learning rate: 0.00368 
2025-12-17 04:48:49.588668: train_loss -0.8497 
2025-12-17 04:48:49.588668: val_loss -0.8712 
2025-12-17 04:48:49.608714: Pseudo dice [0.9243, 0.9507, 0.9363] 
2025-12-17 04:48:49.612718: Epoch time: 137.99 s 
2025-12-17 04:48:50.316697:  
2025-12-17 04:48:50.316697: Epoch 672 
2025-12-17 04:48:50.322539: Current learning rate: 0.00367 
2025-12-17 04:51:08.435888: train_loss -0.8514 
2025-12-17 04:51:08.435888: val_loss -0.8738 
2025-12-17 04:51:08.443194: Pseudo dice [0.9304, 0.9571, 0.9254] 
2025-12-17 04:51:08.447198: Epoch time: 138.13 s 
2025-12-17 04:51:09.102788:  
2025-12-17 04:51:09.102788: Epoch 673 
2025-12-17 04:51:09.102788: Current learning rate: 0.00366 
2025-12-17 04:53:27.033101: train_loss -0.8526 
2025-12-17 04:53:27.033101: val_loss -0.8588 
2025-12-17 04:53:27.041108: Pseudo dice [0.9178, 0.9513, 0.926] 
2025-12-17 04:53:27.046853: Epoch time: 137.93 s 
2025-12-17 04:53:27.901905:  
2025-12-17 04:53:27.901905: Epoch 674 
2025-12-17 04:53:27.901905: Current learning rate: 0.00365 
2025-12-17 04:55:46.028977: train_loss -0.8513 
2025-12-17 04:55:46.028977: val_loss -0.8696 
2025-12-17 04:55:46.034983: Pseudo dice [0.9213, 0.958, 0.9369] 
2025-12-17 04:55:46.041296: Epoch time: 138.13 s 
2025-12-17 04:55:46.678134:  
2025-12-17 04:55:46.678134: Epoch 675 
2025-12-17 04:55:46.694057: Current learning rate: 0.00364 
2025-12-17 04:58:04.751680: train_loss -0.8504 
2025-12-17 04:58:04.751680: val_loss -0.8794 
2025-12-17 04:58:04.757613: Pseudo dice [0.9298, 0.9584, 0.9391] 
2025-12-17 04:58:04.761617: Epoch time: 138.07 s 
2025-12-17 04:58:05.412941:  
2025-12-17 04:58:05.412941: Epoch 676 
2025-12-17 04:58:05.428847: Current learning rate: 0.00363 
2025-12-17 05:00:23.350408: train_loss -0.8494 
2025-12-17 05:00:23.350408: val_loss -0.8726 
2025-12-17 05:00:23.369913: Pseudo dice [0.9261, 0.9585, 0.9389] 
2025-12-17 05:00:23.373917: Epoch time: 137.94 s 
2025-12-17 05:00:24.023338:  
2025-12-17 05:00:24.023338: Epoch 677 
2025-12-17 05:00:24.029054: Current learning rate: 0.00362 
2025-12-17 05:02:42.081515: train_loss -0.8535 
2025-12-17 05:02:42.081515: val_loss -0.8765 
2025-12-17 05:02:42.088219: Pseudo dice [0.9306, 0.9582, 0.9352] 
2025-12-17 05:02:42.091827: Epoch time: 138.06 s 
2025-12-17 05:02:42.831032:  
2025-12-17 05:02:42.833035: Epoch 678 
2025-12-17 05:02:42.833035: Current learning rate: 0.00361 
2025-12-17 05:05:00.777138: train_loss -0.8584 
2025-12-17 05:05:00.777138: val_loss -0.8683 
2025-12-17 05:05:00.777138: Pseudo dice [0.9241, 0.9558, 0.9306] 
2025-12-17 05:05:00.786640: Epoch time: 137.95 s 
2025-12-17 05:05:01.442411:  
2025-12-17 05:05:01.444413: Epoch 679 
2025-12-17 05:05:01.444413: Current learning rate: 0.0036 
2025-12-17 05:07:19.314924: train_loss -0.859 
2025-12-17 05:07:19.316427: val_loss -0.8833 
2025-12-17 05:07:19.321935: Pseudo dice [0.9297, 0.9588, 0.9462] 
2025-12-17 05:07:19.325939: Epoch time: 137.87 s 
2025-12-17 05:07:19.329944: Yayy! New best EMA pseudo Dice: 0.9395 
2025-12-17 05:07:20.446551:  
2025-12-17 05:07:20.446551: Epoch 680 
2025-12-17 05:07:20.446551: Current learning rate: 0.00359 
2025-12-17 05:09:38.755850: train_loss -0.859 
2025-12-17 05:09:38.755850: val_loss -0.8691 
2025-12-17 05:09:38.759768: Pseudo dice [0.9256, 0.9535, 0.9329] 
2025-12-17 05:09:38.767371: Epoch time: 138.31 s 
2025-12-17 05:09:39.419207:  
2025-12-17 05:09:39.419207: Epoch 681 
2025-12-17 05:09:39.419207: Current learning rate: 0.00358 
2025-12-17 05:11:57.747702: train_loss -0.8526 
2025-12-17 05:11:57.749704: val_loss -0.8863 
2025-12-17 05:11:57.754370: Pseudo dice [0.9279, 0.9594, 0.9457] 
2025-12-17 05:11:57.758374: Epoch time: 138.33 s 
2025-12-17 05:11:57.764379: Yayy! New best EMA pseudo Dice: 0.9398 
2025-12-17 05:11:58.688704:  
2025-12-17 05:11:58.688704: Epoch 682 
2025-12-17 05:11:58.688704: Current learning rate: 0.00357 
2025-12-17 05:14:16.787184: train_loss -0.8512 
2025-12-17 05:14:16.803022: val_loss -0.8693 
2025-12-17 05:14:16.803022: Pseudo dice [0.9209, 0.9542, 0.9293] 
2025-12-17 05:14:16.803022: Epoch time: 138.1 s 
2025-12-17 05:14:17.459116:  
2025-12-17 05:14:17.459116: Epoch 683 
2025-12-17 05:14:17.459116: Current learning rate: 0.00356 
2025-12-17 05:16:35.440996: train_loss -0.8489 
2025-12-17 05:16:35.441997: val_loss -0.8712 
2025-12-17 05:16:35.447511: Pseudo dice [0.9248, 0.9583, 0.9307] 
2025-12-17 05:16:35.451516: Epoch time: 137.98 s 
2025-12-17 05:16:36.107935:  
2025-12-17 05:16:36.107935: Epoch 684 
2025-12-17 05:16:36.107935: Current learning rate: 0.00355 
2025-12-17 05:18:54.115041: train_loss -0.851 
2025-12-17 05:18:54.115041: val_loss -0.8808 
2025-12-17 05:18:54.115041: Pseudo dice [0.9263, 0.9586, 0.942] 
2025-12-17 05:18:54.130728: Epoch time: 138.01 s 
2025-12-17 05:18:54.767511:  
2025-12-17 05:18:54.767511: Epoch 685 
2025-12-17 05:18:54.767511: Current learning rate: 0.00354 
2025-12-17 05:21:12.860991: train_loss -0.8605 
2025-12-17 05:21:12.860991: val_loss -0.8732 
2025-12-17 05:21:12.863457: Pseudo dice [0.9248, 0.9569, 0.9372] 
2025-12-17 05:21:12.863457: Epoch time: 138.09 s 
2025-12-17 05:21:13.671869:  
2025-12-17 05:21:13.671869: Epoch 686 
2025-12-17 05:21:13.687633: Current learning rate: 0.00353 
2025-12-17 05:23:31.576338: train_loss -0.8557 
2025-12-17 05:23:31.576338: val_loss -0.8775 
2025-12-17 05:23:31.586239: Pseudo dice [0.9284, 0.9596, 0.9324] 
2025-12-17 05:23:31.591793: Epoch time: 137.9 s 
2025-12-17 05:23:32.353684:  
2025-12-17 05:23:32.353684: Epoch 687 
2025-12-17 05:23:32.353684: Current learning rate: 0.00352 
2025-12-17 05:25:50.124187: train_loss -0.8561 
2025-12-17 05:25:50.124187: val_loss -0.8764 
2025-12-17 05:25:50.128190: Pseudo dice [0.9336, 0.9618, 0.9272] 
2025-12-17 05:25:50.133492: Epoch time: 137.77 s 
2025-12-17 05:25:50.780940:  
2025-12-17 05:25:50.780940: Epoch 688 
2025-12-17 05:25:50.780940: Current learning rate: 0.00351 
2025-12-17 05:28:08.716059: train_loss -0.8561 
2025-12-17 05:28:08.716059: val_loss -0.8743 
2025-12-17 05:28:08.727305: Pseudo dice [0.9259, 0.9563, 0.9377] 
2025-12-17 05:28:08.733669: Epoch time: 137.94 s 
2025-12-17 05:28:09.381375:  
2025-12-17 05:28:09.381375: Epoch 689 
2025-12-17 05:28:09.381375: Current learning rate: 0.0035 
2025-12-17 05:30:27.341323: train_loss -0.8537 
2025-12-17 05:30:27.343327: val_loss -0.8632 
2025-12-17 05:30:27.349335: Pseudo dice [0.9193, 0.9519, 0.933] 
2025-12-17 05:30:27.357083: Epoch time: 137.96 s 
2025-12-17 05:30:28.144154:  
2025-12-17 05:30:28.144154: Epoch 690 
2025-12-17 05:30:28.150155: Current learning rate: 0.00349 
2025-12-17 05:32:46.054209: train_loss -0.8518 
2025-12-17 05:32:46.054209: val_loss -0.8801 
2025-12-17 05:32:46.061828: Pseudo dice [0.929, 0.9591, 0.9377] 
2025-12-17 05:32:46.061828: Epoch time: 137.91 s 
2025-12-17 05:32:46.720624:  
2025-12-17 05:32:46.720624: Epoch 691 
2025-12-17 05:32:46.720624: Current learning rate: 0.00348 
2025-12-17 05:35:04.677664: train_loss -0.86 
2025-12-17 05:35:04.677664: val_loss -0.8668 
2025-12-17 05:35:04.685412: Pseudo dice [0.9216, 0.947, 0.9392] 
2025-12-17 05:35:04.693219: Epoch time: 137.96 s 
2025-12-17 05:35:05.525225:  
2025-12-17 05:35:05.527050: Epoch 692 
2025-12-17 05:35:05.527050: Current learning rate: 0.00346 
2025-12-17 05:37:23.445695: train_loss -0.856 
2025-12-17 05:37:23.445695: val_loss -0.8726 
2025-12-17 05:37:23.445695: Pseudo dice [0.9271, 0.9561, 0.9361] 
2025-12-17 05:37:23.461688: Epoch time: 137.92 s 
2025-12-17 05:37:24.184757:  
2025-12-17 05:37:24.184757: Epoch 693 
2025-12-17 05:37:24.190731: Current learning rate: 0.00345 
2025-12-17 05:39:42.112182: train_loss -0.8541 
2025-12-17 05:39:42.114184: val_loss -0.877 
2025-12-17 05:39:42.120190: Pseudo dice [0.9258, 0.9602, 0.9372] 
2025-12-17 05:39:42.124194: Epoch time: 137.93 s 
2025-12-17 05:39:42.805880:  
2025-12-17 05:39:42.805880: Epoch 694 
2025-12-17 05:39:42.823402: Current learning rate: 0.00344 
2025-12-17 05:42:00.650708: train_loss -0.8559 
2025-12-17 05:42:00.650708: val_loss -0.8664 
2025-12-17 05:42:00.656085: Pseudo dice [0.9222, 0.9544, 0.9317] 
2025-12-17 05:42:00.662386: Epoch time: 137.84 s 
2025-12-17 05:42:01.308015:  
2025-12-17 05:42:01.308015: Epoch 695 
2025-12-17 05:42:01.324085: Current learning rate: 0.00343 
2025-12-17 05:44:19.315192: train_loss -0.857 
2025-12-17 05:44:19.315192: val_loss -0.8751 
2025-12-17 05:44:19.328669: Pseudo dice [0.9279, 0.9556, 0.9369] 
2025-12-17 05:44:19.332791: Epoch time: 138.01 s 
2025-12-17 05:44:20.010732:  
2025-12-17 05:44:20.010732: Epoch 696 
2025-12-17 05:44:20.020543: Current learning rate: 0.00342 
2025-12-17 05:46:38.069507: train_loss -0.8533 
2025-12-17 05:46:38.069507: val_loss -0.8734 
2025-12-17 05:46:38.085220: Pseudo dice [0.9246, 0.9561, 0.9339] 
2025-12-17 05:46:38.090166: Epoch time: 138.06 s 
2025-12-17 05:46:38.737815:  
2025-12-17 05:46:38.737815: Epoch 697 
2025-12-17 05:46:38.747971: Current learning rate: 0.00341 
2025-12-17 05:48:56.583882: train_loss -0.8513 
2025-12-17 05:48:56.583882: val_loss -0.882 
2025-12-17 05:48:56.583882: Pseudo dice [0.9346, 0.9608, 0.9306] 
2025-12-17 05:48:56.583882: Epoch time: 137.85 s 
2025-12-17 05:48:57.280315:  
2025-12-17 05:48:57.280315: Epoch 698 
2025-12-17 05:48:57.296031: Current learning rate: 0.0034 
2025-12-17 05:51:15.294213: train_loss -0.8569 
2025-12-17 05:51:15.294213: val_loss -0.8755 
2025-12-17 05:51:15.310019: Pseudo dice [0.9288, 0.9554, 0.9339] 
2025-12-17 05:51:15.317975: Epoch time: 138.01 s 
2025-12-17 05:51:16.150251:  
2025-12-17 05:51:16.150251: Epoch 699 
2025-12-17 05:51:16.155522: Current learning rate: 0.00339 
2025-12-17 05:53:34.221311: train_loss -0.8553 
2025-12-17 05:53:34.221311: val_loss -0.8845 
2025-12-17 05:53:34.228385: Pseudo dice [0.9327, 0.9643, 0.9372] 
2025-12-17 05:53:34.235207: Epoch time: 138.07 s 
2025-12-17 05:53:34.503101: Yayy! New best EMA pseudo Dice: 0.9399 
2025-12-17 05:53:35.431818:  
2025-12-17 05:53:35.431818: Epoch 700 
2025-12-17 05:53:35.435822: Current learning rate: 0.00338 
2025-12-17 05:55:53.562802: train_loss -0.8529 
2025-12-17 05:55:53.564806: val_loss -0.8753 
2025-12-17 05:55:53.568811: Pseudo dice [0.927, 0.9588, 0.9349] 
2025-12-17 05:55:53.572815: Epoch time: 138.13 s 
2025-12-17 05:55:53.578358: Yayy! New best EMA pseudo Dice: 0.9399 
2025-12-17 05:55:54.518657:  
2025-12-17 05:55:54.518657: Epoch 701 
2025-12-17 05:55:54.518657: Current learning rate: 0.00337 
2025-12-17 05:58:12.672543: train_loss -0.8554 
2025-12-17 05:58:12.672543: val_loss -0.874 
2025-12-17 05:58:12.688534: Pseudo dice [0.9255, 0.9558, 0.9317] 
2025-12-17 05:58:12.694089: Epoch time: 138.15 s 
2025-12-17 05:58:13.384972:  
2025-12-17 05:58:13.386974: Epoch 702 
2025-12-17 05:58:13.386974: Current learning rate: 0.00336 
2025-12-17 06:00:31.380780: train_loss -0.853 
2025-12-17 06:00:31.380780: val_loss -0.8813 
2025-12-17 06:00:31.391770: Pseudo dice [0.931, 0.9609, 0.9355] 
2025-12-17 06:00:31.395774: Epoch time: 138.0 s 
2025-12-17 06:00:31.396776: Yayy! New best EMA pseudo Dice: 0.94 
2025-12-17 06:00:32.344404:  
2025-12-17 06:00:32.344404: Epoch 703 
2025-12-17 06:00:32.344404: Current learning rate: 0.00335 
2025-12-17 06:02:50.382591: train_loss -0.8513 
2025-12-17 06:02:50.384593: val_loss -0.8676 
2025-12-17 06:02:50.396618: Pseudo dice [0.9237, 0.954, 0.9301] 
2025-12-17 06:02:50.401256: Epoch time: 138.04 s 
2025-12-17 06:02:51.262614:  
2025-12-17 06:02:51.262614: Epoch 704 
2025-12-17 06:02:51.262614: Current learning rate: 0.00334 
2025-12-17 06:05:09.299294: train_loss -0.8546 
2025-12-17 06:05:09.301297: val_loss -0.8745 
2025-12-17 06:05:09.306894: Pseudo dice [0.9235, 0.9557, 0.9404] 
2025-12-17 06:05:09.312900: Epoch time: 138.04 s 
2025-12-17 06:05:09.960340:  
2025-12-17 06:05:09.963873: Epoch 705 
2025-12-17 06:05:09.963873: Current learning rate: 0.00333 
2025-12-17 06:07:28.076318: train_loss -0.852 
2025-12-17 06:07:28.078320: val_loss -0.8813 
2025-12-17 06:07:28.086067: Pseudo dice [0.9342, 0.9574, 0.9413] 
2025-12-17 06:07:28.094082: Epoch time: 138.12 s 
2025-12-17 06:07:28.099772: Yayy! New best EMA pseudo Dice: 0.9401 
2025-12-17 06:07:29.012239:  
2025-12-17 06:07:29.012239: Epoch 706 
2025-12-17 06:07:29.012239: Current learning rate: 0.00332 
2025-12-17 06:09:47.287621: train_loss -0.8565 
2025-12-17 06:09:47.287621: val_loss -0.8684 
2025-12-17 06:09:47.293626: Pseudo dice [0.9213, 0.9534, 0.9361] 
2025-12-17 06:09:47.297631: Epoch time: 138.28 s 
2025-12-17 06:09:47.982255:  
2025-12-17 06:09:47.982255: Epoch 707 
2025-12-17 06:09:47.982255: Current learning rate: 0.00331 
2025-12-17 06:12:06.206474: train_loss -0.852 
2025-12-17 06:12:06.206474: val_loss -0.8692 
2025-12-17 06:12:06.216225: Pseudo dice [0.9251, 0.9554, 0.9231] 
2025-12-17 06:12:06.220231: Epoch time: 138.22 s 
2025-12-17 06:12:06.881407:  
2025-12-17 06:12:06.881407: Epoch 708 
2025-12-17 06:12:06.881407: Current learning rate: 0.0033 
2025-12-17 06:14:24.832857: train_loss -0.8577 
2025-12-17 06:14:24.832857: val_loss -0.8646 
2025-12-17 06:14:24.846098: Pseudo dice [0.9173, 0.9526, 0.9351] 
2025-12-17 06:14:24.850102: Epoch time: 137.95 s 
2025-12-17 06:14:25.497864:  
2025-12-17 06:14:25.497864: Epoch 709 
2025-12-17 06:14:25.497864: Current learning rate: 0.00329 
2025-12-17 06:16:43.423959: train_loss -0.8545 
2025-12-17 06:16:43.423959: val_loss -0.8698 
2025-12-17 06:16:43.431705: Pseudo dice [0.9203, 0.9544, 0.9398] 
2025-12-17 06:16:43.438547: Epoch time: 137.93 s 
2025-12-17 06:16:44.296370:  
2025-12-17 06:16:44.296370: Epoch 710 
2025-12-17 06:16:44.312165: Current learning rate: 0.00328 
2025-12-17 06:19:02.273308: train_loss -0.8507 
2025-12-17 06:19:02.275311: val_loss -0.8484 
2025-12-17 06:19:02.275311: Pseudo dice [0.9128, 0.9478, 0.9252] 
2025-12-17 06:19:02.275311: Epoch time: 137.98 s 
2025-12-17 06:19:02.922105:  
2025-12-17 06:19:02.922105: Epoch 711 
2025-12-17 06:19:02.922105: Current learning rate: 0.00327 
2025-12-17 06:21:20.936497: train_loss -0.851 
2025-12-17 06:21:20.936497: val_loss -0.8786 
2025-12-17 06:21:20.942098: Pseudo dice [0.93, 0.959, 0.9326] 
2025-12-17 06:21:20.942098: Epoch time: 138.01 s 
2025-12-17 06:21:21.595405:  
2025-12-17 06:21:21.595405: Epoch 712 
2025-12-17 06:21:21.595405: Current learning rate: 0.00326 
2025-12-17 06:23:39.617251: train_loss -0.8542 
2025-12-17 06:23:39.617251: val_loss -0.877 
2025-12-17 06:23:39.625000: Pseudo dice [0.9293, 0.9574, 0.9335] 
2025-12-17 06:23:39.631007: Epoch time: 138.02 s 
2025-12-17 06:23:40.326941:  
2025-12-17 06:23:40.326941: Epoch 713 
2025-12-17 06:23:40.328943: Current learning rate: 0.00325 
2025-12-17 06:25:58.270658: train_loss -0.8541 
2025-12-17 06:25:58.270658: val_loss -0.8723 
2025-12-17 06:25:58.270658: Pseudo dice [0.9317, 0.9564, 0.9296] 
2025-12-17 06:25:58.278792: Epoch time: 137.94 s 
2025-12-17 06:25:58.925942:  
2025-12-17 06:25:58.925942: Epoch 714 
2025-12-17 06:25:58.925942: Current learning rate: 0.00324 
2025-12-17 06:28:16.798317: train_loss -0.855 
2025-12-17 06:28:16.798317: val_loss -0.8654 
2025-12-17 06:28:16.798317: Pseudo dice [0.9194, 0.9515, 0.9323] 
2025-12-17 06:28:16.814234: Epoch time: 137.87 s 
2025-12-17 06:28:17.465424:  
2025-12-17 06:28:17.465424: Epoch 715 
2025-12-17 06:28:17.465424: Current learning rate: 0.00323 
2025-12-17 06:30:35.328348: train_loss -0.8533 
2025-12-17 06:30:35.328348: val_loss -0.8648 
2025-12-17 06:30:35.334358: Pseudo dice [0.9189, 0.953, 0.9314] 
2025-12-17 06:30:35.336360: Epoch time: 137.87 s 
2025-12-17 06:30:36.209278:  
2025-12-17 06:30:36.209278: Epoch 716 
2025-12-17 06:30:36.209278: Current learning rate: 0.00322 
2025-12-17 06:32:54.235897: train_loss -0.855 
2025-12-17 06:32:54.235897: val_loss -0.8663 
2025-12-17 06:32:54.251884: Pseudo dice [0.9236, 0.9501, 0.9287] 
2025-12-17 06:32:54.257505: Epoch time: 138.03 s 
2025-12-17 06:32:54.917436:  
2025-12-17 06:32:54.917436: Epoch 717 
2025-12-17 06:32:54.917436: Current learning rate: 0.00321 
2025-12-17 06:35:13.081665: train_loss -0.8554 
2025-12-17 06:35:13.083668: val_loss -0.8816 
2025-12-17 06:35:13.089673: Pseudo dice [0.9318, 0.9607, 0.9332] 
2025-12-17 06:35:13.091675: Epoch time: 138.16 s 
2025-12-17 06:35:13.741895:  
2025-12-17 06:35:13.741895: Epoch 718 
2025-12-17 06:35:13.741895: Current learning rate: 0.0032 
2025-12-17 06:37:31.636667: train_loss -0.8552 
2025-12-17 06:37:31.636667: val_loss -0.879 
2025-12-17 06:37:31.642411: Pseudo dice [0.9305, 0.9594, 0.9377] 
2025-12-17 06:37:31.642411: Epoch time: 137.89 s 
2025-12-17 06:37:32.414300:  
2025-12-17 06:37:32.414300: Epoch 719 
2025-12-17 06:37:32.414300: Current learning rate: 0.00319 
2025-12-17 06:39:50.356631: train_loss -0.8565 
2025-12-17 06:39:50.356631: val_loss -0.8685 
2025-12-17 06:39:50.376195: Pseudo dice [0.924, 0.9517, 0.9348] 
2025-12-17 06:39:50.382201: Epoch time: 137.96 s 
2025-12-17 06:39:51.043509:  
2025-12-17 06:39:51.043509: Epoch 720 
2025-12-17 06:39:51.045745: Current learning rate: 0.00318 
2025-12-17 06:42:09.121271: train_loss -0.8546 
2025-12-17 06:42:09.121271: val_loss -0.8662 
2025-12-17 06:42:09.128919: Pseudo dice [0.9191, 0.9546, 0.933] 
2025-12-17 06:42:09.133420: Epoch time: 138.08 s 
2025-12-17 06:42:09.782929:  
2025-12-17 06:42:09.782929: Epoch 721 
2025-12-17 06:42:09.782929: Current learning rate: 0.00317 
2025-12-17 06:44:27.795993: train_loss -0.8548 
2025-12-17 06:44:27.795993: val_loss -0.8794 
2025-12-17 06:44:27.807750: Pseudo dice [0.9298, 0.9578, 0.9419] 
2025-12-17 06:44:27.813709: Epoch time: 138.01 s 
2025-12-17 06:44:28.799843:  
2025-12-17 06:44:28.799843: Epoch 722 
2025-12-17 06:44:28.803052: Current learning rate: 0.00316 
2025-12-17 06:46:46.822498: train_loss -0.8542 
2025-12-17 06:46:46.824501: val_loss -0.8604 
2025-12-17 06:46:46.824501: Pseudo dice [0.9174, 0.9493, 0.9311] 
2025-12-17 06:46:46.832438: Epoch time: 138.04 s 
2025-12-17 06:46:47.520252:  
2025-12-17 06:46:47.520252: Epoch 723 
2025-12-17 06:46:47.523752: Current learning rate: 0.00315 
2025-12-17 06:49:05.405571: train_loss -0.8506 
2025-12-17 06:49:05.407573: val_loss -0.8698 
2025-12-17 06:49:05.413158: Pseudo dice [0.9239, 0.9534, 0.9342] 
2025-12-17 06:49:05.417162: Epoch time: 137.89 s 
2025-12-17 06:49:06.073475:  
2025-12-17 06:49:06.073475: Epoch 724 
2025-12-17 06:49:06.075477: Current learning rate: 0.00314 
2025-12-17 06:51:23.967473: train_loss -0.8538 
2025-12-17 06:51:23.967473: val_loss -0.8724 
2025-12-17 06:51:23.975483: Pseudo dice [0.9276, 0.9534, 0.9345] 
2025-12-17 06:51:23.980490: Epoch time: 137.89 s 
2025-12-17 06:51:24.766684:  
2025-12-17 06:51:24.766684: Epoch 725 
2025-12-17 06:51:24.782555: Current learning rate: 0.00313 
2025-12-17 06:53:42.695747: train_loss -0.8592 
2025-12-17 06:53:42.695747: val_loss -0.8733 
2025-12-17 06:53:42.711426: Pseudo dice [0.9278, 0.955, 0.9301] 
2025-12-17 06:53:42.711426: Epoch time: 137.93 s 
2025-12-17 06:53:43.360950:  
2025-12-17 06:53:43.360950: Epoch 726 
2025-12-17 06:53:43.360950: Current learning rate: 0.00312 
2025-12-17 06:56:01.394023: train_loss -0.8523 
2025-12-17 06:56:01.394023: val_loss -0.8779 
2025-12-17 06:56:01.404653: Pseudo dice [0.9295, 0.9584, 0.9335] 
2025-12-17 06:56:01.408656: Epoch time: 138.03 s 
2025-12-17 06:56:02.091831:  
2025-12-17 06:56:02.091831: Epoch 727 
2025-12-17 06:56:02.107609: Current learning rate: 0.00311 
2025-12-17 06:58:20.071718: train_loss -0.8499 
2025-12-17 06:58:20.071718: val_loss -0.8713 
2025-12-17 06:58:20.079727: Pseudo dice [0.9237, 0.9568, 0.9341] 
2025-12-17 06:58:20.085472: Epoch time: 137.98 s 
2025-12-17 06:58:20.873423:  
2025-12-17 06:58:20.873423: Epoch 728 
2025-12-17 06:58:20.889311: Current learning rate: 0.0031 
2025-12-17 07:00:38.850282: train_loss -0.8471 
2025-12-17 07:00:38.850282: val_loss -0.8755 
2025-12-17 07:00:38.850282: Pseudo dice [0.9302, 0.9565, 0.9384] 
2025-12-17 07:00:38.850282: Epoch time: 137.98 s 
2025-12-17 07:00:39.562065:  
2025-12-17 07:00:39.562065: Epoch 729 
2025-12-17 07:00:39.562065: Current learning rate: 0.00309 
2025-12-17 07:02:57.627130: train_loss -0.842 
2025-12-17 07:02:57.627130: val_loss -0.8627 
2025-12-17 07:02:57.627130: Pseudo dice [0.9182, 0.9503, 0.9383] 
2025-12-17 07:02:57.637363: Epoch time: 138.07 s 
2025-12-17 07:02:58.281868:  
2025-12-17 07:02:58.281868: Epoch 730 
2025-12-17 07:02:58.283610: Current learning rate: 0.00308 
2025-12-17 07:05:16.327221: train_loss -0.8531 
2025-12-17 07:05:16.327221: val_loss -0.8671 
2025-12-17 07:05:16.335231: Pseudo dice [0.9247, 0.9524, 0.9341] 
2025-12-17 07:05:16.342978: Epoch time: 138.05 s 
2025-12-17 07:05:17.105987:  
2025-12-17 07:05:17.105987: Epoch 731 
2025-12-17 07:05:17.105987: Current learning rate: 0.00307 
2025-12-17 07:07:35.104692: train_loss -0.849 
2025-12-17 07:07:35.104692: val_loss -0.8701 
2025-12-17 07:07:35.115707: Pseudo dice [0.9237, 0.9542, 0.9335] 
2025-12-17 07:07:35.120714: Epoch time: 138.0 s 
2025-12-17 07:07:35.776943:  
2025-12-17 07:07:35.776943: Epoch 732 
2025-12-17 07:07:35.781507: Current learning rate: 0.00306 
2025-12-17 07:09:54.290355: train_loss -0.856 
2025-12-17 07:09:54.292096: val_loss -0.8682 
2025-12-17 07:09:54.296502: Pseudo dice [0.9218, 0.9519, 0.9318] 
2025-12-17 07:09:54.300506: Epoch time: 138.51 s 
2025-12-17 07:09:54.955899:  
2025-12-17 07:09:54.955899: Epoch 733 
2025-12-17 07:09:54.957901: Current learning rate: 0.00305 
2025-12-17 07:12:12.981962: train_loss -0.8561 
2025-12-17 07:12:12.983964: val_loss -0.8671 
2025-12-17 07:12:12.989971: Pseudo dice [0.9225, 0.9523, 0.9372] 
2025-12-17 07:12:12.993976: Epoch time: 138.03 s 
2025-12-17 07:12:13.933045:  
2025-12-17 07:12:13.933045: Epoch 734 
2025-12-17 07:12:13.938875: Current learning rate: 0.00304 
2025-12-17 07:14:31.935041: train_loss -0.8558 
2025-12-17 07:14:31.935041: val_loss -0.8773 
2025-12-17 07:14:31.941047: Pseudo dice [0.9247, 0.9598, 0.9377] 
2025-12-17 07:14:31.941047: Epoch time: 138.0 s 
2025-12-17 07:14:32.605740:  
2025-12-17 07:14:32.605740: Epoch 735 
2025-12-17 07:14:32.605740: Current learning rate: 0.00303 
2025-12-17 07:16:50.657426: train_loss -0.8501 
2025-12-17 07:16:50.657426: val_loss -0.8595 
2025-12-17 07:16:50.663280: Pseudo dice [0.9166, 0.9481, 0.936] 
2025-12-17 07:16:50.667284: Epoch time: 138.05 s 
2025-12-17 07:16:51.312850:  
2025-12-17 07:16:51.312850: Epoch 736 
2025-12-17 07:16:51.328608: Current learning rate: 0.00302 
2025-12-17 07:19:09.243991: train_loss -0.8507 
2025-12-17 07:19:09.245731: val_loss -0.8762 
2025-12-17 07:19:09.253745: Pseudo dice [0.9271, 0.9557, 0.9401] 
2025-12-17 07:19:09.261495: Epoch time: 137.93 s 
2025-12-17 07:19:09.992947:  
2025-12-17 07:19:09.992947: Epoch 737 
2025-12-17 07:19:09.998956: Current learning rate: 0.00301 
2025-12-17 07:21:28.050951: train_loss -0.8509 
2025-12-17 07:21:28.050951: val_loss -0.8827 
2025-12-17 07:21:28.066647: Pseudo dice [0.9289, 0.9643, 0.9339] 
2025-12-17 07:21:28.068490: Epoch time: 138.06 s 
2025-12-17 07:21:28.714057:  
2025-12-17 07:21:28.714057: Epoch 738 
2025-12-17 07:21:28.731775: Current learning rate: 0.003 
2025-12-17 07:23:46.871770: train_loss -0.8549 
2025-12-17 07:23:46.871770: val_loss -0.8752 
2025-12-17 07:23:46.880935: Pseudo dice [0.9283, 0.9579, 0.9366] 
2025-12-17 07:23:46.886943: Epoch time: 138.16 s 
2025-12-17 07:23:47.535396:  
2025-12-17 07:23:47.535396: Epoch 739 
2025-12-17 07:23:47.551230: Current learning rate: 0.00299 
2025-12-17 07:26:05.510138: train_loss -0.8529 
2025-12-17 07:26:05.510138: val_loss -0.8712 
2025-12-17 07:26:05.525825: Pseudo dice [0.9223, 0.9569, 0.9309] 
2025-12-17 07:26:05.534628: Epoch time: 137.97 s 
2025-12-17 07:26:06.475115:  
2025-12-17 07:26:06.475115: Epoch 740 
2025-12-17 07:26:06.481226: Current learning rate: 0.00297 
2025-12-17 07:28:24.542363: train_loss -0.8524 
2025-12-17 07:28:24.542363: val_loss -0.8789 
2025-12-17 07:28:24.542363: Pseudo dice [0.9292, 0.959, 0.9439] 
2025-12-17 07:28:24.555936: Epoch time: 138.07 s 
2025-12-17 07:28:25.192135:  
2025-12-17 07:28:25.192135: Epoch 741 
2025-12-17 07:28:25.204360: Current learning rate: 0.00296 
2025-12-17 07:30:43.154201: train_loss -0.8569 
2025-12-17 07:30:43.154201: val_loss -0.876 
2025-12-17 07:30:43.170094: Pseudo dice [0.927, 0.9578, 0.9367] 
2025-12-17 07:30:43.170094: Epoch time: 137.96 s 
2025-12-17 07:30:43.834760:  
2025-12-17 07:30:43.834760: Epoch 742 
2025-12-17 07:30:43.834760: Current learning rate: 0.00295 
2025-12-17 07:33:02.680707: train_loss -0.8604 
2025-12-17 07:33:02.680707: val_loss -0.8853 
2025-12-17 07:33:02.696528: Pseudo dice [0.9326, 0.9606, 0.9431] 
2025-12-17 07:33:02.696528: Epoch time: 138.85 s 
2025-12-17 07:33:03.510008:  
2025-12-17 07:33:03.510913: Epoch 743 
2025-12-17 07:33:03.515815: Current learning rate: 0.00294 
2025-12-17 07:35:22.073826: train_loss -0.8497 
2025-12-17 07:35:22.073826: val_loss -0.8696 
2025-12-17 07:35:22.089764: Pseudo dice [0.9211, 0.9537, 0.931] 
2025-12-17 07:35:22.094630: Epoch time: 138.58 s 
2025-12-17 07:35:22.734924:  
2025-12-17 07:35:22.734924: Epoch 744 
2025-12-17 07:35:22.750735: Current learning rate: 0.00293 
2025-12-17 07:37:41.051374: train_loss -0.85 
2025-12-17 07:37:41.051374: val_loss -0.8583 
2025-12-17 07:37:41.065438: Pseudo dice [0.9156, 0.9496, 0.9352] 
2025-12-17 07:37:41.065438: Epoch time: 138.32 s 
2025-12-17 07:37:41.754327:  
2025-12-17 07:37:41.754327: Epoch 745 
2025-12-17 07:37:41.760222: Current learning rate: 0.00292 
2025-12-17 07:40:00.182260: train_loss -0.8561 
2025-12-17 07:40:00.182260: val_loss -0.8765 
2025-12-17 07:40:00.182260: Pseudo dice [0.9318, 0.9577, 0.9333] 
2025-12-17 07:40:00.198361: Epoch time: 138.43 s 
2025-12-17 07:40:00.972332:  
2025-12-17 07:40:00.972332: Epoch 746 
2025-12-17 07:40:00.976738: Current learning rate: 0.00291 
2025-12-17 07:42:19.588353: train_loss -0.8577 
2025-12-17 07:42:19.588353: val_loss -0.8768 
2025-12-17 07:42:19.600652: Pseudo dice [0.9289, 0.9588, 0.9412] 
2025-12-17 07:42:19.604211: Epoch time: 138.63 s 
2025-12-17 07:42:20.238810:  
2025-12-17 07:42:20.238810: Epoch 747 
2025-12-17 07:42:20.238810: Current learning rate: 0.0029 
2025-12-17 07:44:38.370906: train_loss -0.8552 
2025-12-17 07:44:38.370906: val_loss -0.8722 
2025-12-17 07:44:38.386618: Pseudo dice [0.927, 0.9545, 0.9321] 
2025-12-17 07:44:38.388484: Epoch time: 138.13 s 
2025-12-17 07:44:39.036004:  
2025-12-17 07:44:39.036004: Epoch 748 
2025-12-17 07:44:39.036004: Current learning rate: 0.00289 
2025-12-17 07:46:57.031047: train_loss -0.8577 
2025-12-17 07:46:57.031047: val_loss -0.8766 
2025-12-17 07:46:57.031047: Pseudo dice [0.9257, 0.9559, 0.945] 
2025-12-17 07:46:57.031047: Epoch time: 138.0 s 
2025-12-17 07:46:57.855448:  
2025-12-17 07:46:57.855448: Epoch 749 
2025-12-17 07:46:57.855448: Current learning rate: 0.00288 
2025-12-17 07:49:15.790802: train_loss -0.8567 
2025-12-17 07:49:15.790802: val_loss -0.8806 
2025-12-17 07:49:15.806901: Pseudo dice [0.9303, 0.9565, 0.9428] 
2025-12-17 07:49:15.815144: Epoch time: 137.95 s 
2025-12-17 07:49:16.726214:  
2025-12-17 07:49:16.726214: Epoch 750 
2025-12-17 07:49:16.735339: Current learning rate: 0.00287 
2025-12-17 07:51:34.907009: train_loss -0.8541 
2025-12-17 07:51:34.907009: val_loss -0.8736 
2025-12-17 07:51:34.907009: Pseudo dice [0.931, 0.9609, 0.9332] 
2025-12-17 07:51:34.922957: Epoch time: 138.18 s 
2025-12-17 07:51:35.573685:  
2025-12-17 07:51:35.573685: Epoch 751 
2025-12-17 07:51:35.573685: Current learning rate: 0.00286 
2025-12-17 07:53:53.751546: train_loss -0.8578 
2025-12-17 07:53:53.751546: val_loss -0.8761 
2025-12-17 07:53:53.751546: Pseudo dice [0.9275, 0.9569, 0.9374] 
2025-12-17 07:53:53.765362: Epoch time: 138.19 s 
2025-12-17 07:53:53.772278: Yayy! New best EMA pseudo Dice: 0.9401 
2025-12-17 07:53:55.033051:  
2025-12-17 07:53:55.033051: Epoch 752 
2025-12-17 07:53:55.048968: Current learning rate: 0.00285 
2025-12-17 07:56:12.950633: train_loss -0.8574 
2025-12-17 07:56:12.950633: val_loss -0.8723 
2025-12-17 07:56:12.955095: Pseudo dice [0.9258, 0.9525, 0.9376] 
2025-12-17 07:56:12.955095: Epoch time: 137.92 s 
2025-12-17 07:56:13.604259:  
2025-12-17 07:56:13.604259: Epoch 753 
2025-12-17 07:56:13.620326: Current learning rate: 0.00284 
2025-12-17 07:58:31.685736: train_loss -0.8566 
2025-12-17 07:58:31.685736: val_loss -0.8728 
2025-12-17 07:58:31.689571: Pseudo dice [0.9217, 0.9569, 0.9354] 
2025-12-17 07:58:31.689571: Epoch time: 138.08 s 
2025-12-17 07:58:32.354322:  
2025-12-17 07:58:32.354322: Epoch 754 
2025-12-17 07:58:32.354322: Current learning rate: 0.00283 
2025-12-17 08:00:50.488382: train_loss -0.857 
2025-12-17 08:00:50.488382: val_loss -0.8706 
2025-12-17 08:00:50.488382: Pseudo dice [0.9228, 0.9546, 0.9381] 
2025-12-17 08:00:50.488382: Epoch time: 138.13 s 
2025-12-17 08:00:51.279912:  
2025-12-17 08:00:51.279912: Epoch 755 
2025-12-17 08:00:51.279912: Current learning rate: 0.00282 
2025-12-17 08:03:09.192065: train_loss -0.8525 
2025-12-17 08:03:09.192065: val_loss -0.8775 
2025-12-17 08:03:09.198071: Pseudo dice [0.9303, 0.9606, 0.9313] 
2025-12-17 08:03:09.198071: Epoch time: 137.91 s 
2025-12-17 08:03:09.847175:  
2025-12-17 08:03:09.847175: Epoch 756 
2025-12-17 08:03:09.863087: Current learning rate: 0.00281 
2025-12-17 08:05:28.022110: train_loss -0.8514 
2025-12-17 08:05:28.022110: val_loss -0.8702 
2025-12-17 08:05:28.037900: Pseudo dice [0.9269, 0.953, 0.9328] 
2025-12-17 08:05:28.037900: Epoch time: 138.17 s 
2025-12-17 08:05:28.686127:  
2025-12-17 08:05:28.686127: Epoch 757 
2025-12-17 08:05:28.702188: Current learning rate: 0.0028 
2025-12-17 08:07:46.793185: train_loss -0.8532 
2025-12-17 08:07:46.793185: val_loss -0.875 
2025-12-17 08:07:46.804323: Pseudo dice [0.9268, 0.955, 0.936] 
2025-12-17 08:07:46.808133: Epoch time: 138.11 s 
2025-12-17 08:07:47.792971:  
2025-12-17 08:07:47.792971: Epoch 758 
2025-12-17 08:07:47.799161: Current learning rate: 0.00279 
2025-12-17 08:10:06.051565: train_loss -0.8582 
2025-12-17 08:10:06.051565: val_loss -0.87 
2025-12-17 08:10:06.067603: Pseudo dice [0.9188, 0.9543, 0.9379] 
2025-12-17 08:10:06.067603: Epoch time: 138.26 s 
2025-12-17 08:10:06.718068:  
2025-12-17 08:10:06.718068: Epoch 759 
2025-12-17 08:10:06.718068: Current learning rate: 0.00278 
2025-12-17 08:12:24.669481: train_loss -0.8585 
2025-12-17 08:12:24.669481: val_loss -0.8691 
2025-12-17 08:12:24.685600: Pseudo dice [0.9241, 0.9523, 0.9409] 
2025-12-17 08:12:24.694561: Epoch time: 137.95 s 
2025-12-17 08:12:25.349388:  
2025-12-17 08:12:25.349388: Epoch 760 
2025-12-17 08:12:25.349388: Current learning rate: 0.00277 
2025-12-17 08:14:43.399189: train_loss -0.8613 
2025-12-17 08:14:43.400930: val_loss -0.8788 
2025-12-17 08:14:43.412955: Pseudo dice [0.9277, 0.9564, 0.9406] 
2025-12-17 08:14:43.418700: Epoch time: 138.07 s 
2025-12-17 08:14:44.208572:  
2025-12-17 08:14:44.208572: Epoch 761 
2025-12-17 08:14:44.208572: Current learning rate: 0.00276 
2025-12-17 08:17:02.198362: train_loss -0.8601 
2025-12-17 08:17:02.198362: val_loss -0.8699 
2025-12-17 08:17:02.198362: Pseudo dice [0.9243, 0.9502, 0.9351] 
2025-12-17 08:17:02.218374: Epoch time: 137.99 s 
2025-12-17 08:17:02.863680:  
2025-12-17 08:17:02.863680: Epoch 762 
2025-12-17 08:17:02.883015: Current learning rate: 0.00275 
2025-12-17 08:19:20.854955: train_loss -0.8526 
2025-12-17 08:19:20.854955: val_loss -0.879 
2025-12-17 08:19:20.862972: Pseudo dice [0.9293, 0.9597, 0.9367] 
2025-12-17 08:19:20.870720: Epoch time: 137.99 s 
2025-12-17 08:19:21.565834:  
2025-12-17 08:19:21.565834: Epoch 763 
2025-12-17 08:19:21.577203: Current learning rate: 0.00274 
2025-12-17 08:21:39.275389: train_loss -0.8494 
2025-12-17 08:21:39.277391: val_loss -0.8634 
2025-12-17 08:21:39.279393: Pseudo dice [0.9242, 0.9502, 0.9283] 
2025-12-17 08:21:39.289404: Epoch time: 137.71 s 
2025-12-17 08:21:40.157630:  
2025-12-17 08:21:40.157630: Epoch 764 
2025-12-17 08:21:40.157630: Current learning rate: 0.00273 
2025-12-17 08:23:58.090352: train_loss -0.8534 
2025-12-17 08:23:58.092357: val_loss -0.8787 
2025-12-17 08:23:58.100368: Pseudo dice [0.9288, 0.9587, 0.9385] 
2025-12-17 08:23:58.106114: Epoch time: 137.93 s 
2025-12-17 08:23:58.768577:  
2025-12-17 08:23:58.768577: Epoch 765 
2025-12-17 08:23:58.768577: Current learning rate: 0.00272 
2025-12-17 08:26:16.542268: train_loss -0.8579 
2025-12-17 08:26:16.544271: val_loss -0.8679 
2025-12-17 08:26:16.544271: Pseudo dice [0.9228, 0.9511, 0.9289] 
2025-12-17 08:26:16.552784: Epoch time: 137.77 s 
2025-12-17 08:26:17.279422:  
2025-12-17 08:26:17.279422: Epoch 766 
2025-12-17 08:26:17.291475: Current learning rate: 0.00271 
2025-12-17 08:28:35.149895: train_loss -0.8608 
2025-12-17 08:28:35.149895: val_loss -0.8845 
2025-12-17 08:28:35.149895: Pseudo dice [0.9322, 0.9609, 0.94] 
2025-12-17 08:28:35.165080: Epoch time: 137.87 s 
2025-12-17 08:28:35.816694:  
2025-12-17 08:28:35.816694: Epoch 767 
2025-12-17 08:28:35.822672: Current learning rate: 0.0027 
2025-12-17 08:30:53.882058: train_loss -0.857 
2025-12-17 08:30:53.884060: val_loss -0.8785 
2025-12-17 08:30:53.885800: Pseudo dice [0.9265, 0.9585, 0.9451] 
2025-12-17 08:30:53.885800: Epoch time: 138.08 s 
2025-12-17 08:30:54.553230:  
2025-12-17 08:30:54.553230: Epoch 768 
2025-12-17 08:30:54.553230: Current learning rate: 0.00268 
2025-12-17 08:33:12.384436: train_loss -0.8593 
2025-12-17 08:33:12.386176: val_loss -0.8862 
2025-12-17 08:33:12.394186: Pseudo dice [0.9362, 0.963, 0.9388] 
2025-12-17 08:33:12.400194: Epoch time: 137.83 s 
2025-12-17 08:33:12.403937: Yayy! New best EMA pseudo Dice: 0.9403 
2025-12-17 08:33:13.398932:  
2025-12-17 08:33:13.398932: Epoch 769 
2025-12-17 08:33:13.398932: Current learning rate: 0.00267 
2025-12-17 08:35:31.524671: train_loss -0.8544 
2025-12-17 08:35:31.524671: val_loss -0.8786 
2025-12-17 08:35:31.530236: Pseudo dice [0.9297, 0.9617, 0.934] 
2025-12-17 08:35:31.535980: Epoch time: 138.13 s 
2025-12-17 08:35:31.539984: Yayy! New best EMA pseudo Dice: 0.9405 
2025-12-17 08:35:32.706048:  
2025-12-17 08:35:32.706048: Epoch 770 
2025-12-17 08:35:32.715571: Current learning rate: 0.00266 
2025-12-17 08:37:50.710016: train_loss -0.8554 
2025-12-17 08:37:50.710016: val_loss -0.8742 
2025-12-17 08:37:50.715307: Pseudo dice [0.9246, 0.955, 0.9372] 
2025-12-17 08:37:50.721313: Epoch time: 138.0 s 
2025-12-17 08:37:51.374452:  
2025-12-17 08:37:51.374452: Epoch 771 
2025-12-17 08:37:51.390361: Current learning rate: 0.00265 
2025-12-17 08:40:09.421940: train_loss -0.8552 
2025-12-17 08:40:09.421940: val_loss -0.8777 
2025-12-17 08:40:09.421940: Pseudo dice [0.9278, 0.9566, 0.9415] 
2025-12-17 08:40:09.421940: Epoch time: 138.05 s 
2025-12-17 08:40:09.437976: Yayy! New best EMA pseudo Dice: 0.9405 
2025-12-17 08:40:10.419434:  
2025-12-17 08:40:10.419434: Epoch 772 
2025-12-17 08:40:10.419434: Current learning rate: 0.00264 
2025-12-17 08:42:28.389662: train_loss -0.8553 
2025-12-17 08:42:28.389662: val_loss -0.8767 
2025-12-17 08:42:28.404176: Pseudo dice [0.9298, 0.9615, 0.9361] 
2025-12-17 08:42:28.409178: Epoch time: 137.97 s 
2025-12-17 08:42:28.413183: Yayy! New best EMA pseudo Dice: 0.9407 
2025-12-17 08:42:29.348253:  
2025-12-17 08:42:29.348253: Epoch 773 
2025-12-17 08:42:29.348253: Current learning rate: 0.00263 
2025-12-17 08:44:47.339545: train_loss -0.8468 
2025-12-17 08:44:47.344310: val_loss -0.8583 
2025-12-17 08:44:47.350316: Pseudo dice [0.9203, 0.9504, 0.934] 
2025-12-17 08:44:47.354320: Epoch time: 137.99 s 
2025-12-17 08:44:48.003407:  
2025-12-17 08:44:48.003407: Epoch 774 
2025-12-17 08:44:48.003407: Current learning rate: 0.00262 
2025-12-17 08:47:05.954117: train_loss -0.8475 
2025-12-17 08:47:05.954117: val_loss -0.8693 
2025-12-17 08:47:05.969890: Pseudo dice [0.9233, 0.9528, 0.9336] 
2025-12-17 08:47:05.969890: Epoch time: 137.95 s 
2025-12-17 08:47:06.840656:  
2025-12-17 08:47:06.842659: Epoch 775 
2025-12-17 08:47:06.842659: Current learning rate: 0.00261 
2025-12-17 08:49:24.826193: train_loss -0.8563 
2025-12-17 08:49:24.826193: val_loss -0.8755 
2025-12-17 08:49:24.835171: Pseudo dice [0.9277, 0.9573, 0.9317] 
2025-12-17 08:49:24.841178: Epoch time: 137.99 s 
2025-12-17 08:49:25.504042:  
2025-12-17 08:49:25.504042: Epoch 776 
2025-12-17 08:49:25.519368: Current learning rate: 0.0026 
2025-12-17 08:51:43.529173: train_loss -0.8606 
2025-12-17 08:51:43.529173: val_loss -0.8763 
2025-12-17 08:51:43.536067: Pseudo dice [0.9259, 0.9584, 0.9427] 
2025-12-17 08:51:43.540071: Epoch time: 138.03 s 
2025-12-17 08:51:44.250414:  
2025-12-17 08:51:44.250414: Epoch 777 
2025-12-17 08:51:44.254900: Current learning rate: 0.00259 
2025-12-17 08:54:02.194286: train_loss -0.858 
2025-12-17 08:54:02.196289: val_loss -0.8776 
2025-12-17 08:54:02.201862: Pseudo dice [0.9288, 0.9603, 0.9347] 
2025-12-17 08:54:02.205868: Epoch time: 137.95 s 
2025-12-17 08:54:02.917298:  
2025-12-17 08:54:02.917298: Epoch 778 
2025-12-17 08:54:02.917298: Current learning rate: 0.00258 
2025-12-17 08:56:21.004160: train_loss -0.8543 
2025-12-17 08:56:21.006162: val_loss -0.8761 
2025-12-17 08:56:21.012148: Pseudo dice [0.9262, 0.9558, 0.9364] 
2025-12-17 08:56:21.016152: Epoch time: 138.09 s 
2025-12-17 08:56:21.681341:  
2025-12-17 08:56:21.681341: Epoch 779 
2025-12-17 08:56:21.684152: Current learning rate: 0.00257 
2025-12-17 08:58:39.816616: train_loss -0.8582 
2025-12-17 08:58:39.816616: val_loss -0.8733 
2025-12-17 08:58:39.824624: Pseudo dice [0.9232, 0.9558, 0.9401] 
2025-12-17 08:58:39.828366: Epoch time: 138.14 s 
2025-12-17 08:58:40.507285:  
2025-12-17 08:58:40.509287: Epoch 780 
2025-12-17 08:58:40.515294: Current learning rate: 0.00256 
2025-12-17 09:00:58.380043: train_loss -0.8609 
2025-12-17 09:00:58.382045: val_loss -0.8821 
2025-12-17 09:00:58.388051: Pseudo dice [0.9293, 0.9629, 0.9396] 
2025-12-17 09:00:58.393636: Epoch time: 137.87 s 
2025-12-17 09:00:59.366683:  
2025-12-17 09:00:59.366683: Epoch 781 
2025-12-17 09:00:59.382595: Current learning rate: 0.00255 
2025-12-17 09:03:17.253428: train_loss -0.8608 
2025-12-17 09:03:17.253428: val_loss -0.8638 
2025-12-17 09:03:17.272937: Pseudo dice [0.9192, 0.9521, 0.936] 
2025-12-17 09:03:17.276942: Epoch time: 137.89 s 
2025-12-17 09:03:17.994596:  
2025-12-17 09:03:17.994596: Epoch 782 
2025-12-17 09:03:17.994596: Current learning rate: 0.00254 
2025-12-17 09:05:36.008457: train_loss -0.8586 
2025-12-17 09:05:36.010460: val_loss -0.8665 
2025-12-17 09:05:36.017226: Pseudo dice [0.9233, 0.9563, 0.929] 
2025-12-17 09:05:36.024234: Epoch time: 138.01 s 
2025-12-17 09:05:36.671821:  
2025-12-17 09:05:36.671821: Epoch 783 
2025-12-17 09:05:36.689645: Current learning rate: 0.00253 
2025-12-17 09:07:54.690593: train_loss -0.8607 
2025-12-17 09:07:54.690593: val_loss -0.88 
2025-12-17 09:07:54.696602: Pseudo dice [0.9275, 0.9615, 0.94] 
2025-12-17 09:07:54.702611: Epoch time: 138.02 s 
2025-12-17 09:07:55.497833:  
2025-12-17 09:07:55.497833: Epoch 784 
2025-12-17 09:07:55.509798: Current learning rate: 0.00252 
2025-12-17 09:10:13.733655: train_loss -0.8579 
2025-12-17 09:10:13.733655: val_loss -0.8687 
2025-12-17 09:10:13.745028: Pseudo dice [0.9223, 0.9543, 0.9381] 
2025-12-17 09:10:13.749032: Epoch time: 138.24 s 
2025-12-17 09:10:14.411351:  
2025-12-17 09:10:14.411351: Epoch 785 
2025-12-17 09:10:14.411351: Current learning rate: 0.00251 
2025-12-17 09:12:32.352041: train_loss -0.8585 
2025-12-17 09:12:32.352041: val_loss -0.8772 
2025-12-17 09:12:32.373406: Pseudo dice [0.928, 0.9578, 0.9396] 
2025-12-17 09:12:32.377411: Epoch time: 137.94 s 
2025-12-17 09:12:33.041726:  
2025-12-17 09:12:33.041726: Epoch 786 
2025-12-17 09:12:33.041726: Current learning rate: 0.0025 
2025-12-17 09:14:51.096663: train_loss -0.8581 
2025-12-17 09:14:51.096663: val_loss -0.8777 
2025-12-17 09:14:51.102612: Pseudo dice [0.9262, 0.9608, 0.9388] 
2025-12-17 09:14:51.106617: Epoch time: 138.06 s 
2025-12-17 09:14:52.076708:  
2025-12-17 09:14:52.076708: Epoch 787 
2025-12-17 09:14:52.076708: Current learning rate: 0.00249 
2025-12-17 09:17:10.186805: train_loss -0.855 
2025-12-17 09:17:10.188807: val_loss -0.8697 
2025-12-17 09:17:10.188807: Pseudo dice [0.9229, 0.9529, 0.9375] 
2025-12-17 09:17:10.188807: Epoch time: 138.11 s 
2025-12-17 09:17:10.854235:  
2025-12-17 09:17:10.854235: Epoch 788 
2025-12-17 09:17:10.858954: Current learning rate: 0.00248 
2025-12-17 09:19:28.831073: train_loss -0.8593 
2025-12-17 09:19:28.833075: val_loss -0.878 
2025-12-17 09:19:28.840039: Pseudo dice [0.9281, 0.9589, 0.94] 
2025-12-17 09:19:28.843781: Epoch time: 137.98 s 
2025-12-17 09:19:29.508080:  
2025-12-17 09:19:29.508080: Epoch 789 
2025-12-17 09:19:29.508080: Current learning rate: 0.00247 
2025-12-17 09:21:47.573198: train_loss -0.8527 
2025-12-17 09:21:47.573198: val_loss -0.8791 
2025-12-17 09:21:47.582704: Pseudo dice [0.9305, 0.9552, 0.9396] 
2025-12-17 09:21:47.586708: Epoch time: 138.07 s 
2025-12-17 09:21:48.347221:  
2025-12-17 09:21:48.347221: Epoch 790 
2025-12-17 09:21:48.366520: Current learning rate: 0.00245 
2025-12-17 09:24:06.397331: train_loss -0.8586 
2025-12-17 09:24:06.399333: val_loss -0.8775 
2025-12-17 09:24:06.405079: Pseudo dice [0.9312, 0.9593, 0.9343] 
2025-12-17 09:24:06.409878: Epoch time: 138.05 s 
2025-12-17 09:24:07.072896:  
2025-12-17 09:24:07.072896: Epoch 791 
2025-12-17 09:24:07.072896: Current learning rate: 0.00244 
2025-12-17 09:26:25.162376: train_loss -0.8574 
2025-12-17 09:26:25.162376: val_loss -0.8642 
2025-12-17 09:26:25.170384: Pseudo dice [0.9203, 0.9509, 0.9355] 
2025-12-17 09:26:25.176390: Epoch time: 138.09 s 
2025-12-17 09:26:25.835412:  
2025-12-17 09:26:25.835412: Epoch 792 
2025-12-17 09:26:25.835412: Current learning rate: 0.00243 
2025-12-17 09:28:43.875692: train_loss -0.8543 
2025-12-17 09:28:43.875692: val_loss -0.8827 
2025-12-17 09:28:43.882980: Pseudo dice [0.9319, 0.96, 0.9389] 
2025-12-17 09:28:43.888987: Epoch time: 138.04 s 
2025-12-17 09:28:44.903265:  
2025-12-17 09:28:44.903265: Epoch 793 
2025-12-17 09:28:44.921285: Current learning rate: 0.00242 
2025-12-17 09:31:02.959103: train_loss -0.8562 
2025-12-17 09:31:02.959103: val_loss -0.8738 
2025-12-17 09:31:02.966850: Pseudo dice [0.927, 0.9579, 0.9369] 
2025-12-17 09:31:02.974858: Epoch time: 138.06 s 
2025-12-17 09:31:03.624922:  
2025-12-17 09:31:03.624922: Epoch 794 
2025-12-17 09:31:03.624922: Current learning rate: 0.00241 
2025-12-17 09:33:21.646036: train_loss -0.8637 
2025-12-17 09:33:21.646036: val_loss -0.8787 
2025-12-17 09:33:21.653781: Pseudo dice [0.9302, 0.9575, 0.9356] 
2025-12-17 09:33:21.657786: Epoch time: 138.02 s 
2025-12-17 09:33:22.321352:  
2025-12-17 09:33:22.321352: Epoch 795 
2025-12-17 09:33:22.321352: Current learning rate: 0.0024 
2025-12-17 09:35:40.381273: train_loss -0.858 
2025-12-17 09:35:40.381273: val_loss -0.8843 
2025-12-17 09:35:40.389720: Pseudo dice [0.929, 0.9613, 0.944] 
2025-12-17 09:35:40.393724: Epoch time: 138.06 s 
2025-12-17 09:35:40.397228: Yayy! New best EMA pseudo Dice: 0.9408 
2025-12-17 09:35:41.454340:  
2025-12-17 09:35:41.454340: Epoch 796 
2025-12-17 09:35:41.465598: Current learning rate: 0.00239 
2025-12-17 09:37:59.486953: train_loss -0.8558 
2025-12-17 09:37:59.486953: val_loss -0.877 
2025-12-17 09:37:59.500250: Pseudo dice [0.9286, 0.9587, 0.9416] 
2025-12-17 09:37:59.506897: Epoch time: 138.03 s 
2025-12-17 09:37:59.510902: Yayy! New best EMA pseudo Dice: 0.9411 
2025-12-17 09:38:00.463704:  
2025-12-17 09:38:00.463704: Epoch 797 
2025-12-17 09:38:00.479491: Current learning rate: 0.00238 
2025-12-17 09:40:18.380634: train_loss -0.8601 
2025-12-17 09:40:18.382637: val_loss -0.874 
2025-12-17 09:40:18.387644: Pseudo dice [0.9243, 0.9543, 0.9338] 
2025-12-17 09:40:18.393524: Epoch time: 137.92 s 
2025-12-17 09:40:19.113399:  
2025-12-17 09:40:19.113399: Epoch 798 
2025-12-17 09:40:19.129200: Current learning rate: 0.00237 
2025-12-17 09:42:37.031454: train_loss -0.8598 
2025-12-17 09:42:37.031454: val_loss -0.8825 
2025-12-17 09:42:37.038878: Pseudo dice [0.9267, 0.9592, 0.9461] 
2025-12-17 09:42:37.044884: Epoch time: 137.92 s 
2025-12-17 09:42:38.040444:  
2025-12-17 09:42:38.040444: Epoch 799 
2025-12-17 09:42:38.046219: Current learning rate: 0.00236 
2025-12-17 09:44:56.024779: train_loss -0.8572 
2025-12-17 09:44:56.026782: val_loss -0.8679 
2025-12-17 09:44:56.033462: Pseudo dice [0.9206, 0.9548, 0.9378] 
2025-12-17 09:44:56.037465: Epoch time: 137.99 s 
2025-12-17 09:44:56.963174:  
2025-12-17 09:44:56.963174: Epoch 800 
2025-12-17 09:44:56.963174: Current learning rate: 0.00235 
2025-12-17 09:47:14.880645: train_loss -0.8563 
2025-12-17 09:47:14.880645: val_loss -0.8814 
2025-12-17 09:47:14.896456: Pseudo dice [0.93, 0.9582, 0.9391] 
2025-12-17 09:47:14.896456: Epoch time: 137.92 s 
2025-12-17 09:47:15.605057:  
2025-12-17 09:47:15.608555: Epoch 801 
2025-12-17 09:47:15.608555: Current learning rate: 0.00234 
2025-12-17 09:49:33.537828: train_loss -0.8577 
2025-12-17 09:49:33.537828: val_loss -0.874 
2025-12-17 09:49:33.543833: Pseudo dice [0.9229, 0.9589, 0.9404] 
2025-12-17 09:49:33.543833: Epoch time: 137.93 s 
2025-12-17 09:49:34.331638:  
2025-12-17 09:49:34.331638: Epoch 802 
2025-12-17 09:49:34.337141: Current learning rate: 0.00233 
2025-12-17 09:51:52.406989: train_loss -0.8571 
2025-12-17 09:51:52.406989: val_loss -0.8678 
2025-12-17 09:51:52.419855: Pseudo dice [0.9177, 0.9515, 0.9466] 
2025-12-17 09:51:52.424860: Epoch time: 138.09 s 
2025-12-17 09:51:53.090289:  
2025-12-17 09:51:53.090289: Epoch 803 
2025-12-17 09:51:53.090289: Current learning rate: 0.00232 
2025-12-17 09:54:11.130482: train_loss -0.8569 
2025-12-17 09:54:11.130482: val_loss -0.8785 
2025-12-17 09:54:11.136378: Pseudo dice [0.9295, 0.9601, 0.9323] 
2025-12-17 09:54:11.142384: Epoch time: 138.06 s 
2025-12-17 09:54:11.798340:  
2025-12-17 09:54:11.798340: Epoch 804 
2025-12-17 09:54:11.814253: Current learning rate: 0.00231 
2025-12-17 09:56:29.736296: train_loss -0.8619 
2025-12-17 09:56:29.736296: val_loss -0.8786 
2025-12-17 09:56:29.743907: Pseudo dice [0.929, 0.9596, 0.9365] 
2025-12-17 09:56:29.749913: Epoch time: 137.94 s 
2025-12-17 09:56:30.688726:  
2025-12-17 09:56:30.688726: Epoch 805 
2025-12-17 09:56:30.699244: Current learning rate: 0.0023 
2025-12-17 09:58:48.666000: train_loss -0.8589 
2025-12-17 09:58:48.666000: val_loss -0.8857 
2025-12-17 09:58:48.670222: Pseudo dice [0.9319, 0.96, 0.9481] 
2025-12-17 09:58:48.677761: Epoch time: 137.98 s 
2025-12-17 09:58:48.681764: Yayy! New best EMA pseudo Dice: 0.9413 
2025-12-17 09:58:49.633919:  
2025-12-17 09:58:49.633919: Epoch 806 
2025-12-17 09:58:49.633919: Current learning rate: 0.00229 
2025-12-17 10:01:07.617384: train_loss -0.8601 
2025-12-17 10:01:07.617384: val_loss -0.8701 
2025-12-17 10:01:07.621651: Pseudo dice [0.9246, 0.952, 0.9378] 
2025-12-17 10:01:07.621651: Epoch time: 137.98 s 
2025-12-17 10:01:08.282780:  
2025-12-17 10:01:08.282780: Epoch 807 
2025-12-17 10:01:08.282780: Current learning rate: 0.00228 
2025-12-17 10:03:26.408457: train_loss -0.8561 
2025-12-17 10:03:26.408457: val_loss -0.8953 
2025-12-17 10:03:26.422224: Pseudo dice [0.9395, 0.9653, 0.9412] 
2025-12-17 10:03:26.430234: Epoch time: 138.13 s 
2025-12-17 10:03:26.435978: Yayy! New best EMA pseudo Dice: 0.9418 
2025-12-17 10:03:27.511124:  
2025-12-17 10:03:27.511124: Epoch 808 
2025-12-17 10:03:27.516173: Current learning rate: 0.00226 
2025-12-17 10:05:45.639707: train_loss -0.8599 
2025-12-17 10:05:45.639707: val_loss -0.8825 
2025-12-17 10:05:45.648324: Pseudo dice [0.9301, 0.96, 0.9404] 
2025-12-17 10:05:45.653830: Epoch time: 138.13 s 
2025-12-17 10:05:45.661075: Yayy! New best EMA pseudo Dice: 0.942 
2025-12-17 10:05:46.625424:  
2025-12-17 10:05:46.625424: Epoch 809 
2025-12-17 10:05:46.631170: Current learning rate: 0.00225 
2025-12-17 10:08:04.648284: train_loss -0.8627 
2025-12-17 10:08:04.650024: val_loss -0.884 
2025-12-17 10:08:04.654028: Pseudo dice [0.9345, 0.9607, 0.9389] 
2025-12-17 10:08:04.662039: Epoch time: 138.02 s 
2025-12-17 10:08:04.667848: Yayy! New best EMA pseudo Dice: 0.9422 
2025-12-17 10:08:05.809166:  
2025-12-17 10:08:05.809166: Epoch 810 
2025-12-17 10:08:05.816000: Current learning rate: 0.00224 
2025-12-17 10:10:24.182188: train_loss -0.856 
2025-12-17 10:10:24.182188: val_loss -0.8701 
2025-12-17 10:10:24.198285: Pseudo dice [0.9251, 0.9532, 0.9358] 
2025-12-17 10:10:24.198285: Epoch time: 138.37 s 
2025-12-17 10:10:24.991306:  
2025-12-17 10:10:24.991306: Epoch 811 
2025-12-17 10:10:24.991306: Current learning rate: 0.00223 
2025-12-17 10:12:43.088718: train_loss -0.861 
2025-12-17 10:12:43.088718: val_loss -0.8898 
2025-12-17 10:12:43.096725: Pseudo dice [0.932, 0.9638, 0.9434] 
2025-12-17 10:12:43.102470: Epoch time: 138.11 s 
2025-12-17 10:12:43.106396: Yayy! New best EMA pseudo Dice: 0.9423 
2025-12-17 10:12:44.037644:  
2025-12-17 10:12:44.037644: Epoch 812 
2025-12-17 10:12:44.053483: Current learning rate: 0.00222 
2025-12-17 10:15:01.958627: train_loss -0.8598 
2025-12-17 10:15:01.958627: val_loss -0.8787 
2025-12-17 10:15:01.958627: Pseudo dice [0.9266, 0.9565, 0.9455] 
2025-12-17 10:15:01.958627: Epoch time: 137.92 s 
2025-12-17 10:15:01.970711: Yayy! New best EMA pseudo Dice: 0.9423 
2025-12-17 10:15:02.913891:  
2025-12-17 10:15:02.913891: Epoch 813 
2025-12-17 10:15:02.913891: Current learning rate: 0.00221 
2025-12-17 10:17:20.859974: train_loss -0.8589 
2025-12-17 10:17:20.859974: val_loss -0.8786 
2025-12-17 10:17:20.866401: Pseudo dice [0.931, 0.9572, 0.9372] 
2025-12-17 10:17:20.872410: Epoch time: 137.95 s 
2025-12-17 10:17:21.715485:  
2025-12-17 10:17:21.715485: Epoch 814 
2025-12-17 10:17:21.715485: Current learning rate: 0.0022 
2025-12-17 10:19:39.731581: train_loss -0.8631 
2025-12-17 10:19:39.731581: val_loss -0.8907 
2025-12-17 10:19:39.738174: Pseudo dice [0.9373, 0.9633, 0.9404] 
2025-12-17 10:19:39.738174: Epoch time: 138.02 s 
2025-12-17 10:19:39.738174: Yayy! New best EMA pseudo Dice: 0.9427 
2025-12-17 10:19:40.864912:  
2025-12-17 10:19:40.864912: Epoch 815 
2025-12-17 10:19:40.869403: Current learning rate: 0.00219 
2025-12-17 10:21:58.863794: train_loss -0.8629 
2025-12-17 10:21:58.863794: val_loss -0.8792 
2025-12-17 10:21:58.882683: Pseudo dice [0.9286, 0.9557, 0.9437] 
2025-12-17 10:21:58.888691: Epoch time: 138.0 s 
2025-12-17 10:21:59.617532:  
2025-12-17 10:21:59.617532: Epoch 816 
2025-12-17 10:21:59.617532: Current learning rate: 0.00218 
2025-12-17 10:24:17.690269: train_loss -0.8481 
2025-12-17 10:24:17.690269: val_loss -0.8809 
2025-12-17 10:24:17.691270: Pseudo dice [0.9295, 0.9591, 0.9341] 
2025-12-17 10:24:17.691270: Epoch time: 138.07 s 
2025-12-17 10:24:18.525679:  
2025-12-17 10:24:18.525679: Epoch 817 
2025-12-17 10:24:18.525679: Current learning rate: 0.00217 
2025-12-17 10:26:36.763293: train_loss -0.8508 
2025-12-17 10:26:36.763293: val_loss -0.8726 
2025-12-17 10:26:36.773314: Pseudo dice [0.9232, 0.9549, 0.9391] 
2025-12-17 10:26:36.779059: Epoch time: 138.24 s 
2025-12-17 10:26:37.450606:  
2025-12-17 10:26:37.450606: Epoch 818 
2025-12-17 10:26:37.458677: Current learning rate: 0.00216 
2025-12-17 10:28:55.480337: train_loss -0.8561 
2025-12-17 10:28:55.480337: val_loss -0.8676 
2025-12-17 10:28:55.488044: Pseudo dice [0.9241, 0.9536, 0.9258] 
2025-12-17 10:28:55.492048: Epoch time: 138.03 s 
2025-12-17 10:28:56.228395:  
2025-12-17 10:28:56.228395: Epoch 819 
2025-12-17 10:28:56.230398: Current learning rate: 0.00215 
2025-12-17 10:31:14.346609: train_loss -0.8549 
2025-12-17 10:31:14.346609: val_loss -0.8771 
2025-12-17 10:31:14.352115: Pseudo dice [0.9268, 0.9555, 0.9388] 
2025-12-17 10:31:14.358121: Epoch time: 138.12 s 
2025-12-17 10:31:15.149465:  
2025-12-17 10:31:15.149465: Epoch 820 
2025-12-17 10:31:15.149465: Current learning rate: 0.00214 
2025-12-17 10:33:33.114954: train_loss -0.8583 
2025-12-17 10:33:33.114954: val_loss -0.8809 
2025-12-17 10:33:33.122457: Pseudo dice [0.9319, 0.9634, 0.937] 
2025-12-17 10:33:33.126461: Epoch time: 137.97 s 
2025-12-17 10:33:33.763072:  
2025-12-17 10:33:33.763072: Epoch 821 
2025-12-17 10:33:33.763072: Current learning rate: 0.00213 
2025-12-17 10:35:52.078055: train_loss -0.8577 
2025-12-17 10:35:52.078055: val_loss -0.8735 
2025-12-17 10:35:52.084060: Pseudo dice [0.9291, 0.9585, 0.9309] 
2025-12-17 10:35:52.089567: Epoch time: 138.31 s 
2025-12-17 10:35:52.723299:  
2025-12-17 10:35:52.723299: Epoch 822 
2025-12-17 10:35:52.723299: Current learning rate: 0.00212 
2025-12-17 10:38:10.620257: train_loss -0.8583 
2025-12-17 10:38:10.620257: val_loss -0.874 
2025-12-17 10:38:10.622704: Pseudo dice [0.9275, 0.9546, 0.9316] 
2025-12-17 10:38:10.622704: Epoch time: 137.9 s 
2025-12-17 10:38:11.397070:  
2025-12-17 10:38:11.397070: Epoch 823 
2025-12-17 10:38:11.412970: Current learning rate: 0.0021 
2025-12-17 10:40:29.259158: train_loss -0.859 
2025-12-17 10:40:29.259158: val_loss -0.866 
2025-12-17 10:40:29.259158: Pseudo dice [0.9196, 0.9569, 0.9306] 
2025-12-17 10:40:29.274934: Epoch time: 137.86 s 
2025-12-17 10:40:29.902236:  
2025-12-17 10:40:29.902236: Epoch 824 
2025-12-17 10:40:29.902236: Current learning rate: 0.00209 
2025-12-17 10:42:47.707947: train_loss -0.8634 
2025-12-17 10:42:47.707947: val_loss -0.8874 
2025-12-17 10:42:47.709950: Pseudo dice [0.9372, 0.964, 0.9353] 
2025-12-17 10:42:47.720232: Epoch time: 137.81 s 
2025-12-17 10:42:48.348080:  
2025-12-17 10:42:48.348080: Epoch 825 
2025-12-17 10:42:48.350581: Current learning rate: 0.00208 
2025-12-17 10:45:06.483437: train_loss -0.8576 
2025-12-17 10:45:06.483437: val_loss -0.8745 
2025-12-17 10:45:06.489034: Pseudo dice [0.9213, 0.9591, 0.9353] 
2025-12-17 10:45:06.495040: Epoch time: 138.14 s 
2025-12-17 10:45:07.227362:  
2025-12-17 10:45:07.227362: Epoch 826 
2025-12-17 10:45:07.230635: Current learning rate: 0.00207 
2025-12-17 10:47:25.105278: train_loss -0.8596 
2025-12-17 10:47:25.105278: val_loss -0.8622 
2025-12-17 10:47:25.112286: Pseudo dice [0.9139, 0.9513, 0.9356] 
2025-12-17 10:47:25.119610: Epoch time: 137.88 s 
2025-12-17 10:47:25.757931:  
2025-12-17 10:47:25.757931: Epoch 827 
2025-12-17 10:47:25.759935: Current learning rate: 0.00206 
2025-12-17 10:49:43.584652: train_loss -0.861 
2025-12-17 10:49:43.584652: val_loss -0.8775 
2025-12-17 10:49:43.594401: Pseudo dice [0.9267, 0.9556, 0.936] 
2025-12-17 10:49:43.600407: Epoch time: 137.83 s 
2025-12-17 10:49:44.392454:  
2025-12-17 10:49:44.392454: Epoch 828 
2025-12-17 10:49:44.392454: Current learning rate: 0.00205 
2025-12-17 10:52:02.541373: train_loss -0.8609 
2025-12-17 10:52:02.541373: val_loss -0.8876 
2025-12-17 10:52:02.549119: Pseudo dice [0.9289, 0.9629, 0.9433] 
2025-12-17 10:52:02.553840: Epoch time: 138.15 s 
2025-12-17 10:52:03.267669:  
2025-12-17 10:52:03.267669: Epoch 829 
2025-12-17 10:52:03.267669: Current learning rate: 0.00204 
2025-12-17 10:54:21.252535: train_loss -0.8604 
2025-12-17 10:54:21.254536: val_loss -0.8781 
2025-12-17 10:54:21.261282: Pseudo dice [0.923, 0.9553, 0.9469] 
2025-12-17 10:54:21.267001: Epoch time: 137.99 s 
2025-12-17 10:54:21.895874:  
2025-12-17 10:54:21.911663: Epoch 830 
2025-12-17 10:54:21.911663: Current learning rate: 0.00203 
2025-12-17 10:56:39.801846: train_loss -0.8565 
2025-12-17 10:56:39.801846: val_loss -0.8773 
2025-12-17 10:56:39.805592: Pseudo dice [0.9293, 0.961, 0.9372] 
2025-12-17 10:56:39.805592: Epoch time: 137.91 s 
2025-12-17 10:56:40.444730:  
2025-12-17 10:56:40.444730: Epoch 831 
2025-12-17 10:56:40.450331: Current learning rate: 0.00202 
2025-12-17 10:58:58.469626: train_loss -0.8592 
2025-12-17 10:58:58.469626: val_loss -0.8764 
2025-12-17 10:58:58.469626: Pseudo dice [0.9277, 0.9574, 0.9324] 
2025-12-17 10:58:58.480201: Epoch time: 138.03 s 
2025-12-17 10:58:59.103186:  
2025-12-17 10:58:59.103186: Epoch 832 
2025-12-17 10:58:59.118911: Current learning rate: 0.00201 
2025-12-17 11:01:17.158932: train_loss -0.8599 
2025-12-17 11:01:17.158932: val_loss -0.8774 
2025-12-17 11:01:17.179132: Pseudo dice [0.9298, 0.9586, 0.9315] 
2025-12-17 11:01:17.183645: Epoch time: 138.06 s 
2025-12-17 11:01:17.808272:  
2025-12-17 11:01:17.808272: Epoch 833 
2025-12-17 11:01:17.817786: Current learning rate: 0.002 
2025-12-17 11:03:35.876930: train_loss -0.856 
2025-12-17 11:03:35.876930: val_loss -0.8698 
2025-12-17 11:03:35.894224: Pseudo dice [0.9229, 0.9549, 0.9342] 
2025-12-17 11:03:35.901259: Epoch time: 138.07 s 
2025-12-17 11:03:36.732294:  
2025-12-17 11:03:36.748083: Epoch 834 
2025-12-17 11:03:36.748083: Current learning rate: 0.00199 
2025-12-17 11:05:54.638999: train_loss -0.8626 
2025-12-17 11:05:54.638999: val_loss -0.8814 
2025-12-17 11:05:54.651939: Pseudo dice [0.9284, 0.9622, 0.9392] 
2025-12-17 11:05:54.656898: Epoch time: 137.91 s 
2025-12-17 11:05:55.274065:  
2025-12-17 11:05:55.274065: Epoch 835 
2025-12-17 11:05:55.287400: Current learning rate: 0.00198 
2025-12-17 11:08:13.219464: train_loss -0.8618 
2025-12-17 11:08:13.219464: val_loss -0.8762 
2025-12-17 11:08:13.231218: Pseudo dice [0.9282, 0.9546, 0.9396] 
2025-12-17 11:08:13.237225: Epoch time: 137.95 s 
2025-12-17 11:08:13.878906:  
2025-12-17 11:08:13.878906: Epoch 836 
2025-12-17 11:08:13.878906: Current learning rate: 0.00196 
2025-12-17 11:10:32.121395: train_loss -0.8614 
2025-12-17 11:10:32.121395: val_loss -0.8837 
2025-12-17 11:10:32.131144: Pseudo dice [0.9327, 0.9615, 0.941] 
2025-12-17 11:10:32.137150: Epoch time: 138.24 s 
2025-12-17 11:10:32.764196:  
2025-12-17 11:10:32.764196: Epoch 837 
2025-12-17 11:10:32.779920: Current learning rate: 0.00195 
2025-12-17 11:12:50.798951: train_loss -0.8591 
2025-12-17 11:12:50.798951: val_loss -0.8729 
2025-12-17 11:12:50.811396: Pseudo dice [0.9239, 0.9528, 0.9392] 
2025-12-17 11:12:50.811396: Epoch time: 138.03 s 
2025-12-17 11:12:51.508293:  
2025-12-17 11:12:51.508293: Epoch 838 
2025-12-17 11:12:51.524017: Current learning rate: 0.00194 
2025-12-17 11:15:09.456689: train_loss -0.8628 
2025-12-17 11:15:09.458692: val_loss -0.873 
2025-12-17 11:15:09.466441: Pseudo dice [0.9257, 0.9551, 0.9356] 
2025-12-17 11:15:09.473690: Epoch time: 137.95 s 
2025-12-17 11:15:10.094206:  
2025-12-17 11:15:10.094206: Epoch 839 
2025-12-17 11:15:10.094206: Current learning rate: 0.00193 
2025-12-17 11:17:28.115740: train_loss -0.8615 
2025-12-17 11:17:28.115740: val_loss -0.8789 
2025-12-17 11:17:28.122961: Pseudo dice [0.9275, 0.9573, 0.9406] 
2025-12-17 11:17:28.122961: Epoch time: 138.02 s 
2025-12-17 11:17:28.980262:  
2025-12-17 11:17:28.980262: Epoch 840 
2025-12-17 11:17:28.994033: Current learning rate: 0.00192 
2025-12-17 11:19:46.771813: train_loss -0.8622 
2025-12-17 11:19:46.771813: val_loss -0.8754 
2025-12-17 11:19:46.787881: Pseudo dice [0.9252, 0.9588, 0.9315] 
2025-12-17 11:19:46.794775: Epoch time: 137.79 s 
2025-12-17 11:19:47.468258:  
2025-12-17 11:19:47.468258: Epoch 841 
2025-12-17 11:19:47.483902: Current learning rate: 0.00191 
2025-12-17 11:22:05.543073: train_loss -0.8572 
2025-12-17 11:22:05.543073: val_loss -0.8739 
2025-12-17 11:22:05.543073: Pseudo dice [0.9265, 0.9568, 0.9365] 
2025-12-17 11:22:05.553724: Epoch time: 138.07 s 
2025-12-17 11:22:06.176910:  
2025-12-17 11:22:06.176910: Epoch 842 
2025-12-17 11:22:06.193046: Current learning rate: 0.0019 
2025-12-17 11:24:24.310418: train_loss -0.8564 
2025-12-17 11:24:24.310418: val_loss -0.8736 
2025-12-17 11:24:24.319665: Pseudo dice [0.9222, 0.9533, 0.9445] 
2025-12-17 11:24:24.324245: Epoch time: 138.13 s 
2025-12-17 11:24:25.053850:  
2025-12-17 11:24:25.053850: Epoch 843 
2025-12-17 11:24:25.064137: Current learning rate: 0.00189 
2025-12-17 11:26:43.196473: train_loss -0.8542 
2025-12-17 11:26:43.196473: val_loss -0.8779 
2025-12-17 11:26:43.202217: Pseudo dice [0.9318, 0.9588, 0.9322] 
2025-12-17 11:26:43.202217: Epoch time: 138.14 s 
2025-12-17 11:26:43.836172:  
2025-12-17 11:26:43.836172: Epoch 844 
2025-12-17 11:26:43.852162: Current learning rate: 0.00188 
2025-12-17 11:29:01.754480: train_loss -0.8646 
2025-12-17 11:29:01.754480: val_loss -0.8661 
2025-12-17 11:29:01.765816: Pseudo dice [0.9174, 0.9524, 0.9423] 
2025-12-17 11:29:01.769778: Epoch time: 137.92 s 
2025-12-17 11:29:02.402209:  
2025-12-17 11:29:02.402209: Epoch 845 
2025-12-17 11:29:02.402209: Current learning rate: 0.00187 
2025-12-17 11:31:20.111189: train_loss -0.8605 
2025-12-17 11:31:20.111189: val_loss -0.885 
2025-12-17 11:31:20.120939: Pseudo dice [0.933, 0.9608, 0.9455] 
2025-12-17 11:31:20.127505: Epoch time: 137.72 s 
2025-12-17 11:31:20.890734:  
2025-12-17 11:31:20.890734: Epoch 846 
2025-12-17 11:31:20.890734: Current learning rate: 0.00186 
2025-12-17 11:33:38.953015: train_loss -0.8628 
2025-12-17 11:33:38.953015: val_loss -0.8737 
2025-12-17 11:33:38.958993: Pseudo dice [0.9266, 0.955, 0.9421] 
2025-12-17 11:33:38.963630: Epoch time: 138.06 s 
2025-12-17 11:33:39.592954:  
2025-12-17 11:33:39.592954: Epoch 847 
2025-12-17 11:33:39.605540: Current learning rate: 0.00185 
2025-12-17 11:35:57.625973: train_loss -0.8585 
2025-12-17 11:35:57.625973: val_loss -0.8863 
2025-12-17 11:35:57.646712: Pseudo dice [0.9345, 0.9622, 0.9365] 
2025-12-17 11:35:57.651226: Epoch time: 138.03 s 
2025-12-17 11:35:58.276109:  
2025-12-17 11:35:58.276109: Epoch 848 
2025-12-17 11:35:58.293488: Current learning rate: 0.00184 
2025-12-17 11:38:16.246539: train_loss -0.8609 
2025-12-17 11:38:16.246539: val_loss -0.8902 
2025-12-17 11:38:16.252545: Pseudo dice [0.933, 0.9616, 0.9451] 
2025-12-17 11:38:16.258289: Epoch time: 137.97 s 
2025-12-17 11:38:17.001069:  
2025-12-17 11:38:17.001069: Epoch 849 
2025-12-17 11:38:17.017315: Current learning rate: 0.00182 
2025-12-17 11:40:35.164880: train_loss -0.8624 
2025-12-17 11:40:35.164880: val_loss -0.8846 
2025-12-17 11:40:35.174630: Pseudo dice [0.9276, 0.9587, 0.9474] 
2025-12-17 11:40:35.174630: Epoch time: 138.16 s 
2025-12-17 11:40:36.079139:  
2025-12-17 11:40:36.079139: Epoch 850 
2025-12-17 11:40:36.079139: Current learning rate: 0.00181 
2025-12-17 11:42:54.094324: train_loss -0.8579 
2025-12-17 11:42:54.094324: val_loss -0.8757 
2025-12-17 11:42:54.100080: Pseudo dice [0.9234, 0.956, 0.9439] 
2025-12-17 11:42:54.106086: Epoch time: 138.02 s 
2025-12-17 11:42:54.719382:  
2025-12-17 11:42:54.719382: Epoch 851 
2025-12-17 11:42:54.719382: Current learning rate: 0.0018 
2025-12-17 11:45:12.690586: train_loss -0.8623 
2025-12-17 11:45:12.690586: val_loss -0.8778 
2025-12-17 11:45:12.690586: Pseudo dice [0.9288, 0.9568, 0.9391] 
2025-12-17 11:45:12.690586: Epoch time: 137.97 s 
2025-12-17 11:45:13.324539:  
2025-12-17 11:45:13.324539: Epoch 852 
2025-12-17 11:45:13.324539: Current learning rate: 0.00179 
2025-12-17 11:47:31.449921: train_loss -0.861 
2025-12-17 11:47:31.449921: val_loss -0.8749 
2025-12-17 11:47:31.457932: Pseudo dice [0.928, 0.9571, 0.9294] 
2025-12-17 11:47:31.461936: Epoch time: 138.13 s 
2025-12-17 11:47:32.088702:  
2025-12-17 11:47:32.088702: Epoch 853 
2025-12-17 11:47:32.088702: Current learning rate: 0.00178 
2025-12-17 11:49:49.959007: train_loss -0.8611 
2025-12-17 11:49:49.959007: val_loss -0.8777 
2025-12-17 11:49:49.978891: Pseudo dice [0.93, 0.9595, 0.937] 
2025-12-17 11:49:49.978891: Epoch time: 137.89 s 
2025-12-17 11:49:50.593300:  
2025-12-17 11:49:50.593300: Epoch 854 
2025-12-17 11:49:50.609023: Current learning rate: 0.00177 
2025-12-17 11:52:08.543971: train_loss -0.8666 
2025-12-17 11:52:08.543971: val_loss -0.8771 
2025-12-17 11:52:08.549977: Pseudo dice [0.9276, 0.9548, 0.9342] 
2025-12-17 11:52:08.555983: Epoch time: 137.95 s 
2025-12-17 11:52:09.175453:  
2025-12-17 11:52:09.175453: Epoch 855 
2025-12-17 11:52:09.191508: Current learning rate: 0.00176 
2025-12-17 11:54:27.157235: train_loss -0.8596 
2025-12-17 11:54:27.157235: val_loss -0.8777 
2025-12-17 11:54:27.157235: Pseudo dice [0.9293, 0.9571, 0.9371] 
2025-12-17 11:54:27.173220: Epoch time: 137.98 s 
2025-12-17 11:54:27.791969:  
2025-12-17 11:54:27.791969: Epoch 856 
2025-12-17 11:54:27.797755: Current learning rate: 0.00175 
2025-12-17 11:56:45.792574: train_loss -0.8619 
2025-12-17 11:56:45.792574: val_loss -0.8749 
2025-12-17 11:56:45.803259: Pseudo dice [0.9259, 0.9572, 0.9363] 
2025-12-17 11:56:45.809884: Epoch time: 138.0 s 
2025-12-17 11:56:46.488778:  
2025-12-17 11:56:46.488778: Epoch 857 
2025-12-17 11:56:46.493647: Current learning rate: 0.00174 
2025-12-17 11:59:04.394329: train_loss -0.8641 
2025-12-17 11:59:04.394329: val_loss -0.8862 
2025-12-17 11:59:04.394329: Pseudo dice [0.9334, 0.9604, 0.9391] 
2025-12-17 11:59:04.410275: Epoch time: 137.92 s 
2025-12-17 11:59:05.058448:  
2025-12-17 11:59:05.058448: Epoch 858 
2025-12-17 11:59:05.068391: Current learning rate: 0.00173 
2025-12-17 12:01:22.830825: train_loss -0.8608 
2025-12-17 12:01:22.830825: val_loss -0.8907 
2025-12-17 12:01:22.848307: Pseudo dice [0.9365, 0.9642, 0.944] 
2025-12-17 12:01:22.855034: Epoch time: 137.77 s 
2025-12-17 12:01:23.699395:  
2025-12-17 12:01:23.715205: Epoch 859 
2025-12-17 12:01:23.715205: Current learning rate: 0.00172 
2025-12-17 12:03:41.754437: train_loss -0.8614 
2025-12-17 12:03:41.756440: val_loss -0.8787 
2025-12-17 12:03:41.768194: Pseudo dice [0.9273, 0.9609, 0.9418] 
2025-12-17 12:03:41.774200: Epoch time: 138.06 s 
2025-12-17 12:03:42.475217:  
2025-12-17 12:03:42.475217: Epoch 860 
2025-12-17 12:03:42.475217: Current learning rate: 0.0017 
2025-12-17 12:06:00.748478: train_loss -0.8622 
2025-12-17 12:06:00.750480: val_loss -0.8707 
2025-12-17 12:06:00.756645: Pseudo dice [0.9209, 0.9521, 0.9455] 
2025-12-17 12:06:00.760649: Epoch time: 138.27 s 
2025-12-17 12:06:01.420526:  
2025-12-17 12:06:01.420526: Epoch 861 
2025-12-17 12:06:01.436516: Current learning rate: 0.00169 
2025-12-17 12:08:19.384102: train_loss -0.8608 
2025-12-17 12:08:19.384102: val_loss -0.8826 
2025-12-17 12:08:19.399788: Pseudo dice [0.9313, 0.9576, 0.9451] 
2025-12-17 12:08:19.399788: Epoch time: 137.96 s 
2025-12-17 12:08:20.020044:  
2025-12-17 12:08:20.020044: Epoch 862 
2025-12-17 12:08:20.020044: Current learning rate: 0.00168 
2025-12-17 12:10:38.394692: train_loss -0.8586 
2025-12-17 12:10:38.394692: val_loss -0.8761 
2025-12-17 12:10:38.396695: Pseudo dice [0.9284, 0.9584, 0.9406] 
2025-12-17 12:10:38.396695: Epoch time: 138.39 s 
2025-12-17 12:10:39.058111:  
2025-12-17 12:10:39.058111: Epoch 863 
2025-12-17 12:10:39.073769: Current learning rate: 0.00167 
2025-12-17 12:12:56.832496: train_loss -0.864 
2025-12-17 12:12:56.832496: val_loss -0.8779 
2025-12-17 12:12:56.832496: Pseudo dice [0.9242, 0.9547, 0.9553] 
2025-12-17 12:12:56.832496: Epoch time: 137.77 s 
2025-12-17 12:12:57.448710:  
2025-12-17 12:12:57.464434: Epoch 864 
2025-12-17 12:12:57.469483: Current learning rate: 0.00166 
2025-12-17 12:15:15.328161: train_loss -0.8613 
2025-12-17 12:15:15.328161: val_loss -0.874 
2025-12-17 12:15:15.328161: Pseudo dice [0.926, 0.9541, 0.9403] 
2025-12-17 12:15:15.344275: Epoch time: 137.88 s 
2025-12-17 12:15:15.966537:  
2025-12-17 12:15:15.966537: Epoch 865 
2025-12-17 12:15:15.966537: Current learning rate: 0.00165 
2025-12-17 12:17:33.778480: train_loss -0.8599 
2025-12-17 12:17:33.780483: val_loss -0.8747 
2025-12-17 12:17:33.788493: Pseudo dice [0.9248, 0.9574, 0.9362] 
2025-12-17 12:17:33.800256: Epoch time: 137.81 s 
2025-12-17 12:17:34.722801:  
2025-12-17 12:17:34.722801: Epoch 866 
2025-12-17 12:17:34.728937: Current learning rate: 0.00164 
2025-12-17 12:19:52.677573: train_loss -0.8648 
2025-12-17 12:19:52.679575: val_loss -0.8727 
2025-12-17 12:19:52.687584: Pseudo dice [0.9238, 0.957, 0.934] 
2025-12-17 12:19:52.695334: Epoch time: 137.96 s 
2025-12-17 12:19:53.308756:  
2025-12-17 12:19:53.308756: Epoch 867 
2025-12-17 12:19:53.322610: Current learning rate: 0.00163 
2025-12-17 12:22:11.203897: train_loss -0.8635 
2025-12-17 12:22:11.203897: val_loss -0.8698 
2025-12-17 12:22:11.211398: Pseudo dice [0.918, 0.955, 0.9417] 
2025-12-17 12:22:11.217405: Epoch time: 137.9 s 
2025-12-17 12:22:11.836265:  
2025-12-17 12:22:11.836265: Epoch 868 
2025-12-17 12:22:11.852167: Current learning rate: 0.00162 
2025-12-17 12:24:29.859754: train_loss -0.8625 
2025-12-17 12:24:29.859754: val_loss -0.8802 
2025-12-17 12:24:29.863497: Pseudo dice [0.9316, 0.9602, 0.9308] 
2025-12-17 12:24:29.872994: Epoch time: 138.02 s 
2025-12-17 12:24:30.573968:  
2025-12-17 12:24:30.573968: Epoch 869 
2025-12-17 12:24:30.593923: Current learning rate: 0.00161 
2025-12-17 12:26:48.559289: train_loss -0.8628 
2025-12-17 12:26:48.561291: val_loss -0.8928 
2025-12-17 12:26:48.567296: Pseudo dice [0.9364, 0.9631, 0.9445] 
2025-12-17 12:26:48.571300: Epoch time: 137.99 s 
2025-12-17 12:26:49.188753:  
2025-12-17 12:26:49.188753: Epoch 870 
2025-12-17 12:26:49.204500: Current learning rate: 0.00159 
2025-12-17 12:29:07.110759: train_loss -0.8601 
2025-12-17 12:29:07.110759: val_loss -0.8814 
2025-12-17 12:29:07.116765: Pseudo dice [0.9314, 0.9601, 0.9322] 
2025-12-17 12:29:07.122771: Epoch time: 137.92 s 
2025-12-17 12:29:07.743175:  
2025-12-17 12:29:07.743175: Epoch 871 
2025-12-17 12:29:07.743175: Current learning rate: 0.00158 
2025-12-17 12:31:25.628720: train_loss -0.8613 
2025-12-17 12:31:25.628720: val_loss -0.8891 
2025-12-17 12:31:25.636467: Pseudo dice [0.9333, 0.9613, 0.9458] 
2025-12-17 12:31:25.642501: Epoch time: 137.89 s 
2025-12-17 12:31:26.429856:  
2025-12-17 12:31:26.429856: Epoch 872 
2025-12-17 12:31:26.429856: Current learning rate: 0.00157 
2025-12-17 12:33:44.468836: train_loss -0.8635 
2025-12-17 12:33:44.470838: val_loss -0.8889 
2025-12-17 12:33:44.478584: Pseudo dice [0.9312, 0.9638, 0.9427] 
2025-12-17 12:33:44.486333: Epoch time: 138.04 s 
2025-12-17 12:33:45.098499:  
2025-12-17 12:33:45.098499: Epoch 873 
2025-12-17 12:33:45.114364: Current learning rate: 0.00156 
2025-12-17 12:36:03.172366: train_loss -0.8612 
2025-12-17 12:36:03.174368: val_loss -0.8902 
2025-12-17 12:36:03.181706: Pseudo dice [0.9342, 0.9624, 0.9433] 
2025-12-17 12:36:03.189552: Epoch time: 138.07 s 
2025-12-17 12:36:03.197563: Yayy! New best EMA pseudo Dice: 0.9431 
2025-12-17 12:36:04.123005:  
2025-12-17 12:36:04.123005: Epoch 874 
2025-12-17 12:36:04.138737: Current learning rate: 0.00155 
2025-12-17 12:38:22.127728: train_loss -0.8638 
2025-12-17 12:38:22.127728: val_loss -0.8743 
2025-12-17 12:38:22.134266: Pseudo dice [0.9244, 0.9579, 0.9305] 
2025-12-17 12:38:22.134266: Epoch time: 138.0 s 
2025-12-17 12:38:22.823136:  
2025-12-17 12:38:22.823136: Epoch 875 
2025-12-17 12:38:22.827378: Current learning rate: 0.00154 
2025-12-17 12:40:40.841867: train_loss -0.8603 
2025-12-17 12:40:40.841867: val_loss -0.8752 
2025-12-17 12:40:40.848409: Pseudo dice [0.9248, 0.9574, 0.9448] 
2025-12-17 12:40:40.848409: Epoch time: 138.02 s 
2025-12-17 12:40:41.557398:  
2025-12-17 12:40:41.557398: Epoch 876 
2025-12-17 12:40:41.557398: Current learning rate: 0.00153 
2025-12-17 12:42:59.757409: train_loss -0.861 
2025-12-17 12:42:59.759414: val_loss -0.881 
2025-12-17 12:42:59.767154: Pseudo dice [0.9294, 0.9571, 0.9438] 
2025-12-17 12:42:59.774633: Epoch time: 138.2 s 
2025-12-17 12:43:00.396988:  
2025-12-17 12:43:00.398990: Epoch 877 
2025-12-17 12:43:00.398990: Current learning rate: 0.00152 
2025-12-17 12:45:18.302139: train_loss -0.8633 
2025-12-17 12:45:18.302139: val_loss -0.877 
2025-12-17 12:45:18.318022: Pseudo dice [0.928, 0.9573, 0.9343] 
2025-12-17 12:45:18.318022: Epoch time: 137.91 s 
2025-12-17 12:45:18.936598:  
2025-12-17 12:45:18.936598: Epoch 878 
2025-12-17 12:45:18.952400: Current learning rate: 0.00151 
2025-12-17 12:47:37.037474: train_loss -0.8588 
2025-12-17 12:47:37.037474: val_loss -0.8809 
2025-12-17 12:47:37.043480: Pseudo dice [0.929, 0.9601, 0.9386] 
2025-12-17 12:47:37.049487: Epoch time: 138.1 s 
2025-12-17 12:47:37.826998:  
2025-12-17 12:47:37.826998: Epoch 879 
2025-12-17 12:47:37.842825: Current learning rate: 0.00149 
2025-12-17 12:49:55.704878: train_loss -0.866 
2025-12-17 12:49:55.706880: val_loss -0.8876 
2025-12-17 12:49:55.714629: Pseudo dice [0.9359, 0.963, 0.9392] 
2025-12-17 12:49:55.718635: Epoch time: 137.88 s 
2025-12-17 12:49:56.341954:  
2025-12-17 12:49:56.341954: Epoch 880 
2025-12-17 12:49:56.341954: Current learning rate: 0.00148 
2025-12-17 12:52:14.418298: train_loss -0.8636 
2025-12-17 12:52:14.420300: val_loss -0.8694 
2025-12-17 12:52:14.425306: Pseudo dice [0.9256, 0.9551, 0.9316] 
2025-12-17 12:52:14.432863: Epoch time: 138.09 s 
2025-12-17 12:52:15.104384:  
2025-12-17 12:52:15.104384: Epoch 881 
2025-12-17 12:52:15.104384: Current learning rate: 0.00147 
2025-12-17 12:54:33.105657: train_loss -0.86 
2025-12-17 12:54:33.105657: val_loss -0.8744 
2025-12-17 12:54:33.105657: Pseudo dice [0.9265, 0.956, 0.9363] 
2025-12-17 12:54:33.121605: Epoch time: 138.0 s 
2025-12-17 12:54:33.735401:  
2025-12-17 12:54:33.735401: Epoch 882 
2025-12-17 12:54:33.735401: Current learning rate: 0.00146 
2025-12-17 12:56:51.667472: train_loss -0.864 
2025-12-17 12:56:51.672029: val_loss -0.8824 
2025-12-17 12:56:51.672029: Pseudo dice [0.9325, 0.9614, 0.9302] 
2025-12-17 12:56:51.681112: Epoch time: 137.93 s 
2025-12-17 12:56:52.361199:  
2025-12-17 12:56:52.361199: Epoch 883 
2025-12-17 12:56:52.361199: Current learning rate: 0.00145 
2025-12-17 12:59:10.229940: train_loss -0.8616 
2025-12-17 12:59:10.231942: val_loss -0.8794 
2025-12-17 12:59:10.237949: Pseudo dice [0.9288, 0.9573, 0.9319] 
2025-12-17 12:59:10.243693: Epoch time: 137.87 s 
2025-12-17 12:59:10.877724:  
2025-12-17 12:59:10.877724: Epoch 884 
2025-12-17 12:59:10.877724: Current learning rate: 0.00144 
2025-12-17 13:01:28.962428: train_loss -0.8597 
2025-12-17 13:01:28.962428: val_loss -0.8848 
2025-12-17 13:01:28.966170: Pseudo dice [0.9292, 0.9598, 0.943] 
2025-12-17 13:01:28.975413: Epoch time: 138.08 s 
2025-12-17 13:01:29.826519:  
2025-12-17 13:01:29.828259: Epoch 885 
2025-12-17 13:01:29.832003: Current learning rate: 0.00143 
2025-12-17 13:03:47.803732: train_loss -0.8635 
2025-12-17 13:03:47.803732: val_loss -0.8747 
2025-12-17 13:03:47.805473: Pseudo dice [0.9263, 0.957, 0.9327] 
2025-12-17 13:03:47.817409: Epoch time: 137.98 s 
2025-12-17 13:03:48.537871:  
2025-12-17 13:03:48.537871: Epoch 886 
2025-12-17 13:03:48.537871: Current learning rate: 0.00142 
2025-12-17 13:06:06.402094: train_loss -0.8609 
2025-12-17 13:06:06.402094: val_loss -0.8775 
2025-12-17 13:06:06.418179: Pseudo dice [0.9264, 0.9556, 0.938] 
2025-12-17 13:06:06.424431: Epoch time: 137.86 s 
2025-12-17 13:06:07.051738:  
2025-12-17 13:06:07.051738: Epoch 887 
2025-12-17 13:06:07.051738: Current learning rate: 0.00141 
2025-12-17 13:08:24.998394: train_loss -0.8633 
2025-12-17 13:08:24.998394: val_loss -0.8674 
2025-12-17 13:08:25.004400: Pseudo dice [0.9228, 0.9536, 0.9342] 
2025-12-17 13:08:25.010406: Epoch time: 137.95 s 
2025-12-17 13:08:25.624683:  
2025-12-17 13:08:25.624683: Epoch 888 
2025-12-17 13:08:25.624683: Current learning rate: 0.00139 
2025-12-17 13:10:43.954849: train_loss -0.8589 
2025-12-17 13:10:43.956854: val_loss -0.8751 
2025-12-17 13:10:43.966610: Pseudo dice [0.9234, 0.9563, 0.9384] 
2025-12-17 13:10:43.974617: Epoch time: 138.33 s 
2025-12-17 13:10:44.737146:  
2025-12-17 13:10:44.737146: Epoch 889 
2025-12-17 13:10:44.752959: Current learning rate: 0.00138 
2025-12-17 13:13:02.663548: train_loss -0.86 
2025-12-17 13:13:02.679457: val_loss -0.8815 
2025-12-17 13:13:02.686028: Pseudo dice [0.931, 0.9597, 0.9362] 
2025-12-17 13:13:02.690033: Epoch time: 137.93 s 
2025-12-17 13:13:03.308700:  
2025-12-17 13:13:03.310703: Epoch 890 
2025-12-17 13:13:03.314481: Current learning rate: 0.00137 
2025-12-17 13:15:21.466364: train_loss -0.8611 
2025-12-17 13:15:21.466364: val_loss -0.8767 
2025-12-17 13:15:21.476374: Pseudo dice [0.9292, 0.957, 0.934] 
2025-12-17 13:15:21.484123: Epoch time: 138.16 s 
2025-12-17 13:15:22.114233:  
2025-12-17 13:15:22.114233: Epoch 891 
2025-12-17 13:15:22.114233: Current learning rate: 0.00136 
2025-12-17 13:17:40.291554: train_loss -0.8618 
2025-12-17 13:17:40.293556: val_loss -0.8858 
2025-12-17 13:17:40.303306: Pseudo dice [0.9331, 0.9619, 0.9331] 
2025-12-17 13:17:40.311314: Epoch time: 138.18 s 
2025-12-17 13:17:41.264542:  
2025-12-17 13:17:41.264542: Epoch 892 
2025-12-17 13:17:41.264542: Current learning rate: 0.00135 
2025-12-17 13:19:59.233136: train_loss -0.863 
2025-12-17 13:19:59.233136: val_loss -0.8747 
2025-12-17 13:19:59.235960: Pseudo dice [0.9253, 0.9543, 0.935] 
2025-12-17 13:19:59.235960: Epoch time: 137.97 s 
2025-12-17 13:19:59.865459:  
2025-12-17 13:19:59.865459: Epoch 893 
2025-12-17 13:19:59.865459: Current learning rate: 0.00134 
2025-12-17 13:22:17.904038: train_loss -0.8624 
2025-12-17 13:22:17.904038: val_loss -0.8834 
2025-12-17 13:22:17.914836: Pseudo dice [0.9298, 0.9591, 0.9456] 
2025-12-17 13:22:17.918840: Epoch time: 138.05 s 
2025-12-17 13:22:18.544708:  
2025-12-17 13:22:18.544708: Epoch 894 
2025-12-17 13:22:18.544708: Current learning rate: 0.00133 
2025-12-17 13:24:36.493575: train_loss -0.8577 
2025-12-17 13:24:36.493575: val_loss -0.8847 
2025-12-17 13:24:36.499582: Pseudo dice [0.9329, 0.9588, 0.9398] 
2025-12-17 13:24:36.505326: Epoch time: 137.95 s 
2025-12-17 13:24:37.221030:  
2025-12-17 13:24:37.221030: Epoch 895 
2025-12-17 13:24:37.228286: Current learning rate: 0.00132 
2025-12-17 13:26:55.163868: train_loss -0.862 
2025-12-17 13:26:55.163868: val_loss -0.8756 
2025-12-17 13:26:55.179693: Pseudo dice [0.9247, 0.958, 0.9366] 
2025-12-17 13:26:55.179693: Epoch time: 137.94 s 
2025-12-17 13:26:55.796584:  
2025-12-17 13:26:55.796584: Epoch 896 
2025-12-17 13:26:55.812469: Current learning rate: 0.0013 
2025-12-17 13:29:13.828960: train_loss -0.8582 
2025-12-17 13:29:13.828960: val_loss -0.8699 
2025-12-17 13:29:13.842260: Pseudo dice [0.9194, 0.9532, 0.9414] 
2025-12-17 13:29:13.849847: Epoch time: 138.03 s 
2025-12-17 13:29:14.477807:  
2025-12-17 13:29:14.477807: Epoch 897 
2025-12-17 13:29:14.477807: Current learning rate: 0.00129 
2025-12-17 13:31:32.385821: train_loss -0.8627 
2025-12-17 13:31:32.385821: val_loss -0.8864 
2025-12-17 13:31:32.395412: Pseudo dice [0.9279, 0.9636, 0.9452] 
2025-12-17 13:31:32.399416: Epoch time: 137.91 s 
2025-12-17 13:31:33.304029:  
2025-12-17 13:31:33.304029: Epoch 898 
2025-12-17 13:31:33.324154: Current learning rate: 0.00128 
2025-12-17 13:33:51.314496: train_loss -0.8655 
2025-12-17 13:33:51.314496: val_loss -0.8807 
2025-12-17 13:33:51.330195: Pseudo dice [0.9262, 0.9585, 0.9431] 
2025-12-17 13:33:51.337702: Epoch time: 138.01 s 
2025-12-17 13:33:51.978890:  
2025-12-17 13:33:51.978890: Epoch 899 
2025-12-17 13:33:51.984402: Current learning rate: 0.00127 
2025-12-17 13:36:09.858214: train_loss -0.859 
2025-12-17 13:36:09.860219: val_loss -0.881 
2025-12-17 13:36:09.869968: Pseudo dice [0.9356, 0.9586, 0.9298] 
2025-12-17 13:36:09.875975: Epoch time: 137.9 s 
2025-12-17 13:36:10.829796:  
2025-12-17 13:36:10.829796: Epoch 900 
2025-12-17 13:36:10.829796: Current learning rate: 0.00126 
2025-12-17 13:38:28.729774: train_loss -0.8679 
2025-12-17 13:38:28.729774: val_loss -0.8875 
2025-12-17 13:38:28.729774: Pseudo dice [0.9299, 0.9627, 0.9466] 
2025-12-17 13:38:28.741574: Epoch time: 137.9 s 
2025-12-17 13:38:29.388655:  
2025-12-17 13:38:29.388655: Epoch 901 
2025-12-17 13:38:29.394161: Current learning rate: 0.00125 
2025-12-17 13:40:47.479645: train_loss -0.8607 
2025-12-17 13:40:47.479645: val_loss -0.8847 
2025-12-17 13:40:47.487899: Pseudo dice [0.9354, 0.9637, 0.9336] 
2025-12-17 13:40:47.493401: Epoch time: 138.09 s 
2025-12-17 13:40:48.119163:  
2025-12-17 13:40:48.119163: Epoch 902 
2025-12-17 13:40:48.119163: Current learning rate: 0.00124 
2025-12-17 13:43:05.937666: train_loss -0.862 
2025-12-17 13:43:05.941431: val_loss -0.8758 
2025-12-17 13:43:05.947438: Pseudo dice [0.9258, 0.9564, 0.9393] 
2025-12-17 13:43:05.953443: Epoch time: 137.82 s 
2025-12-17 13:43:06.629529:  
2025-12-17 13:43:06.645382: Epoch 903 
2025-12-17 13:43:06.645382: Current learning rate: 0.00122 
2025-12-17 13:45:24.483920: train_loss -0.8626 
2025-12-17 13:45:24.483920: val_loss -0.8858 
2025-12-17 13:45:24.499597: Pseudo dice [0.9336, 0.9602, 0.939] 
2025-12-17 13:45:24.499597: Epoch time: 137.85 s 
2025-12-17 13:45:25.118131:  
2025-12-17 13:45:25.118131: Epoch 904 
2025-12-17 13:45:25.134048: Current learning rate: 0.00121 
2025-12-17 13:47:43.141916: train_loss -0.8606 
2025-12-17 13:47:43.141916: val_loss -0.874 
2025-12-17 13:47:43.147922: Pseudo dice [0.9227, 0.9548, 0.9389] 
2025-12-17 13:47:43.153928: Epoch time: 138.02 s 
2025-12-17 13:47:43.947003:  
2025-12-17 13:47:43.962770: Epoch 905 
2025-12-17 13:47:43.962770: Current learning rate: 0.0012 
2025-12-17 13:50:01.891556: train_loss -0.8633 
2025-12-17 13:50:01.891556: val_loss -0.8736 
2025-12-17 13:50:01.898845: Pseudo dice [0.9227, 0.9571, 0.9425] 
2025-12-17 13:50:01.904851: Epoch time: 137.94 s 
2025-12-17 13:50:02.573373:  
2025-12-17 13:50:02.573373: Epoch 906 
2025-12-17 13:50:02.573373: Current learning rate: 0.00119 
2025-12-17 13:52:20.462202: train_loss -0.859 
2025-12-17 13:52:20.462202: val_loss -0.8794 
2025-12-17 13:52:20.462202: Pseudo dice [0.9281, 0.9584, 0.9383] 
2025-12-17 13:52:20.462202: Epoch time: 137.89 s 
2025-12-17 13:52:21.143584:  
2025-12-17 13:52:21.143584: Epoch 907 
2025-12-17 13:52:21.143584: Current learning rate: 0.00118 
2025-12-17 13:54:39.110371: train_loss -0.8611 
2025-12-17 13:54:39.110371: val_loss -0.8829 
2025-12-17 13:54:39.116377: Pseudo dice [0.9318, 0.9575, 0.9425] 
2025-12-17 13:54:39.124211: Epoch time: 137.97 s 
2025-12-17 13:54:39.819136:  
2025-12-17 13:54:39.819136: Epoch 908 
2025-12-17 13:54:39.819136: Current learning rate: 0.00117 
2025-12-17 13:56:57.550310: train_loss -0.8631 
2025-12-17 13:56:57.550310: val_loss -0.8742 
2025-12-17 13:56:57.556315: Pseudo dice [0.924, 0.9556, 0.9435] 
2025-12-17 13:56:57.562322: Epoch time: 137.73 s 
2025-12-17 13:56:58.218927:  
2025-12-17 13:56:58.226451: Epoch 909 
2025-12-17 13:56:58.226451: Current learning rate: 0.00116 
2025-12-17 13:59:16.217178: train_loss -0.8629 
2025-12-17 13:59:16.217178: val_loss -0.8834 
2025-12-17 13:59:16.219735: Pseudo dice [0.93, 0.9602, 0.939] 
2025-12-17 13:59:16.219735: Epoch time: 138.0 s 
2025-12-17 13:59:16.940730:  
2025-12-17 13:59:16.940730: Epoch 910 
2025-12-17 13:59:16.945258: Current learning rate: 0.00115 
2025-12-17 14:01:34.867596: train_loss -0.8617 
2025-12-17 14:01:34.867596: val_loss -0.8854 
2025-12-17 14:01:34.874907: Pseudo dice [0.9329, 0.96, 0.9445] 
2025-12-17 14:01:34.880913: Epoch time: 137.93 s 
2025-12-17 14:01:35.746050:  
2025-12-17 14:01:35.746050: Epoch 911 
2025-12-17 14:01:35.750421: Current learning rate: 0.00113 
2025-12-17 14:03:53.772098: train_loss -0.8653 
2025-12-17 14:03:53.772098: val_loss -0.8794 
2025-12-17 14:03:53.781003: Pseudo dice [0.9262, 0.9569, 0.9429] 
2025-12-17 14:03:53.786511: Epoch time: 138.03 s 
2025-12-17 14:03:54.458810:  
2025-12-17 14:03:54.458810: Epoch 912 
2025-12-17 14:03:54.474592: Current learning rate: 0.00112 
2025-12-17 14:06:12.393570: train_loss -0.8612 
2025-12-17 14:06:12.393570: val_loss -0.8861 
2025-12-17 14:06:12.401578: Pseudo dice [0.9336, 0.9616, 0.9478] 
2025-12-17 14:06:12.407584: Epoch time: 137.93 s 
2025-12-17 14:06:13.027915:  
2025-12-17 14:06:13.027915: Epoch 913 
2025-12-17 14:06:13.043782: Current learning rate: 0.00111 
2025-12-17 14:08:30.935559: train_loss -0.8653 
2025-12-17 14:08:30.937561: val_loss -0.8777 
2025-12-17 14:08:30.943567: Pseudo dice [0.9231, 0.9606, 0.9455] 
2025-12-17 14:08:30.947571: Epoch time: 137.91 s 
2025-12-17 14:08:31.569907:  
2025-12-17 14:08:31.569907: Epoch 914 
2025-12-17 14:08:31.585646: Current learning rate: 0.0011 
2025-12-17 14:10:49.819625: train_loss -0.8683 
2025-12-17 14:10:49.821367: val_loss -0.8909 
2025-12-17 14:10:49.829379: Pseudo dice [0.9366, 0.9606, 0.9466] 
2025-12-17 14:10:49.833385: Epoch time: 138.25 s 
2025-12-17 14:10:49.837130: Yayy! New best EMA pseudo Dice: 0.9434 
2025-12-17 14:10:50.845874:  
2025-12-17 14:10:50.845874: Epoch 915 
2025-12-17 14:10:50.845874: Current learning rate: 0.00109 
2025-12-17 14:13:08.885824: train_loss -0.8613 
2025-12-17 14:13:08.887826: val_loss -0.8808 
2025-12-17 14:13:08.891569: Pseudo dice [0.928, 0.9571, 0.9397] 
2025-12-17 14:13:08.899618: Epoch time: 138.04 s 
2025-12-17 14:13:09.509328:  
2025-12-17 14:13:09.509328: Epoch 916 
2025-12-17 14:13:09.525246: Current learning rate: 0.00108 
2025-12-17 14:15:27.648361: train_loss -0.8611 
2025-12-17 14:15:27.648361: val_loss -0.8836 
2025-12-17 14:15:27.654367: Pseudo dice [0.931, 0.9597, 0.9397] 
2025-12-17 14:15:27.660111: Epoch time: 138.14 s 
2025-12-17 14:15:28.292233:  
2025-12-17 14:15:28.292233: Epoch 917 
2025-12-17 14:15:28.292233: Current learning rate: 0.00106 
2025-12-17 14:17:46.333465: train_loss -0.8617 
2025-12-17 14:17:46.333465: val_loss -0.8861 
2025-12-17 14:17:46.352971: Pseudo dice [0.9334, 0.9616, 0.9412] 
2025-12-17 14:17:46.358980: Epoch time: 138.04 s 
2025-12-17 14:17:46.364988: Yayy! New best EMA pseudo Dice: 0.9435 
2025-12-17 14:17:47.352198:  
2025-12-17 14:17:47.352198: Epoch 918 
2025-12-17 14:17:47.356535: Current learning rate: 0.00105 
2025-12-17 14:20:05.302997: train_loss -0.8628 
2025-12-17 14:20:05.302997: val_loss -0.8877 
2025-12-17 14:20:05.315980: Pseudo dice [0.9351, 0.9631, 0.9413] 
2025-12-17 14:20:05.322965: Epoch time: 137.95 s 
2025-12-17 14:20:05.328971: Yayy! New best EMA pseudo Dice: 0.9438 
2025-12-17 14:20:06.254094:  
2025-12-17 14:20:06.254094: Epoch 919 
2025-12-17 14:20:06.254094: Current learning rate: 0.00104 
2025-12-17 14:22:24.379740: train_loss -0.8622 
2025-12-17 14:22:24.381742: val_loss -0.8825 
2025-12-17 14:22:24.387748: Pseudo dice [0.9312, 0.9595, 0.9376] 
2025-12-17 14:22:24.393255: Epoch time: 138.13 s 
2025-12-17 14:22:25.015678:  
2025-12-17 14:22:25.015678: Epoch 920 
2025-12-17 14:22:25.031322: Current learning rate: 0.00103 
2025-12-17 14:24:43.087297: train_loss -0.8663 
2025-12-17 14:24:43.087297: val_loss -0.8831 
2025-12-17 14:24:43.103073: Pseudo dice [0.9275, 0.9603, 0.9451] 
2025-12-17 14:24:43.111083: Epoch time: 138.07 s 
2025-12-17 14:24:43.840449:  
2025-12-17 14:24:43.841886: Epoch 921 
2025-12-17 14:24:43.847900: Current learning rate: 0.00102 
2025-12-17 14:27:01.796833: train_loss -0.8611 
2025-12-17 14:27:01.798710: val_loss -0.8794 
2025-12-17 14:27:01.807384: Pseudo dice [0.9266, 0.9569, 0.9389] 
2025-12-17 14:27:01.814105: Epoch time: 137.96 s 
2025-12-17 14:27:02.430110:  
2025-12-17 14:27:02.430110: Epoch 922 
2025-12-17 14:27:02.445968: Current learning rate: 0.00101 
2025-12-17 14:29:20.438274: train_loss -0.8609 
2025-12-17 14:29:20.438274: val_loss -0.8733 
2025-12-17 14:29:20.451528: Pseudo dice [0.9216, 0.9542, 0.9408] 
2025-12-17 14:29:20.454046: Epoch time: 138.01 s 
2025-12-17 14:29:21.215178:  
2025-12-17 14:29:21.215178: Epoch 923 
2025-12-17 14:29:21.231284: Current learning rate: 0.001 
2025-12-17 14:31:39.212682: train_loss -0.8619 
2025-12-17 14:31:39.212682: val_loss -0.8782 
2025-12-17 14:31:39.220348: Pseudo dice [0.9219, 0.9603, 0.9401] 
2025-12-17 14:31:39.224752: Epoch time: 138.0 s 
2025-12-17 14:31:39.964779:  
2025-12-17 14:31:39.964779: Epoch 924 
2025-12-17 14:31:39.970573: Current learning rate: 0.00098 
2025-12-17 14:33:57.768265: train_loss -0.866 
2025-12-17 14:33:57.768265: val_loss -0.8783 
2025-12-17 14:33:57.776165: Pseudo dice [0.924, 0.956, 0.9507] 
2025-12-17 14:33:57.781305: Epoch time: 137.8 s 
2025-12-17 14:33:58.401502:  
2025-12-17 14:33:58.401502: Epoch 925 
2025-12-17 14:33:58.401502: Current learning rate: 0.00097 
2025-12-17 14:36:16.269308: train_loss -0.8636 
2025-12-17 14:36:16.285100: val_loss -0.8784 
2025-12-17 14:36:16.285100: Pseudo dice [0.9265, 0.9581, 0.9339] 
2025-12-17 14:36:16.285100: Epoch time: 137.87 s 
2025-12-17 14:36:16.932904:  
2025-12-17 14:36:16.932904: Epoch 926 
2025-12-17 14:36:16.938578: Current learning rate: 0.00096 
2025-12-17 14:38:34.824274: train_loss -0.8615 
2025-12-17 14:38:34.824274: val_loss -0.8786 
2025-12-17 14:38:34.845556: Pseudo dice [0.928, 0.956, 0.9371] 
2025-12-17 14:38:34.850636: Epoch time: 137.91 s 
2025-12-17 14:38:35.620563:  
2025-12-17 14:38:35.620563: Epoch 927 
2025-12-17 14:38:35.633417: Current learning rate: 0.00095 
2025-12-17 14:40:53.739277: train_loss -0.8619 
2025-12-17 14:40:53.739277: val_loss -0.8858 
2025-12-17 14:40:53.757196: Pseudo dice [0.9303, 0.9578, 0.9481] 
2025-12-17 14:40:53.759198: Epoch time: 138.12 s 
2025-12-17 14:40:54.372622:  
2025-12-17 14:40:54.372622: Epoch 928 
2025-12-17 14:40:54.388622: Current learning rate: 0.00094 
2025-12-17 14:43:12.286021: train_loss -0.8667 
2025-12-17 14:43:12.286021: val_loss -0.8832 
2025-12-17 14:43:12.300185: Pseudo dice [0.9334, 0.9583, 0.9448] 
2025-12-17 14:43:12.306319: Epoch time: 137.91 s 
2025-12-17 14:43:12.948908:  
2025-12-17 14:43:12.948908: Epoch 929 
2025-12-17 14:43:12.948908: Current learning rate: 0.00092 
2025-12-17 14:45:30.932972: train_loss -0.8611 
2025-12-17 14:45:30.932972: val_loss -0.8807 
2025-12-17 14:45:30.953700: Pseudo dice [0.9269, 0.961, 0.9403] 
2025-12-17 14:45:30.957720: Epoch time: 137.98 s 
2025-12-17 14:45:31.819566:  
2025-12-17 14:45:31.819566: Epoch 930 
2025-12-17 14:45:31.839952: Current learning rate: 0.00091 
2025-12-17 14:47:49.634500: train_loss -0.8647 
2025-12-17 14:47:49.634500: val_loss -0.876 
2025-12-17 14:47:49.644256: Pseudo dice [0.929, 0.9551, 0.9384] 
2025-12-17 14:47:49.655937: Epoch time: 137.81 s 
2025-12-17 14:47:50.268805:  
2025-12-17 14:47:50.268805: Epoch 931 
2025-12-17 14:47:50.284723: Current learning rate: 0.0009 
2025-12-17 14:50:08.233417: train_loss -0.8628 
2025-12-17 14:50:08.233417: val_loss -0.8782 
2025-12-17 14:50:08.233417: Pseudo dice [0.9297, 0.9572, 0.9393] 
2025-12-17 14:50:08.251086: Epoch time: 137.96 s 
2025-12-17 14:50:08.864486:  
2025-12-17 14:50:08.864486: Epoch 932 
2025-12-17 14:50:08.884036: Current learning rate: 0.00089 
2025-12-17 14:52:26.799233: train_loss -0.8645 
2025-12-17 14:52:26.801236: val_loss -0.8789 
2025-12-17 14:52:26.805241: Pseudo dice [0.9263, 0.9572, 0.9395] 
2025-12-17 14:52:26.805241: Epoch time: 137.93 s 
2025-12-17 14:52:27.438505:  
2025-12-17 14:52:27.438505: Epoch 933 
2025-12-17 14:52:27.438505: Current learning rate: 0.00088 
2025-12-17 14:54:45.384278: train_loss -0.8621 
2025-12-17 14:54:45.386285: val_loss -0.8789 
2025-12-17 14:54:45.400052: Pseudo dice [0.9283, 0.9576, 0.9389] 
2025-12-17 14:54:45.405671: Epoch time: 137.95 s 
2025-12-17 14:54:46.020205:  
2025-12-17 14:54:46.020205: Epoch 934 
2025-12-17 14:54:46.036222: Current learning rate: 0.00087 
2025-12-17 14:57:03.907411: train_loss -0.8676 
2025-12-17 14:57:03.907411: val_loss -0.8778 
2025-12-17 14:57:03.917140: Pseudo dice [0.9284, 0.9545, 0.9316] 
2025-12-17 14:57:03.923215: Epoch time: 137.89 s 
2025-12-17 14:57:04.540076:  
2025-12-17 14:57:04.540076: Epoch 935 
2025-12-17 14:57:04.555935: Current learning rate: 0.00085 
2025-12-17 14:59:22.495824: train_loss -0.8657 
2025-12-17 14:59:22.495824: val_loss -0.8718 
2025-12-17 14:59:22.495824: Pseudo dice [0.9239, 0.9546, 0.9406] 
2025-12-17 14:59:22.511479: Epoch time: 137.96 s 
2025-12-17 14:59:23.129826:  
2025-12-17 14:59:23.129826: Epoch 936 
2025-12-17 14:59:23.143333: Current learning rate: 0.00084 
2025-12-17 15:01:40.912666: train_loss -0.8655 
2025-12-17 15:01:40.912666: val_loss -0.8882 
2025-12-17 15:01:40.928779: Pseudo dice [0.9334, 0.9622, 0.9442] 
2025-12-17 15:01:40.928779: Epoch time: 137.78 s 
2025-12-17 15:01:41.722227:  
2025-12-17 15:01:41.722227: Epoch 937 
2025-12-17 15:01:41.722227: Current learning rate: 0.00083 
2025-12-17 15:03:59.609034: train_loss -0.8667 
2025-12-17 15:03:59.609034: val_loss -0.8763 
2025-12-17 15:03:59.609034: Pseudo dice [0.9271, 0.9577, 0.9313] 
2025-12-17 15:03:59.627035: Epoch time: 137.89 s 
2025-12-17 15:04:00.383380:  
2025-12-17 15:04:00.383380: Epoch 938 
2025-12-17 15:04:00.403039: Current learning rate: 0.00082 
2025-12-17 15:06:18.266864: train_loss -0.8671 
2025-12-17 15:06:18.268867: val_loss -0.8797 
2025-12-17 15:06:18.278708: Pseudo dice [0.9304, 0.9571, 0.9416] 
2025-12-17 15:06:18.280710: Epoch time: 137.88 s 
2025-12-17 15:06:18.910720:  
2025-12-17 15:06:18.910720: Epoch 939 
2025-12-17 15:06:18.926623: Current learning rate: 0.00081 
2025-12-17 15:08:36.826262: train_loss -0.8592 
2025-12-17 15:08:36.828264: val_loss -0.8888 
2025-12-17 15:08:36.836257: Pseudo dice [0.9355, 0.9624, 0.9367] 
2025-12-17 15:08:36.844263: Epoch time: 137.92 s 
2025-12-17 15:08:37.461468:  
2025-12-17 15:08:37.461468: Epoch 940 
2025-12-17 15:08:37.477387: Current learning rate: 0.00079 
2025-12-17 15:10:55.839242: train_loss -0.866 
2025-12-17 15:10:55.839242: val_loss -0.8931 
2025-12-17 15:10:55.839242: Pseudo dice [0.9411, 0.9608, 0.9382] 
2025-12-17 15:10:55.852321: Epoch time: 138.38 s 
2025-12-17 15:10:56.609401:  
2025-12-17 15:10:56.609401: Epoch 941 
2025-12-17 15:10:56.615116: Current learning rate: 0.00078 
2025-12-17 15:13:14.554959: train_loss -0.8658 
2025-12-17 15:13:14.554959: val_loss -0.89 
2025-12-17 15:13:14.570163: Pseudo dice [0.9331, 0.9618, 0.9504] 
2025-12-17 15:13:14.576093: Epoch time: 137.95 s 
2025-12-17 15:13:15.188585:  
2025-12-17 15:13:15.188585: Epoch 942 
2025-12-17 15:13:15.206230: Current learning rate: 0.00077 
2025-12-17 15:15:33.320138: train_loss -0.862 
2025-12-17 15:15:33.320138: val_loss -0.8772 
2025-12-17 15:15:33.326874: Pseudo dice [0.9265, 0.9539, 0.9405] 
2025-12-17 15:15:33.332470: Epoch time: 138.13 s 
2025-12-17 15:15:33.954148:  
2025-12-17 15:15:33.954148: Epoch 943 
2025-12-17 15:15:33.969897: Current learning rate: 0.00076 
2025-12-17 15:17:52.037656: train_loss -0.8624 
2025-12-17 15:17:52.037656: val_loss -0.8872 
2025-12-17 15:17:52.045800: Pseudo dice [0.9319, 0.9617, 0.943] 
2025-12-17 15:17:52.045800: Epoch time: 138.08 s 
2025-12-17 15:17:53.009124:  
2025-12-17 15:17:53.009124: Epoch 944 
2025-12-17 15:17:53.022986: Current learning rate: 0.00075 
2025-12-17 15:20:10.842083: train_loss -0.8636 
2025-12-17 15:20:10.842083: val_loss -0.8925 
2025-12-17 15:20:10.858171: Pseudo dice [0.9377, 0.9661, 0.9394] 
2025-12-17 15:20:10.866618: Epoch time: 137.83 s 
2025-12-17 15:20:11.494438:  
2025-12-17 15:20:11.494438: Epoch 945 
2025-12-17 15:20:11.494438: Current learning rate: 0.00074 
2025-12-17 15:22:29.585618: train_loss -0.8684 
2025-12-17 15:22:29.585618: val_loss -0.883 
2025-12-17 15:22:29.601547: Pseudo dice [0.9351, 0.9593, 0.9338] 
2025-12-17 15:22:29.611419: Epoch time: 138.09 s 
2025-12-17 15:22:30.235808:  
2025-12-17 15:22:30.235808: Epoch 946 
2025-12-17 15:22:30.244812: Current learning rate: 0.00072 
2025-12-17 15:24:48.341200: train_loss -0.8661 
2025-12-17 15:24:48.341200: val_loss -0.8777 
2025-12-17 15:24:48.362496: Pseudo dice [0.9247, 0.9532, 0.9423] 
2025-12-17 15:24:48.368333: Epoch time: 138.11 s 
2025-12-17 15:24:49.099885:  
2025-12-17 15:24:49.099885: Epoch 947 
2025-12-17 15:24:49.109869: Current learning rate: 0.00071 
2025-12-17 15:27:07.078784: train_loss -0.8628 
2025-12-17 15:27:07.090486: val_loss -0.881 
2025-12-17 15:27:07.096791: Pseudo dice [0.9283, 0.9567, 0.9417] 
2025-12-17 15:27:07.101161: Epoch time: 137.98 s 
2025-12-17 15:27:07.724307:  
2025-12-17 15:27:07.724307: Epoch 948 
2025-12-17 15:27:07.729613: Current learning rate: 0.0007 
2025-12-17 15:29:25.673737: train_loss -0.862 
2025-12-17 15:29:25.675739: val_loss -0.8878 
2025-12-17 15:29:25.681745: Pseudo dice [0.9347, 0.9643, 0.9421] 
2025-12-17 15:29:25.687490: Epoch time: 137.97 s 
2025-12-17 15:29:26.328802:  
2025-12-17 15:29:26.328802: Epoch 949 
2025-12-17 15:29:26.333542: Current learning rate: 0.00069 
2025-12-17 15:31:44.168937: train_loss -0.8659 
2025-12-17 15:31:44.171636: val_loss -0.8726 
2025-12-17 15:31:44.177644: Pseudo dice [0.9245, 0.955, 0.9408] 
2025-12-17 15:31:44.183650: Epoch time: 137.84 s 
2025-12-17 15:31:45.372494:  
2025-12-17 15:31:45.372494: Epoch 950 
2025-12-17 15:31:45.379155: Current learning rate: 0.00067 
2025-12-17 15:34:03.486749: train_loss -0.8646 
2025-12-17 15:34:03.486749: val_loss -0.8806 
2025-12-17 15:34:03.493997: Pseudo dice [0.9273, 0.9608, 0.9369] 
2025-12-17 15:34:03.500822: Epoch time: 138.11 s 
2025-12-17 15:34:04.153569:  
2025-12-17 15:34:04.153569: Epoch 951 
2025-12-17 15:34:04.153569: Current learning rate: 0.00066 
2025-12-17 15:36:22.068988: train_loss -0.8641 
2025-12-17 15:36:22.068988: val_loss -0.8768 
2025-12-17 15:36:22.075787: Pseudo dice [0.9288, 0.9562, 0.9382] 
2025-12-17 15:36:22.079793: Epoch time: 137.92 s 
2025-12-17 15:36:22.731088:  
2025-12-17 15:36:22.731088: Epoch 952 
2025-12-17 15:36:22.731088: Current learning rate: 0.00065 
2025-12-17 15:38:40.653054: train_loss -0.862 
2025-12-17 15:38:40.668944: val_loss -0.8748 
2025-12-17 15:38:40.668944: Pseudo dice [0.922, 0.9528, 0.9482] 
2025-12-17 15:38:40.682108: Epoch time: 137.92 s 
2025-12-17 15:38:41.302078:  
2025-12-17 15:38:41.302078: Epoch 953 
2025-12-17 15:38:41.302078: Current learning rate: 0.00064 
2025-12-17 15:40:59.219960: train_loss -0.8662 
2025-12-17 15:40:59.221962: val_loss -0.8771 
2025-12-17 15:40:59.225726: Pseudo dice [0.9242, 0.9589, 0.9424] 
2025-12-17 15:40:59.233738: Epoch time: 137.92 s 
2025-12-17 15:40:59.863024:  
2025-12-17 15:40:59.863024: Epoch 954 
2025-12-17 15:40:59.882799: Current learning rate: 0.00063 
2025-12-17 15:43:17.808800: train_loss -0.8636 
2025-12-17 15:43:17.808800: val_loss -0.8853 
2025-12-17 15:43:17.816116: Pseudo dice [0.9301, 0.961, 0.9479] 
2025-12-17 15:43:17.822757: Epoch time: 137.95 s 
2025-12-17 15:43:18.509740:  
2025-12-17 15:43:18.509740: Epoch 955 
2025-12-17 15:43:18.522825: Current learning rate: 0.00061 
2025-12-17 15:45:36.684216: train_loss -0.862 
2025-12-17 15:45:36.684216: val_loss -0.8911 
2025-12-17 15:45:36.700334: Pseudo dice [0.9332, 0.962, 0.9466] 
2025-12-17 15:45:36.710237: Epoch time: 138.17 s 
2025-12-17 15:45:37.335423:  
2025-12-17 15:45:37.351212: Epoch 956 
2025-12-17 15:45:37.357121: Current learning rate: 0.0006 
2025-12-17 15:47:55.365235: train_loss -0.8618 
2025-12-17 15:47:55.365235: val_loss -0.8836 
2025-12-17 15:47:55.376629: Pseudo dice [0.9309, 0.9592, 0.9349] 
2025-12-17 15:47:55.381333: Epoch time: 138.03 s 
2025-12-17 15:47:56.173456:  
2025-12-17 15:47:56.173456: Epoch 957 
2025-12-17 15:47:56.193164: Current learning rate: 0.00059 
2025-12-17 15:50:14.117797: train_loss -0.8668 
2025-12-17 15:50:14.117797: val_loss -0.8757 
2025-12-17 15:50:14.133823: Pseudo dice [0.9216, 0.9571, 0.943] 
2025-12-17 15:50:14.133823: Epoch time: 137.94 s 
2025-12-17 15:50:14.768177:  
2025-12-17 15:50:14.768177: Epoch 958 
2025-12-17 15:50:14.768177: Current learning rate: 0.00058 
2025-12-17 15:52:32.693604: train_loss -0.8649 
2025-12-17 15:52:32.693604: val_loss -0.8772 
2025-12-17 15:52:32.693604: Pseudo dice [0.9286, 0.9563, 0.9415] 
2025-12-17 15:52:32.707379: Epoch time: 137.93 s 
2025-12-17 15:52:33.343068:  
2025-12-17 15:52:33.358867: Epoch 959 
2025-12-17 15:52:33.363590: Current learning rate: 0.00056 
2025-12-17 15:54:51.406293: train_loss -0.8641 
2025-12-17 15:54:51.408295: val_loss -0.8776 
2025-12-17 15:54:51.415779: Pseudo dice [0.9249, 0.9591, 0.9429] 
2025-12-17 15:54:51.422282: Epoch time: 138.06 s 
2025-12-17 15:54:52.051067:  
2025-12-17 15:54:52.051067: Epoch 960 
2025-12-17 15:54:52.051067: Current learning rate: 0.00055 
2025-12-17 15:57:10.031542: train_loss -0.867 
2025-12-17 15:57:10.031542: val_loss -0.884 
2025-12-17 15:57:10.037549: Pseudo dice [0.9269, 0.9599, 0.9455] 
2025-12-17 15:57:10.043293: Epoch time: 137.98 s 
2025-12-17 15:57:10.772174:  
2025-12-17 15:57:10.772174: Epoch 961 
2025-12-17 15:57:10.789327: Current learning rate: 0.00054 
2025-12-17 15:59:28.843513: train_loss -0.8648 
2025-12-17 15:59:28.843513: val_loss -0.8913 
2025-12-17 15:59:28.853525: Pseudo dice [0.9351, 0.9624, 0.948] 
2025-12-17 15:59:28.859273: Epoch time: 138.07 s 
2025-12-17 15:59:29.489086:  
2025-12-17 15:59:29.489086: Epoch 962 
2025-12-17 15:59:29.499043: Current learning rate: 0.00053 
2025-12-17 16:01:47.465619: train_loss -0.8682 
2025-12-17 16:01:47.465619: val_loss -0.8739 
2025-12-17 16:01:47.465619: Pseudo dice [0.9237, 0.956, 0.9288] 
2025-12-17 16:01:47.481551: Epoch time: 137.98 s 
2025-12-17 16:01:48.273541:  
2025-12-17 16:01:48.273541: Epoch 963 
2025-12-17 16:01:48.292821: Current learning rate: 0.00051 
2025-12-17 16:04:06.297511: train_loss -0.8693 
2025-12-17 16:04:06.297511: val_loss -0.8783 
2025-12-17 16:04:06.309107: Pseudo dice [0.9256, 0.9585, 0.9395] 
2025-12-17 16:04:06.316140: Epoch time: 138.02 s 
2025-12-17 16:04:07.042021:  
2025-12-17 16:04:07.042021: Epoch 964 
2025-12-17 16:04:07.054787: Current learning rate: 0.0005 
2025-12-17 16:06:24.852670: train_loss -0.8691 
2025-12-17 16:06:24.852670: val_loss -0.877 
2025-12-17 16:06:24.873656: Pseudo dice [0.9226, 0.9574, 0.9389] 
2025-12-17 16:06:24.878590: Epoch time: 137.81 s 
2025-12-17 16:06:25.534289:  
2025-12-17 16:06:25.534289: Epoch 965 
2025-12-17 16:06:25.545393: Current learning rate: 0.00049 
2025-12-17 16:08:43.711433: train_loss -0.8675 
2025-12-17 16:08:43.711433: val_loss -0.8835 
2025-12-17 16:08:43.721448: Pseudo dice [0.9281, 0.9575, 0.9434] 
2025-12-17 16:08:43.729075: Epoch time: 138.18 s 
2025-12-17 16:08:44.360422:  
2025-12-17 16:08:44.360422: Epoch 966 
2025-12-17 16:08:44.374388: Current learning rate: 0.00048 
2025-12-17 16:11:02.668020: train_loss -0.8673 
2025-12-17 16:11:02.668020: val_loss -0.8803 
2025-12-17 16:11:02.678033: Pseudo dice [0.931, 0.957, 0.9351] 
2025-12-17 16:11:02.685809: Epoch time: 138.31 s 
2025-12-17 16:11:03.442584:  
2025-12-17 16:11:03.442584: Epoch 967 
2025-12-17 16:11:03.451155: Current learning rate: 0.00046 
2025-12-17 16:13:21.411479: train_loss -0.8667 
2025-12-17 16:13:21.411479: val_loss -0.8756 
2025-12-17 16:13:21.419227: Pseudo dice [0.9278, 0.9555, 0.9354] 
2025-12-17 16:13:21.426416: Epoch time: 137.97 s 
2025-12-17 16:13:22.098134:  
2025-12-17 16:13:22.098134: Epoch 968 
2025-12-17 16:13:22.119735: Current learning rate: 0.00045 
2025-12-17 16:15:40.064158: train_loss -0.8655 
2025-12-17 16:15:40.064158: val_loss -0.886 
2025-12-17 16:15:40.073910: Pseudo dice [0.9282, 0.958, 0.9464] 
2025-12-17 16:15:40.081918: Epoch time: 137.97 s 
2025-12-17 16:15:40.940110:  
2025-12-17 16:15:40.940110: Epoch 969 
2025-12-17 16:15:40.956032: Current learning rate: 0.00044 
2025-12-17 16:17:58.948931: train_loss -0.8687 
2025-12-17 16:17:58.950933: val_loss -0.8809 
2025-12-17 16:17:58.960685: Pseudo dice [0.9311, 0.9554, 0.9415] 
2025-12-17 16:17:58.968694: Epoch time: 138.01 s 
2025-12-17 16:17:59.752908:  
2025-12-17 16:17:59.754911: Epoch 970 
2025-12-17 16:17:59.760920: Current learning rate: 0.00043 
2025-12-17 16:20:17.778899: train_loss -0.8651 
2025-12-17 16:20:17.778899: val_loss -0.8749 
2025-12-17 16:20:17.784908: Pseudo dice [0.9262, 0.9555, 0.9342] 
2025-12-17 16:20:17.790364: Epoch time: 138.03 s 
2025-12-17 16:20:18.462600:  
2025-12-17 16:20:18.462600: Epoch 971 
2025-12-17 16:20:18.462600: Current learning rate: 0.00041 
2025-12-17 16:22:36.322556: train_loss -0.8675 
2025-12-17 16:22:36.322556: val_loss -0.8773 
2025-12-17 16:22:36.328564: Pseudo dice [0.9267, 0.9527, 0.9421] 
2025-12-17 16:22:36.336333: Epoch time: 137.86 s 
2025-12-17 16:22:36.996685:  
2025-12-17 16:22:36.996685: Epoch 972 
2025-12-17 16:22:36.996685: Current learning rate: 0.0004 
2025-12-17 16:24:55.092173: train_loss -0.87 
2025-12-17 16:24:55.092173: val_loss -0.8843 
2025-12-17 16:24:55.108002: Pseudo dice [0.9283, 0.9576, 0.9394] 
2025-12-17 16:24:55.108002: Epoch time: 138.1 s 
2025-12-17 16:24:55.741902:  
2025-12-17 16:24:55.741902: Epoch 973 
2025-12-17 16:24:55.759705: Current learning rate: 0.00039 
2025-12-17 16:27:13.747036: train_loss -0.8674 
2025-12-17 16:27:13.749038: val_loss -0.8867 
2025-12-17 16:27:13.753044: Pseudo dice [0.9348, 0.9604, 0.9458] 
2025-12-17 16:27:13.762527: Epoch time: 138.01 s 
2025-12-17 16:27:14.482914:  
2025-12-17 16:27:14.482914: Epoch 974 
2025-12-17 16:27:14.490243: Current learning rate: 0.00037 
2025-12-17 16:29:32.366747: train_loss -0.8659 
2025-12-17 16:29:32.366747: val_loss -0.892 
2025-12-17 16:29:32.377645: Pseudo dice [0.936, 0.9642, 0.9409] 
2025-12-17 16:29:32.384465: Epoch time: 137.89 s 
2025-12-17 16:29:33.062927:  
2025-12-17 16:29:33.062927: Epoch 975 
2025-12-17 16:29:33.062927: Current learning rate: 0.00036 
2025-12-17 16:31:51.277789: train_loss -0.861 
2025-12-17 16:31:51.277789: val_loss -0.8721 
2025-12-17 16:31:51.285290: Pseudo dice [0.9204, 0.9541, 0.9411] 
2025-12-17 16:31:51.290772: Epoch time: 138.23 s 
2025-12-17 16:31:52.101795:  
2025-12-17 16:31:52.101795: Epoch 976 
2025-12-17 16:31:52.112889: Current learning rate: 0.00035 
2025-12-17 16:34:09.991241: train_loss -0.8678 
2025-12-17 16:34:09.991241: val_loss -0.8796 
2025-12-17 16:34:10.003088: Pseudo dice [0.9306, 0.9574, 0.935] 
2025-12-17 16:34:10.007363: Epoch time: 137.89 s 
2025-12-17 16:34:10.643160:  
2025-12-17 16:34:10.643160: Epoch 977 
2025-12-17 16:34:10.643160: Current learning rate: 0.00034 
2025-12-17 16:36:28.643147: train_loss -0.8644 
2025-12-17 16:36:28.643147: val_loss -0.8919 
2025-12-17 16:36:28.659216: Pseudo dice [0.9358, 0.9641, 0.9384] 
2025-12-17 16:36:28.659216: Epoch time: 138.0 s 
2025-12-17 16:36:29.372151:  
2025-12-17 16:36:29.372151: Epoch 978 
2025-12-17 16:36:29.381915: Current learning rate: 0.00032 
2025-12-17 16:38:47.139432: train_loss -0.8663 
2025-12-17 16:38:47.139432: val_loss -0.8912 
2025-12-17 16:38:47.151754: Pseudo dice [0.9353, 0.9636, 0.944] 
2025-12-17 16:38:47.158862: Epoch time: 137.77 s 
2025-12-17 16:38:47.868384:  
2025-12-17 16:38:47.868384: Epoch 979 
2025-12-17 16:38:47.868384: Current learning rate: 0.00031 
2025-12-17 16:41:05.845916: train_loss -0.8601 
2025-12-17 16:41:05.845916: val_loss -0.8779 
2025-12-17 16:41:05.853554: Pseudo dice [0.9265, 0.9564, 0.9423] 
2025-12-17 16:41:05.860955: Epoch time: 137.98 s 
2025-12-17 16:41:06.496655:  
2025-12-17 16:41:06.496655: Epoch 980 
2025-12-17 16:41:06.512626: Current learning rate: 0.0003 
2025-12-17 16:43:24.355515: train_loss -0.8674 
2025-12-17 16:43:24.355515: val_loss -0.8768 
2025-12-17 16:43:24.355515: Pseudo dice [0.9269, 0.9559, 0.9467] 
2025-12-17 16:43:24.373278: Epoch time: 137.86 s 
2025-12-17 16:43:25.099276:  
2025-12-17 16:43:25.099276: Epoch 981 
2025-12-17 16:43:25.246450: Current learning rate: 0.00028 
2025-12-17 16:45:43.380381: train_loss -0.8696 
2025-12-17 16:45:43.382383: val_loss -0.882 
2025-12-17 16:45:43.387864: Pseudo dice [0.9307, 0.9603, 0.9406] 
2025-12-17 16:45:43.387864: Epoch time: 138.28 s 
2025-12-17 16:45:44.023955:  
2025-12-17 16:45:44.023955: Epoch 982 
2025-12-17 16:45:44.023955: Current learning rate: 0.00027 
2025-12-17 16:48:01.966953: train_loss -0.8663 
2025-12-17 16:48:01.966953: val_loss -0.8909 
2025-12-17 16:48:01.982772: Pseudo dice [0.9355, 0.963, 0.9409] 
2025-12-17 16:48:01.990150: Epoch time: 137.94 s 
2025-12-17 16:48:02.792415:  
2025-12-17 16:48:02.792415: Epoch 983 
2025-12-17 16:48:02.803123: Current learning rate: 0.00026 
2025-12-17 16:50:20.867853: train_loss -0.8635 
2025-12-17 16:50:20.869856: val_loss -0.8834 
2025-12-17 16:50:20.879611: Pseudo dice [0.9338, 0.9601, 0.9273] 
2025-12-17 16:50:20.887623: Epoch time: 138.08 s 
2025-12-17 16:50:21.648881:  
2025-12-17 16:50:21.648881: Epoch 984 
2025-12-17 16:50:21.648881: Current learning rate: 0.00024 
2025-12-17 16:52:39.644253: train_loss -0.8663 
2025-12-17 16:52:39.644253: val_loss -0.8857 
2025-12-17 16:52:39.664057: Pseudo dice [0.9311, 0.9598, 0.9419] 
2025-12-17 16:52:39.670063: Epoch time: 138.0 s 
2025-12-17 16:52:40.308290:  
2025-12-17 16:52:40.308290: Epoch 985 
2025-12-17 16:52:40.308290: Current learning rate: 0.00023 
2025-12-17 16:54:58.263665: train_loss -0.8687 
2025-12-17 16:54:58.263665: val_loss -0.8893 
2025-12-17 16:54:58.271672: Pseudo dice [0.9342, 0.9614, 0.9455] 
2025-12-17 16:54:58.277417: Epoch time: 137.96 s 
2025-12-17 16:54:58.955588:  
2025-12-17 16:54:58.955588: Epoch 986 
2025-12-17 16:54:58.955588: Current learning rate: 0.00021 
2025-12-17 16:57:16.930303: train_loss -0.8681 
2025-12-17 16:57:16.930303: val_loss -0.8713 
2025-12-17 16:57:16.940057: Pseudo dice [0.9238, 0.9545, 0.9389] 
2025-12-17 16:57:16.946067: Epoch time: 137.97 s 
2025-12-17 16:57:17.706918:  
2025-12-17 16:57:17.706918: Epoch 987 
2025-12-17 16:57:17.706918: Current learning rate: 0.0002 
2025-12-17 16:59:35.677908: train_loss -0.8658 
2025-12-17 16:59:35.677908: val_loss -0.8797 
2025-12-17 16:59:35.699969: Pseudo dice [0.9285, 0.9579, 0.9349] 
2025-12-17 16:59:35.699969: Epoch time: 137.97 s 
2025-12-17 16:59:36.342444:  
2025-12-17 16:59:36.342444: Epoch 988 
2025-12-17 16:59:36.342444: Current learning rate: 0.00019 
2025-12-17 17:01:54.392209: train_loss -0.8619 
2025-12-17 17:01:54.392209: val_loss -0.8824 
2025-12-17 17:01:54.402663: Pseudo dice [0.9295, 0.9609, 0.9321] 
2025-12-17 17:01:54.410271: Epoch time: 138.05 s 
2025-12-17 17:01:55.262354:  
2025-12-17 17:01:55.262354: Epoch 989 
2025-12-17 17:01:55.262354: Current learning rate: 0.00017 
2025-12-17 17:04:13.373979: train_loss -0.8652 
2025-12-17 17:04:13.373979: val_loss -0.8881 
2025-12-17 17:04:13.383732: Pseudo dice [0.933, 0.9616, 0.9416] 
2025-12-17 17:04:13.389740: Epoch time: 138.11 s 
2025-12-17 17:04:14.135818:  
2025-12-17 17:04:14.135818: Epoch 990 
2025-12-17 17:04:14.149598: Current learning rate: 0.00016 
2025-12-17 17:06:32.216658: train_loss -0.8643 
2025-12-17 17:06:32.216658: val_loss -0.8838 
2025-12-17 17:06:32.231327: Pseudo dice [0.9291, 0.958, 0.9412] 
2025-12-17 17:06:32.234164: Epoch time: 138.08 s 
2025-12-17 17:06:32.897905:  
2025-12-17 17:06:32.897905: Epoch 991 
2025-12-17 17:06:32.897905: Current learning rate: 0.00014 
2025-12-17 17:08:52.063588: train_loss -0.8629 
2025-12-17 17:08:52.065591: val_loss -0.8798 
2025-12-17 17:08:52.070598: Pseudo dice [0.9278, 0.9565, 0.9392] 
2025-12-17 17:08:52.079388: Epoch time: 139.18 s 
2025-12-17 17:08:52.716103:  
2025-12-17 17:08:52.716103: Epoch 992 
2025-12-17 17:08:52.716103: Current learning rate: 0.00013 
2025-12-17 17:11:11.413685: train_loss -0.8717 
2025-12-17 17:11:11.413685: val_loss -0.8814 
2025-12-17 17:11:11.417199: Pseudo dice [0.9241, 0.9602, 0.9504] 
2025-12-17 17:11:11.429659: Epoch time: 138.7 s 
2025-12-17 17:11:12.150451:  
2025-12-17 17:11:12.150451: Epoch 993 
2025-12-17 17:11:12.150451: Current learning rate: 0.00011 
2025-12-17 17:13:30.531043: train_loss -0.8655 
2025-12-17 17:13:30.531043: val_loss -0.8911 
2025-12-17 17:13:30.531043: Pseudo dice [0.9382, 0.9622, 0.9414] 
2025-12-17 17:13:30.531043: Epoch time: 138.38 s 
2025-12-17 17:13:31.164844:  
2025-12-17 17:13:31.164844: Epoch 994 
2025-12-17 17:13:31.182654: Current learning rate: 0.0001 
2025-12-17 17:15:49.610341: train_loss -0.865 
2025-12-17 17:15:49.610341: val_loss -0.8859 
2025-12-17 17:15:49.610341: Pseudo dice [0.936, 0.965, 0.9334] 
2025-12-17 17:15:49.626030: Epoch time: 138.45 s 
2025-12-17 17:15:50.419568:  
2025-12-17 17:15:50.419568: Epoch 995 
2025-12-17 17:15:50.435199: Current learning rate: 8e-05 
2025-12-17 17:18:08.936252: train_loss -0.8676 
2025-12-17 17:18:08.936252: val_loss -0.887 
2025-12-17 17:18:08.946001: Pseudo dice [0.928, 0.9581, 0.9477] 
2025-12-17 17:18:08.946001: Epoch time: 138.52 s 
2025-12-17 17:18:09.657409:  
2025-12-17 17:18:09.657409: Epoch 996 
2025-12-17 17:18:09.665639: Current learning rate: 7e-05 
2025-12-17 17:20:27.665613: train_loss -0.8683 
2025-12-17 17:20:27.681610: val_loss -0.8814 
2025-12-17 17:20:27.689618: Pseudo dice [0.9283, 0.9589, 0.9403] 
2025-12-17 17:20:27.695100: Epoch time: 138.01 s 
2025-12-17 17:20:28.331136:  
2025-12-17 17:20:28.331136: Epoch 997 
2025-12-17 17:20:28.331136: Current learning rate: 5e-05 
2025-12-17 17:22:46.372478: train_loss -0.864 
2025-12-17 17:22:46.372478: val_loss -0.878 
2025-12-17 17:22:46.388383: Pseudo dice [0.9273, 0.9553, 0.9421] 
2025-12-17 17:22:46.388383: Epoch time: 138.04 s 
2025-12-17 17:22:47.022077:  
2025-12-17 17:22:47.022077: Epoch 998 
2025-12-17 17:22:47.022077: Current learning rate: 4e-05 
2025-12-17 17:25:05.056607: train_loss -0.8683 
2025-12-17 17:25:05.056607: val_loss -0.8819 
2025-12-17 17:25:05.067353: Pseudo dice [0.9287, 0.9606, 0.9399] 
2025-12-17 17:25:05.073362: Epoch time: 138.03 s 
2025-12-17 17:25:05.823336:  
2025-12-17 17:25:05.823336: Epoch 999 
2025-12-17 17:25:05.839298: Current learning rate: 2e-05 
2025-12-17 17:27:23.828034: train_loss -0.8646 
2025-12-17 17:27:23.828034: val_loss -0.885 
2025-12-17 17:27:23.842091: Pseudo dice [0.9274, 0.9555, 0.9482] 
2025-12-17 17:27:23.842091: Epoch time: 138.0 s 
2025-12-17 17:27:24.932116: Training done. 
2025-12-17 17:27:25.016740: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-17 17:27:25.016740: The split file contains 5 splits. 
2025-12-17 17:27:25.032480: Desired fold for training: 1 
2025-12-17 17:27:25.041595: This split has 400 training and 100 validation cases. 
2025-12-17 17:27:25.048491: predicting OAS30014_MR_d0196_3 
2025-12-17 17:27:25.222425: OAS30014_MR_d0196_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:27:45.379035: predicting OAS30014_MR_d0196_4 
2025-12-17 17:27:45.394890: OAS30014_MR_d0196_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:28:02.179777: predicting OAS30017_MR_d0054_6 
2025-12-17 17:28:02.187159: OAS30017_MR_d0054_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:28:18.992092: predicting OAS30017_MR_d0054_7 
2025-12-17 17:28:19.008009: OAS30017_MR_d0054_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:28:35.822875: predicting OAS30017_MR_d0054_8 
2025-12-17 17:28:35.832824: OAS30017_MR_d0054_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:28:52.651367: predicting OAS30025_MR_d0210_1 
2025-12-17 17:28:52.671181: OAS30025_MR_d0210_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:29:09.474107: predicting OAS30025_MR_d0210_2 
2025-12-17 17:29:09.483663: OAS30025_MR_d0210_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:29:26.310576: predicting OAS30036_MR_d0059_1 
2025-12-17 17:29:26.328024: OAS30036_MR_d0059_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:29:43.129139: predicting OAS30036_MR_d0059_10 
2025-12-17 17:29:43.146597: OAS30036_MR_d0059_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:29:59.958431: predicting OAS30036_MR_d0059_5 
2025-12-17 17:29:59.965180: OAS30036_MR_d0059_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:30:16.818753: predicting OAS30036_MR_d0059_8 
2025-12-17 17:30:16.838535: OAS30036_MR_d0059_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:30:33.630441: predicting OAS30039_MR_d1203_6 
2025-12-17 17:30:33.646527: OAS30039_MR_d1203_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:30:50.472993: predicting OAS30052_MR_d0693_1 
2025-12-17 17:30:50.482827: OAS30052_MR_d0693_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:31:07.293071: predicting OAS30052_MR_d0693_10 
2025-12-17 17:31:07.314771: OAS30052_MR_d0693_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:31:24.096781: predicting OAS30052_MR_d0693_4 
2025-12-17 17:31:24.118437: OAS30052_MR_d0693_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:31:40.960650: predicting OAS30078_MR_d0210_1 
2025-12-17 17:31:40.978176: OAS30078_MR_d0210_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:31:57.762589: predicting OAS30078_MR_d0210_7 
2025-12-17 17:31:57.778593: OAS30078_MR_d0210_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:32:14.573452: predicting OAS30083_MR_d0465_3 
2025-12-17 17:32:14.596919: OAS30083_MR_d0465_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:32:31.418804: predicting OAS30083_MR_d0465_5 
2025-12-17 17:32:31.428323: OAS30083_MR_d0465_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:32:48.224614: predicting OAS30087_MR_d0260_4 
2025-12-17 17:32:48.234063: OAS30087_MR_d0260_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:33:05.037126: predicting OAS30087_MR_d0260_7 
2025-12-17 17:33:05.053249: OAS30087_MR_d0260_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:33:21.890230: predicting OAS30087_MR_d0260_8 
2025-12-17 17:33:21.912544: OAS30087_MR_d0260_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:33:38.694189: predicting OAS30102_MR_d0024_6 
2025-12-17 17:33:38.710305: OAS30102_MR_d0024_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:33:55.494685: predicting OAS30104_MR_d0328_2 
2025-12-17 17:33:55.510473: OAS30104_MR_d0328_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:34:12.311588: predicting OAS30104_MR_d0328_3 
2025-12-17 17:34:12.321607: OAS30104_MR_d0328_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:34:29.116329: predicting OAS30107_MR_d0387_8 
2025-12-17 17:34:29.129184: OAS30107_MR_d0387_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:34:45.991322: predicting OAS30125_MR_d0201_2 
2025-12-17 17:34:46.000592: OAS30125_MR_d0201_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:35:02.793149: predicting OAS30125_MR_d0201_7 
2025-12-17 17:35:02.803167: OAS30125_MR_d0201_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:35:19.595599: predicting OAS30134_MR_d0080_6 
2025-12-17 17:35:19.607733: OAS30134_MR_d0080_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:35:36.413559: predicting OAS30134_MR_d0080_7 
2025-12-17 17:35:36.422626: OAS30134_MR_d0080_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:35:53.213173: predicting OAS30134_MR_d0080_8 
2025-12-17 17:35:53.225691: OAS30134_MR_d0080_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:36:10.036287: predicting OAS30140_MR_d0172_1 
2025-12-17 17:36:10.043875: OAS30140_MR_d0172_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:36:26.834854: predicting OAS30140_MR_d0172_10 
2025-12-17 17:36:26.857645: OAS30140_MR_d0172_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:36:43.656661: predicting OAS30140_MR_d0172_2 
2025-12-17 17:36:43.664675: OAS30140_MR_d0172_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:37:00.454638: predicting OAS30140_MR_d0172_4 
2025-12-17 17:37:00.466972: OAS30140_MR_d0172_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:37:17.313198: predicting OAS30140_MR_d0172_8 
2025-12-17 17:37:17.330995: OAS30140_MR_d0172_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:37:34.142612: predicting OAS30140_MR_d0172_9 
2025-12-17 17:37:34.162432: OAS30140_MR_d0172_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:37:50.941386: predicting OAS30165_MR_d1763_2 
2025-12-17 17:37:50.965321: OAS30165_MR_d1763_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:38:07.809006: predicting OAS30165_MR_d1763_6 
2025-12-17 17:38:07.833379: OAS30165_MR_d1763_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:38:24.626865: predicting OAS30167_MR_d0111_1 
2025-12-17 17:38:24.640758: OAS30167_MR_d0111_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:38:41.474992: predicting OAS30167_MR_d0111_7 
2025-12-17 17:38:41.489101: OAS30167_MR_d0111_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:38:58.281679: predicting OAS30176_MR_d0000_4 
2025-12-17 17:38:58.301457: OAS30176_MR_d0000_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:39:15.089763: predicting OAS30176_MR_d0000_6 
2025-12-17 17:39:15.102910: OAS30176_MR_d0000_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:39:31.875669: predicting OAS30176_MR_d0000_7 
2025-12-17 17:39:31.897512: OAS30176_MR_d0000_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:39:48.692472: predicting OAS30195_MR_d1596_3 
2025-12-17 17:39:48.704287: OAS30195_MR_d1596_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:40:05.542220: predicting OAS30195_MR_d1596_5 
2025-12-17 17:40:05.550173: OAS30195_MR_d1596_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:40:22.348366: predicting OAS30195_MR_d1596_9 
2025-12-17 17:40:22.357858: OAS30195_MR_d1596_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:40:39.193252: predicting OAS30226_MR_d0183_3 
2025-12-17 17:40:39.203053: OAS30226_MR_d0183_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:40:56.030679: predicting OAS30234_MR_d2098_1 
2025-12-17 17:40:56.044293: OAS30234_MR_d2098_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:41:12.842300: predicting OAS30234_MR_d2098_4 
2025-12-17 17:41:12.850538: OAS30234_MR_d2098_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:41:29.667969: predicting OAS30234_MR_d2098_7 
2025-12-17 17:41:29.691296: OAS30234_MR_d2098_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:41:46.469872: predicting OAS30238_MR_d0037_6 
2025-12-17 17:41:46.487938: OAS30238_MR_d0037_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:42:03.276319: predicting OAS30250_MR_d0389_1 
2025-12-17 17:42:03.292402: OAS30250_MR_d0389_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:42:20.117654: predicting OAS30250_MR_d0389_8 
2025-12-17 17:42:20.133415: OAS30250_MR_d0389_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:42:36.973876: predicting OAS30262_MR_d0037_2 
2025-12-17 17:42:36.982370: OAS30262_MR_d0037_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:42:53.764300: predicting OAS30274_MR_d3332_6 
2025-12-17 17:42:53.781956: OAS30274_MR_d3332_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:43:10.617465: predicting OAS30297_MR_d1712_1 
2025-12-17 17:43:10.625216: OAS30297_MR_d1712_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:43:27.402890: predicting OAS30297_MR_d1712_10 
2025-12-17 17:43:27.420839: OAS30297_MR_d1712_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:43:44.228183: predicting OAS30297_MR_d1712_6 
2025-12-17 17:43:44.237394: OAS30297_MR_d1712_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:44:01.073708: predicting OAS30300_MR_d0100_1 
2025-12-17 17:44:01.083220: OAS30300_MR_d0100_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:44:17.936025: predicting OAS30300_MR_d0100_5 
2025-12-17 17:44:17.957546: OAS30300_MR_d0100_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:44:34.771583: predicting OAS30302_MR_d0262_2 
2025-12-17 17:44:34.784778: OAS30302_MR_d0262_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:44:51.600384: predicting OAS30302_MR_d0262_4 
2025-12-17 17:44:51.620322: OAS30302_MR_d0262_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:45:08.448874: predicting OAS30306_MR_d0028_3 
2025-12-17 17:45:08.466544: OAS30306_MR_d0028_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:45:25.300864: predicting OAS30306_MR_d0028_4 
2025-12-17 17:45:25.316677: OAS30306_MR_d0028_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:45:42.138417: predicting OAS30306_MR_d0028_6 
2025-12-17 17:45:42.156516: OAS30306_MR_d0028_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:45:58.961079: predicting OAS30306_MR_d0028_7 
2025-12-17 17:45:58.974945: OAS30306_MR_d0028_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:46:15.826523: predicting OAS30306_MR_d0028_9 
2025-12-17 17:46:15.835052: OAS30306_MR_d0028_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:46:32.639658: predicting OAS30321_MR_d3003_5 
2025-12-17 17:46:32.656971: OAS30321_MR_d3003_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:46:49.431403: predicting OAS30325_MR_d0032_10 
2025-12-17 17:46:49.451076: OAS30325_MR_d0032_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:47:06.287519: predicting OAS30325_MR_d0032_5 
2025-12-17 17:47:06.303479: OAS30325_MR_d0032_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:47:23.101742: predicting OAS30343_MR_d4178_1 
2025-12-17 17:47:23.109248: OAS30343_MR_d4178_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:47:39.920804: predicting OAS30343_MR_d4178_10 
2025-12-17 17:47:39.929818: OAS30343_MR_d4178_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:47:56.711656: predicting OAS30343_MR_d4178_5 
2025-12-17 17:47:56.735264: OAS30343_MR_d4178_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:48:13.522372: predicting OAS30350_MR_d0018_6 
2025-12-17 17:48:13.544046: OAS30350_MR_d0018_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:48:30.386886: predicting OAS30350_MR_d0018_8 
2025-12-17 17:48:30.401292: OAS30350_MR_d0018_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:48:47.193133: predicting OAS30352_MR_d0099_8 
2025-12-17 17:48:47.200928: OAS30352_MR_d0099_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:49:04.001901: predicting OAS30355_MR_d0048_2 
2025-12-17 17:49:04.014699: OAS30355_MR_d0048_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:49:20.805187: predicting OAS30355_MR_d0048_4 
2025-12-17 17:49:20.821036: OAS30355_MR_d0048_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:49:37.607079: predicting OAS30355_MR_d0048_9 
2025-12-17 17:49:37.624380: OAS30355_MR_d0048_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:49:54.467251: predicting OAS30361_MR_d1457_10 
2025-12-17 17:49:54.478939: OAS30361_MR_d1457_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:50:11.288388: predicting OAS30361_MR_d1457_6 
2025-12-17 17:50:11.303643: OAS30361_MR_d1457_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:50:28.101683: predicting OAS30367_MR_d1540_3 
2025-12-17 17:50:28.111049: OAS30367_MR_d1540_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:50:44.902414: predicting OAS30367_MR_d1540_4 
2025-12-17 17:50:44.914173: OAS30367_MR_d1540_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:51:01.738238: predicting OAS30367_MR_d1540_9 
2025-12-17 17:51:01.760045: OAS30367_MR_d1540_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:51:18.602253: predicting OAS30371_MR_d0338_2 
2025-12-17 17:51:18.622064: OAS30371_MR_d0338_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:51:35.461982: predicting OAS30371_MR_d0338_4 
2025-12-17 17:51:35.481954: OAS30371_MR_d0338_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:51:52.327212: predicting OAS30373_MR_d1211_4 
2025-12-17 17:51:52.339093: OAS30373_MR_d1211_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:52:09.163268: predicting OAS30373_MR_d1211_5 
2025-12-17 17:52:09.185229: OAS30373_MR_d1211_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:52:25.975944: predicting OAS30373_MR_d1211_6 
2025-12-17 17:52:25.999184: OAS30373_MR_d1211_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:52:42.838923: predicting OAS30380_MR_d3446_5 
2025-12-17 17:52:42.858055: OAS30380_MR_d3446_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:52:59.653346: predicting OAS30380_MR_d3446_7 
2025-12-17 17:52:59.662716: OAS30380_MR_d3446_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:53:16.465717: predicting OAS30380_MR_d3446_8 
2025-12-17 17:53:16.473534: OAS30380_MR_d3446_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:53:33.257604: predicting OAS30383_MR_d0134_3 
2025-12-17 17:53:33.267717: OAS30383_MR_d0134_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:53:50.067072: predicting OAS30383_MR_d0134_4 
2025-12-17 17:53:50.082973: OAS30383_MR_d0134_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:54:06.928697: predicting OAS30383_MR_d0134_7 
2025-12-17 17:54:06.938531: OAS30383_MR_d0134_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:54:23.782951: predicting OAS30388_MR_d0073_3 
2025-12-17 17:54:23.796507: OAS30388_MR_d0073_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:54:40.584112: predicting OAS30388_MR_d0073_4 
2025-12-17 17:54:40.593693: OAS30388_MR_d0073_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:54:57.391587: predicting OAS30388_MR_d0073_5 
2025-12-17 17:54:57.403281: OAS30388_MR_d0073_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:55:14.243497: predicting OAS30388_MR_d0073_9 
2025-12-17 17:55:14.253139: OAS30388_MR_d0073_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-17 17:55:55.948436: Validation complete 
2025-12-17 17:55:55.948436: Mean Validation Dice:  0.9334803764188582 
