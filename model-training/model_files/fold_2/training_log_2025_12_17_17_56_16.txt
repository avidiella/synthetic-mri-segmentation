
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-12-17 17:56:16.709739: do_dummy_2d_data_aug: False 
2025-12-17 17:56:16.709739: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-17 17:56:16.725434: The split file contains 5 splits. 
2025-12-17 17:56:16.725434: Desired fold for training: 2 
2025-12-17 17:56:16.725434: This split has 400 training and 100 validation cases. 
2025-12-17 17:56:49.462181: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [202, 202, 202], 'spacing': [1.2667700813876164, 1.2667700813876164, 1.2667700813876164], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset500_MRI', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [256, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0000001192092896, 'mean': 0.422696590423584, 'median': 0.4194243550300598, 'min': 0.0027002037968486547, 'percentile_00_5': 0.05628390982747078, 'percentile_99_5': 0.8565635681152344, 'std': 0.19347868859767914}}} 
 
2025-12-17 17:56:49.462181: unpacking dataset... 
2025-12-17 17:56:50.016427: unpacking done... 
2025-12-17 17:56:50.030502: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-12-17 17:56:50.062064:  
2025-12-17 17:56:50.062064: Epoch 0 
2025-12-17 17:56:50.062064: Current learning rate: 0.01 
2025-12-17 17:59:17.804329: train_loss 0.2179 
2025-12-17 17:59:17.804329: val_loss 0.0076 
2025-12-17 17:59:17.804329: Pseudo dice [0.4868, 0.5665, 0.006] 
2025-12-17 17:59:17.804329: Epoch time: 147.74 s 
2025-12-17 17:59:17.804329: Yayy! New best EMA pseudo Dice: 0.3531 
2025-12-17 17:59:18.691542:  
2025-12-17 17:59:18.691542: Epoch 1 
2025-12-17 17:59:18.691542: Current learning rate: 0.00999 
2025-12-17 18:01:36.741355: train_loss -0.0391 
2025-12-17 18:01:36.741355: val_loss -0.1364 
2025-12-17 18:01:36.756998: Pseudo dice [0.5906, 0.5625, 0.3901] 
2025-12-17 18:01:36.756998: Epoch time: 138.05 s 
2025-12-17 18:01:36.756998: Yayy! New best EMA pseudo Dice: 0.3692 
2025-12-17 18:01:37.758195:  
2025-12-17 18:01:37.758195: Epoch 2 
2025-12-17 18:01:37.758195: Current learning rate: 0.00998 
2025-12-17 18:03:55.764667: train_loss -0.1426 
2025-12-17 18:03:55.764667: val_loss -0.1792 
2025-12-17 18:03:55.764667: Pseudo dice [0.5713, 0.5924, 0.4537] 
2025-12-17 18:03:55.764667: Epoch time: 138.01 s 
2025-12-17 18:03:55.764667: Yayy! New best EMA pseudo Dice: 0.3862 
2025-12-17 18:03:56.699483:  
2025-12-17 18:03:56.699483: Epoch 3 
2025-12-17 18:03:56.699483: Current learning rate: 0.00997 
2025-12-17 18:06:14.805130: train_loss -0.2112 
2025-12-17 18:06:14.807133: val_loss -0.2543 
2025-12-17 18:06:14.807133: Pseudo dice [0.5849, 0.6672, 0.4747] 
2025-12-17 18:06:14.807133: Epoch time: 138.11 s 
2025-12-17 18:06:14.809135: Yayy! New best EMA pseudo Dice: 0.4051 
2025-12-17 18:06:15.700555:  
2025-12-17 18:06:15.700555: Epoch 4 
2025-12-17 18:06:15.700555: Current learning rate: 0.00996 
2025-12-17 18:08:33.641817: train_loss -0.2474 
2025-12-17 18:08:33.641817: val_loss -0.3016 
2025-12-17 18:08:33.641817: Pseudo dice [0.625, 0.7103, 0.5672] 
2025-12-17 18:08:33.643819: Epoch time: 137.94 s 
2025-12-17 18:08:33.643819: Yayy! New best EMA pseudo Dice: 0.4281 
2025-12-17 18:08:34.579304:  
2025-12-17 18:08:34.579304: Epoch 5 
2025-12-17 18:08:34.579304: Current learning rate: 0.00995 
2025-12-17 18:10:53.152526: train_loss -0.303 
2025-12-17 18:10:53.152526: val_loss -0.3369 
2025-12-17 18:10:53.154528: Pseudo dice [0.665, 0.6982, 0.6012] 
2025-12-17 18:10:53.154528: Epoch time: 138.58 s 
2025-12-17 18:10:53.154528: Yayy! New best EMA pseudo Dice: 0.4507 
2025-12-17 18:10:54.051890:  
2025-12-17 18:10:54.051890: Epoch 6 
2025-12-17 18:10:54.051890: Current learning rate: 0.00995 
2025-12-17 18:13:11.904171: train_loss -0.3514 
2025-12-17 18:13:11.906173: val_loss -0.3809 
2025-12-17 18:13:11.906173: Pseudo dice [0.7151, 0.7655, 0.6052] 
2025-12-17 18:13:11.906173: Epoch time: 137.85 s 
2025-12-17 18:13:11.906173: Yayy! New best EMA pseudo Dice: 0.4752 
2025-12-17 18:13:12.961550:  
2025-12-17 18:13:12.961550: Epoch 7 
2025-12-17 18:13:12.961550: Current learning rate: 0.00994 
2025-12-17 18:15:30.984675: train_loss -0.3971 
2025-12-17 18:15:30.984675: val_loss -0.4377 
2025-12-17 18:15:30.984675: Pseudo dice [0.7391, 0.8101, 0.6489] 
2025-12-17 18:15:30.984675: Epoch time: 138.02 s 
2025-12-17 18:15:30.984675: Yayy! New best EMA pseudo Dice: 0.5009 
2025-12-17 18:15:31.905145:  
2025-12-17 18:15:31.905145: Epoch 8 
2025-12-17 18:15:31.905145: Current learning rate: 0.00993 
2025-12-17 18:17:49.836045: train_loss -0.4282 
2025-12-17 18:17:49.836045: val_loss -0.4583 
2025-12-17 18:17:49.836045: Pseudo dice [0.7583, 0.8055, 0.6718] 
2025-12-17 18:17:49.836045: Epoch time: 137.93 s 
2025-12-17 18:17:49.836045: Yayy! New best EMA pseudo Dice: 0.5254 
2025-12-17 18:17:50.765044:  
2025-12-17 18:17:50.765044: Epoch 9 
2025-12-17 18:17:50.765044: Current learning rate: 0.00992 
2025-12-17 18:20:10.429959: train_loss -0.4666 
2025-12-17 18:20:10.429959: val_loss -0.5072 
2025-12-17 18:20:10.431962: Pseudo dice [0.7716, 0.8404, 0.6826] 
2025-12-17 18:20:10.433965: Epoch time: 139.67 s 
2025-12-17 18:20:10.433965: Yayy! New best EMA pseudo Dice: 0.5493 
2025-12-17 18:20:11.307694:  
2025-12-17 18:20:11.307694: Epoch 10 
2025-12-17 18:20:11.307694: Current learning rate: 0.00991 
2025-12-17 18:22:29.921240: train_loss -0.5081 
2025-12-17 18:22:29.921240: val_loss -0.5405 
2025-12-17 18:22:29.923244: Pseudo dice [0.8054, 0.8471, 0.6997] 
2025-12-17 18:22:29.923244: Epoch time: 138.61 s 
2025-12-17 18:22:29.923244: Yayy! New best EMA pseudo Dice: 0.5728 
2025-12-17 18:22:30.905688:  
2025-12-17 18:22:30.905688: Epoch 11 
2025-12-17 18:22:30.905688: Current learning rate: 0.0099 
2025-12-17 18:24:49.783363: train_loss -0.5209 
2025-12-17 18:24:49.783363: val_loss -0.5456 
2025-12-17 18:24:49.785364: Pseudo dice [0.7906, 0.8655, 0.7217] 
2025-12-17 18:24:49.785364: Epoch time: 138.88 s 
2025-12-17 18:24:49.787366: Yayy! New best EMA pseudo Dice: 0.5948 
2025-12-17 18:24:50.690579:  
2025-12-17 18:24:50.690579: Epoch 12 
2025-12-17 18:24:50.690579: Current learning rate: 0.00989 
2025-12-17 18:27:09.155813: train_loss -0.5525 
2025-12-17 18:27:09.155813: val_loss -0.5766 
2025-12-17 18:27:09.155813: Pseudo dice [0.8202, 0.8639, 0.745] 
2025-12-17 18:27:09.155813: Epoch time: 138.47 s 
2025-12-17 18:27:09.155813: Yayy! New best EMA pseudo Dice: 0.6163 
2025-12-17 18:27:10.254063:  
2025-12-17 18:27:10.254063: Epoch 13 
2025-12-17 18:27:10.254063: Current learning rate: 0.00988 
2025-12-17 18:29:28.864235: train_loss -0.5835 
2025-12-17 18:29:28.864235: val_loss -0.6054 
2025-12-17 18:29:28.866237: Pseudo dice [0.8253, 0.8791, 0.7683] 
2025-12-17 18:29:28.866237: Epoch time: 138.61 s 
2025-12-17 18:29:28.866237: Yayy! New best EMA pseudo Dice: 0.6371 
2025-12-17 18:29:29.778209:  
2025-12-17 18:29:29.780268: Epoch 14 
2025-12-17 18:29:29.780268: Current learning rate: 0.00987 
2025-12-17 18:31:47.811123: train_loss -0.5976 
2025-12-17 18:31:47.811123: val_loss -0.5887 
2025-12-17 18:31:47.813125: Pseudo dice [0.8101, 0.8761, 0.7851] 
2025-12-17 18:31:47.813125: Epoch time: 138.03 s 
2025-12-17 18:31:47.815128: Yayy! New best EMA pseudo Dice: 0.6557 
2025-12-17 18:31:48.710734:  
2025-12-17 18:31:48.712736: Epoch 15 
2025-12-17 18:31:48.712736: Current learning rate: 0.00986 
2025-12-17 18:34:06.871212: train_loss -0.6009 
2025-12-17 18:34:06.871212: val_loss -0.6223 
2025-12-17 18:34:06.873215: Pseudo dice [0.8242, 0.8763, 0.799] 
2025-12-17 18:34:06.873215: Epoch time: 138.16 s 
2025-12-17 18:34:06.873215: Yayy! New best EMA pseudo Dice: 0.6735 
2025-12-17 18:34:07.780793:  
2025-12-17 18:34:07.780793: Epoch 16 
2025-12-17 18:34:07.780793: Current learning rate: 0.00986 
2025-12-17 18:36:25.950313: train_loss -0.6143 
2025-12-17 18:36:25.950313: val_loss -0.6359 
2025-12-17 18:36:25.952141: Pseudo dice [0.8266, 0.8921, 0.8072] 
2025-12-17 18:36:25.954144: Epoch time: 138.17 s 
2025-12-17 18:36:25.954144: Yayy! New best EMA pseudo Dice: 0.6903 
2025-12-17 18:36:26.863796:  
2025-12-17 18:36:26.867303: Epoch 17 
2025-12-17 18:36:26.867303: Current learning rate: 0.00985 
2025-12-17 18:38:44.963748: train_loss -0.6322 
2025-12-17 18:38:44.965754: val_loss -0.6523 
2025-12-17 18:38:44.965754: Pseudo dice [0.845, 0.8901, 0.794] 
2025-12-17 18:38:44.967756: Epoch time: 138.1 s 
2025-12-17 18:38:44.967756: Yayy! New best EMA pseudo Dice: 0.7056 
2025-12-17 18:38:45.873746:  
2025-12-17 18:38:45.873746: Epoch 18 
2025-12-17 18:38:45.873746: Current learning rate: 0.00984 
2025-12-17 18:41:03.983516: train_loss -0.6398 
2025-12-17 18:41:03.983516: val_loss -0.6537 
2025-12-17 18:41:03.985518: Pseudo dice [0.8415, 0.9001, 0.8175] 
2025-12-17 18:41:03.987520: Epoch time: 138.11 s 
2025-12-17 18:41:03.987520: Yayy! New best EMA pseudo Dice: 0.7203 
2025-12-17 18:41:05.070933:  
2025-12-17 18:41:05.070933: Epoch 19 
2025-12-17 18:41:05.070933: Current learning rate: 0.00983 
2025-12-17 18:43:23.157877: train_loss -0.642 
2025-12-17 18:43:23.157877: val_loss -0.6566 
2025-12-17 18:43:23.173891: Pseudo dice [0.8379, 0.8893, 0.8239] 
2025-12-17 18:43:23.175744: Epoch time: 138.09 s 
2025-12-17 18:43:23.175744: Yayy! New best EMA pseudo Dice: 0.7333 
2025-12-17 18:43:24.100773:  
2025-12-17 18:43:24.100773: Epoch 20 
2025-12-17 18:43:24.102390: Current learning rate: 0.00982 
2025-12-17 18:45:42.279932: train_loss -0.6556 
2025-12-17 18:45:42.279932: val_loss -0.6624 
2025-12-17 18:45:42.281935: Pseudo dice [0.8473, 0.893, 0.8031] 
2025-12-17 18:45:42.281935: Epoch time: 138.18 s 
2025-12-17 18:45:42.281935: Yayy! New best EMA pseudo Dice: 0.7448 
2025-12-17 18:45:43.199595:  
2025-12-17 18:45:43.199595: Epoch 21 
2025-12-17 18:45:43.199595: Current learning rate: 0.00981 
2025-12-17 18:48:01.466516: train_loss -0.6609 
2025-12-17 18:48:01.466516: val_loss -0.6705 
2025-12-17 18:48:01.468521: Pseudo dice [0.8454, 0.9013, 0.8239] 
2025-12-17 18:48:01.470524: Epoch time: 138.27 s 
2025-12-17 18:48:01.470524: Yayy! New best EMA pseudo Dice: 0.756 
2025-12-17 18:48:02.357714:  
2025-12-17 18:48:02.357714: Epoch 22 
2025-12-17 18:48:02.357714: Current learning rate: 0.0098 
2025-12-17 18:50:20.368460: train_loss -0.6707 
2025-12-17 18:50:20.368460: val_loss -0.6924 
2025-12-17 18:50:20.370462: Pseudo dice [0.8476, 0.9015, 0.848] 
2025-12-17 18:50:20.370462: Epoch time: 138.01 s 
2025-12-17 18:50:20.370462: Yayy! New best EMA pseudo Dice: 0.767 
2025-12-17 18:50:21.273492:  
2025-12-17 18:50:21.273492: Epoch 23 
2025-12-17 18:50:21.274965: Current learning rate: 0.00979 
2025-12-17 18:52:39.565403: train_loss -0.6715 
2025-12-17 18:52:39.565403: val_loss -0.6972 
2025-12-17 18:52:39.565403: Pseudo dice [0.8602, 0.9059, 0.8406] 
2025-12-17 18:52:39.565403: Epoch time: 138.29 s 
2025-12-17 18:52:39.565403: Yayy! New best EMA pseudo Dice: 0.7772 
2025-12-17 18:52:40.445761:  
2025-12-17 18:52:40.445761: Epoch 24 
2025-12-17 18:52:40.445761: Current learning rate: 0.00978 
2025-12-17 18:54:58.644864: train_loss -0.6862 
2025-12-17 18:54:58.644864: val_loss -0.6928 
2025-12-17 18:54:58.646866: Pseudo dice [0.8516, 0.9061, 0.8515] 
2025-12-17 18:54:58.646866: Epoch time: 138.2 s 
2025-12-17 18:54:58.646866: Yayy! New best EMA pseudo Dice: 0.7864 
2025-12-17 18:54:59.712475:  
2025-12-17 18:54:59.714382: Epoch 25 
2025-12-17 18:54:59.714382: Current learning rate: 0.00977 
2025-12-17 18:57:17.971559: train_loss -0.6993 
2025-12-17 18:57:17.971559: val_loss -0.701 
2025-12-17 18:57:17.973300: Pseudo dice [0.8658, 0.9104, 0.8369] 
2025-12-17 18:57:17.973300: Epoch time: 138.26 s 
2025-12-17 18:57:17.973300: Yayy! New best EMA pseudo Dice: 0.7949 
2025-12-17 18:57:18.858812:  
2025-12-17 18:57:18.862506: Epoch 26 
2025-12-17 18:57:18.862506: Current learning rate: 0.00977 
2025-12-17 18:59:36.896723: train_loss -0.7029 
2025-12-17 18:59:36.896723: val_loss -0.7167 
2025-12-17 18:59:36.896723: Pseudo dice [0.8632, 0.9095, 0.8503] 
2025-12-17 18:59:36.896723: Epoch time: 138.04 s 
2025-12-17 18:59:36.896723: Yayy! New best EMA pseudo Dice: 0.8028 
2025-12-17 18:59:37.778563:  
2025-12-17 18:59:37.778563: Epoch 27 
2025-12-17 18:59:37.778563: Current learning rate: 0.00976 
2025-12-17 19:01:56.030453: train_loss -0.7075 
2025-12-17 19:01:56.030453: val_loss -0.7147 
2025-12-17 19:01:56.030453: Pseudo dice [0.8672, 0.9144, 0.838] 
2025-12-17 19:01:56.030453: Epoch time: 138.25 s 
2025-12-17 19:01:56.030453: Yayy! New best EMA pseudo Dice: 0.8099 
2025-12-17 19:01:56.926839:  
2025-12-17 19:01:56.928651: Epoch 28 
2025-12-17 19:01:56.928651: Current learning rate: 0.00975 
2025-12-17 19:04:15.114075: train_loss -0.7124 
2025-12-17 19:04:15.116078: val_loss -0.7277 
2025-12-17 19:04:15.116078: Pseudo dice [0.8705, 0.9211, 0.8531] 
2025-12-17 19:04:15.118081: Epoch time: 138.19 s 
2025-12-17 19:04:15.118081: Yayy! New best EMA pseudo Dice: 0.817 
2025-12-17 19:04:16.013627:  
2025-12-17 19:04:16.013627: Epoch 29 
2025-12-17 19:04:16.016074: Current learning rate: 0.00974 
2025-12-17 19:06:34.317065: train_loss -0.7082 
2025-12-17 19:06:34.317065: val_loss -0.7244 
2025-12-17 19:06:34.319068: Pseudo dice [0.8756, 0.9148, 0.8513] 
2025-12-17 19:06:34.319068: Epoch time: 138.31 s 
2025-12-17 19:06:34.320808: Yayy! New best EMA pseudo Dice: 0.8234 
2025-12-17 19:06:35.312697:  
2025-12-17 19:06:35.313701: Epoch 30 
2025-12-17 19:06:35.313701: Current learning rate: 0.00973 
2025-12-17 19:08:53.592438: train_loss -0.7227 
2025-12-17 19:08:53.592438: val_loss -0.7317 
2025-12-17 19:08:53.592438: Pseudo dice [0.8705, 0.914, 0.8664] 
2025-12-17 19:08:53.592438: Epoch time: 138.29 s 
2025-12-17 19:08:53.592438: Yayy! New best EMA pseudo Dice: 0.8294 
2025-12-17 19:08:54.669373:  
2025-12-17 19:08:54.669373: Epoch 31 
2025-12-17 19:08:54.669373: Current learning rate: 0.00972 
2025-12-17 19:11:13.042254: train_loss -0.7185 
2025-12-17 19:11:13.042254: val_loss -0.7299 
2025-12-17 19:11:13.042254: Pseudo dice [0.8761, 0.9224, 0.8562] 
2025-12-17 19:11:13.055819: Epoch time: 138.37 s 
2025-12-17 19:11:13.055819: Yayy! New best EMA pseudo Dice: 0.835 
2025-12-17 19:11:13.942061:  
2025-12-17 19:11:13.942061: Epoch 32 
2025-12-17 19:11:13.942061: Current learning rate: 0.00971 
2025-12-17 19:13:32.068700: train_loss -0.7255 
2025-12-17 19:13:32.070601: val_loss -0.7407 
2025-12-17 19:13:32.072603: Pseudo dice [0.8758, 0.9227, 0.8568] 
2025-12-17 19:13:32.072603: Epoch time: 138.13 s 
2025-12-17 19:13:32.074605: Yayy! New best EMA pseudo Dice: 0.84 
2025-12-17 19:13:33.102107:  
2025-12-17 19:13:33.102107: Epoch 33 
2025-12-17 19:13:33.102107: Current learning rate: 0.0097 
2025-12-17 19:15:51.301232: train_loss -0.7307 
2025-12-17 19:15:51.303235: val_loss -0.7242 
2025-12-17 19:15:51.303235: Pseudo dice [0.8644, 0.9075, 0.8651] 
2025-12-17 19:15:51.303235: Epoch time: 138.2 s 
2025-12-17 19:15:51.303235: Yayy! New best EMA pseudo Dice: 0.8439 
2025-12-17 19:15:52.200319:  
2025-12-17 19:15:52.200319: Epoch 34 
2025-12-17 19:15:52.202322: Current learning rate: 0.00969 
2025-12-17 19:18:10.289271: train_loss -0.7207 
2025-12-17 19:18:10.289271: val_loss -0.7362 
2025-12-17 19:18:10.289271: Pseudo dice [0.8712, 0.919, 0.8699] 
2025-12-17 19:18:10.289271: Epoch time: 138.09 s 
2025-12-17 19:18:10.304928: Yayy! New best EMA pseudo Dice: 0.8482 
2025-12-17 19:18:11.189397:  
2025-12-17 19:18:11.189397: Epoch 35 
2025-12-17 19:18:11.189397: Current learning rate: 0.00968 
2025-12-17 19:20:29.292554: train_loss -0.7307 
2025-12-17 19:20:29.294556: val_loss -0.7522 
2025-12-17 19:20:29.294556: Pseudo dice [0.8747, 0.9239, 0.8831] 
2025-12-17 19:20:29.296558: Epoch time: 138.11 s 
2025-12-17 19:20:29.298061: Yayy! New best EMA pseudo Dice: 0.8527 
2025-12-17 19:20:30.373736:  
2025-12-17 19:20:30.373736: Epoch 36 
2025-12-17 19:20:30.373736: Current learning rate: 0.00968 
2025-12-17 19:22:48.345524: train_loss -0.7394 
2025-12-17 19:22:48.345524: val_loss -0.7624 
2025-12-17 19:22:48.361604: Pseudo dice [0.8925, 0.9319, 0.8647] 
2025-12-17 19:22:48.363609: Epoch time: 137.97 s 
2025-12-17 19:22:48.363609: Yayy! New best EMA pseudo Dice: 0.8571 
2025-12-17 19:22:49.443717:  
2025-12-17 19:22:49.443717: Epoch 37 
2025-12-17 19:22:49.443717: Current learning rate: 0.00967 
2025-12-17 19:25:07.499485: train_loss -0.7464 
2025-12-17 19:25:07.499485: val_loss -0.7529 
2025-12-17 19:25:07.499485: Pseudo dice [0.8826, 0.9277, 0.8661] 
2025-12-17 19:25:07.499485: Epoch time: 138.06 s 
2025-12-17 19:25:07.499485: Yayy! New best EMA pseudo Dice: 0.8606 
2025-12-17 19:25:08.405560:  
2025-12-17 19:25:08.405560: Epoch 38 
2025-12-17 19:25:08.405560: Current learning rate: 0.00966 
2025-12-17 19:27:26.622573: train_loss -0.7236 
2025-12-17 19:27:26.622573: val_loss -0.7341 
2025-12-17 19:27:26.622573: Pseudo dice [0.8694, 0.9173, 0.8672] 
2025-12-17 19:27:26.622573: Epoch time: 138.22 s 
2025-12-17 19:27:26.622573: Yayy! New best EMA pseudo Dice: 0.863 
2025-12-17 19:27:27.671032:  
2025-12-17 19:27:27.671032: Epoch 39 
2025-12-17 19:27:27.681045: Current learning rate: 0.00965 
2025-12-17 19:29:45.712051: train_loss -0.7382 
2025-12-17 19:29:45.712051: val_loss -0.7411 
2025-12-17 19:29:45.712051: Pseudo dice [0.8693, 0.9168, 0.8783] 
2025-12-17 19:29:45.712051: Epoch time: 138.04 s 
2025-12-17 19:29:45.712051: Yayy! New best EMA pseudo Dice: 0.8655 
2025-12-17 19:29:46.640359:  
2025-12-17 19:29:46.640359: Epoch 40 
2025-12-17 19:29:46.640359: Current learning rate: 0.00964 
2025-12-17 19:32:04.791519: train_loss -0.742 
2025-12-17 19:32:04.791519: val_loss -0.751 
2025-12-17 19:32:04.791519: Pseudo dice [0.8756, 0.9226, 0.8774] 
2025-12-17 19:32:04.791519: Epoch time: 138.15 s 
2025-12-17 19:32:04.791519: Yayy! New best EMA pseudo Dice: 0.8682 
2025-12-17 19:32:05.714746:  
2025-12-17 19:32:05.714746: Epoch 41 
2025-12-17 19:32:05.714746: Current learning rate: 0.00963 
2025-12-17 19:34:23.808249: train_loss -0.7446 
2025-12-17 19:34:23.808249: val_loss -0.7507 
2025-12-17 19:34:23.808249: Pseudo dice [0.8755, 0.9201, 0.8748] 
2025-12-17 19:34:23.808249: Epoch time: 138.09 s 
2025-12-17 19:34:23.808249: Yayy! New best EMA pseudo Dice: 0.8704 
2025-12-17 19:34:24.766124:  
2025-12-17 19:34:24.766124: Epoch 42 
2025-12-17 19:34:24.766124: Current learning rate: 0.00962 
2025-12-17 19:36:42.835974: train_loss -0.7433 
2025-12-17 19:36:42.835974: val_loss -0.7481 
2025-12-17 19:36:42.835974: Pseudo dice [0.8716, 0.9193, 0.8743] 
2025-12-17 19:36:42.835974: Epoch time: 138.07 s 
2025-12-17 19:36:42.835974: Yayy! New best EMA pseudo Dice: 0.8722 
2025-12-17 19:36:43.892061:  
2025-12-17 19:36:43.892061: Epoch 43 
2025-12-17 19:36:43.907905: Current learning rate: 0.00961 
2025-12-17 19:39:01.922046: train_loss -0.7455 
2025-12-17 19:39:01.922046: val_loss -0.7539 
2025-12-17 19:39:01.922046: Pseudo dice [0.8788, 0.922, 0.8752] 
2025-12-17 19:39:01.922046: Epoch time: 138.03 s 
2025-12-17 19:39:01.922046: Yayy! New best EMA pseudo Dice: 0.8741 
2025-12-17 19:39:02.806340:  
2025-12-17 19:39:02.806340: Epoch 44 
2025-12-17 19:39:02.806340: Current learning rate: 0.0096 
2025-12-17 19:41:20.831308: train_loss -0.7541 
2025-12-17 19:41:20.831308: val_loss -0.7681 
2025-12-17 19:41:20.833311: Pseudo dice [0.8866, 0.9266, 0.8726] 
2025-12-17 19:41:20.833311: Epoch time: 138.02 s 
2025-12-17 19:41:20.835314: Yayy! New best EMA pseudo Dice: 0.8763 
2025-12-17 19:41:21.751232:  
2025-12-17 19:41:21.751232: Epoch 45 
2025-12-17 19:41:21.751232: Current learning rate: 0.00959 
2025-12-17 19:43:39.677795: train_loss -0.7574 
2025-12-17 19:43:39.677795: val_loss -0.7761 
2025-12-17 19:43:39.677795: Pseudo dice [0.8947, 0.9322, 0.8672] 
2025-12-17 19:43:39.677795: Epoch time: 137.93 s 
2025-12-17 19:43:39.677795: Yayy! New best EMA pseudo Dice: 0.8784 
2025-12-17 19:43:40.584545:  
2025-12-17 19:43:40.584545: Epoch 46 
2025-12-17 19:43:40.584545: Current learning rate: 0.00959 
2025-12-17 19:45:58.745522: train_loss -0.7636 
2025-12-17 19:45:58.745522: val_loss -0.782 
2025-12-17 19:45:58.747526: Pseudo dice [0.8983, 0.9383, 0.8799] 
2025-12-17 19:45:58.747526: Epoch time: 138.16 s 
2025-12-17 19:45:58.747526: Yayy! New best EMA pseudo Dice: 0.8811 
2025-12-17 19:45:59.608194:  
2025-12-17 19:45:59.608194: Epoch 47 
2025-12-17 19:45:59.608194: Current learning rate: 0.00958 
2025-12-17 19:48:17.724097: train_loss -0.7488 
2025-12-17 19:48:17.724097: val_loss -0.7627 
2025-12-17 19:48:17.726099: Pseudo dice [0.8874, 0.9305, 0.8698] 
2025-12-17 19:48:17.728101: Epoch time: 138.12 s 
2025-12-17 19:48:17.728101: Yayy! New best EMA pseudo Dice: 0.8826 
2025-12-17 19:48:18.635992:  
2025-12-17 19:48:18.635992: Epoch 48 
2025-12-17 19:48:18.635992: Current learning rate: 0.00957 
2025-12-17 19:50:37.024578: train_loss -0.7236 
2025-12-17 19:50:37.024578: val_loss -0.7451 
2025-12-17 19:50:37.026581: Pseudo dice [0.8733, 0.9121, 0.8751] 
2025-12-17 19:50:37.028584: Epoch time: 138.39 s 
2025-12-17 19:50:37.028584: Yayy! New best EMA pseudo Dice: 0.883 
2025-12-17 19:50:38.087318:  
2025-12-17 19:50:38.087318: Epoch 49 
2025-12-17 19:50:38.087318: Current learning rate: 0.00956 
2025-12-17 19:52:56.292449: train_loss -0.7453 
2025-12-17 19:52:56.292449: val_loss -0.763 
2025-12-17 19:52:56.292449: Pseudo dice [0.884, 0.9286, 0.8815] 
2025-12-17 19:52:56.292449: Epoch time: 138.22 s 
2025-12-17 19:52:56.546999: Yayy! New best EMA pseudo Dice: 0.8845 
2025-12-17 19:52:57.431479:  
2025-12-17 19:52:57.431479: Epoch 50 
2025-12-17 19:52:57.431479: Current learning rate: 0.00955 
2025-12-17 19:55:15.656975: train_loss -0.7538 
2025-12-17 19:55:15.656975: val_loss -0.7715 
2025-12-17 19:55:15.656975: Pseudo dice [0.8854, 0.9321, 0.8831] 
2025-12-17 19:55:15.662434: Epoch time: 138.23 s 
2025-12-17 19:55:15.662434: Yayy! New best EMA pseudo Dice: 0.8861 
2025-12-17 19:55:16.537007:  
2025-12-17 19:55:16.537007: Epoch 51 
2025-12-17 19:55:16.537007: Current learning rate: 0.00954 
2025-12-17 19:57:34.624240: train_loss -0.7517 
2025-12-17 19:57:34.624240: val_loss -0.776 
2025-12-17 19:57:34.624240: Pseudo dice [0.8896, 0.9321, 0.8847] 
2025-12-17 19:57:34.639914: Epoch time: 138.09 s 
2025-12-17 19:57:34.639914: Yayy! New best EMA pseudo Dice: 0.8877 
2025-12-17 19:57:35.533985:  
2025-12-17 19:57:35.533985: Epoch 52 
2025-12-17 19:57:35.533985: Current learning rate: 0.00953 
2025-12-17 19:59:53.717834: train_loss -0.7666 
2025-12-17 19:59:53.717834: val_loss -0.7935 
2025-12-17 19:59:53.719837: Pseudo dice [0.8941, 0.9313, 0.8983] 
2025-12-17 19:59:53.719837: Epoch time: 138.19 s 
2025-12-17 19:59:53.721839: Yayy! New best EMA pseudo Dice: 0.8897 
2025-12-17 19:59:54.603572:  
2025-12-17 19:59:54.603572: Epoch 53 
2025-12-17 19:59:54.603572: Current learning rate: 0.00952 
2025-12-17 20:02:12.793779: train_loss -0.7658 
2025-12-17 20:02:12.793779: val_loss -0.7938 
2025-12-17 20:02:12.793779: Pseudo dice [0.9022, 0.9395, 0.8834] 
2025-12-17 20:02:12.793779: Epoch time: 138.19 s 
2025-12-17 20:02:12.793779: Yayy! New best EMA pseudo Dice: 0.8916 
2025-12-17 20:02:13.681627:  
2025-12-17 20:02:13.681627: Epoch 54 
2025-12-17 20:02:13.681627: Current learning rate: 0.00951 
2025-12-17 20:04:31.904014: train_loss -0.7684 
2025-12-17 20:04:31.904014: val_loss -0.7926 
2025-12-17 20:04:31.904014: Pseudo dice [0.8937, 0.9341, 0.894] 
2025-12-17 20:04:31.904014: Epoch time: 138.22 s 
2025-12-17 20:04:31.904014: Yayy! New best EMA pseudo Dice: 0.8932 
2025-12-17 20:04:33.057154:  
2025-12-17 20:04:33.057154: Epoch 55 
2025-12-17 20:04:33.059156: Current learning rate: 0.0095 
2025-12-17 20:06:51.138654: train_loss -0.7712 
2025-12-17 20:06:51.138654: val_loss -0.7894 
2025-12-17 20:06:51.138654: Pseudo dice [0.8936, 0.9356, 0.8891] 
2025-12-17 20:06:51.154438: Epoch time: 138.08 s 
2025-12-17 20:06:51.154438: Yayy! New best EMA pseudo Dice: 0.8945 
2025-12-17 20:06:52.036304:  
2025-12-17 20:06:52.036304: Epoch 56 
2025-12-17 20:06:52.036304: Current learning rate: 0.00949 
2025-12-17 20:09:10.423660: train_loss -0.7783 
2025-12-17 20:09:10.423660: val_loss -0.7926 
2025-12-17 20:09:10.423660: Pseudo dice [0.8933, 0.9355, 0.8931] 
2025-12-17 20:09:10.423660: Epoch time: 138.39 s 
2025-12-17 20:09:10.423660: Yayy! New best EMA pseudo Dice: 0.8957 
2025-12-17 20:09:11.321750:  
2025-12-17 20:09:11.321750: Epoch 57 
2025-12-17 20:09:11.321750: Current learning rate: 0.00949 
2025-12-17 20:11:29.865303: train_loss -0.781 
2025-12-17 20:11:29.865303: val_loss -0.7932 
2025-12-17 20:11:29.867987: Pseudo dice [0.8975, 0.9364, 0.886] 
2025-12-17 20:11:29.867987: Epoch time: 138.55 s 
2025-12-17 20:11:29.869989: Yayy! New best EMA pseudo Dice: 0.8968 
2025-12-17 20:11:30.879837:  
2025-12-17 20:11:30.879837: Epoch 58 
2025-12-17 20:11:30.879837: Current learning rate: 0.00948 
2025-12-17 20:13:49.054941: train_loss -0.7843 
2025-12-17 20:13:49.054941: val_loss -0.7942 
2025-12-17 20:13:49.054941: Pseudo dice [0.8993, 0.9355, 0.8802] 
2025-12-17 20:13:49.054941: Epoch time: 138.18 s 
2025-12-17 20:13:49.054941: Yayy! New best EMA pseudo Dice: 0.8976 
2025-12-17 20:13:49.956759:  
2025-12-17 20:13:49.956759: Epoch 59 
2025-12-17 20:13:49.958763: Current learning rate: 0.00947 
2025-12-17 20:16:08.107338: train_loss -0.7816 
2025-12-17 20:16:08.107338: val_loss -0.7996 
2025-12-17 20:16:08.107338: Pseudo dice [0.8965, 0.937, 0.8886] 
2025-12-17 20:16:08.107338: Epoch time: 138.15 s 
2025-12-17 20:16:08.107338: Yayy! New best EMA pseudo Dice: 0.8986 
2025-12-17 20:16:09.003709:  
2025-12-17 20:16:09.003709: Epoch 60 
2025-12-17 20:16:09.003709: Current learning rate: 0.00946 
2025-12-17 20:18:27.214546: train_loss -0.7833 
2025-12-17 20:18:27.214546: val_loss -0.7914 
2025-12-17 20:18:27.216291: Pseudo dice [0.8978, 0.9359, 0.8934] 
2025-12-17 20:18:27.218294: Epoch time: 138.21 s 
2025-12-17 20:18:27.218294: Yayy! New best EMA pseudo Dice: 0.8997 
2025-12-17 20:18:28.446021:  
2025-12-17 20:18:28.448024: Epoch 61 
2025-12-17 20:18:28.448024: Current learning rate: 0.00945 
2025-12-17 20:20:46.639174: train_loss -0.7824 
2025-12-17 20:20:46.639174: val_loss -0.8064 
2025-12-17 20:20:46.639174: Pseudo dice [0.9032, 0.9376, 0.9003] 
2025-12-17 20:20:46.639174: Epoch time: 138.2 s 
2025-12-17 20:20:46.639174: Yayy! New best EMA pseudo Dice: 0.9011 
2025-12-17 20:20:47.542615:  
2025-12-17 20:20:47.542615: Epoch 62 
2025-12-17 20:20:47.542615: Current learning rate: 0.00944 
2025-12-17 20:23:05.653770: train_loss -0.79 
2025-12-17 20:23:05.653770: val_loss -0.8058 
2025-12-17 20:23:05.653770: Pseudo dice [0.907, 0.9434, 0.89] 
2025-12-17 20:23:05.653770: Epoch time: 138.11 s 
2025-12-17 20:23:05.653770: Yayy! New best EMA pseudo Dice: 0.9023 
2025-12-17 20:23:06.561703:  
2025-12-17 20:23:06.561703: Epoch 63 
2025-12-17 20:23:06.561703: Current learning rate: 0.00943 
2025-12-17 20:25:24.674072: train_loss -0.7888 
2025-12-17 20:25:24.674072: val_loss -0.8082 
2025-12-17 20:25:24.674072: Pseudo dice [0.9041, 0.9426, 0.9036] 
2025-12-17 20:25:24.674072: Epoch time: 138.11 s 
2025-12-17 20:25:24.674072: Yayy! New best EMA pseudo Dice: 0.9037 
2025-12-17 20:25:25.690915:  
2025-12-17 20:25:25.690915: Epoch 64 
2025-12-17 20:25:25.698632: Current learning rate: 0.00942 
2025-12-17 20:27:43.799008: train_loss -0.7882 
2025-12-17 20:27:43.799008: val_loss -0.8069 
2025-12-17 20:27:43.801011: Pseudo dice [0.8968, 0.939, 0.9073] 
2025-12-17 20:27:43.801011: Epoch time: 138.11 s 
2025-12-17 20:27:43.803014: Yayy! New best EMA pseudo Dice: 0.9048 
2025-12-17 20:27:44.703354:  
2025-12-17 20:27:44.703354: Epoch 65 
2025-12-17 20:27:44.703354: Current learning rate: 0.00941 
2025-12-17 20:30:03.014868: train_loss -0.7882 
2025-12-17 20:30:03.016870: val_loss -0.8072 
2025-12-17 20:30:03.016870: Pseudo dice [0.8957, 0.9332, 0.9137] 
2025-12-17 20:30:03.020011: Epoch time: 138.31 s 
2025-12-17 20:30:03.020011: Yayy! New best EMA pseudo Dice: 0.9057 
2025-12-17 20:30:03.909886:  
2025-12-17 20:30:03.909886: Epoch 66 
2025-12-17 20:30:03.909886: Current learning rate: 0.0094 
2025-12-17 20:32:22.201562: train_loss -0.7865 
2025-12-17 20:32:22.201562: val_loss -0.7902 
2025-12-17 20:32:22.203565: Pseudo dice [0.8887, 0.9308, 0.897] 
2025-12-17 20:32:22.205567: Epoch time: 138.29 s 
2025-12-17 20:32:23.000741:  
2025-12-17 20:32:23.000741: Epoch 67 
2025-12-17 20:32:23.000741: Current learning rate: 0.00939 
2025-12-17 20:34:41.430257: train_loss -0.7854 
2025-12-17 20:34:41.430257: val_loss -0.8066 
2025-12-17 20:34:41.430257: Pseudo dice [0.9013, 0.934, 0.9092] 
2025-12-17 20:34:41.430257: Epoch time: 138.43 s 
2025-12-17 20:34:41.430257: Yayy! New best EMA pseudo Dice: 0.9066 
2025-12-17 20:34:42.339004:  
2025-12-17 20:34:42.339004: Epoch 68 
2025-12-17 20:34:42.339004: Current learning rate: 0.00939 
2025-12-17 20:37:00.446460: train_loss -0.7934 
2025-12-17 20:37:00.446460: val_loss -0.8103 
2025-12-17 20:37:00.446460: Pseudo dice [0.9033, 0.9425, 0.8981] 
2025-12-17 20:37:00.446460: Epoch time: 138.11 s 
2025-12-17 20:37:00.446460: Yayy! New best EMA pseudo Dice: 0.9074 
2025-12-17 20:37:01.366020:  
2025-12-17 20:37:01.366020: Epoch 69 
2025-12-17 20:37:01.366020: Current learning rate: 0.00938 
2025-12-17 20:39:19.651810: train_loss -0.7851 
2025-12-17 20:39:19.651810: val_loss -0.7938 
2025-12-17 20:39:19.653554: Pseudo dice [0.8915, 0.9328, 0.9099] 
2025-12-17 20:39:19.653554: Epoch time: 138.29 s 
2025-12-17 20:39:19.653554: Yayy! New best EMA pseudo Dice: 0.9078 
2025-12-17 20:39:20.575526:  
2025-12-17 20:39:20.575526: Epoch 70 
2025-12-17 20:39:20.575526: Current learning rate: 0.00937 
2025-12-17 20:41:38.818868: train_loss -0.7865 
2025-12-17 20:41:38.819871: val_loss -0.8069 
2025-12-17 20:41:38.819871: Pseudo dice [0.8995, 0.9349, 0.9079] 
2025-12-17 20:41:38.819871: Epoch time: 138.24 s 
2025-12-17 20:41:38.819871: Yayy! New best EMA pseudo Dice: 0.9085 
2025-12-17 20:41:39.722639:  
2025-12-17 20:41:39.722639: Epoch 71 
2025-12-17 20:41:39.722639: Current learning rate: 0.00936 
2025-12-17 20:43:57.949437: train_loss -0.7949 
2025-12-17 20:43:57.951440: val_loss -0.8121 
2025-12-17 20:43:57.951440: Pseudo dice [0.9012, 0.9346, 0.9111] 
2025-12-17 20:43:57.954157: Epoch time: 138.23 s 
2025-12-17 20:43:57.954157: Yayy! New best EMA pseudo Dice: 0.9092 
2025-12-17 20:43:58.861627:  
2025-12-17 20:43:58.861627: Epoch 72 
2025-12-17 20:43:58.863632: Current learning rate: 0.00935 
2025-12-17 20:46:16.905800: train_loss -0.7904 
2025-12-17 20:46:16.905800: val_loss -0.826 
2025-12-17 20:46:16.907541: Pseudo dice [0.917, 0.9492, 0.9038] 
2025-12-17 20:46:16.907541: Epoch time: 138.04 s 
2025-12-17 20:46:16.911160: Yayy! New best EMA pseudo Dice: 0.9106 
2025-12-17 20:46:17.983149:  
2025-12-17 20:46:17.983149: Epoch 73 
2025-12-17 20:46:17.983149: Current learning rate: 0.00934 
2025-12-17 20:48:36.131295: train_loss -0.7972 
2025-12-17 20:48:36.131295: val_loss -0.8186 
2025-12-17 20:48:36.146965: Pseudo dice [0.9085, 0.9423, 0.904] 
2025-12-17 20:48:36.146965: Epoch time: 138.15 s 
2025-12-17 20:48:36.146965: Yayy! New best EMA pseudo Dice: 0.9114 
2025-12-17 20:48:37.048124:  
2025-12-17 20:48:37.048124: Epoch 74 
2025-12-17 20:48:37.048124: Current learning rate: 0.00933 
2025-12-17 20:50:55.324772: train_loss -0.7919 
2025-12-17 20:50:55.324772: val_loss -0.8079 
2025-12-17 20:50:55.324772: Pseudo dice [0.9035, 0.9408, 0.902] 
2025-12-17 20:50:55.324772: Epoch time: 138.29 s 
2025-12-17 20:50:55.324772: Yayy! New best EMA pseudo Dice: 0.9118 
2025-12-17 20:50:56.229044:  
2025-12-17 20:50:56.229044: Epoch 75 
2025-12-17 20:50:56.229044: Current learning rate: 0.00932 
2025-12-17 20:53:14.408983: train_loss -0.7933 
2025-12-17 20:53:14.410986: val_loss -0.8155 
2025-12-17 20:53:14.410986: Pseudo dice [0.904, 0.9416, 0.9026] 
2025-12-17 20:53:14.410986: Epoch time: 138.18 s 
2025-12-17 20:53:14.410986: Yayy! New best EMA pseudo Dice: 0.9122 
2025-12-17 20:53:15.321475:  
2025-12-17 20:53:15.321475: Epoch 76 
2025-12-17 20:53:15.321475: Current learning rate: 0.00931 
2025-12-17 20:55:33.830093: train_loss -0.7893 
2025-12-17 20:55:33.830093: val_loss -0.8111 
2025-12-17 20:55:33.834100: Pseudo dice [0.9058, 0.9375, 0.9024] 
2025-12-17 20:55:33.836104: Epoch time: 138.51 s 
2025-12-17 20:55:33.838110: Yayy! New best EMA pseudo Dice: 0.9125 
2025-12-17 20:55:34.932472:  
2025-12-17 20:55:34.932472: Epoch 77 
2025-12-17 20:55:34.932472: Current learning rate: 0.0093 
2025-12-17 20:57:53.071099: train_loss -0.7897 
2025-12-17 20:57:53.073102: val_loss -0.8227 
2025-12-17 20:57:53.073102: Pseudo dice [0.9153, 0.9423, 0.9065] 
2025-12-17 20:57:53.075105: Epoch time: 138.14 s 
2025-12-17 20:57:53.075105: Yayy! New best EMA pseudo Dice: 0.9134 
2025-12-17 20:57:54.145790:  
2025-12-17 20:57:54.145790: Epoch 78 
2025-12-17 20:57:54.145790: Current learning rate: 0.0093 
2025-12-17 21:00:12.134493: train_loss -0.7917 
2025-12-17 21:00:12.134493: val_loss -0.8149 
2025-12-17 21:00:12.134493: Pseudo dice [0.9038, 0.9391, 0.9029] 
2025-12-17 21:00:12.150494: Epoch time: 137.99 s 
2025-12-17 21:00:12.150494: Yayy! New best EMA pseudo Dice: 0.9136 
2025-12-17 21:00:13.040751:  
2025-12-17 21:00:13.040751: Epoch 79 
2025-12-17 21:00:13.040751: Current learning rate: 0.00929 
2025-12-17 21:02:31.092196: train_loss -0.7877 
2025-12-17 21:02:31.092196: val_loss -0.7937 
2025-12-17 21:02:31.092196: Pseudo dice [0.8923, 0.9317, 0.9057] 
2025-12-17 21:02:31.108219: Epoch time: 138.05 s 
2025-12-17 21:02:31.870992:  
2025-12-17 21:02:31.870992: Epoch 80 
2025-12-17 21:02:31.870992: Current learning rate: 0.00928 
2025-12-17 21:04:49.960998: train_loss -0.792 
2025-12-17 21:04:49.960998: val_loss -0.7963 
2025-12-17 21:04:49.964492: Pseudo dice [0.9004, 0.9319, 0.8842] 
2025-12-17 21:04:49.966495: Epoch time: 138.09 s 
2025-12-17 21:04:50.625875:  
2025-12-17 21:04:50.625875: Epoch 81 
2025-12-17 21:04:50.625875: Current learning rate: 0.00927 
2025-12-17 21:07:08.845693: train_loss -0.7801 
2025-12-17 21:07:08.845693: val_loss -0.8069 
2025-12-17 21:07:08.845693: Pseudo dice [0.9031, 0.936, 0.8954] 
2025-12-17 21:07:08.845693: Epoch time: 138.23 s 
2025-12-17 21:07:09.495078:  
2025-12-17 21:07:09.495078: Epoch 82 
2025-12-17 21:07:09.495078: Current learning rate: 0.00926 
2025-12-17 21:09:27.807156: train_loss -0.7915 
2025-12-17 21:09:27.809821: val_loss -0.814 
2025-12-17 21:09:27.809821: Pseudo dice [0.9088, 0.9419, 0.9002] 
2025-12-17 21:09:27.809821: Epoch time: 138.31 s 
2025-12-17 21:09:28.505008:  
2025-12-17 21:09:28.505008: Epoch 83 
2025-12-17 21:09:28.505008: Current learning rate: 0.00925 
2025-12-17 21:11:46.879208: train_loss -0.7957 
2025-12-17 21:11:46.879208: val_loss -0.8268 
2025-12-17 21:11:46.879208: Pseudo dice [0.9184, 0.9456, 0.8998] 
2025-12-17 21:11:46.879208: Epoch time: 138.37 s 
2025-12-17 21:11:46.879208: Yayy! New best EMA pseudo Dice: 0.9136 
2025-12-17 21:11:47.911749:  
2025-12-17 21:11:47.911749: Epoch 84 
2025-12-17 21:11:47.911749: Current learning rate: 0.00924 
2025-12-17 21:14:06.108286: train_loss -0.8031 
2025-12-17 21:14:06.110289: val_loss -0.8102 
2025-12-17 21:14:06.112031: Pseudo dice [0.9023, 0.9388, 0.9037] 
2025-12-17 21:14:06.112031: Epoch time: 138.2 s 
2025-12-17 21:14:06.112031: Yayy! New best EMA pseudo Dice: 0.9138 
2025-12-17 21:14:07.004002:  
2025-12-17 21:14:07.004002: Epoch 85 
2025-12-17 21:14:07.004002: Current learning rate: 0.00923 
2025-12-17 21:16:25.276368: train_loss -0.8009 
2025-12-17 21:16:25.276368: val_loss -0.8259 
2025-12-17 21:16:25.284227: Pseudo dice [0.9099, 0.9442, 0.9131] 
2025-12-17 21:16:25.284227: Epoch time: 138.27 s 
2025-12-17 21:16:25.284227: Yayy! New best EMA pseudo Dice: 0.9146 
2025-12-17 21:16:26.360108:  
2025-12-17 21:16:26.360108: Epoch 86 
2025-12-17 21:16:26.360108: Current learning rate: 0.00922 
2025-12-17 21:18:44.487730: train_loss -0.7958 
2025-12-17 21:18:44.487730: val_loss -0.814 
2025-12-17 21:18:44.492166: Pseudo dice [0.9096, 0.9436, 0.8924] 
2025-12-17 21:18:44.492166: Epoch time: 138.13 s 
2025-12-17 21:18:44.494168: Yayy! New best EMA pseudo Dice: 0.9147 
2025-12-17 21:18:45.382031:  
2025-12-17 21:18:45.382031: Epoch 87 
2025-12-17 21:18:45.382031: Current learning rate: 0.00921 
2025-12-17 21:21:03.484743: train_loss -0.805 
2025-12-17 21:21:03.484743: val_loss -0.819 
2025-12-17 21:21:03.484743: Pseudo dice [0.9047, 0.9428, 0.9073] 
2025-12-17 21:21:03.484743: Epoch time: 138.1 s 
2025-12-17 21:21:03.484743: Yayy! New best EMA pseudo Dice: 0.9151 
2025-12-17 21:21:04.371970:  
2025-12-17 21:21:04.371970: Epoch 88 
2025-12-17 21:21:04.371970: Current learning rate: 0.0092 
2025-12-17 21:23:22.658127: train_loss -0.8022 
2025-12-17 21:23:22.658127: val_loss -0.8159 
2025-12-17 21:23:22.660129: Pseudo dice [0.9065, 0.9396, 0.9024] 
2025-12-17 21:23:22.662132: Epoch time: 138.29 s 
2025-12-17 21:23:22.664135: Yayy! New best EMA pseudo Dice: 0.9152 
2025-12-17 21:23:23.656408:  
2025-12-17 21:23:23.656408: Epoch 89 
2025-12-17 21:23:23.656408: Current learning rate: 0.0092 
2025-12-17 21:25:41.867697: train_loss -0.8125 
2025-12-17 21:25:41.869700: val_loss -0.8127 
2025-12-17 21:25:41.871706: Pseudo dice [0.9048, 0.9375, 0.9052] 
2025-12-17 21:25:41.873708: Epoch time: 138.21 s 
2025-12-17 21:25:41.877718: Yayy! New best EMA pseudo Dice: 0.9152 
2025-12-17 21:25:42.959726:  
2025-12-17 21:25:42.959726: Epoch 90 
2025-12-17 21:25:42.959726: Current learning rate: 0.00919 
2025-12-17 21:28:01.104345: train_loss -0.7987 
2025-12-17 21:28:01.106348: val_loss -0.8176 
2025-12-17 21:28:01.110359: Pseudo dice [0.9062, 0.9404, 0.9095] 
2025-12-17 21:28:01.112363: Epoch time: 138.15 s 
2025-12-17 21:28:01.112363: Yayy! New best EMA pseudo Dice: 0.9156 
2025-12-17 21:28:02.011821:  
2025-12-17 21:28:02.013661: Epoch 91 
2025-12-17 21:28:02.013661: Current learning rate: 0.00918 
2025-12-17 21:30:20.124694: train_loss -0.8019 
2025-12-17 21:30:20.124694: val_loss -0.826 
2025-12-17 21:30:20.124694: Pseudo dice [0.9077, 0.9441, 0.9102] 
2025-12-17 21:30:20.124694: Epoch time: 138.11 s 
2025-12-17 21:30:20.124694: Yayy! New best EMA pseudo Dice: 0.9161 
2025-12-17 21:30:21.028756:  
2025-12-17 21:30:21.028756: Epoch 92 
2025-12-17 21:30:21.028756: Current learning rate: 0.00917 
2025-12-17 21:32:39.257913: train_loss -0.8092 
2025-12-17 21:32:39.257913: val_loss -0.8324 
2025-12-17 21:32:39.257913: Pseudo dice [0.9157, 0.9429, 0.9119] 
2025-12-17 21:32:39.257913: Epoch time: 138.23 s 
2025-12-17 21:32:39.257913: Yayy! New best EMA pseudo Dice: 0.9168 
2025-12-17 21:32:40.149892:  
2025-12-17 21:32:40.149892: Epoch 93 
2025-12-17 21:32:40.149892: Current learning rate: 0.00916 
2025-12-17 21:34:58.264530: train_loss -0.8068 
2025-12-17 21:34:58.264530: val_loss -0.8249 
2025-12-17 21:34:58.264530: Pseudo dice [0.9116, 0.9451, 0.896] 
2025-12-17 21:34:58.264530: Epoch time: 138.11 s 
2025-12-17 21:34:58.264530: Yayy! New best EMA pseudo Dice: 0.9169 
2025-12-17 21:34:59.138565:  
2025-12-17 21:34:59.138565: Epoch 94 
2025-12-17 21:34:59.138565: Current learning rate: 0.00915 
2025-12-17 21:37:17.350604: train_loss -0.8064 
2025-12-17 21:37:17.350604: val_loss -0.8201 
2025-12-17 21:37:17.352606: Pseudo dice [0.9063, 0.9418, 0.9162] 
2025-12-17 21:37:17.354609: Epoch time: 138.21 s 
2025-12-17 21:37:17.354609: Yayy! New best EMA pseudo Dice: 0.9174 
2025-12-17 21:37:18.252181:  
2025-12-17 21:37:18.252181: Epoch 95 
2025-12-17 21:37:18.252181: Current learning rate: 0.00914 
2025-12-17 21:39:36.295223: train_loss -0.8017 
2025-12-17 21:39:36.295223: val_loss -0.8075 
2025-12-17 21:39:36.311015: Pseudo dice [0.8952, 0.9369, 0.9088] 
2025-12-17 21:39:36.311015: Epoch time: 138.04 s 
2025-12-17 21:39:37.085853:  
2025-12-17 21:39:37.085853: Epoch 96 
2025-12-17 21:39:37.085853: Current learning rate: 0.00913 
2025-12-17 21:41:55.275710: train_loss -0.7986 
2025-12-17 21:41:55.275710: val_loss -0.8233 
2025-12-17 21:41:55.275710: Pseudo dice [0.9097, 0.9379, 0.915] 
2025-12-17 21:41:55.275710: Epoch time: 138.19 s 
2025-12-17 21:41:55.275710: Yayy! New best EMA pseudo Dice: 0.9174 
2025-12-17 21:41:56.164639:  
2025-12-17 21:41:56.164639: Epoch 97 
2025-12-17 21:41:56.164639: Current learning rate: 0.00912 
2025-12-17 21:44:14.418317: train_loss -0.804 
2025-12-17 21:44:14.418317: val_loss -0.8253 
2025-12-17 21:44:14.421818: Pseudo dice [0.9086, 0.9408, 0.9118] 
2025-12-17 21:44:14.423821: Epoch time: 138.26 s 
2025-12-17 21:44:14.425823: Yayy! New best EMA pseudo Dice: 0.9177 
2025-12-17 21:44:15.309513:  
2025-12-17 21:44:15.309513: Epoch 98 
2025-12-17 21:44:15.309513: Current learning rate: 0.00911 
2025-12-17 21:46:33.459279: train_loss -0.8055 
2025-12-17 21:46:33.459279: val_loss -0.8362 
2025-12-17 21:46:33.461282: Pseudo dice [0.9169, 0.9474, 0.9129] 
2025-12-17 21:46:33.461282: Epoch time: 138.15 s 
2025-12-17 21:46:33.461282: Yayy! New best EMA pseudo Dice: 0.9185 
2025-12-17 21:46:34.326551:  
2025-12-17 21:46:34.326551: Epoch 99 
2025-12-17 21:46:34.326551: Current learning rate: 0.0091 
2025-12-17 21:48:52.389966: train_loss -0.8101 
2025-12-17 21:48:52.389966: val_loss -0.8351 
2025-12-17 21:48:52.393059: Pseudo dice [0.9143, 0.9495, 0.918] 
2025-12-17 21:48:52.393059: Epoch time: 138.06 s 
2025-12-17 21:48:52.633056: Yayy! New best EMA pseudo Dice: 0.9194 
2025-12-17 21:48:53.530475:  
2025-12-17 21:48:53.530475: Epoch 100 
2025-12-17 21:48:53.536836: Current learning rate: 0.0091 
2025-12-17 21:51:12.568431: train_loss -0.8173 
2025-12-17 21:51:12.568431: val_loss -0.8273 
2025-12-17 21:51:12.573129: Pseudo dice [0.9092, 0.9456, 0.9169] 
2025-12-17 21:51:12.573129: Epoch time: 139.04 s 
2025-12-17 21:51:12.575132: Yayy! New best EMA pseudo Dice: 0.9198 
2025-12-17 21:51:13.462317:  
2025-12-17 21:51:13.462317: Epoch 101 
2025-12-17 21:51:13.464509: Current learning rate: 0.00909 
2025-12-17 21:53:32.295670: train_loss -0.8092 
2025-12-17 21:53:32.295670: val_loss -0.8212 
2025-12-17 21:53:32.297673: Pseudo dice [0.9073, 0.9422, 0.9115] 
2025-12-17 21:53:32.299675: Epoch time: 138.83 s 
2025-12-17 21:53:32.301678: Yayy! New best EMA pseudo Dice: 0.9199 
2025-12-17 21:53:33.508891:  
2025-12-17 21:53:33.508891: Epoch 102 
2025-12-17 21:53:33.510570: Current learning rate: 0.00908 
2025-12-17 21:55:52.040271: train_loss -0.8013 
2025-12-17 21:55:52.040271: val_loss -0.8206 
2025-12-17 21:55:52.052499: Pseudo dice [0.9092, 0.9416, 0.9107] 
2025-12-17 21:55:52.054399: Epoch time: 138.55 s 
2025-12-17 21:55:52.054399: Yayy! New best EMA pseudo Dice: 0.9199 
2025-12-17 21:55:52.950288:  
2025-12-17 21:55:52.950288: Epoch 103 
2025-12-17 21:55:52.950288: Current learning rate: 0.00907 
2025-12-17 21:58:11.699275: train_loss -0.8062 
2025-12-17 21:58:11.699275: val_loss -0.8409 
2025-12-17 21:58:11.706929: Pseudo dice [0.9195, 0.9443, 0.919] 
2025-12-17 21:58:11.706929: Epoch time: 138.75 s 
2025-12-17 21:58:11.708932: Yayy! New best EMA pseudo Dice: 0.9207 
2025-12-17 21:58:12.603006:  
2025-12-17 21:58:12.605008: Epoch 104 
2025-12-17 21:58:12.605008: Current learning rate: 0.00906 
2025-12-17 22:00:31.192122: train_loss -0.8124 
2025-12-17 22:00:31.192122: val_loss -0.8294 
2025-12-17 22:00:31.197030: Pseudo dice [0.9119, 0.9442, 0.9099] 
2025-12-17 22:00:31.198033: Epoch time: 138.59 s 
2025-12-17 22:00:31.200036: Yayy! New best EMA pseudo Dice: 0.9208 
2025-12-17 22:00:32.133892:  
2025-12-17 22:00:32.133892: Epoch 105 
2025-12-17 22:00:32.135765: Current learning rate: 0.00905 
2025-12-17 22:02:50.325681: train_loss -0.8079 
2025-12-17 22:02:50.325681: val_loss -0.816 
2025-12-17 22:02:50.327683: Pseudo dice [0.9047, 0.9359, 0.9102] 
2025-12-17 22:02:50.329424: Epoch time: 138.19 s 
2025-12-17 22:02:50.967064:  
2025-12-17 22:02:50.967064: Epoch 106 
2025-12-17 22:02:50.969066: Current learning rate: 0.00904 
2025-12-17 22:05:09.252465: train_loss -0.8038 
2025-12-17 22:05:09.252465: val_loss -0.821 
2025-12-17 22:05:09.256469: Pseudo dice [0.9069, 0.9441, 0.9098] 
2025-12-17 22:05:09.256469: Epoch time: 138.29 s 
2025-12-17 22:05:09.900927:  
2025-12-17 22:05:09.900927: Epoch 107 
2025-12-17 22:05:09.900927: Current learning rate: 0.00903 
2025-12-17 22:07:28.077469: train_loss -0.8035 
2025-12-17 22:07:28.077469: val_loss -0.8207 
2025-12-17 22:07:28.077469: Pseudo dice [0.9024, 0.9396, 0.9177] 
2025-12-17 22:07:28.081964: Epoch time: 138.18 s 
2025-12-17 22:07:28.893426:  
2025-12-17 22:07:28.893426: Epoch 108 
2025-12-17 22:07:28.895893: Current learning rate: 0.00902 
2025-12-17 22:09:47.422853: train_loss -0.808 
2025-12-17 22:09:47.422853: val_loss -0.8282 
2025-12-17 22:09:47.424855: Pseudo dice [0.9061, 0.9446, 0.9204] 
2025-12-17 22:09:47.426857: Epoch time: 138.53 s 
2025-12-17 22:09:48.048701:  
2025-12-17 22:09:48.048701: Epoch 109 
2025-12-17 22:09:48.064799: Current learning rate: 0.00901 
2025-12-17 22:12:06.197486: train_loss -0.8095 
2025-12-17 22:12:06.197486: val_loss -0.828 
2025-12-17 22:12:06.199488: Pseudo dice [0.9109, 0.94, 0.9067] 
2025-12-17 22:12:06.201490: Epoch time: 138.15 s 
2025-12-17 22:12:06.825292:  
2025-12-17 22:12:06.825292: Epoch 110 
2025-12-17 22:12:06.825292: Current learning rate: 0.009 
2025-12-17 22:14:24.994057: train_loss -0.8116 
2025-12-17 22:14:24.994057: val_loss -0.8271 
2025-12-17 22:14:24.997802: Pseudo dice [0.9056, 0.9445, 0.9235] 
2025-12-17 22:14:24.999805: Epoch time: 138.17 s 
2025-12-17 22:14:24.999805: Yayy! New best EMA pseudo Dice: 0.9209 
2025-12-17 22:14:25.883312:  
2025-12-17 22:14:25.883312: Epoch 111 
2025-12-17 22:14:25.883312: Current learning rate: 0.009 
2025-12-17 22:16:44.044858: train_loss -0.8171 
2025-12-17 22:16:44.046860: val_loss -0.8336 
2025-12-17 22:16:44.048862: Pseudo dice [0.9141, 0.9426, 0.9085] 
2025-12-17 22:16:44.048862: Epoch time: 138.16 s 
2025-12-17 22:16:44.048862: Yayy! New best EMA pseudo Dice: 0.921 
2025-12-17 22:16:44.951194:  
2025-12-17 22:16:44.951194: Epoch 112 
2025-12-17 22:16:44.951194: Current learning rate: 0.00899 
2025-12-17 22:19:03.291094: train_loss -0.8183 
2025-12-17 22:19:03.291094: val_loss -0.8332 
2025-12-17 22:19:03.291094: Pseudo dice [0.9112, 0.9434, 0.9145] 
2025-12-17 22:19:03.306903: Epoch time: 138.34 s 
2025-12-17 22:19:03.306903: Yayy! New best EMA pseudo Dice: 0.9212 
2025-12-17 22:19:04.180902:  
2025-12-17 22:19:04.180902: Epoch 113 
2025-12-17 22:19:04.180902: Current learning rate: 0.00898 
2025-12-17 22:21:22.420536: train_loss -0.8197 
2025-12-17 22:21:22.420536: val_loss -0.8316 
2025-12-17 22:21:22.422538: Pseudo dice [0.9163, 0.9448, 0.8994] 
2025-12-17 22:21:22.424540: Epoch time: 138.24 s 
2025-12-17 22:21:23.084414:  
2025-12-17 22:21:23.084414: Epoch 114 
2025-12-17 22:21:23.090223: Current learning rate: 0.00897 
2025-12-17 22:23:41.363015: train_loss -0.8128 
2025-12-17 22:23:41.363015: val_loss -0.8445 
2025-12-17 22:23:41.365017: Pseudo dice [0.9182, 0.9492, 0.9176] 
2025-12-17 22:23:41.367019: Epoch time: 138.28 s 
2025-12-17 22:23:41.367019: Yayy! New best EMA pseudo Dice: 0.9218 
2025-12-17 22:23:42.434572:  
2025-12-17 22:23:42.434572: Epoch 115 
2025-12-17 22:23:42.434572: Current learning rate: 0.00896 
2025-12-17 22:26:00.711435: train_loss -0.8128 
2025-12-17 22:26:00.713437: val_loss -0.8254 
2025-12-17 22:26:00.713437: Pseudo dice [0.9071, 0.9365, 0.908] 
2025-12-17 22:26:00.713437: Epoch time: 138.28 s 
2025-12-17 22:26:01.331272:  
2025-12-17 22:26:01.331272: Epoch 116 
2025-12-17 22:26:01.347122: Current learning rate: 0.00895 
2025-12-17 22:28:19.416281: train_loss -0.8171 
2025-12-17 22:28:19.418263: val_loss -0.828 
2025-12-17 22:28:19.420265: Pseudo dice [0.9065, 0.9425, 0.9209] 
2025-12-17 22:28:19.420265: Epoch time: 138.09 s 
2025-12-17 22:28:20.074162:  
2025-12-17 22:28:20.074162: Epoch 117 
2025-12-17 22:28:20.074162: Current learning rate: 0.00894 
2025-12-17 22:30:38.180514: train_loss -0.8142 
2025-12-17 22:30:38.180514: val_loss -0.8302 
2025-12-17 22:30:38.184517: Pseudo dice [0.9127, 0.9406, 0.9068] 
2025-12-17 22:30:38.184517: Epoch time: 138.12 s 
2025-12-17 22:30:38.833505:  
2025-12-17 22:30:38.835246: Epoch 118 
2025-12-17 22:30:38.835246: Current learning rate: 0.00893 
2025-12-17 22:32:57.007070: train_loss -0.8144 
2025-12-17 22:32:57.007070: val_loss -0.8353 
2025-12-17 22:32:57.007070: Pseudo dice [0.9164, 0.9458, 0.9122] 
2025-12-17 22:32:57.010980: Epoch time: 138.17 s 
2025-12-17 22:32:57.656555:  
2025-12-17 22:32:57.656555: Epoch 119 
2025-12-17 22:32:57.656555: Current learning rate: 0.00892 
2025-12-17 22:35:15.794872: train_loss -0.8106 
2025-12-17 22:35:15.794872: val_loss -0.8345 
2025-12-17 22:35:15.794872: Pseudo dice [0.9154, 0.9466, 0.9124] 
2025-12-17 22:35:15.794872: Epoch time: 138.14 s 
2025-12-17 22:35:15.810730: Yayy! New best EMA pseudo Dice: 0.9221 
2025-12-17 22:35:16.851010:  
2025-12-17 22:35:16.851010: Epoch 120 
2025-12-17 22:35:16.851010: Current learning rate: 0.00891 
2025-12-17 22:37:35.020705: train_loss -0.8171 
2025-12-17 22:37:35.020705: val_loss -0.8403 
2025-12-17 22:37:35.034006: Pseudo dice [0.9123, 0.9503, 0.9181] 
2025-12-17 22:37:35.036008: Epoch time: 138.17 s 
2025-12-17 22:37:35.036008: Yayy! New best EMA pseudo Dice: 0.9225 
2025-12-17 22:37:35.954183:  
2025-12-17 22:37:35.954183: Epoch 121 
2025-12-17 22:37:35.970030: Current learning rate: 0.0089 
2025-12-17 22:39:54.069604: train_loss -0.8159 
2025-12-17 22:39:54.069604: val_loss -0.8424 
2025-12-17 22:39:54.071605: Pseudo dice [0.9191, 0.9556, 0.9168] 
2025-12-17 22:39:54.073607: Epoch time: 138.12 s 
2025-12-17 22:39:54.075609: Yayy! New best EMA pseudo Dice: 0.9233 
2025-12-17 22:39:54.974600:  
2025-12-17 22:39:54.976445: Epoch 122 
2025-12-17 22:39:54.976445: Current learning rate: 0.00889 
2025-12-17 22:42:13.120478: train_loss -0.8152 
2025-12-17 22:42:13.120478: val_loss -0.831 
2025-12-17 22:42:13.120478: Pseudo dice [0.9118, 0.9394, 0.9162] 
2025-12-17 22:42:13.120478: Epoch time: 138.15 s 
2025-12-17 22:42:13.761649:  
2025-12-17 22:42:13.763652: Epoch 123 
2025-12-17 22:42:13.763652: Current learning rate: 0.00889 
2025-12-17 22:44:31.954501: train_loss -0.8138 
2025-12-17 22:44:31.954501: val_loss -0.8286 
2025-12-17 22:44:31.954501: Pseudo dice [0.9077, 0.944, 0.9185] 
2025-12-17 22:44:31.958002: Epoch time: 138.19 s 
2025-12-17 22:44:32.631158:  
2025-12-17 22:44:32.631158: Epoch 124 
2025-12-17 22:44:32.631158: Current learning rate: 0.00888 
2025-12-17 22:46:50.611531: train_loss -0.8146 
2025-12-17 22:46:50.611531: val_loss -0.8331 
2025-12-17 22:46:50.613534: Pseudo dice [0.9145, 0.9421, 0.9147] 
2025-12-17 22:46:50.617543: Epoch time: 137.98 s 
2025-12-17 22:46:51.260091:  
2025-12-17 22:46:51.260091: Epoch 125 
2025-12-17 22:46:51.260091: Current learning rate: 0.00887 
2025-12-17 22:49:09.243903: train_loss -0.809 
2025-12-17 22:49:09.243903: val_loss -0.8266 
2025-12-17 22:49:09.243903: Pseudo dice [0.907, 0.9428, 0.9159] 
2025-12-17 22:49:09.243903: Epoch time: 137.98 s 
2025-12-17 22:49:10.056740:  
2025-12-17 22:49:10.072567: Epoch 126 
2025-12-17 22:49:10.072567: Current learning rate: 0.00886 
2025-12-17 22:51:28.170131: train_loss -0.8173 
2025-12-17 22:51:28.170131: val_loss -0.8326 
2025-12-17 22:51:28.170131: Pseudo dice [0.908, 0.9433, 0.9208] 
2025-12-17 22:51:28.170131: Epoch time: 138.11 s 
2025-12-17 22:51:28.836521:  
2025-12-17 22:51:28.836521: Epoch 127 
2025-12-17 22:51:28.836521: Current learning rate: 0.00885 
2025-12-17 22:53:47.004789: train_loss -0.8219 
2025-12-17 22:53:47.004789: val_loss -0.8419 
2025-12-17 22:53:47.004789: Pseudo dice [0.9128, 0.9486, 0.9287] 
2025-12-17 22:53:47.004789: Epoch time: 138.18 s 
2025-12-17 22:53:47.011342: Yayy! New best EMA pseudo Dice: 0.9239 
2025-12-17 22:53:47.884196:  
2025-12-17 22:53:47.884196: Epoch 128 
2025-12-17 22:53:47.884196: Current learning rate: 0.00884 
2025-12-17 22:56:06.164153: train_loss -0.8207 
2025-12-17 22:56:06.164153: val_loss -0.8416 
2025-12-17 22:56:06.164153: Pseudo dice [0.9098, 0.9455, 0.9329] 
2025-12-17 22:56:06.164153: Epoch time: 138.28 s 
2025-12-17 22:56:06.180032: Yayy! New best EMA pseudo Dice: 0.9245 
2025-12-17 22:56:07.078601:  
2025-12-17 22:56:07.078601: Epoch 129 
2025-12-17 22:56:07.078601: Current learning rate: 0.00883 
2025-12-17 22:58:25.172385: train_loss -0.8153 
2025-12-17 22:58:25.172385: val_loss -0.8348 
2025-12-17 22:58:25.172385: Pseudo dice [0.9114, 0.9452, 0.9144] 
2025-12-17 22:58:25.188420: Epoch time: 138.1 s 
2025-12-17 22:58:25.841398:  
2025-12-17 22:58:25.841398: Epoch 130 
2025-12-17 22:58:25.841398: Current learning rate: 0.00882 
2025-12-17 23:00:44.065592: train_loss -0.8117 
2025-12-17 23:00:44.065592: val_loss -0.8427 
2025-12-17 23:00:44.073161: Pseudo dice [0.9172, 0.9509, 0.9214] 
2025-12-17 23:00:44.073161: Epoch time: 138.23 s 
2025-12-17 23:00:44.075164: Yayy! New best EMA pseudo Dice: 0.9249 
2025-12-17 23:00:44.968640:  
2025-12-17 23:00:44.984591: Epoch 131 
2025-12-17 23:00:44.986007: Current learning rate: 0.00881 
2025-12-17 23:03:03.057322: train_loss -0.8167 
2025-12-17 23:03:03.057322: val_loss -0.8216 
2025-12-17 23:03:03.064282: Pseudo dice [0.9033, 0.9383, 0.9147] 
2025-12-17 23:03:03.064282: Epoch time: 138.09 s 
2025-12-17 23:03:03.866241:  
2025-12-17 23:03:03.866241: Epoch 132 
2025-12-17 23:03:03.866241: Current learning rate: 0.0088 
2025-12-17 23:05:22.044165: train_loss -0.822 
2025-12-17 23:05:22.044165: val_loss -0.8482 
2025-12-17 23:05:22.057915: Pseudo dice [0.9245, 0.9526, 0.9178] 
2025-12-17 23:05:22.059919: Epoch time: 138.18 s 
2025-12-17 23:05:22.059919: Yayy! New best EMA pseudo Dice: 0.9251 
2025-12-17 23:05:22.948775:  
2025-12-17 23:05:22.948775: Epoch 133 
2025-12-17 23:05:22.948775: Current learning rate: 0.00879 
2025-12-17 23:07:41.185489: train_loss -0.8141 
2025-12-17 23:07:41.185489: val_loss -0.8434 
2025-12-17 23:07:41.201278: Pseudo dice [0.917, 0.9511, 0.9108] 
2025-12-17 23:07:41.201278: Epoch time: 138.24 s 
2025-12-17 23:07:41.201278: Yayy! New best EMA pseudo Dice: 0.9252 
2025-12-17 23:07:42.091630:  
2025-12-17 23:07:42.091630: Epoch 134 
2025-12-17 23:07:42.091630: Current learning rate: 0.00879 
2025-12-17 23:10:00.469954: train_loss -0.8246 
2025-12-17 23:10:00.469954: val_loss -0.836 
2025-12-17 23:10:00.469954: Pseudo dice [0.9083, 0.946, 0.9209] 
2025-12-17 23:10:00.469954: Epoch time: 138.38 s 
2025-12-17 23:10:01.108570:  
2025-12-17 23:10:01.108570: Epoch 135 
2025-12-17 23:10:01.108570: Current learning rate: 0.00878 
2025-12-17 23:12:19.294837: train_loss -0.8185 
2025-12-17 23:12:19.296839: val_loss -0.8317 
2025-12-17 23:12:19.300848: Pseudo dice [0.9058, 0.941, 0.916] 
2025-12-17 23:12:19.302850: Epoch time: 138.19 s 
2025-12-17 23:12:20.035038:  
2025-12-17 23:12:20.035038: Epoch 136 
2025-12-17 23:12:20.035038: Current learning rate: 0.00877 
2025-12-17 23:14:38.365242: train_loss -0.8169 
2025-12-17 23:14:38.365242: val_loss -0.8366 
2025-12-17 23:14:38.365242: Pseudo dice [0.915, 0.9454, 0.9212] 
2025-12-17 23:14:38.365242: Epoch time: 138.33 s 
2025-12-17 23:14:39.029853:  
2025-12-17 23:14:39.029853: Epoch 137 
2025-12-17 23:14:39.029853: Current learning rate: 0.00876 
2025-12-17 23:16:57.172191: train_loss -0.816 
2025-12-17 23:16:57.172191: val_loss -0.84 
2025-12-17 23:16:57.172191: Pseudo dice [0.9202, 0.952, 0.9075] 
2025-12-17 23:16:57.188027: Epoch time: 138.14 s 
2025-12-17 23:16:58.013986:  
2025-12-17 23:16:58.013986: Epoch 138 
2025-12-17 23:16:58.013986: Current learning rate: 0.00875 
2025-12-17 23:19:16.090378: train_loss -0.8156 
2025-12-17 23:19:16.092380: val_loss -0.8376 
2025-12-17 23:19:16.096387: Pseudo dice [0.9099, 0.9465, 0.9291] 
2025-12-17 23:19:16.098390: Epoch time: 138.08 s 
2025-12-17 23:19:16.100392: Yayy! New best EMA pseudo Dice: 0.9255 
2025-12-17 23:19:17.084874:  
2025-12-17 23:19:17.084874: Epoch 139 
2025-12-17 23:19:17.086707: Current learning rate: 0.00874 
2025-12-17 23:21:35.159609: train_loss -0.8222 
2025-12-17 23:21:35.159609: val_loss -0.8478 
2025-12-17 23:21:35.159609: Pseudo dice [0.9238, 0.9497, 0.9166] 
2025-12-17 23:21:35.159609: Epoch time: 138.08 s 
2025-12-17 23:21:35.159609: Yayy! New best EMA pseudo Dice: 0.9259 
2025-12-17 23:21:36.060701:  
2025-12-17 23:21:36.076604: Epoch 140 
2025-12-17 23:21:36.076604: Current learning rate: 0.00873 
2025-12-17 23:23:54.442318: train_loss -0.8191 
2025-12-17 23:23:54.442318: val_loss -0.8313 
2025-12-17 23:23:54.442318: Pseudo dice [0.9067, 0.9406, 0.9207] 
2025-12-17 23:23:54.442318: Epoch time: 138.38 s 
2025-12-17 23:23:55.096109:  
2025-12-17 23:23:55.096109: Epoch 141 
2025-12-17 23:23:55.096109: Current learning rate: 0.00872 
2025-12-17 23:26:13.238771: train_loss -0.8236 
2025-12-17 23:26:13.238771: val_loss -0.8515 
2025-12-17 23:26:13.242777: Pseudo dice [0.9234, 0.9518, 0.9252] 
2025-12-17 23:26:13.244780: Epoch time: 138.14 s 
2025-12-17 23:26:13.246781: Yayy! New best EMA pseudo Dice: 0.9264 
2025-12-17 23:26:14.282981:  
2025-12-17 23:26:14.282981: Epoch 142 
2025-12-17 23:26:14.282981: Current learning rate: 0.00871 
2025-12-17 23:28:32.519789: train_loss -0.821 
2025-12-17 23:28:32.519789: val_loss -0.8273 
2025-12-17 23:28:32.535807: Pseudo dice [0.9086, 0.9447, 0.9113] 
2025-12-17 23:28:32.537638: Epoch time: 138.24 s 
2025-12-17 23:28:33.199569:  
2025-12-17 23:28:33.199569: Epoch 143 
2025-12-17 23:28:33.199569: Current learning rate: 0.0087 
2025-12-17 23:30:51.365877: train_loss -0.8242 
2025-12-17 23:30:51.365877: val_loss -0.8351 
2025-12-17 23:30:51.367880: Pseudo dice [0.9069, 0.9494, 0.9241] 
2025-12-17 23:30:51.369882: Epoch time: 138.17 s 
2025-12-17 23:30:52.188912:  
2025-12-17 23:30:52.188912: Epoch 144 
2025-12-17 23:30:52.188912: Current learning rate: 0.00869 
2025-12-17 23:33:10.386069: train_loss -0.8257 
2025-12-17 23:33:10.386069: val_loss -0.8434 
2025-12-17 23:33:10.386069: Pseudo dice [0.9181, 0.9479, 0.9227] 
2025-12-17 23:33:10.386069: Epoch time: 138.2 s 
2025-12-17 23:33:11.147591:  
2025-12-17 23:33:11.149594: Epoch 145 
2025-12-17 23:33:11.149594: Current learning rate: 0.00868 
2025-12-17 23:35:29.571842: train_loss -0.8231 
2025-12-17 23:35:29.571842: val_loss -0.8592 
2025-12-17 23:35:29.573845: Pseudo dice [0.9237, 0.9553, 0.93] 
2025-12-17 23:35:29.576349: Epoch time: 138.42 s 
2025-12-17 23:35:29.578351: Yayy! New best EMA pseudo Dice: 0.9274 
2025-12-17 23:35:30.462646:  
2025-12-17 23:35:30.462646: Epoch 146 
2025-12-17 23:35:30.462646: Current learning rate: 0.00868 
2025-12-17 23:37:48.780363: train_loss -0.8219 
2025-12-17 23:37:48.780363: val_loss -0.844 
2025-12-17 23:37:48.780363: Pseudo dice [0.9151, 0.9509, 0.9153] 
2025-12-17 23:37:48.784313: Epoch time: 138.32 s 
2025-12-17 23:37:49.426381:  
2025-12-17 23:37:49.426381: Epoch 147 
2025-12-17 23:37:49.426381: Current learning rate: 0.00867 
2025-12-17 23:40:07.531331: train_loss -0.817 
2025-12-17 23:40:07.531331: val_loss -0.8415 
2025-12-17 23:40:07.531331: Pseudo dice [0.9179, 0.9482, 0.9194] 
2025-12-17 23:40:07.536093: Epoch time: 138.1 s 
2025-12-17 23:40:07.538095: Yayy! New best EMA pseudo Dice: 0.9274 
2025-12-17 23:40:08.647348:  
2025-12-17 23:40:08.647348: Epoch 148 
2025-12-17 23:40:08.655018: Current learning rate: 0.00866 
2025-12-17 23:42:26.719163: train_loss -0.818 
2025-12-17 23:42:26.719163: val_loss -0.836 
2025-12-17 23:42:26.721166: Pseudo dice [0.9138, 0.9466, 0.9146] 
2025-12-17 23:42:26.723167: Epoch time: 138.07 s 
2025-12-17 23:42:27.388326:  
2025-12-17 23:42:27.388326: Epoch 149 
2025-12-17 23:42:27.391009: Current learning rate: 0.00865 
2025-12-17 23:44:45.571566: train_loss -0.8083 
2025-12-17 23:44:45.571566: val_loss -0.8282 
2025-12-17 23:44:45.571566: Pseudo dice [0.9111, 0.9419, 0.9071] 
2025-12-17 23:44:45.571566: Epoch time: 138.18 s 
2025-12-17 23:44:46.655419:  
2025-12-17 23:44:46.655419: Epoch 150 
2025-12-17 23:44:46.655419: Current learning rate: 0.00864 
2025-12-17 23:47:04.929481: train_loss -0.8163 
2025-12-17 23:47:04.931484: val_loss -0.8311 
2025-12-17 23:47:04.935256: Pseudo dice [0.908, 0.9418, 0.9327] 
2025-12-17 23:47:04.935256: Epoch time: 138.28 s 
2025-12-17 23:47:05.726356:  
2025-12-17 23:47:05.726356: Epoch 151 
2025-12-17 23:47:05.726356: Current learning rate: 0.00863 
2025-12-17 23:49:23.830533: train_loss -0.8201 
2025-12-17 23:49:23.830533: val_loss -0.8494 
2025-12-17 23:49:23.830533: Pseudo dice [0.9215, 0.9532, 0.9144] 
2025-12-17 23:49:23.846377: Epoch time: 138.1 s 
2025-12-17 23:49:24.495798:  
2025-12-17 23:49:24.495798: Epoch 152 
2025-12-17 23:49:24.495798: Current learning rate: 0.00862 
2025-12-17 23:51:42.774410: train_loss -0.8234 
2025-12-17 23:51:42.774410: val_loss -0.8327 
2025-12-17 23:51:42.774410: Pseudo dice [0.9072, 0.9438, 0.9266] 
2025-12-17 23:51:42.774410: Epoch time: 138.28 s 
2025-12-17 23:51:43.426806:  
2025-12-17 23:51:43.426806: Epoch 153 
2025-12-17 23:51:43.426806: Current learning rate: 0.00861 
2025-12-17 23:54:01.607428: train_loss -0.8088 
2025-12-17 23:54:01.607428: val_loss -0.8286 
2025-12-17 23:54:01.607428: Pseudo dice [0.9061, 0.9422, 0.9168] 
2025-12-17 23:54:01.623460: Epoch time: 138.18 s 
2025-12-17 23:54:02.398185:  
2025-12-17 23:54:02.398185: Epoch 154 
2025-12-17 23:54:02.398185: Current learning rate: 0.0086 
2025-12-17 23:56:20.413197: train_loss -0.8175 
2025-12-17 23:56:20.413197: val_loss -0.8223 
2025-12-17 23:56:20.415200: Pseudo dice [0.9029, 0.9416, 0.9072] 
2025-12-17 23:56:20.417202: Epoch time: 138.02 s 
2025-12-17 23:56:21.083896:  
2025-12-17 23:56:21.083896: Epoch 155 
2025-12-17 23:56:21.083896: Current learning rate: 0.00859 
2025-12-17 23:58:39.136252: train_loss -0.8152 
2025-12-17 23:58:39.138254: val_loss -0.8324 
2025-12-17 23:58:39.140257: Pseudo dice [0.9077, 0.9451, 0.9251] 
2025-12-17 23:58:39.142260: Epoch time: 138.05 s 
2025-12-17 23:58:39.957623:  
2025-12-17 23:58:39.973550: Epoch 156 
2025-12-17 23:58:39.975484: Current learning rate: 0.00858 
2025-12-18 00:00:58.277033: train_loss -0.8156 
2025-12-18 00:00:58.277033: val_loss -0.8393 
2025-12-18 00:00:58.277033: Pseudo dice [0.9116, 0.9448, 0.9268] 
2025-12-18 00:00:58.277033: Epoch time: 138.32 s 
2025-12-18 00:00:59.018421:  
2025-12-18 00:00:59.018421: Epoch 157 
2025-12-18 00:00:59.018421: Current learning rate: 0.00858 
2025-12-18 00:03:17.085826: train_loss -0.824 
2025-12-18 00:03:17.085826: val_loss -0.8409 
2025-12-18 00:03:17.092225: Pseudo dice [0.9163, 0.9477, 0.9159] 
2025-12-18 00:03:17.094434: Epoch time: 138.07 s 
2025-12-18 00:03:17.760301:  
2025-12-18 00:03:17.760301: Epoch 158 
2025-12-18 00:03:17.760301: Current learning rate: 0.00857 
2025-12-18 00:05:36.191634: train_loss -0.8172 
2025-12-18 00:05:36.193638: val_loss -0.8404 
2025-12-18 00:05:36.197644: Pseudo dice [0.9151, 0.946, 0.921] 
2025-12-18 00:05:36.199647: Epoch time: 138.43 s 
2025-12-18 00:05:36.863498:  
2025-12-18 00:05:36.863498: Epoch 159 
2025-12-18 00:05:36.865241: Current learning rate: 0.00856 
2025-12-18 00:07:55.307315: train_loss -0.8162 
2025-12-18 00:07:55.307315: val_loss -0.832 
2025-12-18 00:07:55.310388: Pseudo dice [0.9112, 0.9402, 0.9205] 
2025-12-18 00:07:55.310388: Epoch time: 138.45 s 
2025-12-18 00:07:56.117045:  
2025-12-18 00:07:56.117045: Epoch 160 
2025-12-18 00:07:56.117045: Current learning rate: 0.00855 
2025-12-18 00:10:14.633581: train_loss -0.8236 
2025-12-18 00:10:14.635583: val_loss -0.8302 
2025-12-18 00:10:14.637585: Pseudo dice [0.9071, 0.9416, 0.9204] 
2025-12-18 00:10:14.639587: Epoch time: 138.52 s 
2025-12-18 00:10:15.300294:  
2025-12-18 00:10:15.302034: Epoch 161 
2025-12-18 00:10:15.302034: Current learning rate: 0.00854 
2025-12-18 00:12:33.423639: train_loss -0.8239 
2025-12-18 00:12:33.423639: val_loss -0.8466 
2025-12-18 00:12:33.425642: Pseudo dice [0.9116, 0.9498, 0.9298] 
2025-12-18 00:12:33.425642: Epoch time: 138.12 s 
2025-12-18 00:12:34.263499:  
2025-12-18 00:12:34.263499: Epoch 162 
2025-12-18 00:12:34.263499: Current learning rate: 0.00853 
2025-12-18 00:14:52.423560: train_loss -0.8249 
2025-12-18 00:14:52.423560: val_loss -0.8598 
2025-12-18 00:14:52.427421: Pseudo dice [0.9267, 0.952, 0.9263] 
2025-12-18 00:14:52.429423: Epoch time: 138.16 s 
2025-12-18 00:14:53.087988:  
2025-12-18 00:14:53.087988: Epoch 163 
2025-12-18 00:14:53.087988: Current learning rate: 0.00852 
2025-12-18 00:17:11.391472: train_loss -0.7912 
2025-12-18 00:17:11.391472: val_loss -0.808 
2025-12-18 00:17:11.394047: Pseudo dice [0.8964, 0.9378, 0.9187] 
2025-12-18 00:17:11.396050: Epoch time: 138.3 s 
2025-12-18 00:17:12.058330:  
2025-12-18 00:17:12.058330: Epoch 164 
2025-12-18 00:17:12.058330: Current learning rate: 0.00851 
2025-12-18 00:19:30.377658: train_loss -0.8015 
2025-12-18 00:19:30.377658: val_loss -0.8288 
2025-12-18 00:19:30.381855: Pseudo dice [0.9092, 0.9411, 0.9161] 
2025-12-18 00:19:30.384542: Epoch time: 138.32 s 
2025-12-18 00:19:31.025715:  
2025-12-18 00:19:31.025715: Epoch 165 
2025-12-18 00:19:31.025715: Current learning rate: 0.0085 
2025-12-18 00:21:49.113511: train_loss -0.8075 
2025-12-18 00:21:49.115444: val_loss -0.824 
2025-12-18 00:21:49.117450: Pseudo dice [0.9044, 0.9418, 0.9126] 
2025-12-18 00:21:49.119453: Epoch time: 138.1 s 
2025-12-18 00:21:49.778971:  
2025-12-18 00:21:49.778971: Epoch 166 
2025-12-18 00:21:49.778971: Current learning rate: 0.00849 
2025-12-18 00:24:07.872613: train_loss -0.7858 
2025-12-18 00:24:07.872613: val_loss -0.8181 
2025-12-18 00:24:07.876199: Pseudo dice [0.9144, 0.9431, 0.8995] 
2025-12-18 00:24:07.876199: Epoch time: 138.09 s 
2025-12-18 00:24:08.522684:  
2025-12-18 00:24:08.522684: Epoch 167 
2025-12-18 00:24:08.522684: Current learning rate: 0.00848 
2025-12-18 00:26:26.804133: train_loss -0.7891 
2025-12-18 00:26:26.806134: val_loss -0.805 
2025-12-18 00:26:26.808136: Pseudo dice [0.8963, 0.9386, 0.9054] 
2025-12-18 00:26:26.810138: Epoch time: 138.28 s 
2025-12-18 00:26:27.639692:  
2025-12-18 00:26:27.639692: Epoch 168 
2025-12-18 00:26:27.643573: Current learning rate: 0.00847 
2025-12-18 00:28:45.763939: train_loss -0.7893 
2025-12-18 00:28:45.765940: val_loss -0.8294 
2025-12-18 00:28:45.767943: Pseudo dice [0.901, 0.946, 0.9303] 
2025-12-18 00:28:45.769930: Epoch time: 138.12 s 
2025-12-18 00:28:46.436838:  
2025-12-18 00:28:46.436838: Epoch 169 
2025-12-18 00:28:46.436838: Current learning rate: 0.00847 
2025-12-18 00:31:04.636634: train_loss -0.8017 
2025-12-18 00:31:04.636634: val_loss -0.8325 
2025-12-18 00:31:04.636634: Pseudo dice [0.9115, 0.9453, 0.9156] 
2025-12-18 00:31:04.636634: Epoch time: 138.2 s 
2025-12-18 00:31:05.291632:  
2025-12-18 00:31:05.291632: Epoch 170 
2025-12-18 00:31:05.291632: Current learning rate: 0.00846 
2025-12-18 00:33:23.595224: train_loss -0.7981 
2025-12-18 00:33:23.595224: val_loss -0.8026 
2025-12-18 00:33:23.595224: Pseudo dice [0.8905, 0.935, 0.9099] 
2025-12-18 00:33:23.604466: Epoch time: 138.31 s 
2025-12-18 00:33:24.275604:  
2025-12-18 00:33:24.275604: Epoch 171 
2025-12-18 00:33:24.275604: Current learning rate: 0.00845 
2025-12-18 00:35:42.466499: train_loss -0.796 
2025-12-18 00:35:42.468502: val_loss -0.823 
2025-12-18 00:35:42.472508: Pseudo dice [0.9006, 0.946, 0.918] 
2025-12-18 00:35:42.472508: Epoch time: 138.19 s 
2025-12-18 00:35:43.133423:  
2025-12-18 00:35:43.133423: Epoch 172 
2025-12-18 00:35:43.133423: Current learning rate: 0.00844 
2025-12-18 00:38:01.435011: train_loss -0.8084 
2025-12-18 00:38:01.435011: val_loss -0.8307 
2025-12-18 00:38:01.437014: Pseudo dice [0.9066, 0.9444, 0.9247] 
2025-12-18 00:38:01.440513: Epoch time: 138.3 s 
2025-12-18 00:38:02.104754:  
2025-12-18 00:38:02.104754: Epoch 173 
2025-12-18 00:38:02.106757: Current learning rate: 0.00843 
2025-12-18 00:40:20.237557: train_loss -0.8202 
2025-12-18 00:40:20.237557: val_loss -0.8363 
2025-12-18 00:40:20.237557: Pseudo dice [0.9134, 0.9487, 0.9218] 
2025-12-18 00:40:20.237557: Epoch time: 138.13 s 
2025-12-18 00:40:21.076229:  
2025-12-18 00:40:21.076229: Epoch 174 
2025-12-18 00:40:21.076229: Current learning rate: 0.00842 
2025-12-18 00:42:39.155380: train_loss -0.8229 
2025-12-18 00:42:39.155380: val_loss -0.8408 
2025-12-18 00:42:39.157382: Pseudo dice [0.9139, 0.9494, 0.9183] 
2025-12-18 00:42:39.159384: Epoch time: 138.08 s 
2025-12-18 00:42:39.819479:  
2025-12-18 00:42:39.819479: Epoch 175 
2025-12-18 00:42:39.819479: Current learning rate: 0.00841 
2025-12-18 00:44:58.078092: train_loss -0.8161 
2025-12-18 00:44:58.078092: val_loss -0.8389 
2025-12-18 00:44:58.081693: Pseudo dice [0.9129, 0.947, 0.9275] 
2025-12-18 00:44:58.081693: Epoch time: 138.26 s 
2025-12-18 00:44:58.727802:  
2025-12-18 00:44:58.727802: Epoch 176 
2025-12-18 00:44:58.743724: Current learning rate: 0.0084 
2025-12-18 00:47:16.999396: train_loss -0.8056 
2025-12-18 00:47:16.999396: val_loss -0.8276 
2025-12-18 00:47:16.999396: Pseudo dice [0.9064, 0.9428, 0.914] 
2025-12-18 00:47:16.999396: Epoch time: 138.27 s 
2025-12-18 00:47:17.649245:  
2025-12-18 00:47:17.649245: Epoch 177 
2025-12-18 00:47:17.649245: Current learning rate: 0.00839 
2025-12-18 00:49:35.723659: train_loss -0.8032 
2025-12-18 00:49:35.723659: val_loss -0.8253 
2025-12-18 00:49:35.723659: Pseudo dice [0.9078, 0.9426, 0.9136] 
2025-12-18 00:49:35.723659: Epoch time: 138.07 s 
2025-12-18 00:49:36.373114:  
2025-12-18 00:49:36.373114: Epoch 178 
2025-12-18 00:49:36.373114: Current learning rate: 0.00838 
2025-12-18 00:51:54.688044: train_loss -0.8186 
2025-12-18 00:51:54.688044: val_loss -0.8307 
2025-12-18 00:51:54.691785: Pseudo dice [0.9067, 0.9438, 0.9199] 
2025-12-18 00:51:54.693787: Epoch time: 138.31 s 
2025-12-18 00:51:55.343860:  
2025-12-18 00:51:55.343860: Epoch 179 
2025-12-18 00:51:55.343860: Current learning rate: 0.00837 
2025-12-18 00:54:13.464649: train_loss -0.8209 
2025-12-18 00:54:13.466654: val_loss -0.835 
2025-12-18 00:54:13.468656: Pseudo dice [0.9094, 0.9437, 0.9189] 
2025-12-18 00:54:13.470659: Epoch time: 138.12 s 
2025-12-18 00:54:14.286985:  
2025-12-18 00:54:14.286985: Epoch 180 
2025-12-18 00:54:14.303075: Current learning rate: 0.00836 
2025-12-18 00:56:32.437552: train_loss -0.8235 
2025-12-18 00:56:32.439554: val_loss -0.8403 
2025-12-18 00:56:32.443558: Pseudo dice [0.9102, 0.9483, 0.9231] 
2025-12-18 00:56:32.445560: Epoch time: 138.15 s 
2025-12-18 00:56:33.134716:  
2025-12-18 00:56:33.134716: Epoch 181 
2025-12-18 00:56:33.134716: Current learning rate: 0.00836 
2025-12-18 00:58:51.283196: train_loss -0.8293 
2025-12-18 00:58:51.283196: val_loss -0.842 
2025-12-18 00:58:51.287200: Pseudo dice [0.9134, 0.9517, 0.922] 
2025-12-18 00:58:51.289202: Epoch time: 138.15 s 
2025-12-18 00:58:51.940264:  
2025-12-18 00:58:51.940264: Epoch 182 
2025-12-18 00:58:51.940264: Current learning rate: 0.00835 
2025-12-18 01:01:10.278159: train_loss -0.82 
2025-12-18 01:01:10.278159: val_loss -0.8383 
2025-12-18 01:01:10.282163: Pseudo dice [0.9073, 0.9425, 0.9286] 
2025-12-18 01:01:10.284165: Epoch time: 138.34 s 
2025-12-18 01:01:10.934543:  
2025-12-18 01:01:10.934543: Epoch 183 
2025-12-18 01:01:10.934543: Current learning rate: 0.00834 
2025-12-18 01:03:29.276942: train_loss -0.8236 
2025-12-18 01:03:29.276942: val_loss -0.8374 
2025-12-18 01:03:29.280946: Pseudo dice [0.9122, 0.946, 0.9181] 
2025-12-18 01:03:29.282948: Epoch time: 138.36 s 
2025-12-18 01:03:29.929180:  
2025-12-18 01:03:29.929180: Epoch 184 
2025-12-18 01:03:29.929180: Current learning rate: 0.00833 
2025-12-18 01:05:48.121102: train_loss -0.829 
2025-12-18 01:05:48.121102: val_loss -0.8496 
2025-12-18 01:05:48.136927: Pseudo dice [0.9187, 0.9504, 0.9234] 
2025-12-18 01:05:48.136927: Epoch time: 138.19 s 
2025-12-18 01:05:48.787672:  
2025-12-18 01:05:48.787672: Epoch 185 
2025-12-18 01:05:48.787672: Current learning rate: 0.00832 
2025-12-18 01:08:06.934641: train_loss -0.8326 
2025-12-18 01:08:06.934641: val_loss -0.8511 
2025-12-18 01:08:06.934641: Pseudo dice [0.9169, 0.9505, 0.9301] 
2025-12-18 01:08:06.950408: Epoch time: 138.15 s 
2025-12-18 01:08:07.758630:  
2025-12-18 01:08:07.758630: Epoch 186 
2025-12-18 01:08:07.758630: Current learning rate: 0.00831 
2025-12-18 01:10:26.316653: train_loss -0.8297 
2025-12-18 01:10:26.316653: val_loss -0.8443 
2025-12-18 01:10:26.320397: Pseudo dice [0.9161, 0.9453, 0.9235] 
2025-12-18 01:10:26.322400: Epoch time: 138.56 s 
2025-12-18 01:10:26.986014:  
2025-12-18 01:10:26.986014: Epoch 187 
2025-12-18 01:10:26.986014: Current learning rate: 0.0083 
2025-12-18 01:12:45.017153: train_loss -0.8262 
2025-12-18 01:12:45.017153: val_loss -0.8461 
2025-12-18 01:12:45.031650: Pseudo dice [0.9143, 0.9513, 0.9259] 
2025-12-18 01:12:45.033152: Epoch time: 138.03 s 
2025-12-18 01:12:45.681413:  
2025-12-18 01:12:45.681413: Epoch 188 
2025-12-18 01:12:45.681413: Current learning rate: 0.00829 
2025-12-18 01:15:03.867854: train_loss -0.8258 
2025-12-18 01:15:03.867854: val_loss -0.8417 
2025-12-18 01:15:03.873600: Pseudo dice [0.9142, 0.9463, 0.9196] 
2025-12-18 01:15:03.875602: Epoch time: 138.19 s 
2025-12-18 01:15:04.540978:  
2025-12-18 01:15:04.540978: Epoch 189 
2025-12-18 01:15:04.540978: Current learning rate: 0.00828 
2025-12-18 01:17:22.680119: train_loss -0.8322 
2025-12-18 01:17:22.680119: val_loss -0.8501 
2025-12-18 01:17:22.682122: Pseudo dice [0.9163, 0.9537, 0.9273] 
2025-12-18 01:17:22.682122: Epoch time: 138.14 s 
2025-12-18 01:17:23.387363:  
2025-12-18 01:17:23.387363: Epoch 190 
2025-12-18 01:17:23.387363: Current learning rate: 0.00827 
2025-12-18 01:19:41.645643: train_loss -0.8277 
2025-12-18 01:19:41.647645: val_loss -0.8527 
2025-12-18 01:19:41.649648: Pseudo dice [0.9235, 0.9537, 0.9175] 
2025-12-18 01:19:41.651650: Epoch time: 138.26 s 
2025-12-18 01:19:41.653390: Yayy! New best EMA pseudo Dice: 0.9277 
2025-12-18 01:19:42.535215:  
2025-12-18 01:19:42.535215: Epoch 191 
2025-12-18 01:19:42.549057: Current learning rate: 0.00826 
2025-12-18 01:22:00.666121: train_loss -0.8262 
2025-12-18 01:22:00.666121: val_loss -0.847 
2025-12-18 01:22:00.666121: Pseudo dice [0.9158, 0.9461, 0.919] 
2025-12-18 01:22:00.681772: Epoch time: 138.13 s 
2025-12-18 01:22:01.508416:  
2025-12-18 01:22:01.508416: Epoch 192 
2025-12-18 01:22:01.522283: Current learning rate: 0.00825 
2025-12-18 01:24:19.792330: train_loss -0.8248 
2025-12-18 01:24:19.794333: val_loss -0.8489 
2025-12-18 01:24:19.796336: Pseudo dice [0.9189, 0.9486, 0.9303] 
2025-12-18 01:24:19.800343: Epoch time: 138.28 s 
2025-12-18 01:24:19.802345: Yayy! New best EMA pseudo Dice: 0.9281 
2025-12-18 01:24:20.756201:  
2025-12-18 01:24:20.756201: Epoch 193 
2025-12-18 01:24:20.756201: Current learning rate: 0.00824 
2025-12-18 01:26:39.021779: train_loss -0.8291 
2025-12-18 01:26:39.021779: val_loss -0.8533 
2025-12-18 01:26:39.037714: Pseudo dice [0.9202, 0.9536, 0.9255] 
2025-12-18 01:26:39.040176: Epoch time: 138.27 s 
2025-12-18 01:26:39.040176: Yayy! New best EMA pseudo Dice: 0.9286 
2025-12-18 01:26:39.979590:  
2025-12-18 01:26:39.979590: Epoch 194 
2025-12-18 01:26:39.979590: Current learning rate: 0.00824 
2025-12-18 01:28:58.180995: train_loss -0.8287 
2025-12-18 01:28:58.180995: val_loss -0.8337 
2025-12-18 01:28:58.184999: Pseudo dice [0.9079, 0.9423, 0.9255] 
2025-12-18 01:28:58.187001: Epoch time: 138.2 s 
2025-12-18 01:28:58.880368:  
2025-12-18 01:28:58.880368: Epoch 195 
2025-12-18 01:28:58.882371: Current learning rate: 0.00823 
2025-12-18 01:31:17.106886: train_loss -0.8283 
2025-12-18 01:31:17.106886: val_loss -0.8412 
2025-12-18 01:31:17.111807: Pseudo dice [0.9083, 0.9474, 0.9342] 
2025-12-18 01:31:17.111807: Epoch time: 138.23 s 
2025-12-18 01:31:17.784384:  
2025-12-18 01:31:17.784384: Epoch 196 
2025-12-18 01:31:17.784384: Current learning rate: 0.00822 
2025-12-18 01:33:36.092687: train_loss -0.8337 
2025-12-18 01:33:36.092687: val_loss -0.8544 
2025-12-18 01:33:36.092687: Pseudo dice [0.9223, 0.9515, 0.9284] 
2025-12-18 01:33:36.105171: Epoch time: 138.31 s 
2025-12-18 01:33:36.107174: Yayy! New best EMA pseudo Dice: 0.929 
2025-12-18 01:33:37.031168:  
2025-12-18 01:33:37.031168: Epoch 197 
2025-12-18 01:33:37.031168: Current learning rate: 0.00821 
2025-12-18 01:35:55.339782: train_loss -0.8278 
2025-12-18 01:35:55.339782: val_loss -0.8424 
2025-12-18 01:35:55.342074: Pseudo dice [0.9108, 0.945, 0.9227] 
2025-12-18 01:35:55.342074: Epoch time: 138.31 s 
2025-12-18 01:35:56.157884:  
2025-12-18 01:35:56.157884: Epoch 198 
2025-12-18 01:35:56.157884: Current learning rate: 0.0082 
2025-12-18 01:38:14.236281: train_loss -0.828 
2025-12-18 01:38:14.238101: val_loss -0.8542 
2025-12-18 01:38:14.240104: Pseudo dice [0.9213, 0.9513, 0.9286] 
2025-12-18 01:38:14.244107: Epoch time: 138.08 s 
2025-12-18 01:38:14.246110: Yayy! New best EMA pseudo Dice: 0.9292 
2025-12-18 01:38:15.178135:  
2025-12-18 01:38:15.178135: Epoch 199 
2025-12-18 01:38:15.178135: Current learning rate: 0.00819 
2025-12-18 01:40:33.357751: train_loss -0.8379 
2025-12-18 01:40:33.357751: val_loss -0.8513 
2025-12-18 01:40:33.359754: Pseudo dice [0.917, 0.9514, 0.929] 
2025-12-18 01:40:33.365311: Epoch time: 138.18 s 
2025-12-18 01:40:33.609794: Yayy! New best EMA pseudo Dice: 0.9295 
2025-12-18 01:40:34.544866:  
2025-12-18 01:40:34.544866: Epoch 200 
2025-12-18 01:40:34.544866: Current learning rate: 0.00818 
2025-12-18 01:42:52.860301: train_loss -0.8306 
2025-12-18 01:42:52.860301: val_loss -0.8513 
2025-12-18 01:42:52.866314: Pseudo dice [0.9176, 0.9475, 0.9278] 
2025-12-18 01:42:52.866314: Epoch time: 138.32 s 
2025-12-18 01:42:52.870142: Yayy! New best EMA pseudo Dice: 0.9297 
2025-12-18 01:42:53.796718:  
2025-12-18 01:42:53.796718: Epoch 201 
2025-12-18 01:42:53.796718: Current learning rate: 0.00817 
2025-12-18 01:45:12.136860: train_loss -0.8332 
2025-12-18 01:45:12.136860: val_loss -0.8423 
2025-12-18 01:45:12.141251: Pseudo dice [0.912, 0.9474, 0.9335] 
2025-12-18 01:45:12.141251: Epoch time: 138.34 s 
2025-12-18 01:45:12.146264: Yayy! New best EMA pseudo Dice: 0.9298 
2025-12-18 01:45:13.087829:  
2025-12-18 01:45:13.087829: Epoch 202 
2025-12-18 01:45:13.097553: Current learning rate: 0.00816 
2025-12-18 01:47:31.335215: train_loss -0.8294 
2025-12-18 01:47:31.335215: val_loss -0.845 
2025-12-18 01:47:31.335215: Pseudo dice [0.9137, 0.9468, 0.9314] 
2025-12-18 01:47:31.335215: Epoch time: 138.25 s 
2025-12-18 01:47:31.335215: Yayy! New best EMA pseudo Dice: 0.9299 
2025-12-18 01:47:32.610779:  
2025-12-18 01:47:32.610779: Epoch 203 
2025-12-18 01:47:32.612782: Current learning rate: 0.00815 
2025-12-18 01:49:50.685613: train_loss -0.8322 
2025-12-18 01:49:50.687615: val_loss -0.8496 
2025-12-18 01:49:50.689618: Pseudo dice [0.9187, 0.95, 0.9271] 
2025-12-18 01:49:50.691620: Epoch time: 138.08 s 
2025-12-18 01:49:50.691620: Yayy! New best EMA pseudo Dice: 0.9301 
2025-12-18 01:49:51.628066:  
2025-12-18 01:49:51.628066: Epoch 204 
2025-12-18 01:49:51.628066: Current learning rate: 0.00814 
2025-12-18 01:52:09.864851: train_loss -0.8302 
2025-12-18 01:52:09.866856: val_loss -0.85 
2025-12-18 01:52:09.870864: Pseudo dice [0.9134, 0.9473, 0.9286] 
2025-12-18 01:52:09.872605: Epoch time: 138.24 s 
2025-12-18 01:52:10.540146:  
2025-12-18 01:52:10.542149: Epoch 205 
2025-12-18 01:52:10.542149: Current learning rate: 0.00813 
2025-12-18 01:54:28.812549: train_loss -0.8306 
2025-12-18 01:54:28.812549: val_loss -0.8508 
2025-12-18 01:54:28.815754: Pseudo dice [0.9174, 0.9503, 0.9244] 
2025-12-18 01:54:28.817756: Epoch time: 138.27 s 
2025-12-18 01:54:28.819758: Yayy! New best EMA pseudo Dice: 0.9301 
2025-12-18 01:54:29.802261:  
2025-12-18 01:54:29.802261: Epoch 206 
2025-12-18 01:54:29.802261: Current learning rate: 0.00813 
2025-12-18 01:56:48.022148: train_loss -0.835 
2025-12-18 01:56:48.022148: val_loss -0.8499 
2025-12-18 01:56:48.024151: Pseudo dice [0.9132, 0.9466, 0.9352] 
2025-12-18 01:56:48.026153: Epoch time: 138.22 s 
2025-12-18 01:56:48.029655: Yayy! New best EMA pseudo Dice: 0.9303 
2025-12-18 01:56:48.946030:  
2025-12-18 01:56:48.948032: Epoch 207 
2025-12-18 01:56:48.949774: Current learning rate: 0.00812 
2025-12-18 01:59:07.076473: train_loss -0.8287 
2025-12-18 01:59:07.076473: val_loss -0.8573 
2025-12-18 01:59:07.076473: Pseudo dice [0.9192, 0.9508, 0.9352] 
2025-12-18 01:59:07.090416: Epoch time: 138.13 s 
2025-12-18 01:59:07.092155: Yayy! New best EMA pseudo Dice: 0.9308 
2025-12-18 01:59:07.986284:  
2025-12-18 01:59:07.988024: Epoch 208 
2025-12-18 01:59:07.988024: Current learning rate: 0.00811 
2025-12-18 02:01:25.988534: train_loss -0.8337 
2025-12-18 02:01:25.988534: val_loss -0.839 
2025-12-18 02:01:25.992540: Pseudo dice [0.9075, 0.9465, 0.9293] 
2025-12-18 02:01:25.994543: Epoch time: 138.0 s 
2025-12-18 02:01:26.963345:  
2025-12-18 02:01:26.963345: Epoch 209 
2025-12-18 02:01:26.970593: Current learning rate: 0.0081 
2025-12-18 02:03:45.400727: train_loss -0.8291 
2025-12-18 02:03:45.400727: val_loss -0.8448 
2025-12-18 02:03:45.413901: Pseudo dice [0.9118, 0.9534, 0.9251] 
2025-12-18 02:03:45.416419: Epoch time: 138.44 s 
2025-12-18 02:03:46.050780:  
2025-12-18 02:03:46.050780: Epoch 210 
2025-12-18 02:03:46.050780: Current learning rate: 0.00809 
2025-12-18 02:06:04.206289: train_loss -0.822 
2025-12-18 02:06:04.206289: val_loss -0.8466 
2025-12-18 02:06:04.210294: Pseudo dice [0.919, 0.949, 0.9143] 
2025-12-18 02:06:04.212297: Epoch time: 138.16 s 
2025-12-18 02:06:04.844678:  
2025-12-18 02:06:04.844678: Epoch 211 
2025-12-18 02:06:04.844678: Current learning rate: 0.00808 
2025-12-18 02:08:22.962981: train_loss -0.827 
2025-12-18 02:08:22.962981: val_loss -0.8501 
2025-12-18 02:08:22.975032: Pseudo dice [0.9204, 0.9497, 0.9171] 
2025-12-18 02:08:22.977036: Epoch time: 138.12 s 
2025-12-18 02:08:23.770472:  
2025-12-18 02:08:23.770472: Epoch 212 
2025-12-18 02:08:23.770472: Current learning rate: 0.00807 
2025-12-18 02:10:42.191570: train_loss -0.8299 
2025-12-18 02:10:42.193472: val_loss -0.8605 
2025-12-18 02:10:42.195474: Pseudo dice [0.9251, 0.9511, 0.9283] 
2025-12-18 02:10:42.197477: Epoch time: 138.42 s 
2025-12-18 02:10:42.843462:  
2025-12-18 02:10:42.843462: Epoch 213 
2025-12-18 02:10:42.843462: Current learning rate: 0.00806 
2025-12-18 02:13:01.169363: train_loss -0.8323 
2025-12-18 02:13:01.169363: val_loss -0.8576 
2025-12-18 02:13:01.173457: Pseudo dice [0.9212, 0.9582, 0.9247] 
2025-12-18 02:13:01.175460: Epoch time: 138.33 s 
2025-12-18 02:13:01.177315: Yayy! New best EMA pseudo Dice: 0.9309 
2025-12-18 02:13:02.042335:  
2025-12-18 02:13:02.042335: Epoch 214 
2025-12-18 02:13:02.042335: Current learning rate: 0.00805 
2025-12-18 02:15:20.154467: train_loss -0.8359 
2025-12-18 02:15:20.156207: val_loss -0.8464 
2025-12-18 02:15:20.160212: Pseudo dice [0.9146, 0.9462, 0.9271] 
2025-12-18 02:15:20.160212: Epoch time: 138.11 s 
2025-12-18 02:15:21.100969:  
2025-12-18 02:15:21.100969: Epoch 215 
2025-12-18 02:15:21.102710: Current learning rate: 0.00804 
2025-12-18 02:17:39.209533: train_loss -0.8343 
2025-12-18 02:17:39.209533: val_loss -0.8545 
2025-12-18 02:17:39.211535: Pseudo dice [0.9163, 0.95, 0.936] 
2025-12-18 02:17:39.211535: Epoch time: 138.11 s 
2025-12-18 02:17:39.217866: Yayy! New best EMA pseudo Dice: 0.9311 
2025-12-18 02:17:40.120801:  
2025-12-18 02:17:40.122542: Epoch 216 
2025-12-18 02:17:40.122542: Current learning rate: 0.00803 
2025-12-18 02:19:58.240687: train_loss -0.8321 
2025-12-18 02:19:58.242693: val_loss -0.8614 
2025-12-18 02:19:58.248706: Pseudo dice [0.9247, 0.9539, 0.9315] 
2025-12-18 02:19:58.250709: Epoch time: 138.12 s 
2025-12-18 02:19:58.252712: Yayy! New best EMA pseudo Dice: 0.9317 
2025-12-18 02:19:59.148846:  
2025-12-18 02:19:59.148846: Epoch 217 
2025-12-18 02:19:59.150588: Current learning rate: 0.00802 
2025-12-18 02:22:17.343737: train_loss -0.8322 
2025-12-18 02:22:17.343737: val_loss -0.8434 
2025-12-18 02:22:17.347480: Pseudo dice [0.9128, 0.9451, 0.9303] 
2025-12-18 02:22:17.347480: Epoch time: 138.2 s 
2025-12-18 02:22:18.073368:  
2025-12-18 02:22:18.073368: Epoch 218 
2025-12-18 02:22:18.073368: Current learning rate: 0.00801 
2025-12-18 02:24:36.331615: train_loss -0.8295 
2025-12-18 02:24:36.336169: val_loss -0.8512 
2025-12-18 02:24:36.338171: Pseudo dice [0.9252, 0.9516, 0.9171] 
2025-12-18 02:24:36.340173: Epoch time: 138.26 s 
2025-12-18 02:24:36.975518:  
2025-12-18 02:24:36.975518: Epoch 219 
2025-12-18 02:24:36.975518: Current learning rate: 0.00801 
2025-12-18 02:26:55.283211: train_loss -0.8258 
2025-12-18 02:26:55.283211: val_loss -0.8542 
2025-12-18 02:26:55.298995: Pseudo dice [0.9209, 0.9548, 0.9315] 
2025-12-18 02:26:55.298995: Epoch time: 138.31 s 
2025-12-18 02:26:55.298995: Yayy! New best EMA pseudo Dice: 0.9318 
2025-12-18 02:26:56.162812:  
2025-12-18 02:26:56.162812: Epoch 220 
2025-12-18 02:26:56.164554: Current learning rate: 0.008 
2025-12-18 02:29:14.296799: train_loss -0.8395 
2025-12-18 02:29:14.296799: val_loss -0.8554 
2025-12-18 02:29:14.300804: Pseudo dice [0.9201, 0.9496, 0.9287] 
2025-12-18 02:29:14.303808: Epoch time: 138.14 s 
2025-12-18 02:29:14.305811: Yayy! New best EMA pseudo Dice: 0.9319 
2025-12-18 02:29:15.440096:  
2025-12-18 02:29:15.440096: Epoch 221 
2025-12-18 02:29:15.440096: Current learning rate: 0.00799 
2025-12-18 02:31:33.624535: train_loss -0.8372 
2025-12-18 02:31:33.624535: val_loss -0.858 
2025-12-18 02:31:33.640523: Pseudo dice [0.9215, 0.9549, 0.9247] 
2025-12-18 02:31:33.642526: Epoch time: 138.2 s 
2025-12-18 02:31:33.644529: Yayy! New best EMA pseudo Dice: 0.9321 
2025-12-18 02:31:34.542986:  
2025-12-18 02:31:34.544727: Epoch 222 
2025-12-18 02:31:34.544727: Current learning rate: 0.00798 
2025-12-18 02:33:52.773261: train_loss -0.8223 
2025-12-18 02:33:52.773261: val_loss -0.8277 
2025-12-18 02:33:52.777184: Pseudo dice [0.8999, 0.9407, 0.9214] 
2025-12-18 02:33:52.779187: Epoch time: 138.23 s 
2025-12-18 02:33:53.422716:  
2025-12-18 02:33:53.422716: Epoch 223 
2025-12-18 02:33:53.422716: Current learning rate: 0.00797 
2025-12-18 02:36:11.614858: train_loss -0.8245 
2025-12-18 02:36:11.614858: val_loss -0.8375 
2025-12-18 02:36:11.614858: Pseudo dice [0.9126, 0.9458, 0.9118] 
2025-12-18 02:36:11.620356: Epoch time: 138.2 s 
2025-12-18 02:36:12.256657:  
2025-12-18 02:36:12.256657: Epoch 224 
2025-12-18 02:36:12.256657: Current learning rate: 0.00796 
2025-12-18 02:38:30.438572: train_loss -0.8309 
2025-12-18 02:38:30.438572: val_loss -0.8574 
2025-12-18 02:38:30.440574: Pseudo dice [0.9203, 0.9492, 0.9373] 
2025-12-18 02:38:30.442576: Epoch time: 138.18 s 
2025-12-18 02:38:31.090357:  
2025-12-18 02:38:31.090357: Epoch 225 
2025-12-18 02:38:31.094042: Current learning rate: 0.00795 
2025-12-18 02:40:49.380696: train_loss -0.8293 
2025-12-18 02:40:49.380696: val_loss -0.8617 
2025-12-18 02:40:49.383700: Pseudo dice [0.9264, 0.956, 0.923] 
2025-12-18 02:40:49.385555: Epoch time: 138.29 s 
2025-12-18 02:40:50.019321:  
2025-12-18 02:40:50.019321: Epoch 226 
2025-12-18 02:40:50.019321: Current learning rate: 0.00794 
2025-12-18 02:43:08.287088: train_loss -0.8346 
2025-12-18 02:43:08.287088: val_loss -0.8556 
2025-12-18 02:43:08.289620: Pseudo dice [0.9224, 0.9503, 0.9281] 
2025-12-18 02:43:08.289620: Epoch time: 138.27 s 
2025-12-18 02:43:08.919828:  
2025-12-18 02:43:08.919828: Epoch 227 
2025-12-18 02:43:08.919828: Current learning rate: 0.00793 
2025-12-18 02:45:27.140873: train_loss -0.8263 
2025-12-18 02:45:27.142876: val_loss -0.8373 
2025-12-18 02:45:27.142876: Pseudo dice [0.9077, 0.9463, 0.9262] 
2025-12-18 02:45:27.142876: Epoch time: 138.22 s 
2025-12-18 02:45:27.941510:  
2025-12-18 02:45:27.941510: Epoch 228 
2025-12-18 02:45:27.941510: Current learning rate: 0.00792 
2025-12-18 02:47:46.179110: train_loss -0.8239 
2025-12-18 02:47:46.179110: val_loss -0.8463 
2025-12-18 02:47:46.191572: Pseudo dice [0.9152, 0.9416, 0.9216] 
2025-12-18 02:47:46.193574: Epoch time: 138.24 s 
2025-12-18 02:47:46.816622:  
2025-12-18 02:47:46.816622: Epoch 229 
2025-12-18 02:47:46.816622: Current learning rate: 0.00791 
2025-12-18 02:50:05.065478: train_loss -0.8298 
2025-12-18 02:50:05.067481: val_loss -0.8527 
2025-12-18 02:50:05.071300: Pseudo dice [0.9219, 0.9531, 0.9247] 
2025-12-18 02:50:05.073251: Epoch time: 138.25 s 
2025-12-18 02:50:05.695813:  
2025-12-18 02:50:05.695813: Epoch 230 
2025-12-18 02:50:05.711534: Current learning rate: 0.0079 
2025-12-18 02:52:23.837546: train_loss -0.8241 
2025-12-18 02:52:23.837546: val_loss -0.858 
2025-12-18 02:52:23.838547: Pseudo dice [0.9232, 0.9518, 0.9304] 
2025-12-18 02:52:23.838547: Epoch time: 138.14 s 
2025-12-18 02:52:24.457712:  
2025-12-18 02:52:24.457712: Epoch 231 
2025-12-18 02:52:24.457712: Current learning rate: 0.00789 
2025-12-18 02:54:42.634085: train_loss -0.832 
2025-12-18 02:54:42.634085: val_loss -0.8458 
2025-12-18 02:54:42.637803: Pseudo dice [0.9141, 0.943, 0.9343] 
2025-12-18 02:54:42.637803: Epoch time: 138.18 s 
2025-12-18 02:54:43.264429:  
2025-12-18 02:54:43.264429: Epoch 232 
2025-12-18 02:54:43.264429: Current learning rate: 0.00789 
2025-12-18 02:57:01.481192: train_loss -0.8283 
2025-12-18 02:57:01.483194: val_loss -0.8513 
2025-12-18 02:57:01.486938: Pseudo dice [0.9199, 0.9521, 0.9301] 
2025-12-18 02:57:01.488940: Epoch time: 138.22 s 
2025-12-18 02:57:02.162681:  
2025-12-18 02:57:02.162681: Epoch 233 
2025-12-18 02:57:02.162681: Current learning rate: 0.00788 
2025-12-18 02:59:20.370405: train_loss -0.8327 
2025-12-18 02:59:20.372408: val_loss -0.8486 
2025-12-18 02:59:20.374411: Pseudo dice [0.9133, 0.9504, 0.9297] 
2025-12-18 02:59:20.376413: Epoch time: 138.21 s 
2025-12-18 02:59:21.173671:  
2025-12-18 02:59:21.173671: Epoch 234 
2025-12-18 02:59:21.173671: Current learning rate: 0.00787 
2025-12-18 03:01:39.133242: train_loss -0.8356 
2025-12-18 03:01:39.133242: val_loss -0.844 
2025-12-18 03:01:39.135245: Pseudo dice [0.9148, 0.9442, 0.9217] 
2025-12-18 03:01:39.137248: Epoch time: 137.96 s 
2025-12-18 03:01:39.768304:  
2025-12-18 03:01:39.768304: Epoch 235 
2025-12-18 03:01:39.768304: Current learning rate: 0.00786 
2025-12-18 03:03:57.977259: train_loss -0.8356 
2025-12-18 03:03:57.977259: val_loss -0.8472 
2025-12-18 03:03:57.980336: Pseudo dice [0.9151, 0.9478, 0.9255] 
2025-12-18 03:03:57.980336: Epoch time: 138.21 s 
2025-12-18 03:03:58.604481:  
2025-12-18 03:03:58.604481: Epoch 236 
2025-12-18 03:03:58.606222: Current learning rate: 0.00785 
2025-12-18 03:06:16.786683: train_loss -0.8281 
2025-12-18 03:06:16.786683: val_loss -0.8463 
2025-12-18 03:06:16.797055: Pseudo dice [0.9134, 0.9457, 0.9283] 
2025-12-18 03:06:16.797055: Epoch time: 138.18 s 
2025-12-18 03:06:17.419768:  
2025-12-18 03:06:17.419768: Epoch 237 
2025-12-18 03:06:17.435747: Current learning rate: 0.00784 
2025-12-18 03:08:35.734929: train_loss -0.8306 
2025-12-18 03:08:35.734929: val_loss -0.8519 
2025-12-18 03:08:35.750737: Pseudo dice [0.9188, 0.9527, 0.9249] 
2025-12-18 03:08:35.750737: Epoch time: 138.32 s 
2025-12-18 03:08:36.365867:  
2025-12-18 03:08:36.365867: Epoch 238 
2025-12-18 03:08:36.365867: Current learning rate: 0.00783 
2025-12-18 03:10:54.940591: train_loss -0.8254 
2025-12-18 03:10:54.942594: val_loss -0.8548 
2025-12-18 03:10:54.944539: Pseudo dice [0.9174, 0.9484, 0.9385] 
2025-12-18 03:10:54.948138: Epoch time: 138.57 s 
2025-12-18 03:10:55.570498:  
2025-12-18 03:10:55.570498: Epoch 239 
2025-12-18 03:10:55.570498: Current learning rate: 0.00782 
2025-12-18 03:13:13.706127: train_loss -0.8294 
2025-12-18 03:13:13.706127: val_loss -0.8381 
2025-12-18 03:13:13.722194: Pseudo dice [0.9134, 0.9453, 0.9168] 
2025-12-18 03:13:13.722194: Epoch time: 138.14 s 
2025-12-18 03:13:14.513741:  
2025-12-18 03:13:14.513741: Epoch 240 
2025-12-18 03:13:14.513741: Current learning rate: 0.00781 
2025-12-18 03:15:32.758488: train_loss -0.82 
2025-12-18 03:15:32.758488: val_loss -0.8169 
2025-12-18 03:15:32.762445: Pseudo dice [0.8998, 0.9449, 0.9126] 
2025-12-18 03:15:32.764447: Epoch time: 138.24 s 
2025-12-18 03:15:33.399741:  
2025-12-18 03:15:33.401744: Epoch 241 
2025-12-18 03:15:33.401744: Current learning rate: 0.0078 
2025-12-18 03:17:51.628690: train_loss -0.8047 
2025-12-18 03:17:51.628690: val_loss -0.8499 
2025-12-18 03:17:51.628690: Pseudo dice [0.9224, 0.9536, 0.9247] 
2025-12-18 03:17:51.644549: Epoch time: 138.23 s 
2025-12-18 03:17:52.281847:  
2025-12-18 03:17:52.281847: Epoch 242 
2025-12-18 03:17:52.281847: Current learning rate: 0.00779 
2025-12-18 03:20:10.203177: train_loss -0.8258 
2025-12-18 03:20:10.203177: val_loss -0.8377 
2025-12-18 03:20:10.205179: Pseudo dice [0.9164, 0.9481, 0.9111] 
2025-12-18 03:20:10.209183: Epoch time: 137.92 s 
2025-12-18 03:20:10.844949:  
2025-12-18 03:20:10.844949: Epoch 243 
2025-12-18 03:20:10.844949: Current learning rate: 0.00778 
2025-12-18 03:22:29.169134: train_loss -0.8281 
2025-12-18 03:22:29.169134: val_loss -0.8512 
2025-12-18 03:22:29.172876: Pseudo dice [0.9201, 0.9528, 0.9237] 
2025-12-18 03:22:29.172876: Epoch time: 138.33 s 
2025-12-18 03:22:29.820083:  
2025-12-18 03:22:29.820083: Epoch 244 
2025-12-18 03:22:29.820083: Current learning rate: 0.00777 
2025-12-18 03:24:47.996979: train_loss -0.8342 
2025-12-18 03:24:47.996979: val_loss -0.8555 
2025-12-18 03:24:48.010334: Pseudo dice [0.9174, 0.9504, 0.9353] 
2025-12-18 03:24:48.012853: Epoch time: 138.18 s 
2025-12-18 03:24:48.647569:  
2025-12-18 03:24:48.647569: Epoch 245 
2025-12-18 03:24:48.647569: Current learning rate: 0.00777 
2025-12-18 03:27:06.781179: train_loss -0.8296 
2025-12-18 03:27:06.783182: val_loss -0.8376 
2025-12-18 03:27:06.789876: Pseudo dice [0.917, 0.9512, 0.9118] 
2025-12-18 03:27:06.791879: Epoch time: 138.13 s 
2025-12-18 03:27:07.410798:  
2025-12-18 03:27:07.410798: Epoch 246 
2025-12-18 03:27:07.428512: Current learning rate: 0.00776 
2025-12-18 03:29:25.630988: train_loss -0.8164 
2025-12-18 03:29:25.630988: val_loss -0.8414 
2025-12-18 03:29:25.644752: Pseudo dice [0.9149, 0.9498, 0.9183] 
2025-12-18 03:29:25.646756: Epoch time: 138.22 s 
2025-12-18 03:29:26.438773:  
2025-12-18 03:29:26.438773: Epoch 247 
2025-12-18 03:29:26.451975: Current learning rate: 0.00775 
2025-12-18 03:31:44.478928: train_loss -0.8232 
2025-12-18 03:31:44.478928: val_loss -0.8431 
2025-12-18 03:31:44.494690: Pseudo dice [0.9162, 0.9448, 0.9089] 
2025-12-18 03:31:44.497643: Epoch time: 138.04 s 
2025-12-18 03:31:45.112055:  
2025-12-18 03:31:45.112055: Epoch 248 
2025-12-18 03:31:45.112055: Current learning rate: 0.00774 
2025-12-18 03:34:03.303936: train_loss -0.8213 
2025-12-18 03:34:03.303936: val_loss -0.8352 
2025-12-18 03:34:03.321898: Pseudo dice [0.9132, 0.9484, 0.9105] 
2025-12-18 03:34:03.321898: Epoch time: 138.19 s 
2025-12-18 03:34:03.952578:  
2025-12-18 03:34:03.952578: Epoch 249 
2025-12-18 03:34:03.967106: Current learning rate: 0.00773 
2025-12-18 03:36:22.106467: train_loss -0.8286 
2025-12-18 03:36:22.108469: val_loss -0.8525 
2025-12-18 03:36:22.110653: Pseudo dice [0.9154, 0.9494, 0.9341] 
2025-12-18 03:36:22.114659: Epoch time: 138.15 s 
2025-12-18 03:36:23.005071:  
2025-12-18 03:36:23.005071: Epoch 250 
2025-12-18 03:36:23.005071: Current learning rate: 0.00772 
2025-12-18 03:38:40.977467: train_loss -0.834 
2025-12-18 03:38:40.978469: val_loss -0.8426 
2025-12-18 03:38:40.982475: Pseudo dice [0.909, 0.947, 0.9352] 
2025-12-18 03:38:40.984477: Epoch time: 137.97 s 
2025-12-18 03:38:41.643461:  
2025-12-18 03:38:41.643461: Epoch 251 
2025-12-18 03:38:41.643461: Current learning rate: 0.00771 
2025-12-18 03:40:59.745132: train_loss -0.835 
2025-12-18 03:40:59.745132: val_loss -0.8614 
2025-12-18 03:40:59.745132: Pseudo dice [0.9212, 0.9533, 0.9336] 
2025-12-18 03:40:59.745132: Epoch time: 138.1 s 
2025-12-18 03:41:00.364020:  
2025-12-18 03:41:00.364020: Epoch 252 
2025-12-18 03:41:00.380049: Current learning rate: 0.0077 
2025-12-18 03:43:18.458658: train_loss -0.8355 
2025-12-18 03:43:18.458658: val_loss -0.8516 
2025-12-18 03:43:18.460660: Pseudo dice [0.9161, 0.9499, 0.9239] 
2025-12-18 03:43:18.460660: Epoch time: 138.09 s 
2025-12-18 03:43:19.254565:  
2025-12-18 03:43:19.254565: Epoch 253 
2025-12-18 03:43:19.254565: Current learning rate: 0.00769 
2025-12-18 03:45:37.533048: train_loss -0.8342 
2025-12-18 03:45:37.533048: val_loss -0.8447 
2025-12-18 03:45:37.537219: Pseudo dice [0.9178, 0.9544, 0.9134] 
2025-12-18 03:45:37.537219: Epoch time: 138.28 s 
2025-12-18 03:45:38.276940:  
2025-12-18 03:45:38.276940: Epoch 254 
2025-12-18 03:45:38.276940: Current learning rate: 0.00768 
2025-12-18 03:47:56.373682: train_loss -0.8347 
2025-12-18 03:47:56.373682: val_loss -0.8478 
2025-12-18 03:47:56.373682: Pseudo dice [0.9154, 0.9483, 0.9257] 
2025-12-18 03:47:56.389320: Epoch time: 138.1 s 
2025-12-18 03:47:57.024531:  
2025-12-18 03:47:57.024531: Epoch 255 
2025-12-18 03:47:57.026835: Current learning rate: 0.00767 
2025-12-18 03:50:15.282107: train_loss -0.8281 
2025-12-18 03:50:15.282107: val_loss -0.8419 
2025-12-18 03:50:15.286114: Pseudo dice [0.9113, 0.9496, 0.9273] 
2025-12-18 03:50:15.289315: Epoch time: 138.27 s 
2025-12-18 03:50:15.923887:  
2025-12-18 03:50:15.923887: Epoch 256 
2025-12-18 03:50:15.923887: Current learning rate: 0.00766 
2025-12-18 03:52:34.139557: train_loss -0.8271 
2025-12-18 03:52:34.139557: val_loss -0.8554 
2025-12-18 03:52:34.143564: Pseudo dice [0.9216, 0.9533, 0.926] 
2025-12-18 03:52:34.147308: Epoch time: 138.22 s 
2025-12-18 03:52:34.936422:  
2025-12-18 03:52:34.936422: Epoch 257 
2025-12-18 03:52:34.936422: Current learning rate: 0.00765 
2025-12-18 03:54:53.242930: train_loss -0.8198 
2025-12-18 03:54:53.244933: val_loss -0.846 
2025-12-18 03:54:53.246934: Pseudo dice [0.9185, 0.9512, 0.9125] 
2025-12-18 03:54:53.249942: Epoch time: 138.31 s 
2025-12-18 03:54:53.883170:  
2025-12-18 03:54:53.883170: Epoch 258 
2025-12-18 03:54:53.883170: Current learning rate: 0.00764 
2025-12-18 03:57:11.966203: train_loss -0.8143 
2025-12-18 03:57:11.966203: val_loss -0.8575 
2025-12-18 03:57:11.966203: Pseudo dice [0.9273, 0.9571, 0.9257] 
2025-12-18 03:57:11.966203: Epoch time: 138.08 s 
2025-12-18 03:57:12.615515:  
2025-12-18 03:57:12.615515: Epoch 259 
2025-12-18 03:57:12.615515: Current learning rate: 0.00764 
2025-12-18 03:59:30.737421: train_loss -0.8325 
2025-12-18 03:59:30.737421: val_loss -0.8587 
2025-12-18 03:59:30.744153: Pseudo dice [0.924, 0.955, 0.9233] 
2025-12-18 03:59:30.744153: Epoch time: 138.12 s 
2025-12-18 03:59:31.716585:  
2025-12-18 03:59:31.716585: Epoch 260 
2025-12-18 03:59:31.716585: Current learning rate: 0.00763 
2025-12-18 04:01:49.858484: train_loss -0.8323 
2025-12-18 04:01:49.858484: val_loss -0.8459 
2025-12-18 04:01:49.858484: Pseudo dice [0.918, 0.9462, 0.9243] 
2025-12-18 04:01:49.858484: Epoch time: 138.14 s 
2025-12-18 04:01:50.492549:  
2025-12-18 04:01:50.492549: Epoch 261 
2025-12-18 04:01:50.506171: Current learning rate: 0.00762 
2025-12-18 04:04:08.729200: train_loss -0.8266 
2025-12-18 04:04:08.731202: val_loss -0.8467 
2025-12-18 04:04:08.731202: Pseudo dice [0.9167, 0.9494, 0.9251] 
2025-12-18 04:04:08.731202: Epoch time: 138.24 s 
2025-12-18 04:04:09.365771:  
2025-12-18 04:04:09.365771: Epoch 262 
2025-12-18 04:04:09.381752: Current learning rate: 0.00761 
2025-12-18 04:06:27.560616: train_loss -0.8325 
2025-12-18 04:06:27.560616: val_loss -0.8553 
2025-12-18 04:06:27.564624: Pseudo dice [0.9239, 0.9545, 0.9181] 
2025-12-18 04:06:27.568629: Epoch time: 138.19 s 
2025-12-18 04:06:28.316255:  
2025-12-18 04:06:28.316255: Epoch 263 
2025-12-18 04:06:28.316255: Current learning rate: 0.0076 
2025-12-18 04:08:46.711056: train_loss -0.8348 
2025-12-18 04:08:46.711056: val_loss -0.8487 
2025-12-18 04:08:46.715060: Pseudo dice [0.9092, 0.9487, 0.9353] 
2025-12-18 04:08:46.717062: Epoch time: 138.39 s 
2025-12-18 04:08:47.355702:  
2025-12-18 04:08:47.355702: Epoch 264 
2025-12-18 04:08:47.361829: Current learning rate: 0.00759 
2025-12-18 04:11:05.835442: train_loss -0.8379 
2025-12-18 04:11:05.835442: val_loss -0.8616 
2025-12-18 04:11:05.838593: Pseudo dice [0.9246, 0.9536, 0.9331] 
2025-12-18 04:11:05.838593: Epoch time: 138.48 s 
2025-12-18 04:11:06.470406:  
2025-12-18 04:11:06.470406: Epoch 265 
2025-12-18 04:11:06.470406: Current learning rate: 0.00758 
2025-12-18 04:13:24.665246: train_loss -0.8372 
2025-12-18 04:13:24.666987: val_loss -0.848 
2025-12-18 04:13:24.668989: Pseudo dice [0.9174, 0.9477, 0.9168] 
2025-12-18 04:13:24.672995: Epoch time: 138.19 s 
2025-12-18 04:13:25.601285:  
2025-12-18 04:13:25.601285: Epoch 266 
2025-12-18 04:13:25.601285: Current learning rate: 0.00757 
2025-12-18 04:15:43.809216: train_loss -0.8401 
2025-12-18 04:15:43.809216: val_loss -0.8535 
2025-12-18 04:15:43.811218: Pseudo dice [0.9182, 0.9497, 0.9279] 
2025-12-18 04:15:43.816236: Epoch time: 138.21 s 
2025-12-18 04:15:44.434994:  
2025-12-18 04:15:44.434994: Epoch 267 
2025-12-18 04:15:44.434994: Current learning rate: 0.00756 
2025-12-18 04:18:02.621475: train_loss -0.8403 
2025-12-18 04:18:02.621475: val_loss -0.8554 
2025-12-18 04:18:02.621475: Pseudo dice [0.9125, 0.951, 0.937] 
2025-12-18 04:18:02.637343: Epoch time: 138.19 s 
2025-12-18 04:18:03.271564:  
2025-12-18 04:18:03.271564: Epoch 268 
2025-12-18 04:18:03.285336: Current learning rate: 0.00755 
2025-12-18 04:20:21.656622: train_loss -0.8332 
2025-12-18 04:20:21.656622: val_loss -0.8545 
2025-12-18 04:20:21.663615: Pseudo dice [0.9178, 0.9553, 0.9285] 
2025-12-18 04:20:21.663615: Epoch time: 138.39 s 
2025-12-18 04:20:22.432390:  
2025-12-18 04:20:22.432390: Epoch 269 
2025-12-18 04:20:22.432390: Current learning rate: 0.00754 
2025-12-18 04:22:40.667888: train_loss -0.8349 
2025-12-18 04:22:40.667888: val_loss -0.8525 
2025-12-18 04:22:40.667888: Pseudo dice [0.9158, 0.9499, 0.9317] 
2025-12-18 04:22:40.667888: Epoch time: 138.24 s 
2025-12-18 04:22:41.302767:  
2025-12-18 04:22:41.302767: Epoch 270 
2025-12-18 04:22:41.302767: Current learning rate: 0.00753 
2025-12-18 04:24:59.567640: train_loss -0.8375 
2025-12-18 04:24:59.567640: val_loss -0.8608 
2025-12-18 04:24:59.567640: Pseudo dice [0.9229, 0.9549, 0.9333] 
2025-12-18 04:24:59.567640: Epoch time: 138.26 s 
2025-12-18 04:24:59.567640: Yayy! New best EMA pseudo Dice: 0.9322 
2025-12-18 04:25:00.448307:  
2025-12-18 04:25:00.448307: Epoch 271 
2025-12-18 04:25:00.448307: Current learning rate: 0.00752 
2025-12-18 04:27:18.597434: train_loss -0.8289 
2025-12-18 04:27:18.599438: val_loss -0.8542 
2025-12-18 04:27:18.603442: Pseudo dice [0.9232, 0.9536, 0.9186] 
2025-12-18 04:27:18.609452: Epoch time: 138.15 s 
2025-12-18 04:27:19.529603:  
2025-12-18 04:27:19.529603: Epoch 272 
2025-12-18 04:27:19.532482: Current learning rate: 0.00751 
2025-12-18 04:29:37.748800: train_loss -0.8355 
2025-12-18 04:29:37.748800: val_loss -0.8579 
2025-12-18 04:29:37.764523: Pseudo dice [0.9247, 0.9536, 0.9299] 
2025-12-18 04:29:37.764523: Epoch time: 138.22 s 
2025-12-18 04:29:37.764523: Yayy! New best EMA pseudo Dice: 0.9326 
2025-12-18 04:29:38.653132:  
2025-12-18 04:29:38.653132: Epoch 273 
2025-12-18 04:29:38.655134: Current learning rate: 0.00751 
2025-12-18 04:31:57.019149: train_loss -0.8342 
2025-12-18 04:31:57.021152: val_loss -0.8622 
2025-12-18 04:31:57.026908: Pseudo dice [0.9233, 0.9546, 0.9318] 
2025-12-18 04:31:57.030830: Epoch time: 138.37 s 
2025-12-18 04:31:57.036837: Yayy! New best EMA pseudo Dice: 0.933 
2025-12-18 04:31:57.953636:  
2025-12-18 04:31:57.953636: Epoch 274 
2025-12-18 04:31:57.955756: Current learning rate: 0.0075 
2025-12-18 04:34:16.219425: train_loss -0.8303 
2025-12-18 04:34:16.219425: val_loss -0.8469 
2025-12-18 04:34:16.223429: Pseudo dice [0.9134, 0.9488, 0.9331] 
2025-12-18 04:34:16.225430: Epoch time: 138.27 s 
2025-12-18 04:34:16.859320:  
2025-12-18 04:34:16.859320: Epoch 275 
2025-12-18 04:34:16.859320: Current learning rate: 0.00749 
2025-12-18 04:36:35.212887: train_loss -0.8321 
2025-12-18 04:36:35.212887: val_loss -0.8529 
2025-12-18 04:36:35.212887: Pseudo dice [0.9177, 0.9464, 0.924] 
2025-12-18 04:36:35.212887: Epoch time: 138.35 s 
2025-12-18 04:36:35.848289:  
2025-12-18 04:36:35.848289: Epoch 276 
2025-12-18 04:36:35.848289: Current learning rate: 0.00748 
2025-12-18 04:38:53.830814: train_loss -0.8388 
2025-12-18 04:38:53.830814: val_loss -0.8645 
2025-12-18 04:38:53.846494: Pseudo dice [0.9232, 0.9537, 0.9331] 
2025-12-18 04:38:53.846494: Epoch time: 137.98 s 
2025-12-18 04:38:54.463698:  
2025-12-18 04:38:54.463698: Epoch 277 
2025-12-18 04:38:54.463698: Current learning rate: 0.00747 
2025-12-18 04:41:12.832875: train_loss -0.8353 
2025-12-18 04:41:12.832875: val_loss -0.8673 
2025-12-18 04:41:12.832875: Pseudo dice [0.9237, 0.9514, 0.9462] 
2025-12-18 04:41:12.832875: Epoch time: 138.37 s 
2025-12-18 04:41:12.832875: Yayy! New best EMA pseudo Dice: 0.9337 
2025-12-18 04:41:13.885533:  
2025-12-18 04:41:13.885533: Epoch 278 
2025-12-18 04:41:13.885533: Current learning rate: 0.00746 
2025-12-18 04:43:32.241750: train_loss -0.8398 
2025-12-18 04:43:32.241750: val_loss -0.8577 
2025-12-18 04:43:32.243753: Pseudo dice [0.9197, 0.9483, 0.9339] 
2025-12-18 04:43:32.245756: Epoch time: 138.36 s 
2025-12-18 04:43:32.249723: Yayy! New best EMA pseudo Dice: 0.9337 
2025-12-18 04:43:33.164614:  
2025-12-18 04:43:33.166616: Epoch 279 
2025-12-18 04:43:33.168849: Current learning rate: 0.00745 
2025-12-18 04:45:51.287563: train_loss -0.8409 
2025-12-18 04:45:51.287563: val_loss -0.8605 
2025-12-18 04:45:51.303579: Pseudo dice [0.921, 0.9561, 0.924] 
2025-12-18 04:45:51.307152: Epoch time: 138.12 s 
2025-12-18 04:45:51.309154: Yayy! New best EMA pseudo Dice: 0.9337 
2025-12-18 04:45:52.228904:  
2025-12-18 04:45:52.230906: Epoch 280 
2025-12-18 04:45:52.230906: Current learning rate: 0.00744 
2025-12-18 04:48:10.367281: train_loss -0.8392 
2025-12-18 04:48:10.367281: val_loss -0.8589 
2025-12-18 04:48:10.370308: Pseudo dice [0.9202, 0.9538, 0.9317] 
2025-12-18 04:48:10.374313: Epoch time: 138.14 s 
2025-12-18 04:48:10.376316: Yayy! New best EMA pseudo Dice: 0.9339 
2025-12-18 04:48:11.287009:  
2025-12-18 04:48:11.287009: Epoch 281 
2025-12-18 04:48:11.287009: Current learning rate: 0.00743 
2025-12-18 04:50:29.301627: train_loss -0.8372 
2025-12-18 04:50:29.301627: val_loss -0.8597 
2025-12-18 04:50:29.301627: Pseudo dice [0.9222, 0.954, 0.9329] 
2025-12-18 04:50:29.317315: Epoch time: 138.01 s 
2025-12-18 04:50:29.317315: Yayy! New best EMA pseudo Dice: 0.9341 
2025-12-18 04:50:30.221248:  
2025-12-18 04:50:30.221248: Epoch 282 
2025-12-18 04:50:30.221248: Current learning rate: 0.00742 
2025-12-18 04:52:48.241205: train_loss -0.8372 
2025-12-18 04:52:48.241205: val_loss -0.8582 
2025-12-18 04:52:48.245212: Pseudo dice [0.9209, 0.9533, 0.9334] 
2025-12-18 04:52:48.249216: Epoch time: 138.02 s 
2025-12-18 04:52:48.251218: Yayy! New best EMA pseudo Dice: 0.9343 
2025-12-18 04:52:49.158318:  
2025-12-18 04:52:49.158318: Epoch 283 
2025-12-18 04:52:49.158318: Current learning rate: 0.00741 
2025-12-18 04:55:07.314352: train_loss -0.8381 
2025-12-18 04:55:07.316354: val_loss -0.8575 
2025-12-18 04:55:07.318356: Pseudo dice [0.922, 0.9521, 0.9292] 
2025-12-18 04:55:07.322171: Epoch time: 138.16 s 
2025-12-18 04:55:07.324174: Yayy! New best EMA pseudo Dice: 0.9343 
2025-12-18 04:55:08.424545:  
2025-12-18 04:55:08.424545: Epoch 284 
2025-12-18 04:55:08.424545: Current learning rate: 0.0074 
2025-12-18 04:57:26.442607: train_loss -0.8373 
2025-12-18 04:57:26.444610: val_loss -0.8577 
2025-12-18 04:57:26.444610: Pseudo dice [0.9145, 0.9492, 0.9415] 
2025-12-18 04:57:26.444610: Epoch time: 138.02 s 
2025-12-18 04:57:26.450885: Yayy! New best EMA pseudo Dice: 0.9344 
2025-12-18 04:57:27.345732:  
2025-12-18 04:57:27.345732: Epoch 285 
2025-12-18 04:57:27.348505: Current learning rate: 0.00739 
2025-12-18 04:59:45.537323: train_loss -0.8385 
2025-12-18 04:59:45.537323: val_loss -0.8657 
2025-12-18 04:59:45.555169: Pseudo dice [0.9196, 0.9575, 0.9405] 
2025-12-18 04:59:45.559173: Epoch time: 138.19 s 
2025-12-18 04:59:45.561175: Yayy! New best EMA pseudo Dice: 0.9349 
2025-12-18 04:59:46.464338:  
2025-12-18 04:59:46.464338: Epoch 286 
2025-12-18 04:59:46.464338: Current learning rate: 0.00738 
2025-12-18 05:02:04.791461: train_loss -0.8352 
2025-12-18 05:02:04.793463: val_loss -0.8684 
2025-12-18 05:02:04.797468: Pseudo dice [0.9282, 0.9557, 0.9358] 
2025-12-18 05:02:04.799916: Epoch time: 138.33 s 
2025-12-18 05:02:04.801919: Yayy! New best EMA pseudo Dice: 0.9354 
2025-12-18 05:02:05.712045:  
2025-12-18 05:02:05.712045: Epoch 287 
2025-12-18 05:02:05.712045: Current learning rate: 0.00738 
2025-12-18 05:04:23.816587: train_loss -0.8366 
2025-12-18 05:04:23.816587: val_loss -0.8568 
2025-12-18 05:04:23.816587: Pseudo dice [0.92, 0.9533, 0.9247] 
2025-12-18 05:04:23.816587: Epoch time: 138.1 s 
2025-12-18 05:04:24.575810:  
2025-12-18 05:04:24.575810: Epoch 288 
2025-12-18 05:04:24.575810: Current learning rate: 0.00737 
2025-12-18 05:06:42.690735: train_loss -0.838 
2025-12-18 05:06:42.690735: val_loss -0.8599 
2025-12-18 05:06:42.690735: Pseudo dice [0.9232, 0.9516, 0.9267] 
2025-12-18 05:06:42.690735: Epoch time: 138.12 s 
2025-12-18 05:06:43.324012:  
2025-12-18 05:06:43.324012: Epoch 289 
2025-12-18 05:06:43.324012: Current learning rate: 0.00736 
2025-12-18 05:09:01.684222: train_loss -0.8345 
2025-12-18 05:09:01.684222: val_loss -0.8511 
2025-12-18 05:09:01.692290: Pseudo dice [0.9134, 0.9497, 0.9384] 
2025-12-18 05:09:01.694293: Epoch time: 138.36 s 
2025-12-18 05:09:02.538897:  
2025-12-18 05:09:02.538897: Epoch 290 
2025-12-18 05:09:02.538897: Current learning rate: 0.00735 
2025-12-18 05:11:20.871157: train_loss -0.8383 
2025-12-18 05:11:20.873159: val_loss -0.8605 
2025-12-18 05:11:20.877163: Pseudo dice [0.9217, 0.9559, 0.9313] 
2025-12-18 05:11:20.880906: Epoch time: 138.33 s 
2025-12-18 05:11:21.621911:  
2025-12-18 05:11:21.621911: Epoch 291 
2025-12-18 05:11:21.621911: Current learning rate: 0.00734 
2025-12-18 05:13:39.903814: train_loss -0.8378 
2025-12-18 05:13:39.903814: val_loss -0.8675 
2025-12-18 05:13:39.921462: Pseudo dice [0.9266, 0.9534, 0.9358] 
2025-12-18 05:13:39.927225: Epoch time: 138.28 s 
2025-12-18 05:13:40.568856:  
2025-12-18 05:13:40.568856: Epoch 292 
2025-12-18 05:13:40.568856: Current learning rate: 0.00733 
2025-12-18 05:15:58.784716: train_loss -0.8428 
2025-12-18 05:15:58.786718: val_loss -0.8478 
2025-12-18 05:15:58.790723: Pseudo dice [0.9163, 0.9508, 0.927] 
2025-12-18 05:15:58.794732: Epoch time: 138.22 s 
2025-12-18 05:15:59.448152:  
2025-12-18 05:15:59.448152: Epoch 293 
2025-12-18 05:15:59.448152: Current learning rate: 0.00732 
2025-12-18 05:18:17.599099: train_loss -0.8406 
2025-12-18 05:18:17.599099: val_loss -0.8645 
2025-12-18 05:18:17.605467: Pseudo dice [0.9257, 0.9521, 0.9313] 
2025-12-18 05:18:17.607469: Epoch time: 138.15 s 
2025-12-18 05:18:18.335919:  
2025-12-18 05:18:18.335919: Epoch 294 
2025-12-18 05:18:18.335919: Current learning rate: 0.00731 
2025-12-18 05:20:36.520703: train_loss -0.8424 
2025-12-18 05:20:36.522705: val_loss -0.8641 
2025-12-18 05:20:36.525281: Pseudo dice [0.926, 0.9545, 0.9308] 
2025-12-18 05:20:36.529286: Epoch time: 138.19 s 
2025-12-18 05:20:37.178478:  
2025-12-18 05:20:37.178478: Epoch 295 
2025-12-18 05:20:37.178478: Current learning rate: 0.0073 
2025-12-18 05:22:55.145949: train_loss -0.8456 
2025-12-18 05:22:55.147690: val_loss -0.8579 
2025-12-18 05:22:55.151512: Pseudo dice [0.9177, 0.9498, 0.9346] 
2025-12-18 05:22:55.153514: Epoch time: 137.97 s 
2025-12-18 05:22:55.936924:  
2025-12-18 05:22:55.936924: Epoch 296 
2025-12-18 05:22:55.952666: Current learning rate: 0.00729 
2025-12-18 05:25:14.145038: train_loss -0.8413 
2025-12-18 05:25:14.145038: val_loss -0.8567 
2025-12-18 05:25:14.146778: Pseudo dice [0.9196, 0.9454, 0.9347] 
2025-12-18 05:25:14.153167: Epoch time: 138.21 s 
2025-12-18 05:25:14.918313:  
2025-12-18 05:25:14.918313: Epoch 297 
2025-12-18 05:25:14.922196: Current learning rate: 0.00728 
2025-12-18 05:27:32.915194: train_loss -0.8413 
2025-12-18 05:27:32.930985: val_loss -0.8654 
2025-12-18 05:27:32.930985: Pseudo dice [0.9277, 0.9575, 0.9306] 
2025-12-18 05:27:32.930985: Epoch time: 138.0 s 
2025-12-18 05:27:33.575350:  
2025-12-18 05:27:33.575350: Epoch 298 
2025-12-18 05:27:33.575350: Current learning rate: 0.00727 
2025-12-18 05:29:51.575381: train_loss -0.8419 
2025-12-18 05:29:51.575381: val_loss -0.8558 
2025-12-18 05:29:51.575381: Pseudo dice [0.9202, 0.9505, 0.9249] 
2025-12-18 05:29:51.582628: Epoch time: 138.0 s 
2025-12-18 05:29:52.223804:  
2025-12-18 05:29:52.223804: Epoch 299 
2025-12-18 05:29:52.223804: Current learning rate: 0.00726 
2025-12-18 05:32:10.551772: train_loss -0.8381 
2025-12-18 05:32:10.551772: val_loss -0.8527 
2025-12-18 05:32:10.555778: Pseudo dice [0.9175, 0.9507, 0.931] 
2025-12-18 05:32:10.559014: Epoch time: 138.33 s 
2025-12-18 05:32:11.579002:  
2025-12-18 05:32:11.579002: Epoch 300 
2025-12-18 05:32:11.580744: Current learning rate: 0.00725 
2025-12-18 05:34:30.028788: train_loss -0.8347 
2025-12-18 05:34:30.028788: val_loss -0.8519 
2025-12-18 05:34:30.041509: Pseudo dice [0.9163, 0.9487, 0.9331] 
2025-12-18 05:34:30.043511: Epoch time: 138.45 s 
2025-12-18 05:34:30.688238:  
2025-12-18 05:34:30.688238: Epoch 301 
2025-12-18 05:34:30.691957: Current learning rate: 0.00724 
2025-12-18 05:36:48.736782: train_loss -0.8388 
2025-12-18 05:36:48.736782: val_loss -0.8598 
2025-12-18 05:36:48.736782: Pseudo dice [0.9221, 0.9523, 0.93] 
2025-12-18 05:36:48.736782: Epoch time: 138.05 s 
2025-12-18 05:36:49.544726:  
2025-12-18 05:36:49.544726: Epoch 302 
2025-12-18 05:36:49.544726: Current learning rate: 0.00724 
2025-12-18 05:39:07.624338: train_loss -0.8389 
2025-12-18 05:39:07.626340: val_loss -0.8672 
2025-12-18 05:39:07.630083: Pseudo dice [0.9244, 0.9522, 0.9422] 
2025-12-18 05:39:07.632085: Epoch time: 138.08 s 
2025-12-18 05:39:08.435336:  
2025-12-18 05:39:08.435336: Epoch 303 
2025-12-18 05:39:08.435336: Current learning rate: 0.00723 
2025-12-18 05:41:26.593545: train_loss -0.8351 
2025-12-18 05:41:26.593545: val_loss -0.8605 
2025-12-18 05:41:26.593545: Pseudo dice [0.9225, 0.9533, 0.9221] 
2025-12-18 05:41:26.593545: Epoch time: 138.17 s 
2025-12-18 05:41:27.242346:  
2025-12-18 05:41:27.242346: Epoch 304 
2025-12-18 05:41:27.248607: Current learning rate: 0.00722 
2025-12-18 05:43:45.325446: train_loss -0.8377 
2025-12-18 05:43:45.325446: val_loss -0.8535 
2025-12-18 05:43:45.325446: Pseudo dice [0.9185, 0.9474, 0.925] 
2025-12-18 05:43:45.331307: Epoch time: 138.08 s 
2025-12-18 05:43:45.974624:  
2025-12-18 05:43:45.974624: Epoch 305 
2025-12-18 05:43:45.974624: Current learning rate: 0.00721 
2025-12-18 05:46:04.081658: train_loss -0.8391 
2025-12-18 05:46:04.081658: val_loss -0.8638 
2025-12-18 05:46:04.081658: Pseudo dice [0.9265, 0.955, 0.9225] 
2025-12-18 05:46:04.081658: Epoch time: 138.11 s 
2025-12-18 05:46:04.905035:  
2025-12-18 05:46:04.905035: Epoch 306 
2025-12-18 05:46:04.909513: Current learning rate: 0.0072 
2025-12-18 05:48:22.990741: train_loss -0.8423 
2025-12-18 05:48:22.990741: val_loss -0.8635 
2025-12-18 05:48:22.990741: Pseudo dice [0.92, 0.9539, 0.9372] 
2025-12-18 05:48:23.002834: Epoch time: 138.09 s 
2025-12-18 05:48:23.655672:  
2025-12-18 05:48:23.655672: Epoch 307 
2025-12-18 05:48:23.662254: Current learning rate: 0.00719 
2025-12-18 05:50:41.815435: train_loss -0.8359 
2025-12-18 05:50:41.815435: val_loss -0.852 
2025-12-18 05:50:41.823186: Pseudo dice [0.9205, 0.9563, 0.9166] 
2025-12-18 05:50:41.825191: Epoch time: 138.16 s 
2025-12-18 05:50:42.624784:  
2025-12-18 05:50:42.624784: Epoch 308 
2025-12-18 05:50:42.624784: Current learning rate: 0.00718 
2025-12-18 05:53:00.726053: train_loss -0.8375 
2025-12-18 05:53:00.726053: val_loss -0.8501 
2025-12-18 05:53:00.730059: Pseudo dice [0.9179, 0.9475, 0.9232] 
2025-12-18 05:53:00.731799: Epoch time: 138.1 s 
2025-12-18 05:53:01.369816:  
2025-12-18 05:53:01.369816: Epoch 309 
2025-12-18 05:53:01.379412: Current learning rate: 0.00717 
2025-12-18 05:55:19.456342: train_loss -0.8422 
2025-12-18 05:55:19.456342: val_loss -0.8526 
2025-12-18 05:55:19.472422: Pseudo dice [0.9171, 0.9515, 0.9345] 
2025-12-18 05:55:19.476678: Epoch time: 138.09 s 
2025-12-18 05:55:20.120754:  
2025-12-18 05:55:20.120754: Epoch 310 
2025-12-18 05:55:20.122758: Current learning rate: 0.00716 
2025-12-18 05:57:38.289045: train_loss -0.8342 
2025-12-18 05:57:38.289045: val_loss -0.8606 
2025-12-18 05:57:38.293372: Pseudo dice [0.9213, 0.9515, 0.9258] 
2025-12-18 05:57:38.296571: Epoch time: 138.18 s 
2025-12-18 05:57:38.947980:  
2025-12-18 05:57:38.947980: Epoch 311 
2025-12-18 05:57:38.963794: Current learning rate: 0.00715 
2025-12-18 05:59:57.047709: train_loss -0.8367 
2025-12-18 05:59:57.047709: val_loss -0.8503 
2025-12-18 05:59:57.047709: Pseudo dice [0.914, 0.9483, 0.9295] 
2025-12-18 05:59:57.047709: Epoch time: 138.1 s 
2025-12-18 05:59:57.681543:  
2025-12-18 05:59:57.681543: Epoch 312 
2025-12-18 05:59:57.681543: Current learning rate: 0.00714 
2025-12-18 06:02:16.019722: train_loss -0.8366 
2025-12-18 06:02:16.019722: val_loss -0.8647 
2025-12-18 06:02:16.031598: Pseudo dice [0.9229, 0.9567, 0.937] 
2025-12-18 06:02:16.034866: Epoch time: 138.34 s 
2025-12-18 06:02:16.668300:  
2025-12-18 06:02:16.668300: Epoch 313 
2025-12-18 06:02:16.673734: Current learning rate: 0.00713 
2025-12-18 06:04:35.166101: train_loss -0.8281 
2025-12-18 06:04:35.168107: val_loss -0.8507 
2025-12-18 06:04:35.170109: Pseudo dice [0.915, 0.9511, 0.9263] 
2025-12-18 06:04:35.174118: Epoch time: 138.5 s 
2025-12-18 06:04:35.807641:  
2025-12-18 06:04:35.807641: Epoch 314 
2025-12-18 06:04:35.822056: Current learning rate: 0.00712 
2025-12-18 06:06:53.928446: train_loss -0.833 
2025-12-18 06:06:53.928446: val_loss -0.8462 
2025-12-18 06:06:53.928446: Pseudo dice [0.9091, 0.9478, 0.9403] 
2025-12-18 06:06:53.938540: Epoch time: 138.12 s 
2025-12-18 06:06:54.564477:  
2025-12-18 06:06:54.564477: Epoch 315 
2025-12-18 06:06:54.578826: Current learning rate: 0.00711 
2025-12-18 06:09:13.073445: train_loss -0.836 
2025-12-18 06:09:13.073445: val_loss -0.8584 
2025-12-18 06:09:13.078205: Pseudo dice [0.92, 0.9533, 0.9205] 
2025-12-18 06:09:13.078205: Epoch time: 138.51 s 
2025-12-18 06:09:13.722925:  
2025-12-18 06:09:13.722925: Epoch 316 
2025-12-18 06:09:13.738933: Current learning rate: 0.0071 
2025-12-18 06:11:32.250634: train_loss -0.8382 
2025-12-18 06:11:32.252640: val_loss -0.8656 
2025-12-18 06:11:32.260405: Pseudo dice [0.924, 0.9504, 0.9364] 
2025-12-18 06:11:32.260405: Epoch time: 138.53 s 
2025-12-18 06:11:32.905731:  
2025-12-18 06:11:32.905731: Epoch 317 
2025-12-18 06:11:32.910980: Current learning rate: 0.0071 
2025-12-18 06:13:51.046622: train_loss -0.838 
2025-12-18 06:13:51.046622: val_loss -0.8564 
2025-12-18 06:13:51.046622: Pseudo dice [0.9137, 0.9521, 0.9374] 
2025-12-18 06:13:51.046622: Epoch time: 138.14 s 
2025-12-18 06:13:51.696360:  
2025-12-18 06:13:51.696360: Epoch 318 
2025-12-18 06:13:51.696360: Current learning rate: 0.00709 
2025-12-18 06:16:09.759957: train_loss -0.8378 
2025-12-18 06:16:09.761965: val_loss -0.8618 
2025-12-18 06:16:09.765974: Pseudo dice [0.9201, 0.9564, 0.9277] 
2025-12-18 06:16:09.769719: Epoch time: 138.06 s 
2025-12-18 06:16:10.559338:  
2025-12-18 06:16:10.575116: Epoch 319 
2025-12-18 06:16:10.577384: Current learning rate: 0.00708 
2025-12-18 06:18:28.662036: train_loss -0.8409 
2025-12-18 06:18:28.662036: val_loss -0.8619 
2025-12-18 06:18:28.662036: Pseudo dice [0.9236, 0.952, 0.9336] 
2025-12-18 06:18:28.677974: Epoch time: 138.1 s 
2025-12-18 06:18:29.327970:  
2025-12-18 06:18:29.327970: Epoch 320 
2025-12-18 06:18:29.343950: Current learning rate: 0.00707 
2025-12-18 06:20:47.593770: train_loss -0.8419 
2025-12-18 06:20:47.593770: val_loss -0.852 
2025-12-18 06:20:47.593770: Pseudo dice [0.916, 0.9477, 0.9219] 
2025-12-18 06:20:47.593770: Epoch time: 138.27 s 
2025-12-18 06:20:48.228295:  
2025-12-18 06:20:48.228295: Epoch 321 
2025-12-18 06:20:48.244219: Current learning rate: 0.00706 
2025-12-18 06:23:06.352314: train_loss -0.8436 
2025-12-18 06:23:06.367946: val_loss -0.8637 
2025-12-18 06:23:06.367946: Pseudo dice [0.9208, 0.9533, 0.9343] 
2025-12-18 06:23:06.367946: Epoch time: 138.12 s 
2025-12-18 06:23:07.018935:  
2025-12-18 06:23:07.018935: Epoch 322 
2025-12-18 06:23:07.018935: Current learning rate: 0.00705 
2025-12-18 06:25:25.315794: train_loss -0.8427 
2025-12-18 06:25:25.317626: val_loss -0.8644 
2025-12-18 06:25:25.319628: Pseudo dice [0.9231, 0.9532, 0.9372] 
2025-12-18 06:25:25.321630: Epoch time: 138.3 s 
2025-12-18 06:25:25.964980:  
2025-12-18 06:25:25.964980: Epoch 323 
2025-12-18 06:25:25.964980: Current learning rate: 0.00704 
2025-12-18 06:27:44.074519: train_loss -0.8469 
2025-12-18 06:27:44.074519: val_loss -0.8613 
2025-12-18 06:27:44.090606: Pseudo dice [0.9222, 0.9505, 0.9317] 
2025-12-18 06:27:44.090606: Epoch time: 138.11 s 
2025-12-18 06:27:44.725591:  
2025-12-18 06:27:44.741693: Epoch 324 
2025-12-18 06:27:44.744164: Current learning rate: 0.00703 
2025-12-18 06:30:02.796249: train_loss -0.844 
2025-12-18 06:30:02.796249: val_loss -0.8582 
2025-12-18 06:30:02.812174: Pseudo dice [0.9167, 0.9515, 0.934] 
2025-12-18 06:30:02.812174: Epoch time: 138.07 s 
2025-12-18 06:30:03.446736:  
2025-12-18 06:30:03.446736: Epoch 325 
2025-12-18 06:30:03.446736: Current learning rate: 0.00702 
2025-12-18 06:32:21.636598: train_loss -0.8473 
2025-12-18 06:32:21.636598: val_loss -0.8575 
2025-12-18 06:32:21.644357: Pseudo dice [0.9182, 0.9493, 0.9354] 
2025-12-18 06:32:21.648367: Epoch time: 138.19 s 
2025-12-18 06:32:22.468777:  
2025-12-18 06:32:22.468777: Epoch 326 
2025-12-18 06:32:22.482960: Current learning rate: 0.00701 
2025-12-18 06:34:40.604934: train_loss -0.8465 
2025-12-18 06:34:40.604934: val_loss -0.8653 
2025-12-18 06:34:40.620585: Pseudo dice [0.9263, 0.9563, 0.9333] 
2025-12-18 06:34:40.622588: Epoch time: 138.14 s 
2025-12-18 06:34:41.255115:  
2025-12-18 06:34:41.255115: Epoch 327 
2025-12-18 06:34:41.267320: Current learning rate: 0.007 
2025-12-18 06:36:59.482067: train_loss -0.8401 
2025-12-18 06:36:59.482067: val_loss -0.8683 
2025-12-18 06:36:59.495504: Pseudo dice [0.9259, 0.9558, 0.9314] 
2025-12-18 06:36:59.498008: Epoch time: 138.23 s 
2025-12-18 06:37:00.131052:  
2025-12-18 06:37:00.131052: Epoch 328 
2025-12-18 06:37:00.131052: Current learning rate: 0.00699 
2025-12-18 06:39:18.247422: train_loss -0.8435 
2025-12-18 06:39:18.247422: val_loss -0.8553 
2025-12-18 06:39:18.247422: Pseudo dice [0.924, 0.951, 0.9147] 
2025-12-18 06:39:18.257808: Epoch time: 138.12 s 
2025-12-18 06:39:18.911515:  
2025-12-18 06:39:18.911515: Epoch 329 
2025-12-18 06:39:18.914138: Current learning rate: 0.00698 
2025-12-18 06:41:37.028405: train_loss -0.8479 
2025-12-18 06:41:37.028405: val_loss -0.8671 
2025-12-18 06:41:37.036156: Pseudo dice [0.9221, 0.956, 0.937] 
2025-12-18 06:41:37.040162: Epoch time: 138.12 s 
2025-12-18 06:41:37.681396:  
2025-12-18 06:41:37.681396: Epoch 330 
2025-12-18 06:41:37.697150: Current learning rate: 0.00697 
2025-12-18 06:43:55.753249: train_loss -0.8458 
2025-12-18 06:43:55.753249: val_loss -0.8554 
2025-12-18 06:43:55.759267: Pseudo dice [0.9141, 0.947, 0.9338] 
2025-12-18 06:43:55.761270: Epoch time: 138.07 s 
2025-12-18 06:43:56.402542:  
2025-12-18 06:43:56.402542: Epoch 331 
2025-12-18 06:43:56.402542: Current learning rate: 0.00696 
2025-12-18 06:46:14.490772: train_loss -0.8371 
2025-12-18 06:46:14.492774: val_loss -0.8556 
2025-12-18 06:46:14.494514: Pseudo dice [0.9175, 0.9548, 0.9249] 
2025-12-18 06:46:14.494514: Epoch time: 138.09 s 
2025-12-18 06:46:15.335419:  
2025-12-18 06:46:15.335419: Epoch 332 
2025-12-18 06:46:15.339847: Current learning rate: 0.00696 
2025-12-18 06:48:33.350021: train_loss -0.8422 
2025-12-18 06:48:33.350021: val_loss -0.8563 
2025-12-18 06:48:33.353969: Pseudo dice [0.9154, 0.9517, 0.9331] 
2025-12-18 06:48:33.355971: Epoch time: 138.01 s 
2025-12-18 06:48:33.991657:  
2025-12-18 06:48:33.991657: Epoch 333 
2025-12-18 06:48:34.007671: Current learning rate: 0.00695 
2025-12-18 06:50:52.150496: train_loss -0.841 
2025-12-18 06:50:52.150496: val_loss -0.857 
2025-12-18 06:50:52.155095: Pseudo dice [0.9176, 0.9589, 0.929] 
2025-12-18 06:50:52.158392: Epoch time: 138.16 s 
2025-12-18 06:50:52.785375:  
2025-12-18 06:50:52.785375: Epoch 334 
2025-12-18 06:50:52.785375: Current learning rate: 0.00694 
2025-12-18 06:53:10.874062: train_loss -0.8461 
2025-12-18 06:53:10.876065: val_loss -0.865 
2025-12-18 06:53:10.880070: Pseudo dice [0.9251, 0.9562, 0.9322] 
2025-12-18 06:53:10.883551: Epoch time: 138.09 s 
2025-12-18 06:53:11.638711:  
2025-12-18 06:53:11.638711: Epoch 335 
2025-12-18 06:53:11.638711: Current learning rate: 0.00693 
2025-12-18 06:55:29.931825: train_loss -0.8447 
2025-12-18 06:55:29.931825: val_loss -0.8721 
2025-12-18 06:55:29.935269: Pseudo dice [0.9255, 0.9581, 0.9359] 
2025-12-18 06:55:29.938780: Epoch time: 138.29 s 
2025-12-18 06:55:30.581539:  
2025-12-18 06:55:30.581539: Epoch 336 
2025-12-18 06:55:30.597653: Current learning rate: 0.00692 
2025-12-18 06:57:48.717775: train_loss -0.8476 
2025-12-18 06:57:48.717775: val_loss -0.8694 
2025-12-18 06:57:48.723781: Pseudo dice [0.9297, 0.9566, 0.9284] 
2025-12-18 06:57:48.725783: Epoch time: 138.14 s 
2025-12-18 06:57:48.727578: Yayy! New best EMA pseudo Dice: 0.9355 
2025-12-18 06:57:49.620593:  
2025-12-18 06:57:49.621595: Epoch 337 
2025-12-18 06:57:49.622805: Current learning rate: 0.00691 
2025-12-18 07:00:07.742284: train_loss -0.8444 
2025-12-18 07:00:07.742284: val_loss -0.875 
2025-12-18 07:00:07.745174: Pseudo dice [0.9287, 0.9581, 0.938] 
2025-12-18 07:00:07.745174: Epoch time: 138.12 s 
2025-12-18 07:00:07.745174: Yayy! New best EMA pseudo Dice: 0.9361 
2025-12-18 07:00:08.677601:  
2025-12-18 07:00:08.693518: Epoch 338 
2025-12-18 07:00:08.693518: Current learning rate: 0.0069 
2025-12-18 07:02:26.766067: train_loss -0.8455 
2025-12-18 07:02:26.766067: val_loss -0.8585 
2025-12-18 07:02:26.766067: Pseudo dice [0.9189, 0.9525, 0.9311] 
2025-12-18 07:02:26.766067: Epoch time: 138.09 s 
2025-12-18 07:02:27.416602:  
2025-12-18 07:02:27.416602: Epoch 339 
2025-12-18 07:02:27.416602: Current learning rate: 0.00689 
2025-12-18 07:04:45.567483: train_loss -0.8427 
2025-12-18 07:04:45.569486: val_loss -0.8591 
2025-12-18 07:04:45.575501: Pseudo dice [0.9213, 0.9514, 0.9305] 
2025-12-18 07:04:45.577242: Epoch time: 138.15 s 
2025-12-18 07:04:46.225266:  
2025-12-18 07:04:46.225266: Epoch 340 
2025-12-18 07:04:46.225266: Current learning rate: 0.00688 
2025-12-18 07:07:04.316972: train_loss -0.8393 
2025-12-18 07:07:04.318974: val_loss -0.8606 
2025-12-18 07:07:04.322979: Pseudo dice [0.9215, 0.9485, 0.9315] 
2025-12-18 07:07:04.324981: Epoch time: 138.09 s 
2025-12-18 07:07:05.089422:  
2025-12-18 07:07:05.089422: Epoch 341 
2025-12-18 07:07:05.105053: Current learning rate: 0.00687 
2025-12-18 07:09:23.494699: train_loss -0.8391 
2025-12-18 07:09:23.494699: val_loss -0.8562 
2025-12-18 07:09:23.510636: Pseudo dice [0.9186, 0.9554, 0.927] 
2025-12-18 07:09:23.515078: Epoch time: 138.41 s 
2025-12-18 07:09:24.178516:  
2025-12-18 07:09:24.178516: Epoch 342 
2025-12-18 07:09:24.178516: Current learning rate: 0.00686 
2025-12-18 07:11:42.598178: train_loss -0.8279 
2025-12-18 07:11:42.598178: val_loss -0.8559 
2025-12-18 07:11:42.598178: Pseudo dice [0.9209, 0.9559, 0.93] 
2025-12-18 07:11:42.614204: Epoch time: 138.42 s 
2025-12-18 07:11:43.422872:  
2025-12-18 07:11:43.422872: Epoch 343 
2025-12-18 07:11:43.422872: Current learning rate: 0.00685 
2025-12-18 07:14:01.587417: train_loss -0.8231 
2025-12-18 07:14:01.587417: val_loss -0.8431 
2025-12-18 07:14:01.591421: Pseudo dice [0.9142, 0.9456, 0.9229] 
2025-12-18 07:14:01.593423: Epoch time: 138.16 s 
2025-12-18 07:14:02.242966:  
2025-12-18 07:14:02.242966: Epoch 344 
2025-12-18 07:14:02.258883: Current learning rate: 0.00684 
2025-12-18 07:16:20.444466: train_loss -0.8367 
2025-12-18 07:16:20.444466: val_loss -0.8535 
2025-12-18 07:16:20.444466: Pseudo dice [0.9148, 0.9533, 0.9298] 
2025-12-18 07:16:20.444466: Epoch time: 138.2 s 
2025-12-18 07:16:21.109885:  
2025-12-18 07:16:21.109885: Epoch 345 
2025-12-18 07:16:21.109885: Current learning rate: 0.00683 
2025-12-18 07:18:39.242187: train_loss -0.8381 
2025-12-18 07:18:39.242187: val_loss -0.8606 
2025-12-18 07:18:39.242187: Pseudo dice [0.9256, 0.952, 0.9256] 
2025-12-18 07:18:39.242187: Epoch time: 138.13 s 
2025-12-18 07:18:39.923226:  
2025-12-18 07:18:39.923226: Epoch 346 
2025-12-18 07:18:39.923226: Current learning rate: 0.00682 
2025-12-18 07:20:58.019140: train_loss -0.8331 
2025-12-18 07:20:58.019140: val_loss -0.8611 
2025-12-18 07:20:58.024885: Pseudo dice [0.9235, 0.955, 0.93] 
2025-12-18 07:20:58.026889: Epoch time: 138.1 s 
2025-12-18 07:20:58.752945:  
2025-12-18 07:20:58.752945: Epoch 347 
2025-12-18 07:20:58.752945: Current learning rate: 0.00681 
2025-12-18 07:23:16.893118: train_loss -0.8418 
2025-12-18 07:23:16.893118: val_loss -0.8571 
2025-12-18 07:23:16.909106: Pseudo dice [0.9188, 0.9478, 0.9313] 
2025-12-18 07:23:16.909106: Epoch time: 138.14 s 
2025-12-18 07:23:17.542037:  
2025-12-18 07:23:17.542037: Epoch 348 
2025-12-18 07:23:17.557811: Current learning rate: 0.0068 
2025-12-18 07:25:35.781590: train_loss -0.8354 
2025-12-18 07:25:35.781590: val_loss -0.8619 
2025-12-18 07:25:35.781590: Pseudo dice [0.9262, 0.9516, 0.9256] 
2025-12-18 07:25:35.797466: Epoch time: 138.24 s 
2025-12-18 07:25:36.621384:  
2025-12-18 07:25:36.621384: Epoch 349 
2025-12-18 07:25:36.621384: Current learning rate: 0.0068 
2025-12-18 07:27:54.662800: train_loss -0.84 
2025-12-18 07:27:54.664301: val_loss -0.851 
2025-12-18 07:27:54.668306: Pseudo dice [0.9168, 0.9453, 0.9273] 
2025-12-18 07:27:54.672310: Epoch time: 138.04 s 
2025-12-18 07:27:55.615239:  
2025-12-18 07:27:55.615239: Epoch 350 
2025-12-18 07:27:55.629534: Current learning rate: 0.00679 
2025-12-18 07:30:13.767298: train_loss -0.8432 
2025-12-18 07:30:13.767298: val_loss -0.8693 
2025-12-18 07:30:13.773792: Pseudo dice [0.9267, 0.9553, 0.9365] 
2025-12-18 07:30:13.773792: Epoch time: 138.15 s 
2025-12-18 07:30:14.417469:  
2025-12-18 07:30:14.417469: Epoch 351 
2025-12-18 07:30:14.417469: Current learning rate: 0.00678 
2025-12-18 07:32:32.472370: train_loss -0.8459 
2025-12-18 07:32:32.472370: val_loss -0.8563 
2025-12-18 07:32:32.484290: Pseudo dice [0.9184, 0.9488, 0.928] 
2025-12-18 07:32:32.486244: Epoch time: 138.05 s 
2025-12-18 07:32:33.122431:  
2025-12-18 07:32:33.122431: Epoch 352 
2025-12-18 07:32:33.133881: Current learning rate: 0.00677 
2025-12-18 07:34:51.518716: train_loss -0.8402 
2025-12-18 07:34:51.518716: val_loss -0.8698 
2025-12-18 07:34:51.524227: Pseudo dice [0.9306, 0.9577, 0.9286] 
2025-12-18 07:34:51.526229: Epoch time: 138.4 s 
2025-12-18 07:34:52.298099:  
2025-12-18 07:34:52.298099: Epoch 353 
2025-12-18 07:34:52.298099: Current learning rate: 0.00676 
2025-12-18 07:37:10.474470: train_loss -0.8439 
2025-12-18 07:37:10.476449: val_loss -0.8677 
2025-12-18 07:37:10.478451: Pseudo dice [0.9264, 0.9546, 0.9312] 
2025-12-18 07:37:10.480454: Epoch time: 138.18 s 
2025-12-18 07:37:11.125333:  
2025-12-18 07:37:11.125333: Epoch 354 
2025-12-18 07:37:11.141189: Current learning rate: 0.00675 
2025-12-18 07:39:29.381271: train_loss -0.8374 
2025-12-18 07:39:29.381271: val_loss -0.8672 
2025-12-18 07:39:29.394572: Pseudo dice [0.9281, 0.9582, 0.9238] 
2025-12-18 07:39:29.397857: Epoch time: 138.26 s 
2025-12-18 07:39:30.205342:  
2025-12-18 07:39:30.205342: Epoch 355 
2025-12-18 07:39:30.218738: Current learning rate: 0.00674 
2025-12-18 07:41:48.447309: train_loss -0.8386 
2025-12-18 07:41:48.447309: val_loss -0.8653 
2025-12-18 07:41:48.453317: Pseudo dice [0.9246, 0.9558, 0.9355] 
2025-12-18 07:41:48.457322: Epoch time: 138.24 s 
2025-12-18 07:41:49.173443:  
2025-12-18 07:41:49.173443: Epoch 356 
2025-12-18 07:41:49.173443: Current learning rate: 0.00673 
2025-12-18 07:44:07.417499: train_loss -0.8381 
2025-12-18 07:44:07.417499: val_loss -0.8604 
2025-12-18 07:44:07.421342: Pseudo dice [0.9237, 0.9537, 0.921] 
2025-12-18 07:44:07.423345: Epoch time: 138.24 s 
2025-12-18 07:44:08.066416:  
2025-12-18 07:44:08.066416: Epoch 357 
2025-12-18 07:44:08.066416: Current learning rate: 0.00672 
2025-12-18 07:46:26.288953: train_loss -0.8421 
2025-12-18 07:46:26.288953: val_loss -0.8632 
2025-12-18 07:46:26.306819: Pseudo dice [0.9221, 0.9499, 0.9386] 
2025-12-18 07:46:26.306819: Epoch time: 138.22 s 
2025-12-18 07:46:26.953557:  
2025-12-18 07:46:26.953557: Epoch 358 
2025-12-18 07:46:26.969343: Current learning rate: 0.00671 
2025-12-18 07:48:44.823335: train_loss -0.8507 
2025-12-18 07:48:44.823335: val_loss -0.8621 
2025-12-18 07:48:44.830253: Pseudo dice [0.9248, 0.9533, 0.9246] 
2025-12-18 07:48:44.830253: Epoch time: 137.87 s 
2025-12-18 07:48:45.566365:  
2025-12-18 07:48:45.566365: Epoch 359 
2025-12-18 07:48:45.584075: Current learning rate: 0.0067 
2025-12-18 07:51:03.633013: train_loss -0.8462 
2025-12-18 07:51:03.633013: val_loss -0.8593 
2025-12-18 07:51:03.633013: Pseudo dice [0.9198, 0.9477, 0.9349] 
2025-12-18 07:51:03.641117: Epoch time: 138.07 s 
2025-12-18 07:51:04.281102:  
2025-12-18 07:51:04.281102: Epoch 360 
2025-12-18 07:51:04.281102: Current learning rate: 0.00669 
2025-12-18 07:53:22.389822: train_loss -0.843 
2025-12-18 07:53:22.389822: val_loss -0.8571 
2025-12-18 07:53:22.394305: Pseudo dice [0.9189, 0.9492, 0.9373] 
2025-12-18 07:53:22.394305: Epoch time: 138.11 s 
2025-12-18 07:53:23.212912:  
2025-12-18 07:53:23.212912: Epoch 361 
2025-12-18 07:53:23.212912: Current learning rate: 0.00668 
2025-12-18 07:55:41.336091: train_loss -0.8437 
2025-12-18 07:55:41.336091: val_loss -0.8602 
2025-12-18 07:55:41.336091: Pseudo dice [0.9148, 0.948, 0.9453] 
2025-12-18 07:55:41.343121: Epoch time: 138.12 s 
2025-12-18 07:55:42.095934:  
2025-12-18 07:55:42.095934: Epoch 362 
2025-12-18 07:55:42.095934: Current learning rate: 0.00667 
2025-12-18 07:58:00.210758: train_loss -0.8452 
2025-12-18 07:58:00.210758: val_loss -0.8702 
2025-12-18 07:58:00.216769: Pseudo dice [0.9282, 0.9558, 0.9317] 
2025-12-18 07:58:00.220519: Epoch time: 138.11 s 
2025-12-18 07:58:00.869749:  
2025-12-18 07:58:00.869749: Epoch 363 
2025-12-18 07:58:00.885868: Current learning rate: 0.00666 
2025-12-18 08:00:19.115682: train_loss -0.845 
2025-12-18 08:00:19.115682: val_loss -0.8674 
2025-12-18 08:00:19.129753: Pseudo dice [0.9222, 0.9548, 0.9403] 
2025-12-18 08:00:19.131493: Epoch time: 138.25 s 
2025-12-18 08:00:19.796257:  
2025-12-18 08:00:19.796257: Epoch 364 
2025-12-18 08:00:19.796257: Current learning rate: 0.00665 
2025-12-18 08:02:38.127897: train_loss -0.8445 
2025-12-18 08:02:38.143801: val_loss -0.8576 
2025-12-18 08:02:38.143801: Pseudo dice [0.9179, 0.9531, 0.93] 
2025-12-18 08:02:38.143801: Epoch time: 138.33 s 
2025-12-18 08:02:38.924748:  
2025-12-18 08:02:38.924748: Epoch 365 
2025-12-18 08:02:38.931676: Current learning rate: 0.00665 
2025-12-18 08:04:57.096878: train_loss -0.8448 
2025-12-18 08:04:57.096878: val_loss -0.8682 
2025-12-18 08:04:57.096878: Pseudo dice [0.9268, 0.9545, 0.9312] 
2025-12-18 08:04:57.103899: Epoch time: 138.17 s 
2025-12-18 08:04:57.761631:  
2025-12-18 08:04:57.761631: Epoch 366 
2025-12-18 08:04:57.761631: Current learning rate: 0.00664 
2025-12-18 08:07:16.059107: train_loss -0.8441 
2025-12-18 08:07:16.061110: val_loss -0.8697 
2025-12-18 08:07:16.064114: Pseudo dice [0.9252, 0.9574, 0.9387] 
2025-12-18 08:07:16.068119: Epoch time: 138.3 s 
2025-12-18 08:07:16.070121: Yayy! New best EMA pseudo Dice: 0.9363 
2025-12-18 08:07:17.172543:  
2025-12-18 08:07:17.172543: Epoch 367 
2025-12-18 08:07:17.174546: Current learning rate: 0.00663 
2025-12-18 08:09:35.613229: train_loss -0.8469 
2025-12-18 08:09:35.613229: val_loss -0.8686 
2025-12-18 08:09:35.617234: Pseudo dice [0.9234, 0.9585, 0.9312] 
2025-12-18 08:09:35.619237: Epoch time: 138.44 s 
2025-12-18 08:09:35.623242: Yayy! New best EMA pseudo Dice: 0.9365 
2025-12-18 08:09:36.599250:  
2025-12-18 08:09:36.599250: Epoch 368 
2025-12-18 08:09:36.599250: Current learning rate: 0.00662 
2025-12-18 08:11:54.978170: train_loss -0.8465 
2025-12-18 08:11:54.978170: val_loss -0.8685 
2025-12-18 08:11:54.984181: Pseudo dice [0.9224, 0.9608, 0.9323] 
2025-12-18 08:11:54.984181: Epoch time: 138.38 s 
2025-12-18 08:11:54.984181: Yayy! New best EMA pseudo Dice: 0.9367 
2025-12-18 08:11:55.919393:  
2025-12-18 08:11:55.919393: Epoch 369 
2025-12-18 08:11:55.935180: Current learning rate: 0.00661 
2025-12-18 08:14:14.060630: train_loss -0.8404 
2025-12-18 08:14:14.060630: val_loss -0.8665 
2025-12-18 08:14:14.076717: Pseudo dice [0.9216, 0.9541, 0.9399] 
2025-12-18 08:14:14.076717: Epoch time: 138.14 s 
2025-12-18 08:14:14.076717: Yayy! New best EMA pseudo Dice: 0.9369 
2025-12-18 08:14:14.997230:  
2025-12-18 08:14:14.997230: Epoch 370 
2025-12-18 08:14:14.997230: Current learning rate: 0.0066 
2025-12-18 08:16:33.143183: train_loss -0.8456 
2025-12-18 08:16:33.145185: val_loss -0.8545 
2025-12-18 08:16:33.148537: Pseudo dice [0.9164, 0.9525, 0.9293] 
2025-12-18 08:16:33.150539: Epoch time: 138.15 s 
2025-12-18 08:16:33.804541:  
2025-12-18 08:16:33.804541: Epoch 371 
2025-12-18 08:16:33.804541: Current learning rate: 0.00659 
2025-12-18 08:18:52.008504: train_loss -0.8467 
2025-12-18 08:18:52.008504: val_loss -0.862 
2025-12-18 08:18:52.008504: Pseudo dice [0.9204, 0.9527, 0.9343] 
2025-12-18 08:18:52.024139: Epoch time: 138.2 s 
2025-12-18 08:18:52.848393:  
2025-12-18 08:18:52.848393: Epoch 372 
2025-12-18 08:18:52.848393: Current learning rate: 0.00658 
2025-12-18 08:21:11.056624: train_loss -0.8459 
2025-12-18 08:21:11.056624: val_loss -0.8614 
2025-12-18 08:21:11.056624: Pseudo dice [0.9193, 0.9488, 0.9374] 
2025-12-18 08:21:11.069668: Epoch time: 138.21 s 
2025-12-18 08:21:11.723720:  
2025-12-18 08:21:11.723720: Epoch 373 
2025-12-18 08:21:11.738018: Current learning rate: 0.00657 
2025-12-18 08:23:29.872459: train_loss -0.8453 
2025-12-18 08:23:29.872459: val_loss -0.869 
2025-12-18 08:23:29.876463: Pseudo dice [0.927, 0.9542, 0.9321] 
2025-12-18 08:23:29.876463: Epoch time: 138.15 s 
2025-12-18 08:23:30.537098:  
2025-12-18 08:23:30.537098: Epoch 374 
2025-12-18 08:23:30.537098: Current learning rate: 0.00656 
2025-12-18 08:25:48.700679: train_loss -0.8441 
2025-12-18 08:25:48.702681: val_loss -0.8645 
2025-12-18 08:25:48.704683: Pseudo dice [0.922, 0.9512, 0.937] 
2025-12-18 08:25:48.704683: Epoch time: 138.16 s 
2025-12-18 08:25:49.361226:  
2025-12-18 08:25:49.361226: Epoch 375 
2025-12-18 08:25:49.361226: Current learning rate: 0.00655 
2025-12-18 08:28:07.499615: train_loss -0.8418 
2025-12-18 08:28:07.499615: val_loss -0.8556 
2025-12-18 08:28:07.509038: Pseudo dice [0.9138, 0.9488, 0.9371] 
2025-12-18 08:28:07.509038: Epoch time: 138.14 s 
2025-12-18 08:28:08.166097:  
2025-12-18 08:28:08.166097: Epoch 376 
2025-12-18 08:28:08.175506: Current learning rate: 0.00654 
2025-12-18 08:30:26.371494: train_loss -0.8524 
2025-12-18 08:30:26.371494: val_loss -0.8653 
2025-12-18 08:30:26.377387: Pseudo dice [0.9225, 0.9568, 0.9359] 
2025-12-18 08:30:26.381391: Epoch time: 138.21 s 
2025-12-18 08:30:27.037890:  
2025-12-18 08:30:27.037890: Epoch 377 
2025-12-18 08:30:27.037890: Current learning rate: 0.00653 
2025-12-18 08:32:45.233422: train_loss -0.8369 
2025-12-18 08:32:45.233422: val_loss -0.8583 
2025-12-18 08:32:45.233422: Pseudo dice [0.9253, 0.9531, 0.9313] 
2025-12-18 08:32:45.233422: Epoch time: 138.2 s 
2025-12-18 08:32:46.058246:  
2025-12-18 08:32:46.058246: Epoch 378 
2025-12-18 08:32:46.074354: Current learning rate: 0.00652 
2025-12-18 08:35:04.254485: train_loss -0.8143 
2025-12-18 08:35:04.254485: val_loss -0.8376 
2025-12-18 08:35:04.270389: Pseudo dice [0.9149, 0.9516, 0.9078] 
2025-12-18 08:35:04.270389: Epoch time: 138.2 s 
2025-12-18 08:35:04.920031:  
2025-12-18 08:35:04.920031: Epoch 379 
2025-12-18 08:35:04.920031: Current learning rate: 0.00651 
2025-12-18 08:37:22.882127: train_loss -0.7941 
2025-12-18 08:37:22.882127: val_loss -0.8247 
2025-12-18 08:37:22.882127: Pseudo dice [0.9141, 0.9443, 0.9086] 
2025-12-18 08:37:22.897795: Epoch time: 137.96 s 
2025-12-18 08:37:23.612346:  
2025-12-18 08:37:23.612346: Epoch 380 
2025-12-18 08:37:23.612346: Current learning rate: 0.0065 
2025-12-18 08:39:41.722084: train_loss -0.8121 
2025-12-18 08:39:41.738007: val_loss -0.8428 
2025-12-18 08:39:41.738007: Pseudo dice [0.9141, 0.9469, 0.9225] 
2025-12-18 08:39:41.738007: Epoch time: 138.11 s 
2025-12-18 08:39:42.386945:  
2025-12-18 08:39:42.386945: Epoch 381 
2025-12-18 08:39:42.386945: Current learning rate: 0.00649 
2025-12-18 08:42:00.528599: train_loss -0.8236 
2025-12-18 08:42:00.528599: val_loss -0.8496 
2025-12-18 08:42:00.530601: Pseudo dice [0.9153, 0.9503, 0.9208] 
2025-12-18 08:42:00.530601: Epoch time: 138.14 s 
2025-12-18 08:42:01.191204:  
2025-12-18 08:42:01.191204: Epoch 382 
2025-12-18 08:42:01.191204: Current learning rate: 0.00648 
2025-12-18 08:44:19.369262: train_loss -0.8402 
2025-12-18 08:44:19.371264: val_loss -0.8478 
2025-12-18 08:44:19.373266: Pseudo dice [0.9134, 0.9452, 0.9336] 
2025-12-18 08:44:19.373266: Epoch time: 138.18 s 
2025-12-18 08:44:20.190029:  
2025-12-18 08:44:20.190029: Epoch 383 
2025-12-18 08:44:20.190029: Current learning rate: 0.00648 
2025-12-18 08:46:38.980486: train_loss -0.8407 
2025-12-18 08:46:38.982489: val_loss -0.8564 
2025-12-18 08:46:38.988504: Pseudo dice [0.9146, 0.9523, 0.9398] 
2025-12-18 08:46:38.992511: Epoch time: 138.81 s 
2025-12-18 08:46:39.815726:  
2025-12-18 08:46:39.815726: Epoch 384 
2025-12-18 08:46:39.822271: Current learning rate: 0.00647 
2025-12-18 08:48:58.445284: train_loss -0.8305 
2025-12-18 08:48:58.445284: val_loss -0.8459 
2025-12-18 08:48:58.445284: Pseudo dice [0.9081, 0.9451, 0.9433] 
2025-12-18 08:48:58.445284: Epoch time: 138.63 s 
2025-12-18 08:48:59.127500:  
2025-12-18 08:48:59.127500: Epoch 385 
2025-12-18 08:48:59.127500: Current learning rate: 0.00646 
2025-12-18 08:51:17.767040: train_loss -0.8332 
2025-12-18 08:51:17.767040: val_loss -0.8557 
2025-12-18 08:51:17.785001: Pseudo dice [0.922, 0.9483, 0.928] 
2025-12-18 08:51:17.787112: Epoch time: 138.64 s 
2025-12-18 08:51:18.433321:  
2025-12-18 08:51:18.433321: Epoch 386 
2025-12-18 08:51:18.444551: Current learning rate: 0.00645 
2025-12-18 08:53:36.834226: train_loss -0.8431 
2025-12-18 08:53:36.834226: val_loss -0.8657 
2025-12-18 08:53:36.850323: Pseudo dice [0.9255, 0.9578, 0.9359] 
2025-12-18 08:53:36.850323: Epoch time: 138.4 s 
2025-12-18 08:53:37.521487:  
2025-12-18 08:53:37.521487: Epoch 387 
2025-12-18 08:53:37.523250: Current learning rate: 0.00644 
2025-12-18 08:55:56.208943: train_loss -0.8431 
2025-12-18 08:55:56.208943: val_loss -0.8596 
2025-12-18 08:55:56.215189: Pseudo dice [0.9255, 0.9524, 0.9222] 
2025-12-18 08:55:56.219291: Epoch time: 138.69 s 
2025-12-18 08:55:56.887196:  
2025-12-18 08:55:56.887196: Epoch 388 
2025-12-18 08:55:56.887196: Current learning rate: 0.00643 
2025-12-18 08:58:15.084941: train_loss -0.8508 
2025-12-18 08:58:15.084941: val_loss -0.853 
2025-12-18 08:58:15.091307: Pseudo dice [0.9137, 0.9489, 0.9432] 
2025-12-18 08:58:15.091307: Epoch time: 138.2 s 
2025-12-18 08:58:15.749232:  
2025-12-18 08:58:15.749232: Epoch 389 
2025-12-18 08:58:15.751530: Current learning rate: 0.00642 
2025-12-18 09:00:33.678299: train_loss -0.8352 
2025-12-18 09:00:33.680039: val_loss -0.8489 
2025-12-18 09:00:33.684044: Pseudo dice [0.9174, 0.9465, 0.9346] 
2025-12-18 09:00:33.686837: Epoch time: 137.94 s 
2025-12-18 09:00:34.695935:  
2025-12-18 09:00:34.695935: Epoch 390 
2025-12-18 09:00:34.698939: Current learning rate: 0.00641 
2025-12-18 09:02:52.636653: train_loss -0.8388 
2025-12-18 09:02:52.636653: val_loss -0.8704 
2025-12-18 09:02:52.652706: Pseudo dice [0.9271, 0.9578, 0.9342] 
2025-12-18 09:02:52.652706: Epoch time: 137.94 s 
2025-12-18 09:02:53.304405:  
2025-12-18 09:02:53.304405: Epoch 391 
2025-12-18 09:02:53.304405: Current learning rate: 0.0064 
2025-12-18 09:05:11.429917: train_loss -0.8433 
2025-12-18 09:05:11.431658: val_loss -0.8602 
2025-12-18 09:05:11.435663: Pseudo dice [0.9175, 0.9531, 0.9433] 
2025-12-18 09:05:11.438958: Epoch time: 138.13 s 
2025-12-18 09:05:12.109201:  
2025-12-18 09:05:12.109201: Epoch 392 
2025-12-18 09:05:12.113254: Current learning rate: 0.00639 
2025-12-18 09:07:30.134917: train_loss -0.8481 
2025-12-18 09:07:30.134917: val_loss -0.8616 
2025-12-18 09:07:30.138923: Pseudo dice [0.9205, 0.958, 0.9323] 
2025-12-18 09:07:30.140926: Epoch time: 138.03 s 
2025-12-18 09:07:30.917986:  
2025-12-18 09:07:30.917986: Epoch 393 
2025-12-18 09:07:30.928683: Current learning rate: 0.00638 
2025-12-18 09:09:49.239489: train_loss -0.8441 
2025-12-18 09:09:49.239489: val_loss -0.8586 
2025-12-18 09:09:49.255505: Pseudo dice [0.916, 0.9504, 0.9392] 
2025-12-18 09:09:49.255505: Epoch time: 138.32 s 
2025-12-18 09:09:49.922928:  
2025-12-18 09:09:49.922928: Epoch 394 
2025-12-18 09:09:49.922928: Current learning rate: 0.00637 
2025-12-18 09:12:07.945711: train_loss -0.8473 
2025-12-18 09:12:07.947713: val_loss -0.862 
2025-12-18 09:12:07.951718: Pseudo dice [0.9245, 0.9519, 0.9228] 
2025-12-18 09:12:07.951718: Epoch time: 138.02 s 
2025-12-18 09:12:08.613420:  
2025-12-18 09:12:08.613420: Epoch 395 
2025-12-18 09:12:08.619807: Current learning rate: 0.00636 
2025-12-18 09:14:26.764771: train_loss -0.8451 
2025-12-18 09:14:26.764771: val_loss -0.8567 
2025-12-18 09:14:26.770523: Pseudo dice [0.9139, 0.9484, 0.9322] 
2025-12-18 09:14:26.774489: Epoch time: 138.15 s 
2025-12-18 09:14:27.767956:  
2025-12-18 09:14:27.767956: Epoch 396 
2025-12-18 09:14:27.780061: Current learning rate: 0.00635 
2025-12-18 09:16:45.788673: train_loss -0.8446 
2025-12-18 09:16:45.790676: val_loss -0.8597 
2025-12-18 09:16:45.794458: Pseudo dice [0.9165, 0.9497, 0.9351] 
2025-12-18 09:16:45.796324: Epoch time: 138.02 s 
2025-12-18 09:16:46.474770:  
2025-12-18 09:16:46.474770: Epoch 397 
2025-12-18 09:16:46.486630: Current learning rate: 0.00634 
2025-12-18 09:19:04.654323: train_loss -0.8426 
2025-12-18 09:19:04.654323: val_loss -0.868 
2025-12-18 09:19:04.656325: Pseudo dice [0.9235, 0.9547, 0.9399] 
2025-12-18 09:19:04.656325: Epoch time: 138.18 s 
2025-12-18 09:19:05.319729:  
2025-12-18 09:19:05.319729: Epoch 398 
2025-12-18 09:19:05.319729: Current learning rate: 0.00633 
2025-12-18 09:21:23.412613: train_loss -0.8458 
2025-12-18 09:21:23.414616: val_loss -0.8689 
2025-12-18 09:21:23.418622: Pseudo dice [0.929, 0.9601, 0.9322] 
2025-12-18 09:21:23.420447: Epoch time: 138.09 s 
2025-12-18 09:21:24.207358:  
2025-12-18 09:21:24.207358: Epoch 399 
2025-12-18 09:21:24.207358: Current learning rate: 0.00632 
2025-12-18 09:23:42.260605: train_loss -0.8468 
2025-12-18 09:23:42.260605: val_loss -0.8647 
2025-12-18 09:23:42.264610: Pseudo dice [0.9189, 0.9565, 0.936] 
2025-12-18 09:23:42.268614: Epoch time: 138.07 s 
2025-12-18 09:23:43.172451:  
2025-12-18 09:23:43.172451: Epoch 400 
2025-12-18 09:23:43.172451: Current learning rate: 0.00631 
2025-12-18 09:26:01.203505: train_loss -0.8501 
2025-12-18 09:26:01.203505: val_loss -0.8699 
2025-12-18 09:26:01.207509: Pseudo dice [0.924, 0.9526, 0.9501] 
2025-12-18 09:26:01.211513: Epoch time: 138.03 s 
2025-12-18 09:26:01.873899:  
2025-12-18 09:26:01.873899: Epoch 401 
2025-12-18 09:26:01.873899: Current learning rate: 0.0063 
2025-12-18 09:28:20.081867: train_loss -0.8464 
2025-12-18 09:28:20.081867: val_loss -0.8747 
2025-12-18 09:28:20.085606: Pseudo dice [0.93, 0.9569, 0.9325] 
2025-12-18 09:28:20.089610: Epoch time: 138.21 s 
2025-12-18 09:28:21.001310:  
2025-12-18 09:28:21.001310: Epoch 402 
2025-12-18 09:28:21.001310: Current learning rate: 0.0063 
2025-12-18 09:30:39.091674: train_loss -0.8472 
2025-12-18 09:30:39.091674: val_loss -0.8596 
2025-12-18 09:30:39.095678: Pseudo dice [0.9176, 0.9531, 0.932] 
2025-12-18 09:30:39.097680: Epoch time: 138.09 s 
2025-12-18 09:30:39.763455:  
2025-12-18 09:30:39.763455: Epoch 403 
2025-12-18 09:30:39.763455: Current learning rate: 0.00629 
2025-12-18 09:32:57.957752: train_loss -0.8467 
2025-12-18 09:32:57.957752: val_loss -0.8754 
2025-12-18 09:32:57.963602: Pseudo dice [0.9299, 0.9574, 0.932] 
2025-12-18 09:32:57.967105: Epoch time: 138.2 s 
2025-12-18 09:32:58.623829:  
2025-12-18 09:32:58.623829: Epoch 404 
2025-12-18 09:32:58.623829: Current learning rate: 0.00628 
2025-12-18 09:35:16.830253: train_loss -0.8435 
2025-12-18 09:35:16.830253: val_loss -0.8688 
2025-12-18 09:35:16.830253: Pseudo dice [0.924, 0.9554, 0.9371] 
2025-12-18 09:35:16.837717: Epoch time: 138.21 s 
2025-12-18 09:35:16.839718: Yayy! New best EMA pseudo Dice: 0.9369 
2025-12-18 09:35:17.731452:  
2025-12-18 09:35:17.731452: Epoch 405 
2025-12-18 09:35:17.747368: Current learning rate: 0.00627 
2025-12-18 09:37:35.930191: train_loss -0.8487 
2025-12-18 09:37:35.930191: val_loss -0.8726 
2025-12-18 09:37:35.932193: Pseudo dice [0.9252, 0.9581, 0.9362] 
2025-12-18 09:37:35.936416: Epoch time: 138.2 s 
2025-12-18 09:37:35.940421: Yayy! New best EMA pseudo Dice: 0.9372 
2025-12-18 09:37:36.871311:  
2025-12-18 09:37:36.873313: Epoch 406 
2025-12-18 09:37:36.873313: Current learning rate: 0.00626 
2025-12-18 09:39:54.986423: train_loss -0.845 
2025-12-18 09:39:54.986423: val_loss -0.8607 
2025-12-18 09:39:55.002408: Pseudo dice [0.9214, 0.9535, 0.9365] 
2025-12-18 09:39:55.006247: Epoch time: 138.12 s 
2025-12-18 09:39:55.834795:  
2025-12-18 09:39:55.834795: Epoch 407 
2025-12-18 09:39:55.839379: Current learning rate: 0.00625 
2025-12-18 09:42:13.939198: train_loss -0.8398 
2025-12-18 09:42:13.939198: val_loss -0.8629 
2025-12-18 09:42:13.955256: Pseudo dice [0.9274, 0.9564, 0.9189] 
2025-12-18 09:42:13.955256: Epoch time: 138.1 s 
2025-12-18 09:42:14.621200:  
2025-12-18 09:42:14.621200: Epoch 408 
2025-12-18 09:42:14.621200: Current learning rate: 0.00624 
2025-12-18 09:44:32.854575: train_loss -0.8438 
2025-12-18 09:44:32.854575: val_loss -0.8672 
2025-12-18 09:44:32.872320: Pseudo dice [0.9266, 0.9592, 0.9255] 
2025-12-18 09:44:32.872320: Epoch time: 138.23 s 
2025-12-18 09:44:33.519120:  
2025-12-18 09:44:33.519120: Epoch 409 
2025-12-18 09:44:33.519120: Current learning rate: 0.00623 
2025-12-18 09:46:51.721697: train_loss -0.8459 
2025-12-18 09:46:51.721697: val_loss -0.8666 
2025-12-18 09:46:51.721697: Pseudo dice [0.9268, 0.9585, 0.9414] 
2025-12-18 09:46:51.721697: Epoch time: 138.2 s 
2025-12-18 09:46:51.721697: Yayy! New best EMA pseudo Dice: 0.9374 
2025-12-18 09:46:52.638462:  
2025-12-18 09:46:52.638462: Epoch 410 
2025-12-18 09:46:52.642205: Current learning rate: 0.00622 
2025-12-18 09:49:10.857196: train_loss -0.8515 
2025-12-18 09:49:10.857196: val_loss -0.8669 
2025-12-18 09:49:10.868399: Pseudo dice [0.9246, 0.958, 0.9321] 
2025-12-18 09:49:10.873021: Epoch time: 138.23 s 
2025-12-18 09:49:10.873021: Yayy! New best EMA pseudo Dice: 0.9375 
2025-12-18 09:49:11.780176:  
2025-12-18 09:49:11.780176: Epoch 411 
2025-12-18 09:49:11.780176: Current learning rate: 0.00621 
2025-12-18 09:51:29.976914: train_loss -0.8447 
2025-12-18 09:51:29.976914: val_loss -0.8578 
2025-12-18 09:51:29.978916: Pseudo dice [0.9201, 0.9521, 0.9257] 
2025-12-18 09:51:29.978916: Epoch time: 138.2 s 
2025-12-18 09:51:30.713343:  
2025-12-18 09:51:30.713343: Epoch 412 
2025-12-18 09:51:30.717085: Current learning rate: 0.0062 
2025-12-18 09:53:48.984291: train_loss -0.8089 
2025-12-18 09:53:48.986294: val_loss -0.7681 
2025-12-18 09:53:48.989385: Pseudo dice [0.8842, 0.9309, 0.8699] 
2025-12-18 09:53:48.993645: Epoch time: 138.27 s 
2025-12-18 09:53:49.775891:  
2025-12-18 09:53:49.775891: Epoch 413 
2025-12-18 09:53:49.775891: Current learning rate: 0.00619 
2025-12-18 09:56:07.971212: train_loss -0.7721 
2025-12-18 09:56:07.971212: val_loss -0.8163 
2025-12-18 09:56:07.975217: Pseudo dice [0.9048, 0.9365, 0.9147] 
2025-12-18 09:56:07.979221: Epoch time: 138.2 s 
2025-12-18 09:56:08.613591:  
2025-12-18 09:56:08.613591: Epoch 414 
2025-12-18 09:56:08.613591: Current learning rate: 0.00618 
2025-12-18 09:58:26.635371: train_loss -0.8086 
2025-12-18 09:58:26.635371: val_loss -0.8423 
2025-12-18 09:58:26.639377: Pseudo dice [0.9155, 0.9494, 0.919] 
2025-12-18 09:58:26.643121: Epoch time: 138.02 s 
2025-12-18 09:58:27.368550:  
2025-12-18 09:58:27.368550: Epoch 415 
2025-12-18 09:58:27.368550: Current learning rate: 0.00617 
2025-12-18 10:00:45.597861: train_loss -0.8259 
2025-12-18 10:00:45.597861: val_loss -0.8513 
2025-12-18 10:00:45.610104: Pseudo dice [0.9216, 0.9494, 0.9252] 
2025-12-18 10:00:45.613847: Epoch time: 138.23 s 
2025-12-18 10:00:46.247593:  
2025-12-18 10:00:46.247593: Epoch 416 
2025-12-18 10:00:46.247593: Current learning rate: 0.00616 
2025-12-18 10:03:04.346490: train_loss -0.8191 
2025-12-18 10:03:04.346490: val_loss -0.8443 
2025-12-18 10:03:04.352578: Pseudo dice [0.9157, 0.9517, 0.922] 
2025-12-18 10:03:04.354589: Epoch time: 138.1 s 
2025-12-18 10:03:04.997726:  
2025-12-18 10:03:04.997726: Epoch 417 
2025-12-18 10:03:05.006238: Current learning rate: 0.00615 
2025-12-18 10:05:23.199174: train_loss -0.8259 
2025-12-18 10:05:23.215136: val_loss -0.8564 
2025-12-18 10:05:23.215136: Pseudo dice [0.9196, 0.9517, 0.9303] 
2025-12-18 10:05:23.215136: Epoch time: 138.2 s 
2025-12-18 10:05:23.990579:  
2025-12-18 10:05:23.990579: Epoch 418 
2025-12-18 10:05:24.000811: Current learning rate: 0.00614 
2025-12-18 10:07:42.016842: train_loss -0.8354 
2025-12-18 10:07:42.018844: val_loss -0.8501 
2025-12-18 10:07:42.022850: Pseudo dice [0.9121, 0.9531, 0.9314] 
2025-12-18 10:07:42.028200: Epoch time: 138.03 s 
2025-12-18 10:07:42.664452:  
2025-12-18 10:07:42.664452: Epoch 419 
2025-12-18 10:07:42.664452: Current learning rate: 0.00613 
2025-12-18 10:10:01.283057: train_loss -0.8412 
2025-12-18 10:10:01.285060: val_loss -0.8466 
2025-12-18 10:10:01.285060: Pseudo dice [0.9117, 0.9486, 0.924] 
2025-12-18 10:10:01.285060: Epoch time: 138.62 s 
2025-12-18 10:10:02.093388:  
2025-12-18 10:10:02.093388: Epoch 420 
2025-12-18 10:10:02.093388: Current learning rate: 0.00612 
2025-12-18 10:12:20.216114: train_loss -0.8374 
2025-12-18 10:12:20.216114: val_loss -0.8607 
2025-12-18 10:12:20.220120: Pseudo dice [0.9202, 0.9533, 0.9327] 
2025-12-18 10:12:20.224127: Epoch time: 138.12 s 
2025-12-18 10:12:20.987951:  
2025-12-18 10:12:20.987951: Epoch 421 
2025-12-18 10:12:20.993251: Current learning rate: 0.00612 
2025-12-18 10:14:39.127162: train_loss -0.8407 
2025-12-18 10:14:39.127162: val_loss -0.8568 
2025-12-18 10:14:39.127162: Pseudo dice [0.9175, 0.9508, 0.931] 
2025-12-18 10:14:39.127162: Epoch time: 138.14 s 
2025-12-18 10:14:39.761517:  
2025-12-18 10:14:39.761517: Epoch 422 
2025-12-18 10:14:39.761517: Current learning rate: 0.00611 
2025-12-18 10:16:57.842940: train_loss -0.8362 
2025-12-18 10:16:57.842940: val_loss -0.8609 
2025-12-18 10:16:57.858672: Pseudo dice [0.9193, 0.9532, 0.9356] 
2025-12-18 10:16:57.858672: Epoch time: 138.08 s 
2025-12-18 10:16:58.492320:  
2025-12-18 10:16:58.492320: Epoch 423 
2025-12-18 10:16:58.508333: Current learning rate: 0.0061 
2025-12-18 10:19:16.651973: train_loss -0.8376 
2025-12-18 10:19:16.651973: val_loss -0.8591 
2025-12-18 10:19:16.657981: Pseudo dice [0.9221, 0.9526, 0.9296] 
2025-12-18 10:19:16.661724: Epoch time: 138.16 s 
2025-12-18 10:19:17.404715:  
2025-12-18 10:19:17.404715: Epoch 424 
2025-12-18 10:19:17.404715: Current learning rate: 0.00609 
2025-12-18 10:21:35.601597: train_loss -0.8423 
2025-12-18 10:21:35.601597: val_loss -0.8571 
2025-12-18 10:21:35.603599: Pseudo dice [0.9188, 0.9532, 0.9292] 
2025-12-18 10:21:35.603599: Epoch time: 138.2 s 
2025-12-18 10:21:36.249660:  
2025-12-18 10:21:36.249660: Epoch 425 
2025-12-18 10:21:36.249660: Current learning rate: 0.00608 
2025-12-18 10:23:54.271398: train_loss -0.845 
2025-12-18 10:23:54.273139: val_loss -0.8608 
2025-12-18 10:23:54.281157: Pseudo dice [0.9201, 0.9574, 0.9323] 
2025-12-18 10:23:54.283159: Epoch time: 138.04 s 
2025-12-18 10:23:55.112036:  
2025-12-18 10:23:55.112036: Epoch 426 
2025-12-18 10:23:55.112036: Current learning rate: 0.00607 
2025-12-18 10:26:13.226671: train_loss -0.8458 
2025-12-18 10:26:13.228673: val_loss -0.8691 
2025-12-18 10:26:13.234421: Pseudo dice [0.9279, 0.9568, 0.9353] 
2025-12-18 10:26:13.240169: Epoch time: 138.13 s 
2025-12-18 10:26:13.879282:  
2025-12-18 10:26:13.879282: Epoch 427 
2025-12-18 10:26:13.879282: Current learning rate: 0.00606 
2025-12-18 10:28:31.997320: train_loss -0.8419 
2025-12-18 10:28:31.999322: val_loss -0.8674 
2025-12-18 10:28:32.004328: Pseudo dice [0.9259, 0.9526, 0.9366] 
2025-12-18 10:28:32.006330: Epoch time: 138.12 s 
2025-12-18 10:28:32.637733:  
2025-12-18 10:28:32.637733: Epoch 428 
2025-12-18 10:28:32.653596: Current learning rate: 0.00605 
2025-12-18 10:30:50.612858: train_loss -0.8507 
2025-12-18 10:30:50.612858: val_loss -0.8686 
2025-12-18 10:30:50.612858: Pseudo dice [0.9264, 0.9554, 0.9342] 
2025-12-18 10:30:50.612858: Epoch time: 137.98 s 
2025-12-18 10:30:51.246716:  
2025-12-18 10:30:51.246716: Epoch 429 
2025-12-18 10:30:51.246716: Current learning rate: 0.00604 
2025-12-18 10:33:09.268438: train_loss -0.8506 
2025-12-18 10:33:09.270440: val_loss -0.8726 
2025-12-18 10:33:09.273941: Pseudo dice [0.9237, 0.9542, 0.9495] 
2025-12-18 10:33:09.277945: Epoch time: 138.02 s 
2025-12-18 10:33:09.913430:  
2025-12-18 10:33:09.913430: Epoch 430 
2025-12-18 10:33:09.913430: Current learning rate: 0.00603 
2025-12-18 10:35:28.154698: train_loss -0.8432 
2025-12-18 10:35:28.160511: val_loss -0.8574 
2025-12-18 10:35:28.164301: Pseudo dice [0.9182, 0.9497, 0.9269] 
2025-12-18 10:35:28.166303: Epoch time: 138.24 s 
2025-12-18 10:35:28.826666:  
2025-12-18 10:35:28.826666: Epoch 431 
2025-12-18 10:35:28.826666: Current learning rate: 0.00602 
2025-12-18 10:37:46.712497: train_loss -0.8413 
2025-12-18 10:37:46.714504: val_loss -0.8656 
2025-12-18 10:37:46.722529: Pseudo dice [0.9202, 0.9532, 0.942] 
2025-12-18 10:37:46.724532: Epoch time: 137.89 s 
2025-12-18 10:37:47.522300:  
2025-12-18 10:37:47.522300: Epoch 432 
2025-12-18 10:37:47.522300: Current learning rate: 0.00601 
2025-12-18 10:40:05.507398: train_loss -0.8445 
2025-12-18 10:40:05.509400: val_loss -0.8534 
2025-12-18 10:40:05.515144: Pseudo dice [0.915, 0.9511, 0.9298] 
2025-12-18 10:40:05.519148: Epoch time: 137.99 s 
2025-12-18 10:40:06.151946:  
2025-12-18 10:40:06.151946: Epoch 433 
2025-12-18 10:40:06.151946: Current learning rate: 0.006 
2025-12-18 10:42:24.244630: train_loss -0.8445 
2025-12-18 10:42:24.244630: val_loss -0.8703 
2025-12-18 10:42:24.248634: Pseudo dice [0.924, 0.9543, 0.9445] 
2025-12-18 10:42:24.252639: Epoch time: 138.09 s 
2025-12-18 10:42:24.880161:  
2025-12-18 10:42:24.880161: Epoch 434 
2025-12-18 10:42:24.896139: Current learning rate: 0.00599 
2025-12-18 10:44:43.080672: train_loss -0.8483 
2025-12-18 10:44:43.080672: val_loss -0.8691 
2025-12-18 10:44:43.080672: Pseudo dice [0.926, 0.9576, 0.9369] 
2025-12-18 10:44:43.086492: Epoch time: 138.2 s 
2025-12-18 10:44:43.722371:  
2025-12-18 10:44:43.722371: Epoch 435 
2025-12-18 10:44:43.736137: Current learning rate: 0.00598 
2025-12-18 10:47:01.792627: train_loss -0.8446 
2025-12-18 10:47:01.792627: val_loss -0.8679 
2025-12-18 10:47:01.803255: Pseudo dice [0.9255, 0.9537, 0.9297] 
2025-12-18 10:47:01.806630: Epoch time: 138.07 s 
2025-12-18 10:47:02.439448:  
2025-12-18 10:47:02.439448: Epoch 436 
2025-12-18 10:47:02.451903: Current learning rate: 0.00597 
2025-12-18 10:49:20.448446: train_loss -0.8492 
2025-12-18 10:49:20.448446: val_loss -0.8619 
2025-12-18 10:49:20.452450: Pseudo dice [0.916, 0.9503, 0.9438] 
2025-12-18 10:49:20.456454: Epoch time: 138.01 s 
2025-12-18 10:49:21.095295:  
2025-12-18 10:49:21.095295: Epoch 437 
2025-12-18 10:49:21.108652: Current learning rate: 0.00596 
2025-12-18 10:51:38.973546: train_loss -0.849 
2025-12-18 10:51:38.973546: val_loss -0.8696 
2025-12-18 10:51:38.977550: Pseudo dice [0.9226, 0.9538, 0.9368] 
2025-12-18 10:51:38.981292: Epoch time: 137.88 s 
2025-12-18 10:51:39.616805:  
2025-12-18 10:51:39.616805: Epoch 438 
2025-12-18 10:51:39.616805: Current learning rate: 0.00595 
2025-12-18 10:53:57.612839: train_loss -0.8451 
2025-12-18 10:53:57.612839: val_loss -0.8616 
2025-12-18 10:53:57.618370: Pseudo dice [0.9212, 0.95, 0.9364] 
2025-12-18 10:53:57.618370: Epoch time: 138.0 s 
2025-12-18 10:53:58.422051:  
2025-12-18 10:53:58.422051: Epoch 439 
2025-12-18 10:53:58.422051: Current learning rate: 0.00594 
2025-12-18 10:56:16.507634: train_loss -0.8432 
2025-12-18 10:56:16.507634: val_loss -0.8601 
2025-12-18 10:56:16.511848: Pseudo dice [0.9173, 0.9509, 0.9359] 
2025-12-18 10:56:16.513851: Epoch time: 138.09 s 
2025-12-18 10:56:17.140599:  
2025-12-18 10:56:17.140599: Epoch 440 
2025-12-18 10:56:17.156240: Current learning rate: 0.00593 
2025-12-18 10:58:35.381214: train_loss -0.8428 
2025-12-18 10:58:35.381214: val_loss -0.8769 
2025-12-18 10:58:35.381214: Pseudo dice [0.9336, 0.9641, 0.9337] 
2025-12-18 10:58:35.381214: Epoch time: 138.24 s 
2025-12-18 10:58:36.017851:  
2025-12-18 10:58:36.017851: Epoch 441 
2025-12-18 10:58:36.017851: Current learning rate: 0.00592 
2025-12-18 11:00:54.207352: train_loss -0.8433 
2025-12-18 11:00:54.209356: val_loss -0.8652 
2025-12-18 11:00:54.215366: Pseudo dice [0.9223, 0.9557, 0.9371] 
2025-12-18 11:00:54.219371: Epoch time: 138.19 s 
2025-12-18 11:00:54.846083:  
2025-12-18 11:00:54.846083: Epoch 442 
2025-12-18 11:00:54.846083: Current learning rate: 0.00592 
2025-12-18 11:03:13.025616: train_loss -0.842 
2025-12-18 11:03:13.025616: val_loss -0.8714 
2025-12-18 11:03:13.029394: Pseudo dice [0.9287, 0.957, 0.9347] 
2025-12-18 11:03:13.034797: Epoch time: 138.18 s 
2025-12-18 11:03:13.732346:  
2025-12-18 11:03:13.732346: Epoch 443 
2025-12-18 11:03:13.732346: Current learning rate: 0.00591 
2025-12-18 11:05:32.012022: train_loss -0.8451 
2025-12-18 11:05:32.014024: val_loss -0.8611 
2025-12-18 11:05:32.018028: Pseudo dice [0.9161, 0.9515, 0.9396] 
2025-12-18 11:05:32.018028: Epoch time: 138.28 s 
2025-12-18 11:05:32.638608:  
2025-12-18 11:05:32.638608: Epoch 444 
2025-12-18 11:05:32.638608: Current learning rate: 0.0059 
2025-12-18 11:07:50.648018: train_loss -0.8481 
2025-12-18 11:07:50.648018: val_loss -0.8621 
2025-12-18 11:07:50.652022: Pseudo dice [0.9167, 0.9514, 0.9415] 
2025-12-18 11:07:50.656026: Epoch time: 138.01 s 
2025-12-18 11:07:51.475727:  
2025-12-18 11:07:51.475727: Epoch 445 
2025-12-18 11:07:51.491704: Current learning rate: 0.00589 
2025-12-18 11:10:10.015862: train_loss -0.8429 
2025-12-18 11:10:10.015862: val_loss -0.8643 
2025-12-18 11:10:10.015862: Pseudo dice [0.9232, 0.9545, 0.9316] 
2025-12-18 11:10:10.015862: Epoch time: 138.54 s 
2025-12-18 11:10:10.634641:  
2025-12-18 11:10:10.634641: Epoch 446 
2025-12-18 11:10:10.634641: Current learning rate: 0.00588 
2025-12-18 11:12:28.936885: train_loss -0.8481 
2025-12-18 11:12:28.936885: val_loss -0.8656 
2025-12-18 11:12:28.942389: Pseudo dice [0.9229, 0.952, 0.9319] 
2025-12-18 11:12:28.944392: Epoch time: 138.3 s 
2025-12-18 11:12:29.568880:  
2025-12-18 11:12:29.568880: Epoch 447 
2025-12-18 11:12:29.568880: Current learning rate: 0.00587 
2025-12-18 11:14:47.857288: train_loss -0.8462 
2025-12-18 11:14:47.857288: val_loss -0.8738 
2025-12-18 11:14:47.857288: Pseudo dice [0.9257, 0.9599, 0.9391] 
2025-12-18 11:14:47.857288: Epoch time: 138.29 s 
2025-12-18 11:14:48.489811:  
2025-12-18 11:14:48.489811: Epoch 448 
2025-12-18 11:14:48.489811: Current learning rate: 0.00586 
2025-12-18 11:17:06.577017: train_loss -0.851 
2025-12-18 11:17:06.577017: val_loss -0.8658 
2025-12-18 11:17:06.577017: Pseudo dice [0.9227, 0.9541, 0.9383] 
2025-12-18 11:17:06.577017: Epoch time: 138.09 s 
2025-12-18 11:17:07.305127:  
2025-12-18 11:17:07.305127: Epoch 449 
2025-12-18 11:17:07.305127: Current learning rate: 0.00585 
2025-12-18 11:19:25.524264: train_loss -0.8485 
2025-12-18 11:19:25.524264: val_loss -0.8699 
2025-12-18 11:19:25.524264: Pseudo dice [0.9243, 0.9544, 0.9371] 
2025-12-18 11:19:25.524264: Epoch time: 138.22 s 
2025-12-18 11:19:25.777805: Yayy! New best EMA pseudo Dice: 0.9376 
2025-12-18 11:19:26.699834:  
2025-12-18 11:19:26.699834: Epoch 450 
2025-12-18 11:19:26.699834: Current learning rate: 0.00584 
2025-12-18 11:21:44.900062: train_loss -0.8475 
2025-12-18 11:21:44.900062: val_loss -0.8525 
2025-12-18 11:21:44.900062: Pseudo dice [0.915, 0.9519, 0.9302] 
2025-12-18 11:21:44.907980: Epoch time: 138.2 s 
2025-12-18 11:21:45.682548:  
2025-12-18 11:21:45.682548: Epoch 451 
2025-12-18 11:21:45.682548: Current learning rate: 0.00583 
2025-12-18 11:24:03.967228: train_loss -0.8409 
2025-12-18 11:24:03.967228: val_loss -0.8724 
2025-12-18 11:24:03.971232: Pseudo dice [0.924, 0.9538, 0.9453] 
2025-12-18 11:24:03.974974: Epoch time: 138.28 s 
2025-12-18 11:24:04.724457:  
2025-12-18 11:24:04.724457: Epoch 452 
2025-12-18 11:24:04.724457: Current learning rate: 0.00582 
2025-12-18 11:26:23.126930: train_loss -0.8496 
2025-12-18 11:26:23.126930: val_loss -0.867 
2025-12-18 11:26:23.126930: Pseudo dice [0.9251, 0.9515, 0.9408] 
2025-12-18 11:26:23.136832: Epoch time: 138.4 s 
2025-12-18 11:26:23.138834: Yayy! New best EMA pseudo Dice: 0.9376 
2025-12-18 11:26:23.989047:  
2025-12-18 11:26:23.989047: Epoch 453 
2025-12-18 11:26:24.004971: Current learning rate: 0.00581 
2025-12-18 11:28:42.089580: train_loss -0.8505 
2025-12-18 11:28:42.089580: val_loss -0.8649 
2025-12-18 11:28:42.089580: Pseudo dice [0.9251, 0.9565, 0.9257] 
2025-12-18 11:28:42.103578: Epoch time: 138.1 s 
2025-12-18 11:28:42.769293:  
2025-12-18 11:28:42.769293: Epoch 454 
2025-12-18 11:28:42.785058: Current learning rate: 0.0058 
2025-12-18 11:31:01.134575: train_loss -0.8489 
2025-12-18 11:31:01.134575: val_loss -0.8641 
2025-12-18 11:31:01.150278: Pseudo dice [0.9191, 0.9522, 0.9379] 
2025-12-18 11:31:01.150278: Epoch time: 138.37 s 
2025-12-18 11:31:01.860000:  
2025-12-18 11:31:01.860000: Epoch 455 
2025-12-18 11:31:01.860000: Current learning rate: 0.00579 
2025-12-18 11:33:19.980186: train_loss -0.8397 
2025-12-18 11:33:19.980186: val_loss -0.868 
2025-12-18 11:33:19.980186: Pseudo dice [0.9239, 0.9572, 0.9322] 
2025-12-18 11:33:19.990115: Epoch time: 138.12 s 
2025-12-18 11:33:20.610359:  
2025-12-18 11:33:20.610359: Epoch 456 
2025-12-18 11:33:20.610359: Current learning rate: 0.00578 
2025-12-18 11:35:38.782939: train_loss -0.8464 
2025-12-18 11:35:38.782939: val_loss -0.8621 
2025-12-18 11:35:38.798629: Pseudo dice [0.9196, 0.954, 0.9296] 
2025-12-18 11:35:38.798629: Epoch time: 138.17 s 
2025-12-18 11:35:39.415000:  
2025-12-18 11:35:39.415000: Epoch 457 
2025-12-18 11:35:39.415000: Current learning rate: 0.00577 
2025-12-18 11:37:57.955194: train_loss -0.8447 
2025-12-18 11:37:57.955194: val_loss -0.8744 
2025-12-18 11:37:57.955194: Pseudo dice [0.9282, 0.9605, 0.9361] 
2025-12-18 11:37:57.960891: Epoch time: 138.54 s 
2025-12-18 11:37:58.578360:  
2025-12-18 11:37:58.578360: Epoch 458 
2025-12-18 11:37:58.594135: Current learning rate: 0.00576 
2025-12-18 11:40:16.725323: train_loss -0.8471 
2025-12-18 11:40:16.725323: val_loss -0.8761 
2025-12-18 11:40:16.727326: Pseudo dice [0.9303, 0.9577, 0.9413] 
2025-12-18 11:40:16.735666: Epoch time: 138.15 s 
2025-12-18 11:40:16.739408: Yayy! New best EMA pseudo Dice: 0.9381 
2025-12-18 11:40:17.625828:  
2025-12-18 11:40:17.625828: Epoch 459 
2025-12-18 11:40:17.625828: Current learning rate: 0.00575 
2025-12-18 11:42:35.749142: train_loss -0.8311 
2025-12-18 11:42:35.749142: val_loss -0.8355 
2025-12-18 11:42:35.751144: Pseudo dice [0.9131, 0.9472, 0.9057] 
2025-12-18 11:42:35.757598: Epoch time: 138.12 s 
2025-12-18 11:42:36.373256:  
2025-12-18 11:42:36.373256: Epoch 460 
2025-12-18 11:42:36.373256: Current learning rate: 0.00574 
2025-12-18 11:44:54.650226: train_loss -0.8128 
2025-12-18 11:44:54.650226: val_loss -0.8495 
2025-12-18 11:44:54.650226: Pseudo dice [0.9224, 0.9504, 0.9216] 
2025-12-18 11:44:54.650226: Epoch time: 138.28 s 
2025-12-18 11:44:55.279124:  
2025-12-18 11:44:55.279124: Epoch 461 
2025-12-18 11:44:55.279124: Current learning rate: 0.00573 
2025-12-18 11:47:13.387806: train_loss -0.8219 
2025-12-18 11:47:13.387806: val_loss -0.8517 
2025-12-18 11:47:13.391810: Pseudo dice [0.9148, 0.955, 0.9285] 
2025-12-18 11:47:13.395814: Epoch time: 138.11 s 
2025-12-18 11:47:14.006574:  
2025-12-18 11:47:14.006574: Epoch 462 
2025-12-18 11:47:14.006574: Current learning rate: 0.00572 
2025-12-18 11:49:31.995778: train_loss -0.8205 
2025-12-18 11:49:31.995778: val_loss -0.8457 
2025-12-18 11:49:31.995778: Pseudo dice [0.9136, 0.9467, 0.927] 
2025-12-18 11:49:32.011506: Epoch time: 137.99 s 
2025-12-18 11:49:32.630095:  
2025-12-18 11:49:32.630095: Epoch 463 
2025-12-18 11:49:32.630095: Current learning rate: 0.00571 
2025-12-18 11:51:50.910917: train_loss -0.8273 
2025-12-18 11:51:50.910917: val_loss -0.8569 
2025-12-18 11:51:50.912919: Pseudo dice [0.9206, 0.9543, 0.9256] 
2025-12-18 11:51:50.919971: Epoch time: 138.3 s 
2025-12-18 11:51:51.711695:  
2025-12-18 11:51:51.711695: Epoch 464 
2025-12-18 11:51:51.711695: Current learning rate: 0.0057 
2025-12-18 11:54:09.737303: train_loss -0.8412 
2025-12-18 11:54:09.737303: val_loss -0.8532 
2025-12-18 11:54:09.753033: Pseudo dice [0.9129, 0.9492, 0.934] 
2025-12-18 11:54:09.753033: Epoch time: 138.04 s 
2025-12-18 11:54:10.370485:  
2025-12-18 11:54:10.370485: Epoch 465 
2025-12-18 11:54:10.370485: Current learning rate: 0.0057 
2025-12-18 11:56:28.398163: train_loss -0.8467 
2025-12-18 11:56:28.400164: val_loss -0.8697 
2025-12-18 11:56:28.403906: Pseudo dice [0.9247, 0.9556, 0.937] 
2025-12-18 11:56:28.405909: Epoch time: 138.03 s 
2025-12-18 11:56:29.020868:  
2025-12-18 11:56:29.036650: Epoch 466 
2025-12-18 11:56:29.036650: Current learning rate: 0.00569 
2025-12-18 11:58:47.089376: train_loss -0.8431 
2025-12-18 11:58:47.089376: val_loss -0.8499 
2025-12-18 11:58:47.105304: Pseudo dice [0.9093, 0.9465, 0.9371] 
2025-12-18 11:58:47.105304: Epoch time: 138.07 s 
2025-12-18 11:58:47.722813:  
2025-12-18 11:58:47.722813: Epoch 467 
2025-12-18 11:58:47.722813: Current learning rate: 0.00568 
2025-12-18 12:01:05.925377: train_loss -0.842 
2025-12-18 12:01:05.925377: val_loss -0.8616 
2025-12-18 12:01:05.943363: Pseudo dice [0.9258, 0.9525, 0.9199] 
2025-12-18 12:01:05.943363: Epoch time: 138.2 s 
2025-12-18 12:01:06.574481:  
2025-12-18 12:01:06.574481: Epoch 468 
2025-12-18 12:01:06.574481: Current learning rate: 0.00567 
2025-12-18 12:03:24.563176: train_loss -0.838 
2025-12-18 12:03:24.563176: val_loss -0.8594 
2025-12-18 12:03:24.579154: Pseudo dice [0.921, 0.9489, 0.9288] 
2025-12-18 12:03:24.579154: Epoch time: 137.99 s 
2025-12-18 12:03:25.198149:  
2025-12-18 12:03:25.198149: Epoch 469 
2025-12-18 12:03:25.198149: Current learning rate: 0.00566 
2025-12-18 12:05:43.238272: train_loss -0.8388 
2025-12-18 12:05:43.240274: val_loss -0.866 
2025-12-18 12:05:43.244016: Pseudo dice [0.9244, 0.9559, 0.9369] 
2025-12-18 12:05:43.246018: Epoch time: 138.04 s 
2025-12-18 12:05:44.035948:  
2025-12-18 12:05:44.035948: Epoch 470 
2025-12-18 12:05:44.035948: Current learning rate: 0.00565 
2025-12-18 12:08:01.977583: train_loss -0.8447 
2025-12-18 12:08:01.977583: val_loss -0.8714 
2025-12-18 12:08:01.977583: Pseudo dice [0.927, 0.958, 0.9353] 
2025-12-18 12:08:01.977583: Epoch time: 137.94 s 
2025-12-18 12:08:02.627016:  
2025-12-18 12:08:02.627016: Epoch 471 
2025-12-18 12:08:02.627016: Current learning rate: 0.00564 
2025-12-18 12:10:21.119295: train_loss -0.8354 
2025-12-18 12:10:21.119295: val_loss -0.8719 
2025-12-18 12:10:21.119295: Pseudo dice [0.9318, 0.9575, 0.9316] 
2025-12-18 12:10:21.128544: Epoch time: 138.49 s 
2025-12-18 12:10:21.752741:  
2025-12-18 12:10:21.752741: Epoch 472 
2025-12-18 12:10:21.752741: Current learning rate: 0.00563 
2025-12-18 12:12:39.962618: train_loss -0.8452 
2025-12-18 12:12:39.962618: val_loss -0.8637 
2025-12-18 12:12:39.978352: Pseudo dice [0.9203, 0.9515, 0.9338] 
2025-12-18 12:12:39.978352: Epoch time: 138.21 s 
2025-12-18 12:12:40.596178:  
2025-12-18 12:12:40.596178: Epoch 473 
2025-12-18 12:12:40.611933: Current learning rate: 0.00562 
2025-12-18 12:14:58.799303: train_loss -0.8482 
2025-12-18 12:14:58.799303: val_loss -0.8644 
2025-12-18 12:14:58.805049: Pseudo dice [0.9171, 0.9492, 0.947] 
2025-12-18 12:14:58.809052: Epoch time: 138.2 s 
2025-12-18 12:14:59.499346:  
2025-12-18 12:14:59.499346: Epoch 474 
2025-12-18 12:14:59.501350: Current learning rate: 0.00561 
2025-12-18 12:17:17.757367: train_loss -0.8474 
2025-12-18 12:17:17.757367: val_loss -0.8672 
2025-12-18 12:17:17.764473: Pseudo dice [0.922, 0.9541, 0.9374] 
2025-12-18 12:17:17.769014: Epoch time: 138.26 s 
2025-12-18 12:17:18.393505:  
2025-12-18 12:17:18.393505: Epoch 475 
2025-12-18 12:17:18.393505: Current learning rate: 0.0056 
2025-12-18 12:19:36.533004: train_loss -0.8449 
2025-12-18 12:19:36.533004: val_loss -0.869 
2025-12-18 12:19:36.548755: Pseudo dice [0.9237, 0.9582, 0.9402] 
2025-12-18 12:19:36.548755: Epoch time: 138.14 s 
2025-12-18 12:19:37.182140:  
2025-12-18 12:19:37.182140: Epoch 476 
2025-12-18 12:19:37.182140: Current learning rate: 0.00559 
2025-12-18 12:21:55.128664: train_loss -0.8479 
2025-12-18 12:21:55.128664: val_loss -0.8568 
2025-12-18 12:21:55.130666: Pseudo dice [0.918, 0.9517, 0.9233] 
2025-12-18 12:21:55.130666: Epoch time: 137.95 s 
2025-12-18 12:21:56.073988:  
2025-12-18 12:21:56.073988: Epoch 477 
2025-12-18 12:21:56.073988: Current learning rate: 0.00558 
2025-12-18 12:24:14.144975: train_loss -0.8506 
2025-12-18 12:24:14.144975: val_loss -0.8561 
2025-12-18 12:24:14.144975: Pseudo dice [0.9158, 0.9502, 0.9358] 
2025-12-18 12:24:14.144975: Epoch time: 138.07 s 
2025-12-18 12:24:14.788019:  
2025-12-18 12:24:14.788019: Epoch 478 
2025-12-18 12:24:14.788019: Current learning rate: 0.00557 
2025-12-18 12:26:33.001388: train_loss -0.8449 
2025-12-18 12:26:33.001388: val_loss -0.8653 
2025-12-18 12:26:33.001388: Pseudo dice [0.9286, 0.9537, 0.9269] 
2025-12-18 12:26:33.001388: Epoch time: 138.21 s 
2025-12-18 12:26:33.633402:  
2025-12-18 12:26:33.649306: Epoch 479 
2025-12-18 12:26:33.649306: Current learning rate: 0.00556 
2025-12-18 12:28:51.744061: train_loss -0.8494 
2025-12-18 12:28:51.744061: val_loss -0.8567 
2025-12-18 12:28:51.759710: Pseudo dice [0.9235, 0.9466, 0.9171] 
2025-12-18 12:28:51.759710: Epoch time: 138.11 s 
2025-12-18 12:28:52.473194:  
2025-12-18 12:28:52.473194: Epoch 480 
2025-12-18 12:28:52.473194: Current learning rate: 0.00555 
2025-12-18 12:31:10.806619: train_loss -0.8509 
2025-12-18 12:31:10.806619: val_loss -0.8638 
2025-12-18 12:31:10.810363: Pseudo dice [0.9229, 0.9516, 0.9391] 
2025-12-18 12:31:10.817991: Epoch time: 138.33 s 
2025-12-18 12:31:11.457309:  
2025-12-18 12:31:11.457309: Epoch 481 
2025-12-18 12:31:11.457309: Current learning rate: 0.00554 
2025-12-18 12:33:29.610444: train_loss -0.8449 
2025-12-18 12:33:29.610444: val_loss -0.8672 
2025-12-18 12:33:29.610444: Pseudo dice [0.9214, 0.9525, 0.94] 
2025-12-18 12:33:29.610444: Epoch time: 138.17 s 
2025-12-18 12:33:30.241639:  
2025-12-18 12:33:30.241639: Epoch 482 
2025-12-18 12:33:30.241639: Current learning rate: 0.00553 
2025-12-18 12:35:48.384059: train_loss -0.8477 
2025-12-18 12:35:48.384059: val_loss -0.8687 
2025-12-18 12:35:48.391844: Pseudo dice [0.9283, 0.9579, 0.9312] 
2025-12-18 12:35:48.391844: Epoch time: 138.14 s 
2025-12-18 12:35:49.143054:  
2025-12-18 12:35:49.143054: Epoch 483 
2025-12-18 12:35:49.143054: Current learning rate: 0.00552 
2025-12-18 12:38:07.461284: train_loss -0.8465 
2025-12-18 12:38:07.463024: val_loss -0.8719 
2025-12-18 12:38:07.466876: Pseudo dice [0.9263, 0.9575, 0.9395] 
2025-12-18 12:38:07.470880: Epoch time: 138.32 s 
2025-12-18 12:38:08.271016:  
2025-12-18 12:38:08.271016: Epoch 484 
2025-12-18 12:38:08.271016: Current learning rate: 0.00551 
2025-12-18 12:40:26.369801: train_loss -0.849 
2025-12-18 12:40:26.369801: val_loss -0.8683 
2025-12-18 12:40:26.374567: Pseudo dice [0.9251, 0.9512, 0.9352] 
2025-12-18 12:40:26.377571: Epoch time: 138.1 s 
2025-12-18 12:40:27.010922:  
2025-12-18 12:40:27.010922: Epoch 485 
2025-12-18 12:40:27.026876: Current learning rate: 0.0055 
2025-12-18 12:42:45.213652: train_loss -0.8462 
2025-12-18 12:42:45.213652: val_loss -0.8585 
2025-12-18 12:42:45.213652: Pseudo dice [0.919, 0.9506, 0.9307] 
2025-12-18 12:42:45.213652: Epoch time: 138.2 s 
2025-12-18 12:42:45.971911:  
2025-12-18 12:42:45.971911: Epoch 486 
2025-12-18 12:42:45.987784: Current learning rate: 0.00549 
2025-12-18 12:45:04.288637: train_loss -0.8473 
2025-12-18 12:45:04.288637: val_loss -0.87 
2025-12-18 12:45:04.294780: Pseudo dice [0.927, 0.9534, 0.9368] 
2025-12-18 12:45:04.296782: Epoch time: 138.32 s 
2025-12-18 12:45:04.926422:  
2025-12-18 12:45:04.926422: Epoch 487 
2025-12-18 12:45:04.926422: Current learning rate: 0.00548 
2025-12-18 12:47:23.113395: train_loss -0.8524 
2025-12-18 12:47:23.113395: val_loss -0.8658 
2025-12-18 12:47:23.117180: Pseudo dice [0.9278, 0.9528, 0.9265] 
2025-12-18 12:47:23.121184: Epoch time: 138.19 s 
2025-12-18 12:47:23.742224:  
2025-12-18 12:47:23.742224: Epoch 488 
2025-12-18 12:47:23.758248: Current learning rate: 0.00547 
2025-12-18 12:49:41.921139: train_loss -0.849 
2025-12-18 12:49:41.921139: val_loss -0.8668 
2025-12-18 12:49:41.921139: Pseudo dice [0.9246, 0.9542, 0.9365] 
2025-12-18 12:49:41.931485: Epoch time: 138.18 s 
2025-12-18 12:49:42.571343:  
2025-12-18 12:49:42.571343: Epoch 489 
2025-12-18 12:49:42.571343: Current learning rate: 0.00546 
2025-12-18 12:52:00.787195: train_loss -0.8516 
2025-12-18 12:52:00.789197: val_loss -0.8676 
2025-12-18 12:52:00.793201: Pseudo dice [0.9258, 0.9531, 0.9254] 
2025-12-18 12:52:00.796700: Epoch time: 138.22 s 
2025-12-18 12:52:01.585509:  
2025-12-18 12:52:01.585509: Epoch 490 
2025-12-18 12:52:01.585509: Current learning rate: 0.00546 
2025-12-18 12:54:19.858731: train_loss -0.851 
2025-12-18 12:54:19.858731: val_loss -0.8674 
2025-12-18 12:54:19.864829: Pseudo dice [0.9211, 0.9554, 0.9389] 
2025-12-18 12:54:19.868571: Epoch time: 138.27 s 
2025-12-18 12:54:20.509961:  
2025-12-18 12:54:20.509961: Epoch 491 
2025-12-18 12:54:20.509961: Current learning rate: 0.00545 
2025-12-18 12:56:38.610074: train_loss -0.8462 
2025-12-18 12:56:38.610074: val_loss -0.8673 
2025-12-18 12:56:38.610074: Pseudo dice [0.9249, 0.9546, 0.9355] 
2025-12-18 12:56:38.610074: Epoch time: 138.1 s 
2025-12-18 12:56:39.245599:  
2025-12-18 12:56:39.247601: Epoch 492 
2025-12-18 12:56:39.247601: Current learning rate: 0.00544 
2025-12-18 12:58:57.339191: train_loss -0.846 
2025-12-18 12:58:57.339191: val_loss -0.8726 
2025-12-18 12:58:57.344799: Pseudo dice [0.9291, 0.9552, 0.9407] 
2025-12-18 12:58:57.348803: Epoch time: 138.09 s 
2025-12-18 12:58:58.034593:  
2025-12-18 12:58:58.034593: Epoch 493 
2025-12-18 12:58:58.034593: Current learning rate: 0.00543 
2025-12-18 13:01:16.168197: train_loss -0.8483 
2025-12-18 13:01:16.168197: val_loss -0.8695 
2025-12-18 13:01:16.177702: Pseudo dice [0.9246, 0.955, 0.9386] 
2025-12-18 13:01:16.181706: Epoch time: 138.13 s 
2025-12-18 13:01:16.812365:  
2025-12-18 13:01:16.812365: Epoch 494 
2025-12-18 13:01:16.828229: Current learning rate: 0.00542 
2025-12-18 13:03:34.973056: train_loss -0.8502 
2025-12-18 13:03:34.975059: val_loss -0.8632 
2025-12-18 13:03:34.977625: Pseudo dice [0.9177, 0.9485, 0.9379] 
2025-12-18 13:03:34.981630: Epoch time: 138.16 s 
2025-12-18 13:03:35.620454:  
2025-12-18 13:03:35.620454: Epoch 495 
2025-12-18 13:03:35.620454: Current learning rate: 0.00541 
2025-12-18 13:05:53.790537: train_loss -0.8481 
2025-12-18 13:05:53.790537: val_loss -0.8771 
2025-12-18 13:05:53.794541: Pseudo dice [0.9304, 0.9573, 0.9341] 
2025-12-18 13:05:53.796543: Epoch time: 138.17 s 
2025-12-18 13:05:54.599492:  
2025-12-18 13:05:54.599492: Epoch 496 
2025-12-18 13:05:54.599492: Current learning rate: 0.0054 
2025-12-18 13:08:12.819928: train_loss -0.8449 
2025-12-18 13:08:12.819928: val_loss -0.8675 
2025-12-18 13:08:12.830725: Pseudo dice [0.9193, 0.9576, 0.9472] 
2025-12-18 13:08:12.834729: Epoch time: 138.22 s 
2025-12-18 13:08:13.464091:  
2025-12-18 13:08:13.464091: Epoch 497 
2025-12-18 13:08:13.464091: Current learning rate: 0.00539 
2025-12-18 13:10:32.109277: train_loss -0.85 
2025-12-18 13:10:32.109277: val_loss -0.8555 
2025-12-18 13:10:32.113282: Pseudo dice [0.9168, 0.9497, 0.9294] 
2025-12-18 13:10:32.115285: Epoch time: 138.65 s 
2025-12-18 13:10:32.800131:  
2025-12-18 13:10:32.800131: Epoch 498 
2025-12-18 13:10:32.800131: Current learning rate: 0.00538 
2025-12-18 13:12:51.132421: train_loss -0.8476 
2025-12-18 13:12:51.134423: val_loss -0.8741 
2025-12-18 13:12:51.141578: Pseudo dice [0.9286, 0.9559, 0.942] 
2025-12-18 13:12:51.147588: Epoch time: 138.33 s 
2025-12-18 13:12:51.804003:  
2025-12-18 13:12:51.804003: Epoch 499 
2025-12-18 13:12:51.819917: Current learning rate: 0.00537 
2025-12-18 13:15:10.007685: train_loss -0.8523 
2025-12-18 13:15:10.007685: val_loss -0.8706 
2025-12-18 13:15:10.023394: Pseudo dice [0.9263, 0.9556, 0.9325] 
2025-12-18 13:15:10.028986: Epoch time: 138.2 s 
2025-12-18 13:15:10.911959:  
2025-12-18 13:15:10.911959: Epoch 500 
2025-12-18 13:15:10.911959: Current learning rate: 0.00536 
2025-12-18 13:17:29.049465: train_loss -0.8525 
2025-12-18 13:17:29.049465: val_loss -0.8734 
2025-12-18 13:17:29.049465: Pseudo dice [0.9286, 0.9557, 0.9325] 
2025-12-18 13:17:29.065250: Epoch time: 138.15 s 
2025-12-18 13:17:29.683789:  
2025-12-18 13:17:29.683789: Epoch 501 
2025-12-18 13:17:29.683789: Current learning rate: 0.00535 
2025-12-18 13:19:47.867064: train_loss -0.8532 
2025-12-18 13:19:47.867064: val_loss -0.8704 
2025-12-18 13:19:47.872813: Pseudo dice [0.9255, 0.955, 0.9373] 
2025-12-18 13:19:47.874816: Epoch time: 138.18 s 
2025-12-18 13:19:47.878822: Yayy! New best EMA pseudo Dice: 0.9381 
2025-12-18 13:19:49.103336:  
2025-12-18 13:19:49.103336: Epoch 502 
2025-12-18 13:19:49.108587: Current learning rate: 0.00534 
2025-12-18 13:22:07.393409: train_loss -0.8514 
2025-12-18 13:22:07.395150: val_loss -0.8661 
2025-12-18 13:22:07.399154: Pseudo dice [0.9213, 0.9525, 0.9405] 
2025-12-18 13:22:07.403158: Epoch time: 138.29 s 
2025-12-18 13:22:08.060032:  
2025-12-18 13:22:08.060032: Epoch 503 
2025-12-18 13:22:08.060032: Current learning rate: 0.00533 
2025-12-18 13:24:26.204594: train_loss -0.8516 
2025-12-18 13:24:26.204594: val_loss -0.8658 
2025-12-18 13:24:26.209810: Pseudo dice [0.9202, 0.9514, 0.9406] 
2025-12-18 13:24:26.213814: Epoch time: 138.14 s 
2025-12-18 13:24:26.854803:  
2025-12-18 13:24:26.856543: Epoch 504 
2025-12-18 13:24:26.856543: Current learning rate: 0.00532 
2025-12-18 13:26:45.159741: train_loss -0.8443 
2025-12-18 13:26:45.159741: val_loss -0.8642 
2025-12-18 13:26:45.163751: Pseudo dice [0.9241, 0.9568, 0.9367] 
2025-12-18 13:26:45.167762: Epoch time: 138.3 s 
2025-12-18 13:26:45.171770: Yayy! New best EMA pseudo Dice: 0.9382 
2025-12-18 13:26:46.209778:  
2025-12-18 13:26:46.209778: Epoch 505 
2025-12-18 13:26:46.214870: Current learning rate: 0.00531 
2025-12-18 13:29:04.527879: train_loss -0.8258 
2025-12-18 13:29:04.527879: val_loss -0.8415 
2025-12-18 13:29:04.543537: Pseudo dice [0.9123, 0.945, 0.9142] 
2025-12-18 13:29:04.543537: Epoch time: 138.32 s 
2025-12-18 13:29:05.181072:  
2025-12-18 13:29:05.181072: Epoch 506 
2025-12-18 13:29:05.185454: Current learning rate: 0.0053 
2025-12-18 13:31:23.417490: train_loss -0.8285 
2025-12-18 13:31:23.421012: val_loss -0.863 
2025-12-18 13:31:23.425016: Pseudo dice [0.9234, 0.9543, 0.9364] 
2025-12-18 13:31:23.429020: Epoch time: 138.24 s 
2025-12-18 13:31:24.067226:  
2025-12-18 13:31:24.067226: Epoch 507 
2025-12-18 13:31:24.067226: Current learning rate: 0.00529 
2025-12-18 13:33:42.190571: train_loss -0.8329 
2025-12-18 13:33:42.192573: val_loss -0.8464 
2025-12-18 13:33:42.192573: Pseudo dice [0.914, 0.9455, 0.9291] 
2025-12-18 13:33:42.199195: Epoch time: 138.13 s 
2025-12-18 13:33:43.020185:  
2025-12-18 13:33:43.020185: Epoch 508 
2025-12-18 13:33:43.020185: Current learning rate: 0.00528 
2025-12-18 13:36:01.180406: train_loss -0.8401 
2025-12-18 13:36:01.180406: val_loss -0.8633 
2025-12-18 13:36:01.186191: Pseudo dice [0.9249, 0.9531, 0.9311] 
2025-12-18 13:36:01.190194: Epoch time: 138.16 s 
2025-12-18 13:36:01.814685:  
2025-12-18 13:36:01.814685: Epoch 509 
2025-12-18 13:36:01.830492: Current learning rate: 0.00527 
2025-12-18 13:38:19.929430: train_loss -0.85 
2025-12-18 13:38:19.929430: val_loss -0.8623 
2025-12-18 13:38:19.945282: Pseudo dice [0.92, 0.9548, 0.9339] 
2025-12-18 13:38:19.945282: Epoch time: 138.11 s 
2025-12-18 13:38:20.579248:  
2025-12-18 13:38:20.579248: Epoch 510 
2025-12-18 13:38:20.579248: Current learning rate: 0.00526 
2025-12-18 13:40:38.915920: train_loss -0.8361 
2025-12-18 13:40:38.915920: val_loss -0.8565 
2025-12-18 13:40:38.931718: Pseudo dice [0.9186, 0.9481, 0.9283] 
2025-12-18 13:40:38.935724: Epoch time: 138.34 s 
2025-12-18 13:40:39.566089:  
2025-12-18 13:40:39.566089: Epoch 511 
2025-12-18 13:40:39.579645: Current learning rate: 0.00525 
2025-12-18 13:42:57.833025: train_loss -0.8369 
2025-12-18 13:42:57.833025: val_loss -0.867 
2025-12-18 13:42:57.850519: Pseudo dice [0.9268, 0.9539, 0.9375] 
2025-12-18 13:42:57.854524: Epoch time: 138.27 s 
2025-12-18 13:42:58.491547:  
2025-12-18 13:42:58.491547: Epoch 512 
2025-12-18 13:42:58.497220: Current learning rate: 0.00524 
2025-12-18 13:45:16.843328: train_loss -0.8398 
2025-12-18 13:45:16.843328: val_loss -0.8679 
2025-12-18 13:45:16.843328: Pseudo dice [0.9221, 0.9575, 0.9376] 
2025-12-18 13:45:16.843328: Epoch time: 138.35 s 
2025-12-18 13:45:17.491565:  
2025-12-18 13:45:17.491565: Epoch 513 
2025-12-18 13:45:17.491565: Current learning rate: 0.00523 
2025-12-18 13:47:35.650197: train_loss -0.8415 
2025-12-18 13:47:35.650197: val_loss -0.865 
2025-12-18 13:47:35.654201: Pseudo dice [0.9237, 0.953, 0.9368] 
2025-12-18 13:47:35.659542: Epoch time: 138.16 s 
2025-12-18 13:47:36.297035:  
2025-12-18 13:47:36.297035: Epoch 514 
2025-12-18 13:47:36.299945: Current learning rate: 0.00522 
2025-12-18 13:49:54.445931: train_loss -0.8436 
2025-12-18 13:49:54.445931: val_loss -0.8717 
2025-12-18 13:49:54.451431: Pseudo dice [0.9313, 0.9603, 0.9328] 
2025-12-18 13:49:54.455435: Epoch time: 138.15 s 
2025-12-18 13:49:55.264134:  
2025-12-18 13:49:55.264134: Epoch 515 
2025-12-18 13:49:55.264134: Current learning rate: 0.00521 
2025-12-18 13:52:13.400393: train_loss -0.846 
2025-12-18 13:52:13.400393: val_loss -0.8757 
2025-12-18 13:52:13.404397: Pseudo dice [0.9298, 0.9579, 0.9437] 
2025-12-18 13:52:13.408401: Epoch time: 138.14 s 
2025-12-18 13:52:14.031824:  
2025-12-18 13:52:14.031824: Epoch 516 
2025-12-18 13:52:14.047890: Current learning rate: 0.0052 
2025-12-18 13:54:32.090332: train_loss -0.8504 
2025-12-18 13:54:32.090332: val_loss -0.8693 
2025-12-18 13:54:32.094337: Pseudo dice [0.9238, 0.9564, 0.9362] 
2025-12-18 13:54:32.098078: Epoch time: 138.06 s 
2025-12-18 13:54:32.743400:  
2025-12-18 13:54:32.743400: Epoch 517 
2025-12-18 13:54:32.743400: Current learning rate: 0.00519 
2025-12-18 13:56:50.897816: train_loss -0.846 
2025-12-18 13:56:50.897816: val_loss -0.8676 
2025-12-18 13:56:50.897816: Pseudo dice [0.9228, 0.956, 0.9371] 
2025-12-18 13:56:50.897816: Epoch time: 138.16 s 
2025-12-18 13:56:51.531254:  
2025-12-18 13:56:51.531254: Epoch 518 
2025-12-18 13:56:51.531254: Current learning rate: 0.00518 
2025-12-18 13:59:09.426850: train_loss -0.853 
2025-12-18 13:59:09.426850: val_loss -0.8729 
2025-12-18 13:59:09.426850: Pseudo dice [0.9276, 0.955, 0.938] 
2025-12-18 13:59:09.426850: Epoch time: 137.9 s 
2025-12-18 13:59:10.063828:  
2025-12-18 13:59:10.063828: Epoch 519 
2025-12-18 13:59:10.063828: Current learning rate: 0.00518 
2025-12-18 14:01:28.462538: train_loss -0.8446 
2025-12-18 14:01:28.462538: val_loss -0.872 
2025-12-18 14:01:28.462538: Pseudo dice [0.9261, 0.9552, 0.9442] 
2025-12-18 14:01:28.476547: Epoch time: 138.4 s 
2025-12-18 14:01:28.476547: Yayy! New best EMA pseudo Dice: 0.9385 
2025-12-18 14:01:29.381099:  
2025-12-18 14:01:29.381099: Epoch 520 
2025-12-18 14:01:29.381099: Current learning rate: 0.00517 
2025-12-18 14:03:47.724641: train_loss -0.8444 
2025-12-18 14:03:47.726384: val_loss -0.8698 
2025-12-18 14:03:47.728390: Pseudo dice [0.9263, 0.9581, 0.9403] 
2025-12-18 14:03:47.736358: Epoch time: 138.34 s 
2025-12-18 14:03:47.740364: Yayy! New best EMA pseudo Dice: 0.9388 
2025-12-18 14:03:48.976796:  
2025-12-18 14:03:48.976796: Epoch 521 
2025-12-18 14:03:48.976796: Current learning rate: 0.00516 
2025-12-18 14:06:07.329633: train_loss -0.8432 
2025-12-18 14:06:07.331636: val_loss -0.8597 
2025-12-18 14:06:07.335380: Pseudo dice [0.9184, 0.9482, 0.9415] 
2025-12-18 14:06:07.339122: Epoch time: 138.35 s 
2025-12-18 14:06:07.968460:  
2025-12-18 14:06:07.968460: Epoch 522 
2025-12-18 14:06:07.982478: Current learning rate: 0.00515 
2025-12-18 14:08:26.087900: train_loss -0.8502 
2025-12-18 14:08:26.087900: val_loss -0.8659 
2025-12-18 14:08:26.103620: Pseudo dice [0.9219, 0.9551, 0.9378] 
2025-12-18 14:08:26.103620: Epoch time: 138.12 s 
2025-12-18 14:08:26.734394:  
2025-12-18 14:08:26.734394: Epoch 523 
2025-12-18 14:08:26.734394: Current learning rate: 0.00514 
2025-12-18 14:10:45.381907: train_loss -0.8496 
2025-12-18 14:10:45.381907: val_loss -0.8693 
2025-12-18 14:10:45.381907: Pseudo dice [0.9298, 0.9562, 0.9314] 
2025-12-18 14:10:45.381907: Epoch time: 138.65 s 
2025-12-18 14:10:46.142076:  
2025-12-18 14:10:46.142076: Epoch 524 
2025-12-18 14:10:46.142076: Current learning rate: 0.00513 
2025-12-18 14:13:04.377200: train_loss -0.8392 
2025-12-18 14:13:04.377200: val_loss -0.865 
2025-12-18 14:13:04.382848: Pseudo dice [0.9216, 0.9534, 0.9321] 
2025-12-18 14:13:04.384850: Epoch time: 138.24 s 
2025-12-18 14:13:05.013309:  
2025-12-18 14:13:05.013309: Epoch 525 
2025-12-18 14:13:05.013309: Current learning rate: 0.00512 
2025-12-18 14:15:23.263728: train_loss -0.8533 
2025-12-18 14:15:23.263728: val_loss -0.8706 
2025-12-18 14:15:23.263728: Pseudo dice [0.9267, 0.9545, 0.9433] 
2025-12-18 14:15:23.263728: Epoch time: 138.25 s 
2025-12-18 14:15:23.910851:  
2025-12-18 14:15:23.910851: Epoch 526 
2025-12-18 14:15:23.910851: Current learning rate: 0.00511 
2025-12-18 14:17:42.058389: train_loss -0.8478 
2025-12-18 14:17:42.058389: val_loss -0.8732 
2025-12-18 14:17:42.063394: Pseudo dice [0.9275, 0.9585, 0.9425] 
2025-12-18 14:17:42.067398: Epoch time: 138.15 s 
2025-12-18 14:17:42.071402: Yayy! New best EMA pseudo Dice: 0.939 
2025-12-18 14:17:43.187655:  
2025-12-18 14:17:43.187655: Epoch 527 
2025-12-18 14:17:43.187655: Current learning rate: 0.0051 
2025-12-18 14:20:01.500448: train_loss -0.8516 
2025-12-18 14:20:01.500448: val_loss -0.8743 
2025-12-18 14:20:01.506481: Pseudo dice [0.9258, 0.9589, 0.9384] 
2025-12-18 14:20:01.508972: Epoch time: 138.31 s 
2025-12-18 14:20:01.508972: Yayy! New best EMA pseudo Dice: 0.9392 
2025-12-18 14:20:02.421916:  
2025-12-18 14:20:02.421916: Epoch 528 
2025-12-18 14:20:02.424615: Current learning rate: 0.00509 
2025-12-18 14:22:20.614163: train_loss -0.8526 
2025-12-18 14:22:20.614163: val_loss -0.8739 
2025-12-18 14:22:20.619543: Pseudo dice [0.9265, 0.9576, 0.9493] 
2025-12-18 14:22:20.623547: Epoch time: 138.19 s 
2025-12-18 14:22:20.625549: Yayy! New best EMA pseudo Dice: 0.9397 
2025-12-18 14:22:21.536318:  
2025-12-18 14:22:21.536318: Epoch 529 
2025-12-18 14:22:21.538059: Current learning rate: 0.00508 
2025-12-18 14:24:39.640200: train_loss -0.8542 
2025-12-18 14:24:39.640200: val_loss -0.868 
2025-12-18 14:24:39.647951: Pseudo dice [0.9218, 0.9531, 0.9446] 
2025-12-18 14:24:39.653957: Epoch time: 138.11 s 
2025-12-18 14:24:39.657700: Yayy! New best EMA pseudo Dice: 0.9397 
2025-12-18 14:24:40.600073:  
2025-12-18 14:24:40.600073: Epoch 530 
2025-12-18 14:24:40.606395: Current learning rate: 0.00507 
2025-12-18 14:26:58.867301: train_loss -0.8502 
2025-12-18 14:26:58.867301: val_loss -0.8693 
2025-12-18 14:26:58.867301: Pseudo dice [0.9241, 0.9538, 0.9351] 
2025-12-18 14:26:58.867301: Epoch time: 138.27 s 
2025-12-18 14:26:59.516491:  
2025-12-18 14:26:59.516491: Epoch 531 
2025-12-18 14:26:59.516491: Current learning rate: 0.00506 
2025-12-18 14:29:17.599818: train_loss -0.8505 
2025-12-18 14:29:17.599818: val_loss -0.867 
2025-12-18 14:29:17.605824: Pseudo dice [0.9234, 0.9555, 0.9335] 
2025-12-18 14:29:17.609630: Epoch time: 138.09 s 
2025-12-18 14:29:18.398371:  
2025-12-18 14:29:18.398371: Epoch 532 
2025-12-18 14:29:18.414258: Current learning rate: 0.00505 
2025-12-18 14:31:36.467502: train_loss -0.8554 
2025-12-18 14:31:36.467502: val_loss -0.8686 
2025-12-18 14:31:36.471507: Pseudo dice [0.9214, 0.9535, 0.9342] 
2025-12-18 14:31:36.475511: Epoch time: 138.07 s 
2025-12-18 14:31:37.147798:  
2025-12-18 14:31:37.147798: Epoch 533 
2025-12-18 14:31:37.153806: Current learning rate: 0.00504 
2025-12-18 14:33:55.340987: train_loss -0.85 
2025-12-18 14:33:55.340987: val_loss -0.8697 
2025-12-18 14:33:55.345988: Pseudo dice [0.926, 0.9547, 0.9418] 
2025-12-18 14:33:55.349992: Epoch time: 138.2 s 
2025-12-18 14:33:55.975237:  
2025-12-18 14:33:55.975237: Epoch 534 
2025-12-18 14:33:55.975237: Current learning rate: 0.00503 
2025-12-18 14:36:14.119441: train_loss -0.852 
2025-12-18 14:36:14.119441: val_loss -0.8728 
2025-12-18 14:36:14.125447: Pseudo dice [0.9253, 0.9548, 0.9398] 
2025-12-18 14:36:14.127187: Epoch time: 138.14 s 
2025-12-18 14:36:14.760217:  
2025-12-18 14:36:14.760217: Epoch 535 
2025-12-18 14:36:14.776296: Current learning rate: 0.00502 
2025-12-18 14:38:32.923566: train_loss -0.8525 
2025-12-18 14:38:32.923566: val_loss -0.8752 
2025-12-18 14:38:32.923566: Pseudo dice [0.9301, 0.9623, 0.9261] 
2025-12-18 14:38:32.923566: Epoch time: 138.16 s 
2025-12-18 14:38:33.586439:  
2025-12-18 14:38:33.586439: Epoch 536 
2025-12-18 14:38:33.586439: Current learning rate: 0.00501 
2025-12-18 14:40:51.964427: train_loss -0.8525 
2025-12-18 14:40:51.964427: val_loss -0.8726 
2025-12-18 14:40:51.964427: Pseudo dice [0.9272, 0.9544, 0.9352] 
2025-12-18 14:40:51.982119: Epoch time: 138.39 s 
2025-12-18 14:40:52.660733:  
2025-12-18 14:40:52.660733: Epoch 537 
2025-12-18 14:40:52.666740: Current learning rate: 0.005 
2025-12-18 14:43:10.958302: train_loss -0.8531 
2025-12-18 14:43:10.958302: val_loss -0.8683 
2025-12-18 14:43:10.964041: Pseudo dice [0.9258, 0.9556, 0.9339] 
2025-12-18 14:43:10.966588: Epoch time: 138.3 s 
2025-12-18 14:43:11.787082:  
2025-12-18 14:43:11.787082: Epoch 538 
2025-12-18 14:43:11.787082: Current learning rate: 0.00499 
2025-12-18 14:45:30.127215: train_loss -0.8506 
2025-12-18 14:45:30.129217: val_loss -0.8728 
2025-12-18 14:45:30.134962: Pseudo dice [0.9236, 0.9514, 0.9419] 
2025-12-18 14:45:30.138960: Epoch time: 138.34 s 
2025-12-18 14:45:30.798331:  
2025-12-18 14:45:30.798331: Epoch 539 
2025-12-18 14:45:30.813230: Current learning rate: 0.00498 
2025-12-18 14:47:49.043811: train_loss -0.8476 
2025-12-18 14:47:49.043811: val_loss -0.8636 
2025-12-18 14:47:49.043811: Pseudo dice [0.9252, 0.9526, 0.9238] 
2025-12-18 14:47:49.057525: Epoch time: 138.25 s 
2025-12-18 14:47:49.819394:  
2025-12-18 14:47:49.819394: Epoch 540 
2025-12-18 14:47:49.826931: Current learning rate: 0.00497 
2025-12-18 14:50:07.989081: train_loss -0.8575 
2025-12-18 14:50:07.989081: val_loss -0.8667 
2025-12-18 14:50:07.993367: Pseudo dice [0.9233, 0.9557, 0.9318] 
2025-12-18 14:50:07.998061: Epoch time: 138.17 s 
2025-12-18 14:50:08.673465:  
2025-12-18 14:50:08.673465: Epoch 541 
2025-12-18 14:50:08.679472: Current learning rate: 0.00496 
2025-12-18 14:52:26.855009: train_loss -0.8517 
2025-12-18 14:52:26.855009: val_loss -0.8772 
2025-12-18 14:52:26.863911: Pseudo dice [0.9311, 0.9543, 0.9366] 
2025-12-18 14:52:26.866827: Epoch time: 138.18 s 
2025-12-18 14:52:27.503072:  
2025-12-18 14:52:27.503072: Epoch 542 
2025-12-18 14:52:27.503072: Current learning rate: 0.00495 
2025-12-18 14:54:45.799654: train_loss -0.849 
2025-12-18 14:54:45.801656: val_loss -0.86 
2025-12-18 14:54:45.807663: Pseudo dice [0.9193, 0.95, 0.936] 
2025-12-18 14:54:45.811667: Epoch time: 138.3 s 
2025-12-18 14:54:46.637610:  
2025-12-18 14:54:46.638613: Epoch 543 
2025-12-18 14:54:46.638613: Current learning rate: 0.00494 
2025-12-18 14:57:04.901243: train_loss -0.8525 
2025-12-18 14:57:04.901243: val_loss -0.8691 
2025-12-18 14:57:04.903246: Pseudo dice [0.9266, 0.9588, 0.929] 
2025-12-18 14:57:04.903246: Epoch time: 138.28 s 
2025-12-18 14:57:05.752933:  
2025-12-18 14:57:05.752933: Epoch 544 
2025-12-18 14:57:05.761597: Current learning rate: 0.00493 
2025-12-18 14:59:23.772689: train_loss -0.8527 
2025-12-18 14:59:23.772689: val_loss -0.873 
2025-12-18 14:59:23.777026: Pseudo dice [0.926, 0.9532, 0.9393] 
2025-12-18 14:59:23.777026: Epoch time: 138.02 s 
2025-12-18 14:59:24.405889:  
2025-12-18 14:59:24.405889: Epoch 545 
2025-12-18 14:59:24.405889: Current learning rate: 0.00492 
2025-12-18 15:01:42.607708: train_loss -0.8526 
2025-12-18 15:01:42.607708: val_loss -0.875 
2025-12-18 15:01:42.613577: Pseudo dice [0.9307, 0.9549, 0.9333] 
2025-12-18 15:01:42.617283: Epoch time: 138.2 s 
2025-12-18 15:01:43.353938:  
2025-12-18 15:01:43.353938: Epoch 546 
2025-12-18 15:01:43.353938: Current learning rate: 0.00491 
2025-12-18 15:04:01.693153: train_loss -0.8487 
2025-12-18 15:04:01.693153: val_loss -0.8718 
2025-12-18 15:04:01.703167: Pseudo dice [0.9254, 0.9597, 0.9378] 
2025-12-18 15:04:01.708914: Epoch time: 138.34 s 
2025-12-18 15:04:02.353001:  
2025-12-18 15:04:02.353001: Epoch 547 
2025-12-18 15:04:02.353001: Current learning rate: 0.0049 
2025-12-18 15:06:20.527568: train_loss -0.8503 
2025-12-18 15:06:20.527568: val_loss -0.8691 
2025-12-18 15:06:20.527568: Pseudo dice [0.9256, 0.9568, 0.9377] 
2025-12-18 15:06:20.535102: Epoch time: 138.19 s 
2025-12-18 15:06:21.168416:  
2025-12-18 15:06:21.168416: Epoch 548 
2025-12-18 15:06:21.181495: Current learning rate: 0.00489 
2025-12-18 15:08:39.414988: train_loss -0.8519 
2025-12-18 15:08:39.414988: val_loss -0.8698 
2025-12-18 15:08:39.424865: Pseudo dice [0.9268, 0.9573, 0.9259] 
2025-12-18 15:08:39.424865: Epoch time: 138.25 s 
2025-12-18 15:08:40.074930:  
2025-12-18 15:08:40.074930: Epoch 549 
2025-12-18 15:08:40.074930: Current learning rate: 0.00488 
2025-12-18 15:10:58.500413: train_loss -0.8526 
2025-12-18 15:10:58.500413: val_loss -0.8631 
2025-12-18 15:10:58.500413: Pseudo dice [0.9197, 0.9521, 0.938] 
2025-12-18 15:10:58.516202: Epoch time: 138.43 s 
2025-12-18 15:10:59.578264:  
2025-12-18 15:10:59.578264: Epoch 550 
2025-12-18 15:10:59.592236: Current learning rate: 0.00487 
2025-12-18 15:13:17.880475: train_loss -0.852 
2025-12-18 15:13:17.880475: val_loss -0.8703 
2025-12-18 15:13:17.880475: Pseudo dice [0.928, 0.9559, 0.9263] 
2025-12-18 15:13:17.896307: Epoch time: 138.3 s 
2025-12-18 15:13:18.529600:  
2025-12-18 15:13:18.529600: Epoch 551 
2025-12-18 15:13:18.529600: Current learning rate: 0.00486 
2025-12-18 15:15:36.644338: train_loss -0.8507 
2025-12-18 15:15:36.646341: val_loss -0.8653 
2025-12-18 15:15:36.650344: Pseudo dice [0.9264, 0.9531, 0.9254] 
2025-12-18 15:15:36.654349: Epoch time: 138.11 s 
2025-12-18 15:15:37.288036:  
2025-12-18 15:15:37.288036: Epoch 552 
2025-12-18 15:15:37.288036: Current learning rate: 0.00485 
2025-12-18 15:17:55.421947: train_loss -0.8499 
2025-12-18 15:17:55.423949: val_loss -0.8727 
2025-12-18 15:17:55.427691: Pseudo dice [0.9269, 0.9586, 0.9309] 
2025-12-18 15:17:55.432932: Epoch time: 138.13 s 
2025-12-18 15:17:56.061899:  
2025-12-18 15:17:56.061899: Epoch 553 
2025-12-18 15:17:56.077992: Current learning rate: 0.00484 
2025-12-18 15:20:14.181849: train_loss -0.8575 
2025-12-18 15:20:14.181849: val_loss -0.8765 
2025-12-18 15:20:14.187593: Pseudo dice [0.931, 0.9584, 0.9408] 
2025-12-18 15:20:14.193606: Epoch time: 138.12 s 
2025-12-18 15:20:14.826824:  
2025-12-18 15:20:14.826824: Epoch 554 
2025-12-18 15:20:14.826824: Current learning rate: 0.00484 
2025-12-18 15:22:33.078112: train_loss -0.8512 
2025-12-18 15:22:33.080115: val_loss -0.8647 
2025-12-18 15:22:33.086120: Pseudo dice [0.92, 0.9521, 0.9426] 
2025-12-18 15:22:33.089601: Epoch time: 138.25 s 
2025-12-18 15:22:33.785987:  
2025-12-18 15:22:33.785987: Epoch 555 
2025-12-18 15:22:33.785987: Current learning rate: 0.00483 
2025-12-18 15:24:51.896732: train_loss -0.8508 
2025-12-18 15:24:51.896732: val_loss -0.8709 
2025-12-18 15:24:51.912844: Pseudo dice [0.9234, 0.9532, 0.943] 
2025-12-18 15:24:51.912844: Epoch time: 138.11 s 
2025-12-18 15:24:52.548045:  
2025-12-18 15:24:52.548045: Epoch 556 
2025-12-18 15:24:52.548045: Current learning rate: 0.00482 
2025-12-18 15:27:10.649963: train_loss -0.8537 
2025-12-18 15:27:10.651967: val_loss -0.8795 
2025-12-18 15:27:10.657712: Pseudo dice [0.9326, 0.9595, 0.9392] 
2025-12-18 15:27:10.661717: Epoch time: 138.1 s 
2025-12-18 15:27:11.475682:  
2025-12-18 15:27:11.475682: Epoch 557 
2025-12-18 15:27:11.475682: Current learning rate: 0.00481 
2025-12-18 15:29:29.639265: train_loss -0.8545 
2025-12-18 15:29:29.639265: val_loss -0.8786 
2025-12-18 15:29:29.655029: Pseudo dice [0.9338, 0.9589, 0.9376] 
2025-12-18 15:29:29.658154: Epoch time: 138.18 s 
2025-12-18 15:29:30.272498:  
2025-12-18 15:29:30.272498: Epoch 558 
2025-12-18 15:29:30.290245: Current learning rate: 0.0048 
2025-12-18 15:31:48.448303: train_loss -0.8582 
2025-12-18 15:31:48.448303: val_loss -0.871 
2025-12-18 15:31:48.463979: Pseudo dice [0.9249, 0.9523, 0.9405] 
2025-12-18 15:31:48.463979: Epoch time: 138.18 s 
2025-12-18 15:31:49.210170:  
2025-12-18 15:31:49.210170: Epoch 559 
2025-12-18 15:31:49.229824: Current learning rate: 0.00479 
2025-12-18 15:34:07.459706: train_loss -0.8502 
2025-12-18 15:34:07.459706: val_loss -0.8849 
2025-12-18 15:34:07.471808: Pseudo dice [0.9358, 0.959, 0.9405] 
2025-12-18 15:34:07.475640: Epoch time: 138.25 s 
2025-12-18 15:34:07.481122: Yayy! New best EMA pseudo Dice: 0.9401 
2025-12-18 15:34:08.362849:  
2025-12-18 15:34:08.362849: Epoch 560 
2025-12-18 15:34:08.367888: Current learning rate: 0.00478 
2025-12-18 15:36:26.433963: train_loss -0.8534 
2025-12-18 15:36:26.433963: val_loss -0.872 
2025-12-18 15:36:26.433963: Pseudo dice [0.9278, 0.9586, 0.933] 
2025-12-18 15:36:26.445263: Epoch time: 138.09 s 
2025-12-18 15:36:27.069426:  
2025-12-18 15:36:27.069426: Epoch 561 
2025-12-18 15:36:27.080712: Current learning rate: 0.00477 
2025-12-18 15:38:45.289845: train_loss -0.852 
2025-12-18 15:38:45.291847: val_loss -0.8776 
2025-12-18 15:38:45.297857: Pseudo dice [0.9279, 0.9584, 0.9394] 
2025-12-18 15:38:45.303864: Epoch time: 138.22 s 
2025-12-18 15:38:45.307610: Yayy! New best EMA pseudo Dice: 0.9403 
2025-12-18 15:38:46.413704:  
2025-12-18 15:38:46.413704: Epoch 562 
2025-12-18 15:38:46.423188: Current learning rate: 0.00476 
2025-12-18 15:41:04.511634: train_loss -0.8495 
2025-12-18 15:41:04.511634: val_loss -0.8744 
2025-12-18 15:41:04.527485: Pseudo dice [0.9281, 0.958, 0.9359] 
2025-12-18 15:41:04.527485: Epoch time: 138.1 s 
2025-12-18 15:41:04.527485: Yayy! New best EMA pseudo Dice: 0.9403 
2025-12-18 15:41:05.638316:  
2025-12-18 15:41:05.638316: Epoch 563 
2025-12-18 15:41:05.638316: Current learning rate: 0.00475 
2025-12-18 15:43:24.008212: train_loss -0.8433 
2025-12-18 15:43:24.008212: val_loss -0.8597 
2025-12-18 15:43:24.008212: Pseudo dice [0.9205, 0.9474, 0.9361] 
2025-12-18 15:43:24.021045: Epoch time: 138.37 s 
2025-12-18 15:43:24.642272:  
2025-12-18 15:43:24.642272: Epoch 564 
2025-12-18 15:43:24.642272: Current learning rate: 0.00474 
2025-12-18 15:45:42.819368: train_loss -0.8492 
2025-12-18 15:45:42.821370: val_loss -0.8595 
2025-12-18 15:45:42.827115: Pseudo dice [0.9163, 0.9517, 0.9338] 
2025-12-18 15:45:42.833125: Epoch time: 138.18 s 
2025-12-18 15:45:43.585644:  
2025-12-18 15:45:43.585644: Epoch 565 
2025-12-18 15:45:43.585644: Current learning rate: 0.00473 
2025-12-18 15:48:01.842137: train_loss -0.8487 
2025-12-18 15:48:01.842137: val_loss -0.8614 
2025-12-18 15:48:01.851400: Pseudo dice [0.9149, 0.9522, 0.9497] 
2025-12-18 15:48:01.854003: Epoch time: 138.27 s 
2025-12-18 15:48:02.477058:  
2025-12-18 15:48:02.477058: Epoch 566 
2025-12-18 15:48:02.477058: Current learning rate: 0.00472 
2025-12-18 15:50:20.579287: train_loss -0.8524 
2025-12-18 15:50:20.579287: val_loss -0.8745 
2025-12-18 15:50:20.579287: Pseudo dice [0.927, 0.9588, 0.9392] 
2025-12-18 15:50:20.595210: Epoch time: 138.1 s 
2025-12-18 15:50:21.213186:  
2025-12-18 15:50:21.213186: Epoch 567 
2025-12-18 15:50:21.213186: Current learning rate: 0.00471 
2025-12-18 15:52:39.355666: train_loss -0.8525 
2025-12-18 15:52:39.355666: val_loss -0.8645 
2025-12-18 15:52:39.361515: Pseudo dice [0.9201, 0.9514, 0.9259] 
2025-12-18 15:52:39.365519: Epoch time: 138.14 s 
2025-12-18 15:52:40.020193:  
2025-12-18 15:52:40.020193: Epoch 568 
2025-12-18 15:52:40.020193: Current learning rate: 0.0047 
2025-12-18 15:54:58.098520: train_loss -0.8477 
2025-12-18 15:54:58.100523: val_loss -0.8741 
2025-12-18 15:54:58.106527: Pseudo dice [0.9265, 0.9578, 0.9431] 
2025-12-18 15:54:58.110271: Epoch time: 138.08 s 
2025-12-18 15:54:58.898498:  
2025-12-18 15:54:58.898498: Epoch 569 
2025-12-18 15:54:58.898498: Current learning rate: 0.00469 
2025-12-18 15:57:16.996345: train_loss -0.8489 
2025-12-18 15:57:16.996345: val_loss -0.876 
2025-12-18 15:57:16.996345: Pseudo dice [0.9268, 0.9574, 0.9417] 
2025-12-18 15:57:16.996345: Epoch time: 138.1 s 
2025-12-18 15:57:17.645946:  
2025-12-18 15:57:17.645946: Epoch 570 
2025-12-18 15:57:17.645946: Current learning rate: 0.00468 
2025-12-18 15:59:35.683884: train_loss -0.8524 
2025-12-18 15:59:35.683884: val_loss -0.8747 
2025-12-18 15:59:35.690356: Pseudo dice [0.9264, 0.9557, 0.9401] 
2025-12-18 15:59:35.690356: Epoch time: 138.04 s 
2025-12-18 15:59:36.317224:  
2025-12-18 15:59:36.317224: Epoch 571 
2025-12-18 15:59:36.317224: Current learning rate: 0.00467 
2025-12-18 16:01:54.157398: train_loss -0.8499 
2025-12-18 16:01:54.157398: val_loss -0.8732 
2025-12-18 16:01:54.163941: Pseudo dice [0.9248, 0.9553, 0.9431] 
2025-12-18 16:01:54.165944: Epoch time: 137.84 s 
2025-12-18 16:01:54.812905:  
2025-12-18 16:01:54.812905: Epoch 572 
2025-12-18 16:01:54.814740: Current learning rate: 0.00466 
2025-12-18 16:04:13.026212: train_loss -0.8522 
2025-12-18 16:04:13.042257: val_loss -0.8771 
2025-12-18 16:04:13.046263: Pseudo dice [0.9258, 0.9608, 0.9398] 
2025-12-18 16:04:13.046263: Epoch time: 138.23 s 
2025-12-18 16:04:13.690636:  
2025-12-18 16:04:13.690636: Epoch 573 
2025-12-18 16:04:13.690636: Current learning rate: 0.00465 
2025-12-18 16:06:31.865442: train_loss -0.8535 
2025-12-18 16:06:31.865442: val_loss -0.8785 
2025-12-18 16:06:31.865442: Pseudo dice [0.9297, 0.9582, 0.9424] 
2025-12-18 16:06:31.865442: Epoch time: 138.17 s 
2025-12-18 16:06:32.513530:  
2025-12-18 16:06:32.513530: Epoch 574 
2025-12-18 16:06:32.513530: Current learning rate: 0.00464 
2025-12-18 16:08:50.761085: train_loss -0.8505 
2025-12-18 16:08:50.761085: val_loss -0.8694 
2025-12-18 16:08:50.776826: Pseudo dice [0.9274, 0.9566, 0.9361] 
2025-12-18 16:08:50.776826: Epoch time: 138.25 s 
2025-12-18 16:08:51.587600:  
2025-12-18 16:08:51.587600: Epoch 575 
2025-12-18 16:08:51.587600: Current learning rate: 0.00463 
2025-12-18 16:11:10.014717: train_loss -0.8486 
2025-12-18 16:11:10.015719: val_loss -0.8732 
2025-12-18 16:11:10.022081: Pseudo dice [0.9308, 0.9563, 0.9319] 
2025-12-18 16:11:10.024084: Epoch time: 138.43 s 
2025-12-18 16:11:10.665179:  
2025-12-18 16:11:10.665179: Epoch 576 
2025-12-18 16:11:10.680902: Current learning rate: 0.00462 
2025-12-18 16:13:28.811864: train_loss -0.85 
2025-12-18 16:13:28.811864: val_loss -0.8753 
2025-12-18 16:13:28.811864: Pseudo dice [0.9284, 0.9562, 0.9379] 
2025-12-18 16:13:28.811864: Epoch time: 138.15 s 
2025-12-18 16:13:29.460743:  
2025-12-18 16:13:29.460743: Epoch 577 
2025-12-18 16:13:29.460743: Current learning rate: 0.00461 
2025-12-18 16:15:47.634049: train_loss -0.8594 
2025-12-18 16:15:47.634049: val_loss -0.8806 
2025-12-18 16:15:47.639795: Pseudo dice [0.9308, 0.9577, 0.9415] 
2025-12-18 16:15:47.643799: Epoch time: 138.17 s 
2025-12-18 16:15:47.649805: Yayy! New best EMA pseudo Dice: 0.9406 
2025-12-18 16:15:48.537421:  
2025-12-18 16:15:48.537421: Epoch 578 
2025-12-18 16:15:48.537421: Current learning rate: 0.0046 
2025-12-18 16:18:06.750077: train_loss -0.8564 
2025-12-18 16:18:06.752080: val_loss -0.8709 
2025-12-18 16:18:06.756426: Pseudo dice [0.9287, 0.9562, 0.9284] 
2025-12-18 16:18:06.756426: Epoch time: 138.21 s 
2025-12-18 16:18:07.385510:  
2025-12-18 16:18:07.385510: Epoch 579 
2025-12-18 16:18:07.401151: Current learning rate: 0.00459 
2025-12-18 16:20:25.528809: train_loss -0.8515 
2025-12-18 16:20:25.528809: val_loss -0.8739 
2025-12-18 16:20:25.534554: Pseudo dice [0.9304, 0.9574, 0.9352] 
2025-12-18 16:20:25.540564: Epoch time: 138.14 s 
2025-12-18 16:20:26.183773:  
2025-12-18 16:20:26.183773: Epoch 580 
2025-12-18 16:20:26.183773: Current learning rate: 0.00458 
2025-12-18 16:22:44.388247: train_loss -0.8492 
2025-12-18 16:22:44.388247: val_loss -0.8715 
2025-12-18 16:22:44.394253: Pseudo dice [0.9237, 0.957, 0.9374] 
2025-12-18 16:22:44.394253: Epoch time: 138.2 s 
2025-12-18 16:22:45.297508:  
2025-12-18 16:22:45.297508: Epoch 581 
2025-12-18 16:22:45.299510: Current learning rate: 0.00457 
2025-12-18 16:25:04.772915: train_loss -0.8561 
2025-12-18 16:25:04.772915: val_loss -0.8693 
2025-12-18 16:25:04.779443: Pseudo dice [0.9202, 0.956, 0.9419] 
2025-12-18 16:25:04.783447: Epoch time: 139.48 s 
2025-12-18 16:25:05.434590:  
2025-12-18 16:25:05.434590: Epoch 582 
2025-12-18 16:25:05.436592: Current learning rate: 0.00456 
2025-12-18 16:27:24.124233: train_loss -0.8553 
2025-12-18 16:27:24.124233: val_loss -0.8673 
2025-12-18 16:27:24.127975: Pseudo dice [0.9239, 0.9522, 0.9336] 
2025-12-18 16:27:24.132423: Epoch time: 138.69 s 
2025-12-18 16:27:24.838799:  
2025-12-18 16:27:24.838799: Epoch 583 
2025-12-18 16:27:24.838799: Current learning rate: 0.00455 
2025-12-18 16:29:43.441510: train_loss -0.8495 
2025-12-18 16:29:43.441510: val_loss -0.8753 
2025-12-18 16:29:43.457572: Pseudo dice [0.9287, 0.956, 0.9406] 
2025-12-18 16:29:43.457572: Epoch time: 138.6 s 
2025-12-18 16:29:44.146452:  
2025-12-18 16:29:44.146452: Epoch 584 
2025-12-18 16:29:44.146452: Current learning rate: 0.00454 
2025-12-18 16:32:02.561142: train_loss -0.8516 
2025-12-18 16:32:02.563145: val_loss -0.8671 
2025-12-18 16:32:02.568152: Pseudo dice [0.9237, 0.9532, 0.934] 
2025-12-18 16:32:02.574095: Epoch time: 138.41 s 
2025-12-18 16:32:03.218064:  
2025-12-18 16:32:03.218064: Epoch 585 
2025-12-18 16:32:03.220066: Current learning rate: 0.00453 
2025-12-18 16:34:22.006697: train_loss -0.8558 
2025-12-18 16:34:22.006697: val_loss -0.872 
2025-12-18 16:34:22.012291: Pseudo dice [0.9279, 0.9559, 0.9359] 
2025-12-18 16:34:22.018297: Epoch time: 138.79 s 
2025-12-18 16:34:22.673552:  
2025-12-18 16:34:22.675554: Epoch 586 
2025-12-18 16:34:22.678272: Current learning rate: 0.00452 
2025-12-18 16:36:40.838150: train_loss -0.8522 
2025-12-18 16:36:40.840152: val_loss -0.867 
2025-12-18 16:36:40.844156: Pseudo dice [0.9224, 0.956, 0.9339] 
2025-12-18 16:36:40.848160: Epoch time: 138.16 s 
2025-12-18 16:36:41.524133:  
2025-12-18 16:36:41.526136: Epoch 587 
2025-12-18 16:36:41.528140: Current learning rate: 0.00451 
2025-12-18 16:38:59.654215: train_loss -0.8538 
2025-12-18 16:38:59.656217: val_loss -0.8752 
2025-12-18 16:38:59.659960: Pseudo dice [0.9284, 0.957, 0.9344] 
2025-12-18 16:38:59.664934: Epoch time: 138.13 s 
2025-12-18 16:39:00.308227:  
2025-12-18 16:39:00.308227: Epoch 588 
2025-12-18 16:39:00.308227: Current learning rate: 0.0045 
2025-12-18 16:41:18.583876: train_loss -0.851 
2025-12-18 16:41:18.583876: val_loss -0.875 
2025-12-18 16:41:18.591861: Pseudo dice [0.9286, 0.9556, 0.9326] 
2025-12-18 16:41:18.595865: Epoch time: 138.28 s 
2025-12-18 16:41:19.295109:  
2025-12-18 16:41:19.295109: Epoch 589 
2025-12-18 16:41:19.299054: Current learning rate: 0.00449 
2025-12-18 16:43:37.575994: train_loss -0.8468 
2025-12-18 16:43:37.577996: val_loss -0.8696 
2025-12-18 16:43:37.585748: Pseudo dice [0.9254, 0.9562, 0.9339] 
2025-12-18 16:43:37.591761: Epoch time: 138.28 s 
2025-12-18 16:43:38.232454:  
2025-12-18 16:43:38.232454: Epoch 590 
2025-12-18 16:43:38.232454: Current learning rate: 0.00448 
2025-12-18 16:45:56.607162: train_loss -0.851 
2025-12-18 16:45:56.607162: val_loss -0.8704 
2025-12-18 16:45:56.613168: Pseudo dice [0.924, 0.9569, 0.9393] 
2025-12-18 16:45:56.617172: Epoch time: 138.37 s 
2025-12-18 16:45:57.312593:  
2025-12-18 16:45:57.312593: Epoch 591 
2025-12-18 16:45:57.312593: Current learning rate: 0.00447 
2025-12-18 16:48:15.516424: train_loss -0.8531 
2025-12-18 16:48:15.518426: val_loss -0.8713 
2025-12-18 16:48:15.522429: Pseudo dice [0.9243, 0.9552, 0.9393] 
2025-12-18 16:48:15.528090: Epoch time: 138.2 s 
2025-12-18 16:48:16.330054:  
2025-12-18 16:48:16.330054: Epoch 592 
2025-12-18 16:48:16.330054: Current learning rate: 0.00446 
2025-12-18 16:50:34.576110: train_loss -0.8379 
2025-12-18 16:50:34.576110: val_loss -0.8518 
2025-12-18 16:50:34.582118: Pseudo dice [0.919, 0.9471, 0.9212] 
2025-12-18 16:50:34.584120: Epoch time: 138.25 s 
2025-12-18 16:50:35.223254:  
2025-12-18 16:50:35.223254: Epoch 593 
2025-12-18 16:50:35.239221: Current learning rate: 0.00445 
2025-12-18 16:52:53.391540: train_loss -0.833 
2025-12-18 16:52:53.391540: val_loss -0.859 
2025-12-18 16:52:53.407254: Pseudo dice [0.9213, 0.9528, 0.9313] 
2025-12-18 16:52:53.407254: Epoch time: 138.17 s 
2025-12-18 16:52:54.163949:  
2025-12-18 16:52:54.163949: Epoch 594 
2025-12-18 16:52:54.179737: Current learning rate: 0.00444 
2025-12-18 16:55:12.265541: train_loss -0.8446 
2025-12-18 16:55:12.265541: val_loss -0.8726 
2025-12-18 16:55:12.271547: Pseudo dice [0.9271, 0.9567, 0.9351] 
2025-12-18 16:55:12.275551: Epoch time: 138.1 s 
2025-12-18 16:55:12.918669:  
2025-12-18 16:55:12.918669: Epoch 595 
2025-12-18 16:55:12.918669: Current learning rate: 0.00443 
2025-12-18 16:57:31.132443: train_loss -0.8484 
2025-12-18 16:57:31.132443: val_loss -0.8726 
2025-12-18 16:57:31.132443: Pseudo dice [0.9273, 0.9568, 0.9362] 
2025-12-18 16:57:31.132443: Epoch time: 138.22 s 
2025-12-18 16:57:31.780775:  
2025-12-18 16:57:31.780775: Epoch 596 
2025-12-18 16:57:31.782778: Current learning rate: 0.00442 
2025-12-18 16:59:49.877289: train_loss -0.8454 
2025-12-18 16:59:49.877289: val_loss -0.8768 
2025-12-18 16:59:49.887307: Pseudo dice [0.9309, 0.9549, 0.9416] 
2025-12-18 16:59:49.892829: Epoch time: 138.1 s 
2025-12-18 16:59:50.649357:  
2025-12-18 16:59:50.649357: Epoch 597 
2025-12-18 16:59:50.651360: Current learning rate: 0.00441 
2025-12-18 17:02:08.633016: train_loss -0.8533 
2025-12-18 17:02:08.633016: val_loss -0.871 
2025-12-18 17:02:08.637020: Pseudo dice [0.9228, 0.9543, 0.9408] 
2025-12-18 17:02:08.642026: Epoch time: 137.98 s 
2025-12-18 17:02:09.296490:  
2025-12-18 17:02:09.296490: Epoch 598 
2025-12-18 17:02:09.296490: Current learning rate: 0.0044 
2025-12-18 17:04:27.404639: train_loss -0.8458 
2025-12-18 17:04:27.404639: val_loss -0.8724 
2025-12-18 17:04:27.410645: Pseudo dice [0.9278, 0.9562, 0.9367] 
2025-12-18 17:04:27.412647: Epoch time: 138.11 s 
2025-12-18 17:04:28.239500:  
2025-12-18 17:04:28.239500: Epoch 599 
2025-12-18 17:04:28.239500: Current learning rate: 0.00439 
2025-12-18 17:06:46.397934: train_loss -0.852 
2025-12-18 17:06:46.397934: val_loss -0.8718 
2025-12-18 17:06:46.405437: Pseudo dice [0.9266, 0.9574, 0.9381] 
2025-12-18 17:06:46.411443: Epoch time: 138.16 s 
2025-12-18 17:06:47.544082:  
2025-12-18 17:06:47.546084: Epoch 600 
2025-12-18 17:06:47.548088: Current learning rate: 0.00438 
2025-12-18 17:09:05.812137: train_loss -0.8524 
2025-12-18 17:09:05.812137: val_loss -0.8754 
2025-12-18 17:09:05.820011: Pseudo dice [0.9265, 0.9594, 0.9424] 
2025-12-18 17:09:05.824540: Epoch time: 138.27 s 
2025-12-18 17:09:06.465018:  
2025-12-18 17:09:06.465018: Epoch 601 
2025-12-18 17:09:06.465018: Current learning rate: 0.00437 
2025-12-18 17:11:24.763754: train_loss -0.8538 
2025-12-18 17:11:24.763754: val_loss -0.8666 
2025-12-18 17:11:24.767759: Pseudo dice [0.9222, 0.9531, 0.9348] 
2025-12-18 17:11:24.771763: Epoch time: 138.3 s 
2025-12-18 17:11:25.414090:  
2025-12-18 17:11:25.414090: Epoch 602 
2025-12-18 17:11:25.431491: Current learning rate: 0.00436 
2025-12-18 17:13:43.582624: train_loss -0.851 
2025-12-18 17:13:43.582624: val_loss -0.8733 
2025-12-18 17:13:43.582624: Pseudo dice [0.9292, 0.9565, 0.9376] 
2025-12-18 17:13:43.582624: Epoch time: 138.17 s 
2025-12-18 17:13:44.371322:  
2025-12-18 17:13:44.371322: Epoch 603 
2025-12-18 17:13:44.382579: Current learning rate: 0.00435 
2025-12-18 17:16:02.562633: train_loss -0.8567 
2025-12-18 17:16:02.564635: val_loss -0.8742 
2025-12-18 17:16:02.570382: Pseudo dice [0.9276, 0.9551, 0.9402] 
2025-12-18 17:16:02.574386: Epoch time: 138.19 s 
2025-12-18 17:16:03.230568:  
2025-12-18 17:16:03.230568: Epoch 604 
2025-12-18 17:16:03.230568: Current learning rate: 0.00434 
2025-12-18 17:18:21.325037: train_loss -0.8519 
2025-12-18 17:18:21.325037: val_loss -0.8759 
2025-12-18 17:18:21.330908: Pseudo dice [0.9266, 0.957, 0.9442] 
2025-12-18 17:18:21.334912: Epoch time: 138.09 s 
2025-12-18 17:18:22.131526:  
2025-12-18 17:18:22.147400: Epoch 605 
2025-12-18 17:18:22.150924: Current learning rate: 0.00433 
2025-12-18 17:20:40.390665: train_loss -0.8534 
2025-12-18 17:20:40.390665: val_loss -0.8748 
2025-12-18 17:20:40.396409: Pseudo dice [0.9299, 0.96, 0.9347] 
2025-12-18 17:20:40.400268: Epoch time: 138.26 s 
2025-12-18 17:20:41.046563:  
2025-12-18 17:20:41.048314: Epoch 606 
2025-12-18 17:20:41.048314: Current learning rate: 0.00432 
2025-12-18 17:22:59.120938: train_loss -0.8529 
2025-12-18 17:22:59.120938: val_loss -0.874 
2025-12-18 17:22:59.120938: Pseudo dice [0.9249, 0.9566, 0.9452] 
2025-12-18 17:22:59.132158: Epoch time: 138.09 s 
2025-12-18 17:22:59.831733:  
2025-12-18 17:22:59.831733: Epoch 607 
2025-12-18 17:22:59.844785: Current learning rate: 0.00431 
2025-12-18 17:25:18.016279: train_loss -0.8511 
2025-12-18 17:25:18.016279: val_loss -0.871 
2025-12-18 17:25:18.024670: Pseudo dice [0.9264, 0.9572, 0.9359] 
2025-12-18 17:25:18.027422: Epoch time: 138.18 s 
2025-12-18 17:25:18.666588:  
2025-12-18 17:25:18.666588: Epoch 608 
2025-12-18 17:25:18.672085: Current learning rate: 0.0043 
2025-12-18 17:27:36.874508: train_loss -0.8533 
2025-12-18 17:27:36.878599: val_loss -0.8613 
2025-12-18 17:27:36.885231: Pseudo dice [0.9193, 0.9491, 0.9395] 
2025-12-18 17:27:36.891878: Epoch time: 138.21 s 
2025-12-18 17:27:37.543125:  
2025-12-18 17:27:37.543125: Epoch 609 
2025-12-18 17:27:37.558901: Current learning rate: 0.00429 
2025-12-18 17:29:55.870289: train_loss -0.8521 
2025-12-18 17:29:55.872292: val_loss -0.8617 
2025-12-18 17:29:55.878298: Pseudo dice [0.9177, 0.953, 0.9404] 
2025-12-18 17:29:55.882301: Epoch time: 138.33 s 
2025-12-18 17:29:56.518828:  
2025-12-18 17:29:56.518828: Epoch 610 
2025-12-18 17:29:56.536947: Current learning rate: 0.00429 
2025-12-18 17:32:14.685175: train_loss -0.8581 
2025-12-18 17:32:14.685175: val_loss -0.8647 
2025-12-18 17:32:14.691181: Pseudo dice [0.9215, 0.9527, 0.9355] 
2025-12-18 17:32:14.693183: Epoch time: 138.17 s 
2025-12-18 17:32:15.513634:  
2025-12-18 17:32:15.513634: Epoch 611 
2025-12-18 17:32:15.519201: Current learning rate: 0.00428 
2025-12-18 17:34:33.686017: train_loss -0.851 
2025-12-18 17:34:33.686017: val_loss -0.872 
2025-12-18 17:34:33.700098: Pseudo dice [0.926, 0.9599, 0.9349] 
2025-12-18 17:34:33.704102: Epoch time: 138.19 s 
2025-12-18 17:34:34.333177:  
2025-12-18 17:34:34.333177: Epoch 612 
2025-12-18 17:34:34.349169: Current learning rate: 0.00427 
2025-12-18 17:36:52.503854: train_loss -0.8536 
2025-12-18 17:36:52.503854: val_loss -0.8603 
2025-12-18 17:36:52.509861: Pseudo dice [0.9193, 0.9517, 0.9333] 
2025-12-18 17:36:52.513603: Epoch time: 138.17 s 
2025-12-18 17:36:53.153042:  
2025-12-18 17:36:53.153042: Epoch 613 
2025-12-18 17:36:53.153042: Current learning rate: 0.00426 
2025-12-18 17:39:11.669734: train_loss -0.8526 
2025-12-18 17:39:11.669734: val_loss -0.8736 
2025-12-18 17:39:11.673738: Pseudo dice [0.928, 0.958, 0.9368] 
2025-12-18 17:39:11.675478: Epoch time: 138.52 s 
2025-12-18 17:39:12.310164:  
2025-12-18 17:39:12.310164: Epoch 614 
2025-12-18 17:39:12.328496: Current learning rate: 0.00425 
2025-12-18 17:41:30.339568: train_loss -0.8528 
2025-12-18 17:41:30.339568: val_loss -0.8722 
2025-12-18 17:41:30.355376: Pseudo dice [0.9258, 0.9545, 0.9359] 
2025-12-18 17:41:30.361430: Epoch time: 138.03 s 
2025-12-18 17:41:31.005854:  
2025-12-18 17:41:31.005854: Epoch 615 
2025-12-18 17:41:31.010733: Current learning rate: 0.00424 
2025-12-18 17:43:49.291045: train_loss -0.8582 
2025-12-18 17:43:49.291045: val_loss -0.8689 
2025-12-18 17:43:49.297051: Pseudo dice [0.9243, 0.9562, 0.9377] 
2025-12-18 17:43:49.301055: Epoch time: 138.3 s 
2025-12-18 17:43:50.187105:  
2025-12-18 17:43:50.187105: Epoch 616 
2025-12-18 17:43:50.202566: Current learning rate: 0.00423 
2025-12-18 17:46:08.414448: train_loss -0.8583 
2025-12-18 17:46:08.416450: val_loss -0.8611 
2025-12-18 17:46:08.420192: Pseudo dice [0.9154, 0.9548, 0.9381] 
2025-12-18 17:46:08.424196: Epoch time: 138.23 s 
2025-12-18 17:46:09.063746:  
2025-12-18 17:46:09.063746: Epoch 617 
2025-12-18 17:46:09.077017: Current learning rate: 0.00422 
2025-12-18 17:48:27.201771: train_loss -0.8499 
2025-12-18 17:48:27.203773: val_loss -0.8705 
2025-12-18 17:48:27.209326: Pseudo dice [0.927, 0.9557, 0.9338] 
2025-12-18 17:48:27.213068: Epoch time: 138.14 s 
2025-12-18 17:48:27.847880:  
2025-12-18 17:48:27.847880: Epoch 618 
2025-12-18 17:48:27.861284: Current learning rate: 0.00421 
2025-12-18 17:50:46.023331: train_loss -0.8524 
2025-12-18 17:50:46.023331: val_loss -0.8623 
2025-12-18 17:50:46.027076: Pseudo dice [0.9228, 0.9519, 0.9349] 
2025-12-18 17:50:46.033984: Epoch time: 138.18 s 
2025-12-18 17:50:46.803753:  
2025-12-18 17:50:46.803753: Epoch 619 
2025-12-18 17:50:46.803753: Current learning rate: 0.0042 
2025-12-18 17:53:04.896729: train_loss -0.8516 
2025-12-18 17:53:04.896729: val_loss -0.8621 
2025-12-18 17:53:04.896729: Pseudo dice [0.9198, 0.9519, 0.9344] 
2025-12-18 17:53:04.910469: Epoch time: 138.09 s 
2025-12-18 17:53:05.558741:  
2025-12-18 17:53:05.558741: Epoch 620 
2025-12-18 17:53:05.558741: Current learning rate: 0.00419 
2025-12-18 17:55:23.737576: train_loss -0.8476 
2025-12-18 17:55:23.737576: val_loss -0.8787 
2025-12-18 17:55:23.745906: Pseudo dice [0.9282, 0.9597, 0.9417] 
2025-12-18 17:55:23.750283: Epoch time: 138.18 s 
2025-12-18 17:55:24.403185:  
2025-12-18 17:55:24.403185: Epoch 621 
2025-12-18 17:55:24.410939: Current learning rate: 0.00418 
2025-12-18 17:57:42.506253: train_loss -0.849 
2025-12-18 17:57:42.506253: val_loss -0.8686 
2025-12-18 17:57:42.512000: Pseudo dice [0.9225, 0.9544, 0.9449] 
2025-12-18 17:57:42.514003: Epoch time: 138.1 s 
2025-12-18 17:57:43.254436:  
2025-12-18 17:57:43.254436: Epoch 622 
2025-12-18 17:57:43.262636: Current learning rate: 0.00417 
2025-12-18 18:00:01.542533: train_loss -0.848 
2025-12-18 18:00:01.542533: val_loss -0.8686 
2025-12-18 18:00:01.552717: Pseudo dice [0.9248, 0.9557, 0.933] 
2025-12-18 18:00:01.558465: Epoch time: 138.29 s 
2025-12-18 18:00:02.384310:  
2025-12-18 18:00:02.384310: Epoch 623 
2025-12-18 18:00:02.397081: Current learning rate: 0.00416 
2025-12-18 18:02:20.491012: train_loss -0.854 
2025-12-18 18:02:20.491012: val_loss -0.8651 
2025-12-18 18:02:20.495016: Pseudo dice [0.9188, 0.9551, 0.9375] 
2025-12-18 18:02:20.498758: Epoch time: 138.1 s 
2025-12-18 18:02:21.212769:  
2025-12-18 18:02:21.212769: Epoch 624 
2025-12-18 18:02:21.222344: Current learning rate: 0.00415 
2025-12-18 18:04:39.300934: train_loss -0.8541 
2025-12-18 18:04:39.300934: val_loss -0.8669 
2025-12-18 18:04:39.304940: Pseudo dice [0.92, 0.9541, 0.9396] 
2025-12-18 18:04:39.310699: Epoch time: 138.09 s 
2025-12-18 18:04:40.116988:  
2025-12-18 18:04:40.116988: Epoch 625 
2025-12-18 18:04:40.133110: Current learning rate: 0.00414 
2025-12-18 18:06:58.035605: train_loss -0.8524 
2025-12-18 18:06:58.035605: val_loss -0.8741 
2025-12-18 18:06:58.040611: Pseudo dice [0.9264, 0.9583, 0.9377] 
2025-12-18 18:06:58.040611: Epoch time: 137.92 s 
2025-12-18 18:06:58.689901:  
2025-12-18 18:06:58.689901: Epoch 626 
2025-12-18 18:06:58.689901: Current learning rate: 0.00413 
2025-12-18 18:09:16.939043: train_loss -0.8516 
2025-12-18 18:09:16.939043: val_loss -0.8774 
2025-12-18 18:09:16.939043: Pseudo dice [0.9284, 0.9596, 0.9403] 
2025-12-18 18:09:16.954770: Epoch time: 138.25 s 
2025-12-18 18:09:17.654222:  
2025-12-18 18:09:17.654222: Epoch 627 
2025-12-18 18:09:17.654222: Current learning rate: 0.00412 
2025-12-18 18:11:36.036380: train_loss -0.8504 
2025-12-18 18:11:36.036380: val_loss -0.8773 
2025-12-18 18:11:36.042386: Pseudo dice [0.9294, 0.9574, 0.9413] 
2025-12-18 18:11:36.048130: Epoch time: 138.38 s 
2025-12-18 18:11:36.761787:  
2025-12-18 18:11:36.761787: Epoch 628 
2025-12-18 18:11:36.775806: Current learning rate: 0.00411 
2025-12-18 18:13:54.989088: train_loss -0.8546 
2025-12-18 18:13:54.989088: val_loss -0.8721 
2025-12-18 18:13:54.993092: Pseudo dice [0.9252, 0.9599, 0.9356] 
2025-12-18 18:13:54.999099: Epoch time: 138.23 s 
2025-12-18 18:13:55.810070:  
2025-12-18 18:13:55.810070: Epoch 629 
2025-12-18 18:13:55.810070: Current learning rate: 0.0041 
2025-12-18 18:16:13.809989: train_loss -0.8531 
2025-12-18 18:16:13.809989: val_loss -0.8729 
2025-12-18 18:16:13.809989: Pseudo dice [0.9268, 0.9544, 0.9415] 
2025-12-18 18:16:13.820776: Epoch time: 138.0 s 
2025-12-18 18:16:14.472240:  
2025-12-18 18:16:14.472240: Epoch 630 
2025-12-18 18:16:14.472240: Current learning rate: 0.00409 
2025-12-18 18:18:32.645051: train_loss -0.8529 
2025-12-18 18:18:32.645051: val_loss -0.8607 
2025-12-18 18:18:32.645051: Pseudo dice [0.9183, 0.9481, 0.9324] 
2025-12-18 18:18:32.645051: Epoch time: 138.17 s 
2025-12-18 18:18:33.341950:  
2025-12-18 18:18:33.341950: Epoch 631 
2025-12-18 18:18:33.357922: Current learning rate: 0.00408 
2025-12-18 18:20:51.488249: train_loss -0.8532 
2025-12-18 18:20:51.488249: val_loss -0.8785 
2025-12-18 18:20:51.494254: Pseudo dice [0.9301, 0.9581, 0.9387] 
2025-12-18 18:20:51.498259: Epoch time: 138.15 s 
2025-12-18 18:20:52.148860:  
2025-12-18 18:20:52.148860: Epoch 632 
2025-12-18 18:20:52.148860: Current learning rate: 0.00407 
2025-12-18 18:23:10.290495: train_loss -0.8474 
2025-12-18 18:23:10.290495: val_loss -0.8844 
2025-12-18 18:23:10.298886: Pseudo dice [0.9345, 0.9587, 0.9436] 
2025-12-18 18:23:10.304391: Epoch time: 138.14 s 
2025-12-18 18:23:10.955534:  
2025-12-18 18:23:10.955534: Epoch 633 
2025-12-18 18:23:10.955534: Current learning rate: 0.00406 
2025-12-18 18:25:29.246035: train_loss -0.857 
2025-12-18 18:25:29.246035: val_loss -0.8791 
2025-12-18 18:25:29.246035: Pseudo dice [0.9308, 0.9537, 0.9429] 
2025-12-18 18:25:29.246035: Epoch time: 138.29 s 
2025-12-18 18:25:29.947612:  
2025-12-18 18:25:29.947612: Epoch 634 
2025-12-18 18:25:29.947612: Current learning rate: 0.00405 
2025-12-18 18:27:48.008488: train_loss -0.8543 
2025-12-18 18:27:48.008488: val_loss -0.865 
2025-12-18 18:27:48.008488: Pseudo dice [0.9198, 0.954, 0.9416] 
2025-12-18 18:27:48.024584: Epoch time: 138.06 s 
2025-12-18 18:27:48.847683:  
2025-12-18 18:27:48.847683: Epoch 635 
2025-12-18 18:27:48.847683: Current learning rate: 0.00404 
2025-12-18 18:30:06.958189: train_loss -0.8529 
2025-12-18 18:30:06.960191: val_loss -0.8748 
2025-12-18 18:30:06.965935: Pseudo dice [0.9278, 0.9543, 0.9417] 
2025-12-18 18:30:06.965935: Epoch time: 138.11 s 
2025-12-18 18:30:07.613219:  
2025-12-18 18:30:07.613219: Epoch 636 
2025-12-18 18:30:07.613219: Current learning rate: 0.00403 
2025-12-18 18:32:25.696613: train_loss -0.8559 
2025-12-18 18:32:25.696613: val_loss -0.8791 
2025-12-18 18:32:25.712358: Pseudo dice [0.9289, 0.9614, 0.9389] 
2025-12-18 18:32:25.712358: Epoch time: 138.08 s 
2025-12-18 18:32:26.347086:  
2025-12-18 18:32:26.347086: Epoch 637 
2025-12-18 18:32:26.362973: Current learning rate: 0.00402 
2025-12-18 18:34:44.768497: train_loss -0.8514 
2025-12-18 18:34:44.768497: val_loss -0.8698 
2025-12-18 18:34:44.784295: Pseudo dice [0.9258, 0.9501, 0.935] 
2025-12-18 18:34:44.784295: Epoch time: 138.42 s 
2025-12-18 18:34:45.418053:  
2025-12-18 18:34:45.418053: Epoch 638 
2025-12-18 18:34:45.433880: Current learning rate: 0.00401 
2025-12-18 18:37:03.591024: train_loss -0.8541 
2025-12-18 18:37:03.591024: val_loss -0.8689 
2025-12-18 18:37:03.596769: Pseudo dice [0.9232, 0.9535, 0.9414] 
2025-12-18 18:37:03.596769: Epoch time: 138.17 s 
2025-12-18 18:37:04.245264:  
2025-12-18 18:37:04.245264: Epoch 639 
2025-12-18 18:37:04.245264: Current learning rate: 0.004 
2025-12-18 18:39:22.723128: train_loss -0.8554 
2025-12-18 18:39:22.723128: val_loss -0.8792 
2025-12-18 18:39:22.738865: Pseudo dice [0.9298, 0.9597, 0.9421] 
2025-12-18 18:39:22.738865: Epoch time: 138.48 s 
2025-12-18 18:39:23.371921:  
2025-12-18 18:39:23.387834: Epoch 640 
2025-12-18 18:39:23.387834: Current learning rate: 0.00399 
2025-12-18 18:41:41.494277: train_loss -0.8554 
2025-12-18 18:41:41.494277: val_loss -0.8803 
2025-12-18 18:41:41.494277: Pseudo dice [0.9317, 0.9595, 0.9388] 
2025-12-18 18:41:41.494277: Epoch time: 138.12 s 
2025-12-18 18:41:41.509986: Yayy! New best EMA pseudo Dice: 0.9407 
2025-12-18 18:41:42.686694:  
2025-12-18 18:41:42.686694: Epoch 641 
2025-12-18 18:41:42.686694: Current learning rate: 0.00398 
2025-12-18 18:44:00.885975: train_loss -0.8531 
2025-12-18 18:44:00.885975: val_loss -0.8703 
2025-12-18 18:44:00.885975: Pseudo dice [0.9226, 0.9586, 0.9384] 
2025-12-18 18:44:00.885975: Epoch time: 138.2 s 
2025-12-18 18:44:01.536132:  
2025-12-18 18:44:01.536132: Epoch 642 
2025-12-18 18:44:01.536132: Current learning rate: 0.00397 
2025-12-18 18:46:19.733314: train_loss -0.8511 
2025-12-18 18:46:19.733314: val_loss -0.8677 
2025-12-18 18:46:19.751188: Pseudo dice [0.9231, 0.9528, 0.9367] 
2025-12-18 18:46:19.751188: Epoch time: 138.2 s 
2025-12-18 18:46:20.401207:  
2025-12-18 18:46:20.401207: Epoch 643 
2025-12-18 18:46:20.415401: Current learning rate: 0.00396 
2025-12-18 18:48:38.582888: train_loss -0.8544 
2025-12-18 18:48:38.582888: val_loss -0.8778 
2025-12-18 18:48:38.582888: Pseudo dice [0.9228, 0.9608, 0.9431] 
2025-12-18 18:48:38.598597: Epoch time: 138.18 s 
2025-12-18 18:48:39.326511:  
2025-12-18 18:48:39.326511: Epoch 644 
2025-12-18 18:48:39.342591: Current learning rate: 0.00395 
2025-12-18 18:50:57.547943: train_loss -0.8532 
2025-12-18 18:50:57.547943: val_loss -0.8703 
2025-12-18 18:50:57.567298: Pseudo dice [0.9302, 0.9541, 0.9237] 
2025-12-18 18:50:57.571046: Epoch time: 138.22 s 
2025-12-18 18:50:58.212490:  
2025-12-18 18:50:58.212490: Epoch 645 
2025-12-18 18:50:58.228129: Current learning rate: 0.00394 
2025-12-18 18:53:16.302014: train_loss -0.8543 
2025-12-18 18:53:16.304016: val_loss -0.8839 
2025-12-18 18:53:16.310022: Pseudo dice [0.9334, 0.9627, 0.9449] 
2025-12-18 18:53:16.314026: Epoch time: 138.09 s 
2025-12-18 18:53:16.317768: Yayy! New best EMA pseudo Dice: 0.9408 
2025-12-18 18:53:17.212902:  
2025-12-18 18:53:17.212902: Epoch 646 
2025-12-18 18:53:17.212902: Current learning rate: 0.00393 
2025-12-18 18:55:35.428557: train_loss -0.8584 
2025-12-18 18:55:35.428557: val_loss -0.8761 
2025-12-18 18:55:35.444234: Pseudo dice [0.9306, 0.9581, 0.935] 
2025-12-18 18:55:35.444234: Epoch time: 138.22 s 
2025-12-18 18:55:35.444234: Yayy! New best EMA pseudo Dice: 0.9408 
2025-12-18 18:55:36.712811:  
2025-12-18 18:55:36.712811: Epoch 647 
2025-12-18 18:55:36.712811: Current learning rate: 0.00392 
2025-12-18 18:57:54.636544: train_loss -0.8545 
2025-12-18 18:57:54.636544: val_loss -0.876 
2025-12-18 18:57:54.636544: Pseudo dice [0.9275, 0.9564, 0.9433] 
2025-12-18 18:57:54.636544: Epoch time: 137.92 s 
2025-12-18 18:57:54.636544: Yayy! New best EMA pseudo Dice: 0.941 
2025-12-18 18:57:55.570553:  
2025-12-18 18:57:55.570553: Epoch 648 
2025-12-18 18:57:55.586334: Current learning rate: 0.00391 
2025-12-18 19:00:13.857848: train_loss -0.8539 
2025-12-18 19:00:13.857848: val_loss -0.8738 
2025-12-18 19:00:13.863855: Pseudo dice [0.9289, 0.9538, 0.9376] 
2025-12-18 19:00:13.867859: Epoch time: 138.29 s 
2025-12-18 19:00:14.547349:  
2025-12-18 19:00:14.547349: Epoch 649 
2025-12-18 19:00:14.547349: Current learning rate: 0.0039 
2025-12-18 19:02:32.774066: train_loss -0.8375 
2025-12-18 19:02:32.774066: val_loss -0.8527 
2025-12-18 19:02:32.780074: Pseudo dice [0.9142, 0.9448, 0.9378] 
2025-12-18 19:02:32.784078: Epoch time: 138.23 s 
2025-12-18 19:02:33.694475:  
2025-12-18 19:02:33.696477: Epoch 650 
2025-12-18 19:02:33.696477: Current learning rate: 0.00389 
2025-12-18 19:04:51.832348: train_loss -0.8267 
2025-12-18 19:04:51.832348: val_loss -0.8494 
2025-12-18 19:04:51.838356: Pseudo dice [0.9134, 0.9504, 0.9304] 
2025-12-18 19:04:51.842360: Epoch time: 138.14 s 
2025-12-18 19:04:52.489987:  
2025-12-18 19:04:52.489987: Epoch 651 
2025-12-18 19:04:52.489987: Current learning rate: 0.00388 
2025-12-18 19:07:10.726903: train_loss -0.8265 
2025-12-18 19:07:10.728905: val_loss -0.8667 
2025-12-18 19:07:10.728905: Pseudo dice [0.9255, 0.9551, 0.934] 
2025-12-18 19:07:10.728905: Epoch time: 138.24 s 
2025-12-18 19:07:11.390021:  
2025-12-18 19:07:11.390021: Epoch 652 
2025-12-18 19:07:11.390021: Current learning rate: 0.00387 
2025-12-18 19:09:29.656803: train_loss -0.8418 
2025-12-18 19:09:29.656803: val_loss -0.8642 
2025-12-18 19:09:29.656803: Pseudo dice [0.9218, 0.9528, 0.9331] 
2025-12-18 19:09:29.656803: Epoch time: 138.27 s 
2025-12-18 19:09:30.482903:  
2025-12-18 19:09:30.482903: Epoch 653 
2025-12-18 19:09:30.482903: Current learning rate: 0.00386 
2025-12-18 19:11:48.665665: train_loss -0.8434 
2025-12-18 19:11:48.665665: val_loss -0.8667 
2025-12-18 19:11:48.676593: Pseudo dice [0.9276, 0.9576, 0.9259] 
2025-12-18 19:11:48.681599: Epoch time: 138.18 s 
2025-12-18 19:11:49.332737:  
2025-12-18 19:11:49.332737: Epoch 654 
2025-12-18 19:11:49.332737: Current learning rate: 0.00385 
2025-12-18 19:14:07.474459: train_loss -0.8443 
2025-12-18 19:14:07.474459: val_loss -0.8596 
2025-12-18 19:14:07.480200: Pseudo dice [0.918, 0.9509, 0.9274] 
2025-12-18 19:14:07.486014: Epoch time: 138.16 s 
2025-12-18 19:14:08.134647:  
2025-12-18 19:14:08.134647: Epoch 655 
2025-12-18 19:14:08.134647: Current learning rate: 0.00384 
2025-12-18 19:16:26.421760: train_loss -0.8472 
2025-12-18 19:16:26.421760: val_loss -0.8687 
2025-12-18 19:16:26.432743: Pseudo dice [0.9283, 0.9553, 0.9265] 
2025-12-18 19:16:26.437749: Epoch time: 138.3 s 
2025-12-18 19:16:27.149826:  
2025-12-18 19:16:27.149826: Epoch 656 
2025-12-18 19:16:27.149826: Current learning rate: 0.00383 
2025-12-18 19:18:45.219823: train_loss -0.853 
2025-12-18 19:18:45.219823: val_loss -0.8647 
2025-12-18 19:18:45.219823: Pseudo dice [0.9195, 0.9499, 0.9439] 
2025-12-18 19:18:45.219823: Epoch time: 138.07 s 
2025-12-18 19:18:45.870794:  
2025-12-18 19:18:45.870794: Epoch 657 
2025-12-18 19:18:45.870794: Current learning rate: 0.00382 
2025-12-18 19:21:03.983236: train_loss -0.8542 
2025-12-18 19:21:03.985238: val_loss -0.8689 
2025-12-18 19:21:03.991307: Pseudo dice [0.9245, 0.9545, 0.9424] 
2025-12-18 19:21:03.995311: Epoch time: 138.11 s 
2025-12-18 19:21:04.808241:  
2025-12-18 19:21:04.808241: Epoch 658 
2025-12-18 19:21:04.808241: Current learning rate: 0.00381 
2025-12-18 19:23:22.981585: train_loss -0.8515 
2025-12-18 19:23:22.983587: val_loss -0.8676 
2025-12-18 19:23:22.988921: Pseudo dice [0.9246, 0.955, 0.933] 
2025-12-18 19:23:22.992925: Epoch time: 138.18 s 
2025-12-18 19:23:23.644855:  
2025-12-18 19:23:23.644855: Epoch 659 
2025-12-18 19:23:23.644855: Current learning rate: 0.0038 
2025-12-18 19:25:41.954200: train_loss -0.8522 
2025-12-18 19:25:41.956202: val_loss -0.8757 
2025-12-18 19:25:41.962208: Pseudo dice [0.9268, 0.9545, 0.9466] 
2025-12-18 19:25:41.966212: Epoch time: 138.31 s 
2025-12-18 19:25:42.669757:  
2025-12-18 19:25:42.670760: Epoch 660 
2025-12-18 19:25:42.670760: Current learning rate: 0.00379 
2025-12-18 19:28:00.935483: train_loss -0.8533 
2025-12-18 19:28:00.937223: val_loss -0.872 
2025-12-18 19:28:00.937223: Pseudo dice [0.9278, 0.953, 0.9382] 
2025-12-18 19:28:00.937223: Epoch time: 138.27 s 
2025-12-18 19:28:01.590999:  
2025-12-18 19:28:01.590999: Epoch 661 
2025-12-18 19:28:01.595086: Current learning rate: 0.00378 
2025-12-18 19:30:19.905821: train_loss -0.8557 
2025-12-18 19:30:19.907824: val_loss -0.8743 
2025-12-18 19:30:19.909565: Pseudo dice [0.9279, 0.9522, 0.9389] 
2025-12-18 19:30:19.917067: Epoch time: 138.32 s 
2025-12-18 19:30:20.563851:  
2025-12-18 19:30:20.565853: Epoch 662 
2025-12-18 19:30:20.570215: Current learning rate: 0.00377 
2025-12-18 19:32:38.623296: train_loss -0.8552 
2025-12-18 19:32:38.623296: val_loss -0.8623 
2025-12-18 19:32:38.627301: Pseudo dice [0.9178, 0.9518, 0.9411] 
2025-12-18 19:32:38.631305: Epoch time: 138.06 s 
2025-12-18 19:32:39.363617:  
2025-12-18 19:32:39.363617: Epoch 663 
2025-12-18 19:32:39.363617: Current learning rate: 0.00376 
2025-12-18 19:34:57.497684: train_loss -0.8539 
2025-12-18 19:34:57.499687: val_loss -0.8784 
2025-12-18 19:34:57.503692: Pseudo dice [0.9296, 0.9557, 0.9405] 
2025-12-18 19:34:57.507696: Epoch time: 138.13 s 
2025-12-18 19:34:58.151712:  
2025-12-18 19:34:58.151712: Epoch 664 
2025-12-18 19:34:58.167395: Current learning rate: 0.00375 
2025-12-18 19:37:16.193043: train_loss -0.8527 
2025-12-18 19:37:16.193043: val_loss -0.8796 
2025-12-18 19:37:16.208732: Pseudo dice [0.9298, 0.96, 0.9349] 
2025-12-18 19:37:16.208732: Epoch time: 138.04 s 
2025-12-18 19:37:17.081577:  
2025-12-18 19:37:17.081577: Epoch 665 
2025-12-18 19:37:17.097353: Current learning rate: 0.00374 
2025-12-18 19:39:35.253883: train_loss -0.8511 
2025-12-18 19:39:35.253883: val_loss -0.8643 
2025-12-18 19:39:35.261630: Pseudo dice [0.9197, 0.9508, 0.9414] 
2025-12-18 19:39:35.267638: Epoch time: 138.17 s 
2025-12-18 19:39:36.085967:  
2025-12-18 19:39:36.085967: Epoch 666 
2025-12-18 19:39:36.085967: Current learning rate: 0.00373 
2025-12-18 19:41:54.296722: train_loss -0.8567 
2025-12-18 19:41:54.296722: val_loss -0.8694 
2025-12-18 19:41:54.299107: Pseudo dice [0.9215, 0.9558, 0.9409] 
2025-12-18 19:41:54.299107: Epoch time: 138.21 s 
2025-12-18 19:41:54.942975:  
2025-12-18 19:41:54.944716: Epoch 667 
2025-12-18 19:41:54.949323: Current learning rate: 0.00372 
2025-12-18 19:44:13.093997: train_loss -0.8529 
2025-12-18 19:44:13.093997: val_loss -0.8783 
2025-12-18 19:44:13.096000: Pseudo dice [0.9291, 0.9572, 0.943] 
2025-12-18 19:44:13.102565: Epoch time: 138.15 s 
2025-12-18 19:44:13.745330:  
2025-12-18 19:44:13.745330: Epoch 668 
2025-12-18 19:44:13.745330: Current learning rate: 0.00371 
2025-12-18 19:46:32.033293: train_loss -0.8534 
2025-12-18 19:46:32.033293: val_loss -0.8787 
2025-12-18 19:46:32.040534: Pseudo dice [0.9291, 0.9579, 0.9452] 
2025-12-18 19:46:32.046540: Epoch time: 138.29 s 
2025-12-18 19:46:32.799195:  
2025-12-18 19:46:32.801198: Epoch 669 
2025-12-18 19:46:32.802939: Current learning rate: 0.0037 
2025-12-18 19:48:51.022215: train_loss -0.8489 
2025-12-18 19:48:51.022215: val_loss -0.8683 
2025-12-18 19:48:51.028221: Pseudo dice [0.9248, 0.9542, 0.9322] 
2025-12-18 19:48:51.032225: Epoch time: 138.22 s 
2025-12-18 19:48:51.690290:  
2025-12-18 19:48:51.690290: Epoch 670 
2025-12-18 19:48:51.692293: Current learning rate: 0.00369 
2025-12-18 19:51:09.767428: train_loss -0.8561 
2025-12-18 19:51:09.769431: val_loss -0.8772 
2025-12-18 19:51:09.769431: Pseudo dice [0.9314, 0.9586, 0.9332] 
2025-12-18 19:51:09.777985: Epoch time: 138.08 s 
2025-12-18 19:51:10.650417:  
2025-12-18 19:51:10.650417: Epoch 671 
2025-12-18 19:51:10.652420: Current learning rate: 0.00368 
2025-12-18 19:53:28.690007: train_loss -0.8588 
2025-12-18 19:53:28.690007: val_loss -0.8835 
2025-12-18 19:53:28.696016: Pseudo dice [0.9313, 0.9599, 0.9431] 
2025-12-18 19:53:28.702025: Epoch time: 138.04 s 
2025-12-18 19:53:29.425050:  
2025-12-18 19:53:29.427052: Epoch 672 
2025-12-18 19:53:29.427052: Current learning rate: 0.00367 
2025-12-18 19:55:47.548970: train_loss -0.8538 
2025-12-18 19:55:47.550973: val_loss -0.8841 
2025-12-18 19:55:47.554976: Pseudo dice [0.935, 0.9608, 0.9345] 
2025-12-18 19:55:47.558980: Epoch time: 138.12 s 
2025-12-18 19:55:48.215036:  
2025-12-18 19:55:48.215036: Epoch 673 
2025-12-18 19:55:48.215036: Current learning rate: 0.00366 
2025-12-18 19:58:06.274676: train_loss -0.8532 
2025-12-18 19:58:06.276417: val_loss -0.8618 
2025-12-18 19:58:06.282003: Pseudo dice [0.917, 0.952, 0.9374] 
2025-12-18 19:58:06.286007: Epoch time: 138.06 s 
2025-12-18 19:58:06.926131:  
2025-12-18 19:58:06.926131: Epoch 674 
2025-12-18 19:58:06.942238: Current learning rate: 0.00365 
2025-12-18 20:00:25.303010: train_loss -0.8543 
2025-12-18 20:00:25.303010: val_loss -0.8728 
2025-12-18 20:00:25.311018: Pseudo dice [0.9235, 0.9581, 0.9371] 
2025-12-18 20:00:25.311018: Epoch time: 138.38 s 
2025-12-18 20:00:25.965379:  
2025-12-18 20:00:25.965379: Epoch 675 
2025-12-18 20:00:25.981408: Current learning rate: 0.00364 
2025-12-18 20:02:44.057546: train_loss -0.8551 
2025-12-18 20:02:44.057546: val_loss -0.8805 
2025-12-18 20:02:44.063520: Pseudo dice [0.9331, 0.9607, 0.9336] 
2025-12-18 20:02:44.063520: Epoch time: 138.09 s 
2025-12-18 20:02:44.871505:  
2025-12-18 20:02:44.871505: Epoch 676 
2025-12-18 20:02:44.887526: Current learning rate: 0.00363 
2025-12-18 20:05:02.901874: train_loss -0.8539 
2025-12-18 20:05:02.901874: val_loss -0.8725 
2025-12-18 20:05:02.919621: Pseudo dice [0.9243, 0.9534, 0.9369] 
2025-12-18 20:05:02.919621: Epoch time: 138.03 s 
2025-12-18 20:05:03.583141:  
2025-12-18 20:05:03.583141: Epoch 677 
2025-12-18 20:05:03.583141: Current learning rate: 0.00362 
2025-12-18 20:07:21.824923: train_loss -0.8526 
2025-12-18 20:07:21.824923: val_loss -0.8741 
2025-12-18 20:07:21.831204: Pseudo dice [0.9269, 0.9599, 0.9399] 
2025-12-18 20:07:21.834659: Epoch time: 138.24 s 
2025-12-18 20:07:22.530770:  
2025-12-18 20:07:22.530770: Epoch 678 
2025-12-18 20:07:22.537480: Current learning rate: 0.00361 
2025-12-18 20:09:40.892730: train_loss -0.8525 
2025-12-18 20:09:40.892730: val_loss -0.873 
2025-12-18 20:09:40.898739: Pseudo dice [0.9232, 0.9532, 0.9419] 
2025-12-18 20:09:40.902743: Epoch time: 138.36 s 
2025-12-18 20:09:41.550484:  
2025-12-18 20:09:41.550484: Epoch 679 
2025-12-18 20:09:41.566278: Current learning rate: 0.0036 
2025-12-18 20:11:59.908893: train_loss -0.8571 
2025-12-18 20:11:59.908893: val_loss -0.87 
2025-12-18 20:11:59.924612: Pseudo dice [0.9215, 0.9523, 0.9473] 
2025-12-18 20:11:59.928394: Epoch time: 138.36 s 
2025-12-18 20:12:00.575174:  
2025-12-18 20:12:00.575174: Epoch 680 
2025-12-18 20:12:00.575174: Current learning rate: 0.00359 
2025-12-18 20:14:18.776925: train_loss -0.8556 
2025-12-18 20:14:18.776925: val_loss -0.873 
2025-12-18 20:14:18.788710: Pseudo dice [0.9247, 0.9583, 0.9392] 
2025-12-18 20:14:18.792901: Epoch time: 138.2 s 
2025-12-18 20:14:19.442331:  
2025-12-18 20:14:19.442331: Epoch 681 
2025-12-18 20:14:19.442331: Current learning rate: 0.00358 
2025-12-18 20:16:37.556716: train_loss -0.8569 
2025-12-18 20:16:37.558720: val_loss -0.8747 
2025-12-18 20:16:37.568741: Pseudo dice [0.9281, 0.9557, 0.9324] 
2025-12-18 20:16:37.574496: Epoch time: 138.11 s 
2025-12-18 20:16:38.394309:  
2025-12-18 20:16:38.394309: Epoch 682 
2025-12-18 20:16:38.406205: Current learning rate: 0.00357 
2025-12-18 20:18:56.491597: train_loss -0.8581 
2025-12-18 20:18:56.491597: val_loss -0.8701 
2025-12-18 20:18:56.497048: Pseudo dice [0.9226, 0.9529, 0.9382] 
2025-12-18 20:18:56.503054: Epoch time: 138.1 s 
2025-12-18 20:18:57.204409:  
2025-12-18 20:18:57.204409: Epoch 683 
2025-12-18 20:18:57.204409: Current learning rate: 0.00356 
2025-12-18 20:21:15.423657: train_loss -0.8555 
2025-12-18 20:21:15.425659: val_loss -0.8769 
2025-12-18 20:21:15.429663: Pseudo dice [0.9255, 0.9576, 0.9442] 
2025-12-18 20:21:15.434956: Epoch time: 138.22 s 
2025-12-18 20:21:16.085812:  
2025-12-18 20:21:16.085812: Epoch 684 
2025-12-18 20:21:16.085812: Current learning rate: 0.00355 
2025-12-18 20:23:34.226227: train_loss -0.8504 
2025-12-18 20:23:34.226227: val_loss -0.8711 
2025-12-18 20:23:34.233518: Pseudo dice [0.923, 0.9537, 0.9454] 
2025-12-18 20:23:34.237228: Epoch time: 138.14 s 
2025-12-18 20:23:34.987000:  
2025-12-18 20:23:34.987000: Epoch 685 
2025-12-18 20:23:34.987000: Current learning rate: 0.00354 
2025-12-18 20:25:53.220989: train_loss -0.8531 
2025-12-18 20:25:53.220989: val_loss -0.8721 
2025-12-18 20:25:53.220989: Pseudo dice [0.9236, 0.9608, 0.936] 
2025-12-18 20:25:53.236756: Epoch time: 138.23 s 
2025-12-18 20:25:53.870506:  
2025-12-18 20:25:53.870506: Epoch 686 
2025-12-18 20:25:53.870506: Current learning rate: 0.00353 
2025-12-18 20:28:11.886062: train_loss -0.8513 
2025-12-18 20:28:11.886062: val_loss -0.8684 
2025-12-18 20:28:11.887802: Pseudo dice [0.9202, 0.9567, 0.9335] 
2025-12-18 20:28:11.897171: Epoch time: 138.02 s 
2025-12-18 20:28:12.583949:  
2025-12-18 20:28:12.583949: Epoch 687 
2025-12-18 20:28:12.589486: Current learning rate: 0.00352 
2025-12-18 20:30:30.744659: train_loss -0.8487 
2025-12-18 20:30:30.744659: val_loss -0.8685 
2025-12-18 20:30:30.746662: Pseudo dice [0.925, 0.9543, 0.9356] 
2025-12-18 20:30:30.754078: Epoch time: 138.16 s 
2025-12-18 20:30:31.556736:  
2025-12-18 20:30:31.556736: Epoch 688 
2025-12-18 20:30:31.560482: Current learning rate: 0.00351 
2025-12-18 20:32:49.763092: train_loss -0.8528 
2025-12-18 20:32:49.765094: val_loss -0.8663 
2025-12-18 20:32:49.768836: Pseudo dice [0.9206, 0.9499, 0.9429] 
2025-12-18 20:32:49.774580: Epoch time: 138.21 s 
2025-12-18 20:32:50.418642:  
2025-12-18 20:32:50.418642: Epoch 689 
2025-12-18 20:32:50.434296: Current learning rate: 0.0035 
2025-12-18 20:35:08.528455: train_loss -0.8537 
2025-12-18 20:35:08.528455: val_loss -0.8735 
2025-12-18 20:35:08.532459: Pseudo dice [0.9271, 0.9566, 0.9326] 
2025-12-18 20:35:08.539201: Epoch time: 138.11 s 
2025-12-18 20:35:09.255592:  
2025-12-18 20:35:09.255592: Epoch 690 
2025-12-18 20:35:09.255592: Current learning rate: 0.00349 
2025-12-18 20:37:27.438291: train_loss -0.8543 
2025-12-18 20:37:27.438291: val_loss -0.8674 
2025-12-18 20:37:27.439795: Pseudo dice [0.9238, 0.9521, 0.93] 
2025-12-18 20:37:27.439795: Epoch time: 138.18 s 
2025-12-18 20:37:28.200392:  
2025-12-18 20:37:28.200392: Epoch 691 
2025-12-18 20:37:28.200392: Current learning rate: 0.00348 
2025-12-18 20:39:46.291001: train_loss -0.8529 
2025-12-18 20:39:46.306703: val_loss -0.8733 
2025-12-18 20:39:46.306703: Pseudo dice [0.9276, 0.9544, 0.9386] 
2025-12-18 20:39:46.306703: Epoch time: 138.11 s 
2025-12-18 20:39:46.957367:  
2025-12-18 20:39:46.957367: Epoch 692 
2025-12-18 20:39:46.973155: Current learning rate: 0.00346 
2025-12-18 20:42:05.143285: train_loss -0.8536 
2025-12-18 20:42:05.143285: val_loss -0.8858 
2025-12-18 20:42:05.143285: Pseudo dice [0.9366, 0.9627, 0.9371] 
2025-12-18 20:42:05.155164: Epoch time: 138.19 s 
2025-12-18 20:42:05.806312:  
2025-12-18 20:42:05.806312: Epoch 693 
2025-12-18 20:42:05.806312: Current learning rate: 0.00345 
2025-12-18 20:44:24.190244: train_loss -0.855 
2025-12-18 20:44:24.190244: val_loss -0.8797 
2025-12-18 20:44:24.190244: Pseudo dice [0.9328, 0.9601, 0.9455] 
2025-12-18 20:44:24.203946: Epoch time: 138.38 s 
2025-12-18 20:44:25.202365:  
2025-12-18 20:44:25.202365: Epoch 694 
2025-12-18 20:44:25.202365: Current learning rate: 0.00344 
2025-12-18 20:46:43.295017: train_loss -0.8554 
2025-12-18 20:46:43.295017: val_loss -0.8847 
2025-12-18 20:46:43.301843: Pseudo dice [0.9339, 0.9606, 0.9416] 
2025-12-18 20:46:43.309861: Epoch time: 138.11 s 
2025-12-18 20:46:43.959494:  
2025-12-18 20:46:43.959494: Epoch 695 
2025-12-18 20:46:43.975577: Current learning rate: 0.00343 
2025-12-18 20:49:02.048245: train_loss -0.856 
2025-12-18 20:49:02.048245: val_loss -0.8759 
2025-12-18 20:49:02.063982: Pseudo dice [0.9274, 0.9541, 0.9421] 
2025-12-18 20:49:02.063982: Epoch time: 138.09 s 
2025-12-18 20:49:02.715257:  
2025-12-18 20:49:02.715257: Epoch 696 
2025-12-18 20:49:02.731288: Current learning rate: 0.00342 
2025-12-18 20:51:20.852856: train_loss -0.8549 
2025-12-18 20:51:20.854858: val_loss -0.8749 
2025-12-18 20:51:20.862869: Pseudo dice [0.9289, 0.9545, 0.9397] 
2025-12-18 20:51:20.868613: Epoch time: 138.14 s 
2025-12-18 20:51:21.628041:  
2025-12-18 20:51:21.628041: Epoch 697 
2025-12-18 20:51:21.628041: Current learning rate: 0.00341 
2025-12-18 20:53:39.775077: train_loss -0.8516 
2025-12-18 20:53:39.775077: val_loss -0.8705 
2025-12-18 20:53:39.780821: Pseudo dice [0.9229, 0.9554, 0.9371] 
2025-12-18 20:53:39.782823: Epoch time: 138.15 s 
2025-12-18 20:53:40.430262:  
2025-12-18 20:53:40.430262: Epoch 698 
2025-12-18 20:53:40.446284: Current learning rate: 0.0034 
2025-12-18 20:55:58.525635: train_loss -0.8542 
2025-12-18 20:55:58.525635: val_loss -0.8678 
2025-12-18 20:55:58.525635: Pseudo dice [0.9215, 0.9597, 0.9293] 
2025-12-18 20:55:58.541481: Epoch time: 138.1 s 
2025-12-18 20:55:59.191410:  
2025-12-18 20:55:59.191410: Epoch 699 
2025-12-18 20:55:59.191410: Current learning rate: 0.00339 
2025-12-18 20:58:17.292156: train_loss -0.8574 
2025-12-18 20:58:17.292156: val_loss -0.8732 
2025-12-18 20:58:17.292156: Pseudo dice [0.9256, 0.9546, 0.9376] 
2025-12-18 20:58:17.292156: Epoch time: 138.1 s 
2025-12-18 20:58:18.432183:  
2025-12-18 20:58:18.432183: Epoch 700 
2025-12-18 20:58:18.432183: Current learning rate: 0.00338 
2025-12-18 21:00:36.700951: train_loss -0.8563 
2025-12-18 21:00:36.700951: val_loss -0.8626 
2025-12-18 21:00:36.700951: Pseudo dice [0.9219, 0.9516, 0.9375] 
2025-12-18 21:00:36.700951: Epoch time: 138.27 s 
2025-12-18 21:00:37.365386:  
2025-12-18 21:00:37.365386: Epoch 701 
2025-12-18 21:00:37.365386: Current learning rate: 0.00337 
2025-12-18 21:02:55.487955: train_loss -0.8585 
2025-12-18 21:02:55.489695: val_loss -0.8774 
2025-12-18 21:02:55.497709: Pseudo dice [0.9307, 0.9569, 0.94] 
2025-12-18 21:02:55.501713: Epoch time: 138.12 s 
2025-12-18 21:02:56.156293:  
2025-12-18 21:02:56.156293: Epoch 702 
2025-12-18 21:02:56.156293: Current learning rate: 0.00336 
2025-12-18 21:05:14.325238: train_loss -0.8597 
2025-12-18 21:05:14.325238: val_loss -0.8731 
2025-12-18 21:05:14.329242: Pseudo dice [0.9231, 0.955, 0.9423] 
2025-12-18 21:05:14.329242: Epoch time: 138.17 s 
2025-12-18 21:05:15.037080:  
2025-12-18 21:05:15.037080: Epoch 703 
2025-12-18 21:05:15.037080: Current learning rate: 0.00335 
2025-12-18 21:07:33.248630: train_loss -0.8521 
2025-12-18 21:07:33.248630: val_loss -0.8793 
2025-12-18 21:07:33.248630: Pseudo dice [0.9335, 0.9569, 0.9378] 
2025-12-18 21:07:33.248630: Epoch time: 138.21 s 
2025-12-18 21:07:33.896070:  
2025-12-18 21:07:33.896070: Epoch 704 
2025-12-18 21:07:33.896070: Current learning rate: 0.00334 
2025-12-18 21:09:52.467843: train_loss -0.8547 
2025-12-18 21:09:52.467843: val_loss -0.8751 
2025-12-18 21:09:52.467843: Pseudo dice [0.9261, 0.9576, 0.9403] 
2025-12-18 21:09:52.483592: Epoch time: 138.57 s 
2025-12-18 21:09:53.134297:  
2025-12-18 21:09:53.134297: Epoch 705 
2025-12-18 21:09:53.150062: Current learning rate: 0.00333 
2025-12-18 21:12:11.354235: train_loss -0.8558 
2025-12-18 21:12:11.354235: val_loss -0.877 
2025-12-18 21:12:11.369956: Pseudo dice [0.9288, 0.961, 0.9375] 
2025-12-18 21:12:11.369956: Epoch time: 138.22 s 
2025-12-18 21:12:12.196383:  
2025-12-18 21:12:12.196383: Epoch 706 
2025-12-18 21:12:12.196383: Current learning rate: 0.00332 
2025-12-18 21:14:30.454174: train_loss -0.8531 
2025-12-18 21:14:30.454174: val_loss -0.8646 
2025-12-18 21:14:30.454174: Pseudo dice [0.9198, 0.9532, 0.9365] 
2025-12-18 21:14:30.454174: Epoch time: 138.26 s 
2025-12-18 21:14:31.184089:  
2025-12-18 21:14:31.184089: Epoch 707 
2025-12-18 21:14:31.199855: Current learning rate: 0.00331 
2025-12-18 21:16:49.392241: train_loss -0.8586 
2025-12-18 21:16:49.394243: val_loss -0.8919 
2025-12-18 21:16:49.399987: Pseudo dice [0.9401, 0.9606, 0.9472] 
2025-12-18 21:16:49.403991: Epoch time: 138.21 s 
2025-12-18 21:16:49.407994: Yayy! New best EMA pseudo Dice: 0.9412 
2025-12-18 21:16:50.332412:  
2025-12-18 21:16:50.332412: Epoch 708 
2025-12-18 21:16:50.332412: Current learning rate: 0.0033 
2025-12-18 21:19:08.576314: train_loss -0.8565 
2025-12-18 21:19:08.576314: val_loss -0.8752 
2025-12-18 21:19:08.576314: Pseudo dice [0.9278, 0.9547, 0.9381] 
2025-12-18 21:19:08.592009: Epoch time: 138.25 s 
2025-12-18 21:19:09.247569:  
2025-12-18 21:19:09.247569: Epoch 709 
2025-12-18 21:19:09.251923: Current learning rate: 0.00329 
2025-12-18 21:21:27.562418: train_loss -0.8485 
2025-12-18 21:21:27.564421: val_loss -0.8816 
2025-12-18 21:21:27.572169: Pseudo dice [0.9317, 0.9566, 0.9395] 
2025-12-18 21:21:27.578176: Epoch time: 138.31 s 
2025-12-18 21:21:27.585925: Yayy! New best EMA pseudo Dice: 0.9412 
2025-12-18 21:21:28.702508:  
2025-12-18 21:21:28.702508: Epoch 710 
2025-12-18 21:21:28.702508: Current learning rate: 0.00328 
2025-12-18 21:23:46.852281: train_loss -0.8577 
2025-12-18 21:23:46.852281: val_loss -0.8737 
2025-12-18 21:23:46.854785: Pseudo dice [0.929, 0.959, 0.9353] 
2025-12-18 21:23:46.854785: Epoch time: 138.15 s 
2025-12-18 21:23:47.514530:  
2025-12-18 21:23:47.516533: Epoch 711 
2025-12-18 21:23:47.516533: Current learning rate: 0.00327 
2025-12-18 21:26:05.696269: train_loss -0.8537 
2025-12-18 21:26:05.696269: val_loss -0.8653 
2025-12-18 21:26:05.702276: Pseudo dice [0.921, 0.9523, 0.9329] 
2025-12-18 21:26:05.706280: Epoch time: 138.18 s 
2025-12-18 21:26:06.530283:  
2025-12-18 21:26:06.530283: Epoch 712 
2025-12-18 21:26:06.530283: Current learning rate: 0.00326 
2025-12-18 21:28:24.441483: train_loss -0.86 
2025-12-18 21:28:24.441483: val_loss -0.875 
2025-12-18 21:28:24.449492: Pseudo dice [0.9257, 0.9562, 0.9398] 
2025-12-18 21:28:24.455497: Epoch time: 137.91 s 
2025-12-18 21:28:25.279593:  
2025-12-18 21:28:25.279593: Epoch 713 
2025-12-18 21:28:25.299495: Current learning rate: 0.00325 
2025-12-18 21:30:43.627196: train_loss -0.8563 
2025-12-18 21:30:43.627196: val_loss -0.8749 
2025-12-18 21:30:43.643095: Pseudo dice [0.9258, 0.9557, 0.9404] 
2025-12-18 21:30:43.643095: Epoch time: 138.35 s 
2025-12-18 21:30:44.293276:  
2025-12-18 21:30:44.293276: Epoch 714 
2025-12-18 21:30:44.293276: Current learning rate: 0.00324 
2025-12-18 21:33:02.672204: train_loss -0.8539 
2025-12-18 21:33:02.672204: val_loss -0.8704 
2025-12-18 21:33:02.678211: Pseudo dice [0.9252, 0.9529, 0.9378] 
2025-12-18 21:33:02.683932: Epoch time: 138.38 s 
2025-12-18 21:33:03.346271:  
2025-12-18 21:33:03.346271: Epoch 715 
2025-12-18 21:33:03.346271: Current learning rate: 0.00323 
2025-12-18 21:35:21.656337: train_loss -0.8552 
2025-12-18 21:35:21.656337: val_loss -0.8775 
2025-12-18 21:35:21.662344: Pseudo dice [0.928, 0.9596, 0.9395] 
2025-12-18 21:35:21.666348: Epoch time: 138.31 s 
2025-12-18 21:35:22.397650:  
2025-12-18 21:35:22.397650: Epoch 716 
2025-12-18 21:35:22.397650: Current learning rate: 0.00322 
2025-12-18 21:37:40.538622: train_loss -0.8572 
2025-12-18 21:37:40.538622: val_loss -0.8682 
2025-12-18 21:37:40.548378: Pseudo dice [0.9224, 0.9493, 0.932] 
2025-12-18 21:37:40.552954: Epoch time: 138.16 s 
2025-12-18 21:37:41.358923:  
2025-12-18 21:37:41.358923: Epoch 717 
2025-12-18 21:37:41.374603: Current learning rate: 0.00321 
2025-12-18 21:39:59.524228: train_loss -0.8537 
2025-12-18 21:39:59.524228: val_loss -0.8759 
2025-12-18 21:39:59.531101: Pseudo dice [0.9299, 0.9587, 0.9338] 
2025-12-18 21:39:59.535105: Epoch time: 138.17 s 
2025-12-18 21:40:00.219174:  
2025-12-18 21:40:00.219174: Epoch 718 
2025-12-18 21:40:00.219174: Current learning rate: 0.0032 
2025-12-18 21:42:18.551671: train_loss -0.8551 
2025-12-18 21:42:18.551671: val_loss -0.8689 
2025-12-18 21:42:18.553674: Pseudo dice [0.9251, 0.9548, 0.9365] 
2025-12-18 21:42:18.562901: Epoch time: 138.33 s 
2025-12-18 21:42:19.224910:  
2025-12-18 21:42:19.224910: Epoch 719 
2025-12-18 21:42:19.227426: Current learning rate: 0.00319 
2025-12-18 21:44:37.645055: train_loss -0.8563 
2025-12-18 21:44:37.645055: val_loss -0.8715 
2025-12-18 21:44:37.645055: Pseudo dice [0.9231, 0.9531, 0.9366] 
2025-12-18 21:44:37.645055: Epoch time: 138.42 s 
2025-12-18 21:44:38.310062:  
2025-12-18 21:44:38.310062: Epoch 720 
2025-12-18 21:44:38.310062: Current learning rate: 0.00318 
2025-12-18 21:46:56.440247: train_loss -0.8575 
2025-12-18 21:46:56.440247: val_loss -0.8721 
2025-12-18 21:46:56.455965: Pseudo dice [0.9271, 0.9524, 0.931] 
2025-12-18 21:46:56.455965: Epoch time: 138.13 s 
2025-12-18 21:46:57.102109:  
2025-12-18 21:46:57.102109: Epoch 721 
2025-12-18 21:46:57.117889: Current learning rate: 0.00317 
2025-12-18 21:49:15.146586: train_loss -0.8626 
2025-12-18 21:49:15.146586: val_loss -0.8832 
2025-12-18 21:49:15.146586: Pseudo dice [0.9291, 0.9587, 0.9468] 
2025-12-18 21:49:15.146586: Epoch time: 138.04 s 
2025-12-18 21:49:15.810167:  
2025-12-18 21:49:15.812170: Epoch 722 
2025-12-18 21:49:15.812170: Current learning rate: 0.00316 
2025-12-18 21:51:34.067221: train_loss -0.8574 
2025-12-18 21:51:34.067221: val_loss -0.8802 
2025-12-18 21:51:34.082789: Pseudo dice [0.9343, 0.9598, 0.9295] 
2025-12-18 21:51:34.082789: Epoch time: 138.26 s 
2025-12-18 21:51:34.733466:  
2025-12-18 21:51:34.733466: Epoch 723 
2025-12-18 21:51:34.733466: Current learning rate: 0.00315 
2025-12-18 21:53:53.214339: train_loss -0.8532 
2025-12-18 21:53:53.214339: val_loss -0.8725 
2025-12-18 21:53:53.216342: Pseudo dice [0.9232, 0.9574, 0.9423] 
2025-12-18 21:53:53.224022: Epoch time: 138.48 s 
2025-12-18 21:53:54.046463:  
2025-12-18 21:53:54.046463: Epoch 724 
2025-12-18 21:53:54.062301: Current learning rate: 0.00314 
2025-12-18 21:56:12.103250: train_loss -0.8613 
2025-12-18 21:56:12.103250: val_loss -0.8707 
2025-12-18 21:56:12.109255: Pseudo dice [0.9251, 0.9525, 0.934] 
2025-12-18 21:56:12.113260: Epoch time: 138.06 s 
2025-12-18 21:56:12.776313:  
2025-12-18 21:56:12.776313: Epoch 725 
2025-12-18 21:56:12.776313: Current learning rate: 0.00313 
2025-12-18 21:58:31.038320: train_loss -0.8581 
2025-12-18 21:58:31.038320: val_loss -0.8699 
2025-12-18 21:58:31.044064: Pseudo dice [0.9238, 0.9555, 0.9375] 
2025-12-18 21:58:31.048068: Epoch time: 138.26 s 
2025-12-18 21:58:31.856410:  
2025-12-18 21:58:31.856410: Epoch 726 
2025-12-18 21:58:31.867908: Current learning rate: 0.00312 
2025-12-18 22:00:50.127067: train_loss -0.8532 
2025-12-18 22:00:50.127067: val_loss -0.874 
2025-12-18 22:00:50.134814: Pseudo dice [0.9253, 0.9594, 0.9414] 
2025-12-18 22:00:50.138555: Epoch time: 138.27 s 
2025-12-18 22:00:50.794305:  
2025-12-18 22:00:50.794305: Epoch 727 
2025-12-18 22:00:50.794305: Current learning rate: 0.00311 
2025-12-18 22:03:09.077626: train_loss -0.861 
2025-12-18 22:03:09.077626: val_loss -0.88 
2025-12-18 22:03:09.093284: Pseudo dice [0.9305, 0.9608, 0.9406] 
2025-12-18 22:03:09.093284: Epoch time: 138.28 s 
2025-12-18 22:03:09.746364:  
2025-12-18 22:03:09.746364: Epoch 728 
2025-12-18 22:03:09.746364: Current learning rate: 0.0031 
2025-12-18 22:05:28.025326: train_loss -0.8552 
2025-12-18 22:05:28.025326: val_loss -0.8674 
2025-12-18 22:05:28.031337: Pseudo dice [0.9184, 0.9546, 0.9477] 
2025-12-18 22:05:28.035343: Epoch time: 138.28 s 
2025-12-18 22:05:29.005154:  
2025-12-18 22:05:29.005154: Epoch 729 
2025-12-18 22:05:29.009160: Current learning rate: 0.00309 
2025-12-18 22:07:47.159521: train_loss -0.858 
2025-12-18 22:07:47.159521: val_loss -0.8791 
2025-12-18 22:07:47.169389: Pseudo dice [0.9307, 0.956, 0.9388] 
2025-12-18 22:07:47.175199: Epoch time: 138.16 s 
2025-12-18 22:07:47.827635:  
2025-12-18 22:07:47.827635: Epoch 730 
2025-12-18 22:07:47.827635: Current learning rate: 0.00308 
2025-12-18 22:10:06.276344: train_loss -0.8516 
2025-12-18 22:10:06.276344: val_loss -0.8734 
2025-12-18 22:10:06.291152: Pseudo dice [0.9238, 0.9553, 0.9422] 
2025-12-18 22:10:06.295656: Epoch time: 138.45 s 
2025-12-18 22:10:06.941626:  
2025-12-18 22:10:06.941626: Epoch 731 
2025-12-18 22:10:06.957673: Current learning rate: 0.00307 
2025-12-18 22:12:25.198093: train_loss -0.8544 
2025-12-18 22:12:25.198093: val_loss -0.8658 
2025-12-18 22:12:25.209861: Pseudo dice [0.9227, 0.9501, 0.9289] 
2025-12-18 22:12:25.215870: Epoch time: 138.26 s 
2025-12-18 22:12:25.967178:  
2025-12-18 22:12:25.967178: Epoch 732 
2025-12-18 22:12:25.967178: Current learning rate: 0.00306 
2025-12-18 22:14:44.115413: train_loss -0.8562 
2025-12-18 22:14:44.115413: val_loss -0.8845 
2025-12-18 22:14:44.115413: Pseudo dice [0.9299, 0.9632, 0.9484] 
2025-12-18 22:14:44.115413: Epoch time: 138.15 s 
2025-12-18 22:14:44.780592:  
2025-12-18 22:14:44.780592: Epoch 733 
2025-12-18 22:14:44.780592: Current learning rate: 0.00305 
2025-12-18 22:17:03.061933: train_loss -0.8543 
2025-12-18 22:17:03.061933: val_loss -0.8856 
2025-12-18 22:17:03.061933: Pseudo dice [0.9369, 0.9615, 0.9412] 
2025-12-18 22:17:03.061933: Epoch time: 138.28 s 
2025-12-18 22:17:03.729586:  
2025-12-18 22:17:03.729586: Epoch 734 
2025-12-18 22:17:03.729586: Current learning rate: 0.00304 
2025-12-18 22:19:21.806354: train_loss -0.8555 
2025-12-18 22:19:21.808357: val_loss -0.8684 
2025-12-18 22:19:21.814086: Pseudo dice [0.9238, 0.9521, 0.9375] 
2025-12-18 22:19:21.818001: Epoch time: 138.08 s 
2025-12-18 22:19:22.653391:  
2025-12-18 22:19:22.653391: Epoch 735 
2025-12-18 22:19:22.659805: Current learning rate: 0.00303 
2025-12-18 22:21:40.898938: train_loss -0.8562 
2025-12-18 22:21:40.900939: val_loss -0.8699 
2025-12-18 22:21:40.906449: Pseudo dice [0.9244, 0.9552, 0.9335] 
2025-12-18 22:21:40.910322: Epoch time: 138.25 s 
2025-12-18 22:21:41.557086:  
2025-12-18 22:21:41.557086: Epoch 736 
2025-12-18 22:21:41.566250: Current learning rate: 0.00302 
2025-12-18 22:23:59.771641: train_loss -0.8507 
2025-12-18 22:23:59.785709: val_loss -0.874 
2025-12-18 22:23:59.791197: Pseudo dice [0.9289, 0.9572, 0.936] 
2025-12-18 22:23:59.795369: Epoch time: 138.21 s 
2025-12-18 22:24:00.452283:  
2025-12-18 22:24:00.453743: Epoch 737 
2025-12-18 22:24:00.458262: Current learning rate: 0.00301 
2025-12-18 22:26:18.886611: train_loss -0.8485 
2025-12-18 22:26:18.886611: val_loss -0.8828 
2025-12-18 22:26:18.906182: Pseudo dice [0.9328, 0.9618, 0.9365] 
2025-12-18 22:26:18.910186: Epoch time: 138.45 s 
2025-12-18 22:26:19.568329:  
2025-12-18 22:26:19.568329: Epoch 738 
2025-12-18 22:26:19.588217: Current learning rate: 0.003 
2025-12-18 22:28:37.760707: train_loss -0.8572 
2025-12-18 22:28:37.760707: val_loss -0.8787 
2025-12-18 22:28:37.760707: Pseudo dice [0.9323, 0.9563, 0.9371] 
2025-12-18 22:28:37.760707: Epoch time: 138.19 s 
2025-12-18 22:28:38.426876:  
2025-12-18 22:28:38.426876: Epoch 739 
2025-12-18 22:28:38.426876: Current learning rate: 0.00299 
2025-12-18 22:30:56.683811: train_loss -0.858 
2025-12-18 22:30:56.683811: val_loss -0.8716 
2025-12-18 22:30:56.693438: Pseudo dice [0.9241, 0.9532, 0.9403] 
2025-12-18 22:30:56.697443: Epoch time: 138.26 s 
2025-12-18 22:30:57.403831:  
2025-12-18 22:30:57.403831: Epoch 740 
2025-12-18 22:30:57.419691: Current learning rate: 0.00297 
2025-12-18 22:33:15.591752: train_loss -0.8586 
2025-12-18 22:33:15.591752: val_loss -0.878 
2025-12-18 22:33:15.607541: Pseudo dice [0.9304, 0.9576, 0.9365] 
2025-12-18 22:33:15.613547: Epoch time: 138.19 s 
2025-12-18 22:33:16.271230:  
2025-12-18 22:33:16.271230: Epoch 741 
2025-12-18 22:33:16.271230: Current learning rate: 0.00296 
2025-12-18 22:35:34.966139: train_loss -0.8549 
2025-12-18 22:35:34.966139: val_loss -0.8783 
2025-12-18 22:35:34.966139: Pseudo dice [0.9294, 0.9584, 0.9415] 
2025-12-18 22:35:34.977876: Epoch time: 138.69 s 
2025-12-18 22:35:35.745076:  
2025-12-18 22:35:35.745076: Epoch 742 
2025-12-18 22:35:35.751088: Current learning rate: 0.00295 
2025-12-18 22:37:53.802418: train_loss -0.8604 
2025-12-18 22:37:53.802418: val_loss -0.8749 
2025-12-18 22:37:53.810426: Pseudo dice [0.927, 0.9572, 0.937] 
2025-12-18 22:37:53.816434: Epoch time: 138.06 s 
2025-12-18 22:37:54.462721:  
2025-12-18 22:37:54.462721: Epoch 743 
2025-12-18 22:37:54.476259: Current learning rate: 0.00294 
2025-12-18 22:40:12.845647: train_loss -0.8612 
2025-12-18 22:40:12.845647: val_loss -0.8732 
2025-12-18 22:40:12.845647: Pseudo dice [0.9258, 0.9572, 0.9342] 
2025-12-18 22:40:12.845647: Epoch time: 138.38 s 
2025-12-18 22:40:13.557028:  
2025-12-18 22:40:13.557028: Epoch 744 
2025-12-18 22:40:13.562513: Current learning rate: 0.00293 
2025-12-18 22:42:31.802418: train_loss -0.8592 
2025-12-18 22:42:31.802418: val_loss -0.8788 
2025-12-18 22:42:31.808424: Pseudo dice [0.9319, 0.9586, 0.9332] 
2025-12-18 22:42:31.812427: Epoch time: 138.25 s 
2025-12-18 22:42:32.582920:  
2025-12-18 22:42:32.582920: Epoch 745 
2025-12-18 22:42:32.582920: Current learning rate: 0.00292 
2025-12-18 22:44:50.895994: train_loss -0.8563 
2025-12-18 22:44:50.895994: val_loss -0.8712 
2025-12-18 22:44:50.895994: Pseudo dice [0.9252, 0.9547, 0.9325] 
2025-12-18 22:44:50.911891: Epoch time: 138.31 s 
2025-12-18 22:44:51.595500:  
2025-12-18 22:44:51.595500: Epoch 746 
2025-12-18 22:44:51.595500: Current learning rate: 0.00291 
2025-12-18 22:47:10.044143: train_loss -0.8535 
2025-12-18 22:47:10.044143: val_loss -0.8705 
2025-12-18 22:47:10.044143: Pseudo dice [0.9246, 0.9544, 0.9378] 
2025-12-18 22:47:10.059998: Epoch time: 138.45 s 
2025-12-18 22:47:10.931284:  
2025-12-18 22:47:10.931284: Epoch 747 
2025-12-18 22:47:10.936771: Current learning rate: 0.0029 
2025-12-18 22:49:29.135391: train_loss -0.8524 
2025-12-18 22:49:29.137392: val_loss -0.8733 
2025-12-18 22:49:29.145139: Pseudo dice [0.9253, 0.9514, 0.9426] 
2025-12-18 22:49:29.151145: Epoch time: 138.2 s 
2025-12-18 22:49:29.981476:  
2025-12-18 22:49:29.981476: Epoch 748 
2025-12-18 22:49:29.981476: Current learning rate: 0.00289 
2025-12-18 22:51:48.245332: train_loss -0.8635 
2025-12-18 22:51:48.245332: val_loss -0.8747 
2025-12-18 22:51:48.247334: Pseudo dice [0.9263, 0.9562, 0.9399] 
2025-12-18 22:51:48.257411: Epoch time: 138.28 s 
2025-12-18 22:51:48.943482:  
2025-12-18 22:51:48.943482: Epoch 749 
2025-12-18 22:51:48.945484: Current learning rate: 0.00288 
2025-12-18 22:54:07.248617: train_loss -0.857 
2025-12-18 22:54:07.248617: val_loss -0.8745 
2025-12-18 22:54:07.248617: Pseudo dice [0.9223, 0.9527, 0.9461] 
2025-12-18 22:54:07.248617: Epoch time: 138.31 s 
2025-12-18 22:54:08.222988:  
2025-12-18 22:54:08.222988: Epoch 750 
2025-12-18 22:54:08.222988: Current learning rate: 0.00287 
2025-12-18 22:56:26.451109: train_loss -0.8526 
2025-12-18 22:56:26.451109: val_loss -0.8805 
2025-12-18 22:56:26.458857: Pseudo dice [0.9291, 0.9623, 0.9392] 
2025-12-18 22:56:26.462861: Epoch time: 138.23 s 
2025-12-18 22:56:27.169996:  
2025-12-18 22:56:27.169996: Epoch 751 
2025-12-18 22:56:27.169996: Current learning rate: 0.00286 
2025-12-18 22:58:45.320667: train_loss -0.8608 
2025-12-18 22:58:45.320667: val_loss -0.8791 
2025-12-18 22:58:45.326497: Pseudo dice [0.9279, 0.9562, 0.9435] 
2025-12-18 22:58:45.330501: Epoch time: 138.15 s 
2025-12-18 22:58:45.997577:  
2025-12-18 22:58:45.997577: Epoch 752 
2025-12-18 22:58:45.997577: Current learning rate: 0.00285 
2025-12-18 23:01:04.198962: train_loss -0.8603 
2025-12-18 23:01:04.200965: val_loss -0.8704 
2025-12-18 23:01:04.206972: Pseudo dice [0.92, 0.9516, 0.9432] 
2025-12-18 23:01:04.212470: Epoch time: 138.2 s 
2025-12-18 23:01:05.046540:  
2025-12-18 23:01:05.046540: Epoch 753 
2025-12-18 23:01:05.050894: Current learning rate: 0.00284 
2025-12-18 23:03:23.446700: train_loss -0.8608 
2025-12-18 23:03:23.448702: val_loss -0.8774 
2025-12-18 23:03:23.460336: Pseudo dice [0.926, 0.9537, 0.9436] 
2025-12-18 23:03:23.464556: Epoch time: 138.4 s 
2025-12-18 23:03:24.172228:  
2025-12-18 23:03:24.172228: Epoch 754 
2025-12-18 23:03:24.177429: Current learning rate: 0.00283 
2025-12-18 23:05:42.543805: train_loss -0.855 
2025-12-18 23:05:42.543805: val_loss -0.8716 
2025-12-18 23:05:42.548957: Pseudo dice [0.9219, 0.9539, 0.9439] 
2025-12-18 23:05:42.554456: Epoch time: 138.37 s 
2025-12-18 23:05:43.214346:  
2025-12-18 23:05:43.214346: Epoch 755 
2025-12-18 23:05:43.214346: Current learning rate: 0.00282 
2025-12-18 23:08:01.233197: train_loss -0.8547 
2025-12-18 23:08:01.233197: val_loss -0.8814 
2025-12-18 23:08:01.240514: Pseudo dice [0.9281, 0.959, 0.9404] 
2025-12-18 23:08:01.244518: Epoch time: 138.02 s 
2025-12-18 23:08:01.898196:  
2025-12-18 23:08:01.898196: Epoch 756 
2025-12-18 23:08:01.914103: Current learning rate: 0.00281 
2025-12-18 23:10:20.454391: train_loss -0.8551 
2025-12-18 23:10:20.454391: val_loss -0.8831 
2025-12-18 23:10:20.470333: Pseudo dice [0.9328, 0.9592, 0.9403] 
2025-12-18 23:10:20.470333: Epoch time: 138.56 s 
2025-12-18 23:10:21.167594:  
2025-12-18 23:10:21.167594: Epoch 757 
2025-12-18 23:10:21.167594: Current learning rate: 0.0028 
2025-12-18 23:12:39.461757: train_loss -0.8533 
2025-12-18 23:12:39.463759: val_loss -0.8674 
2025-12-18 23:12:39.471769: Pseudo dice [0.9226, 0.9518, 0.9384] 
2025-12-18 23:12:39.477415: Epoch time: 138.29 s 
2025-12-18 23:12:40.185024:  
2025-12-18 23:12:40.185024: Epoch 758 
2025-12-18 23:12:40.190317: Current learning rate: 0.00279 
2025-12-18 23:14:58.356048: train_loss -0.8528 
2025-12-18 23:14:58.358050: val_loss -0.8798 
2025-12-18 23:14:58.360306: Pseudo dice [0.9267, 0.9608, 0.9449] 
2025-12-18 23:14:58.360306: Epoch time: 138.17 s 
2025-12-18 23:14:59.181027:  
2025-12-18 23:14:59.181027: Epoch 759 
2025-12-18 23:14:59.196835: Current learning rate: 0.00278 
2025-12-18 23:17:17.525382: train_loss -0.8517 
2025-12-18 23:17:17.525382: val_loss -0.8743 
2025-12-18 23:17:17.538285: Pseudo dice [0.9259, 0.9527, 0.9415] 
2025-12-18 23:17:17.541288: Epoch time: 138.34 s 
2025-12-18 23:17:18.277992:  
2025-12-18 23:17:18.277992: Epoch 760 
2025-12-18 23:17:18.277992: Current learning rate: 0.00277 
2025-12-18 23:19:36.442133: train_loss -0.8538 
2025-12-18 23:19:36.442133: val_loss -0.8648 
2025-12-18 23:19:36.449881: Pseudo dice [0.9211, 0.9517, 0.9377] 
2025-12-18 23:19:36.455888: Epoch time: 138.16 s 
2025-12-18 23:19:37.238498:  
2025-12-18 23:19:37.240501: Epoch 761 
2025-12-18 23:19:37.240501: Current learning rate: 0.00276 
2025-12-18 23:21:55.332176: train_loss -0.8543 
2025-12-18 23:21:55.332176: val_loss -0.8831 
2025-12-18 23:21:55.333918: Pseudo dice [0.932, 0.9619, 0.9425] 
2025-12-18 23:21:55.333918: Epoch time: 138.1 s 
2025-12-18 23:21:56.014695:  
2025-12-18 23:21:56.014695: Epoch 762 
2025-12-18 23:21:56.014695: Current learning rate: 0.00275 
2025-12-18 23:24:14.211185: train_loss -0.86 
2025-12-18 23:24:14.211185: val_loss -0.8754 
2025-12-18 23:24:14.217377: Pseudo dice [0.93, 0.9598, 0.9346] 
2025-12-18 23:24:14.221381: Epoch time: 138.2 s 
2025-12-18 23:24:14.889310:  
2025-12-18 23:24:14.889310: Epoch 763 
2025-12-18 23:24:14.889310: Current learning rate: 0.00274 
2025-12-18 23:26:33.243009: train_loss -0.8565 
2025-12-18 23:26:33.243009: val_loss -0.8802 
2025-12-18 23:26:33.249015: Pseudo dice [0.9287, 0.9577, 0.9407] 
2025-12-18 23:26:33.255020: Epoch time: 138.35 s 
2025-12-18 23:26:34.109185:  
2025-12-18 23:26:34.109185: Epoch 764 
2025-12-18 23:26:34.109185: Current learning rate: 0.00273 
2025-12-18 23:28:52.317981: train_loss -0.8579 
2025-12-18 23:28:52.317981: val_loss -0.8837 
2025-12-18 23:28:52.323987: Pseudo dice [0.9331, 0.9587, 0.9388] 
2025-12-18 23:28:52.329731: Epoch time: 138.21 s 
2025-12-18 23:28:52.333542: Yayy! New best EMA pseudo Dice: 0.9415 
2025-12-18 23:28:53.439537:  
2025-12-18 23:28:53.439537: Epoch 765 
2025-12-18 23:28:53.447056: Current learning rate: 0.00272 
2025-12-18 23:31:11.573357: train_loss -0.8631 
2025-12-18 23:31:11.573357: val_loss -0.8729 
2025-12-18 23:31:11.589442: Pseudo dice [0.921, 0.9546, 0.9488] 
2025-12-18 23:31:11.589442: Epoch time: 138.13 s 
2025-12-18 23:31:11.589442: Yayy! New best EMA pseudo Dice: 0.9415 
2025-12-18 23:31:12.541756:  
2025-12-18 23:31:12.541756: Epoch 766 
2025-12-18 23:31:12.561170: Current learning rate: 0.00271 
2025-12-18 23:33:30.720073: train_loss -0.8591 
2025-12-18 23:33:30.720073: val_loss -0.878 
2025-12-18 23:33:30.729070: Pseudo dice [0.9307, 0.9617, 0.934] 
2025-12-18 23:33:30.733976: Epoch time: 138.18 s 
2025-12-18 23:33:30.737980: Yayy! New best EMA pseudo Dice: 0.9415 
2025-12-18 23:33:31.702812:  
2025-12-18 23:33:31.702812: Epoch 767 
2025-12-18 23:33:31.702812: Current learning rate: 0.0027 
2025-12-18 23:35:49.934917: train_loss -0.8588 
2025-12-18 23:35:49.934917: val_loss -0.8784 
2025-12-18 23:35:49.938545: Pseudo dice [0.9297, 0.9572, 0.9408] 
2025-12-18 23:35:49.938545: Epoch time: 138.23 s 
2025-12-18 23:35:49.938545: Yayy! New best EMA pseudo Dice: 0.9416 
2025-12-18 23:35:50.928438:  
2025-12-18 23:35:50.928438: Epoch 768 
2025-12-18 23:35:50.932183: Current learning rate: 0.00268 
2025-12-18 23:38:09.032323: train_loss -0.854 
2025-12-18 23:38:09.032323: val_loss -0.8758 
2025-12-18 23:38:09.038329: Pseudo dice [0.9259, 0.9567, 0.9434] 
2025-12-18 23:38:09.044335: Epoch time: 138.1 s 
2025-12-18 23:38:09.048339: Yayy! New best EMA pseudo Dice: 0.9417 
2025-12-18 23:38:09.992738:  
2025-12-18 23:38:09.992738: Epoch 769 
2025-12-18 23:38:09.994740: Current learning rate: 0.00267 
2025-12-18 23:40:28.245404: train_loss -0.8617 
2025-12-18 23:40:28.245404: val_loss -0.8752 
2025-12-18 23:40:28.251410: Pseudo dice [0.9263, 0.9579, 0.9449] 
2025-12-18 23:40:28.256910: Epoch time: 138.25 s 
2025-12-18 23:40:28.260914: Yayy! New best EMA pseudo Dice: 0.9418 
2025-12-18 23:40:29.457348:  
2025-12-18 23:40:29.457348: Epoch 770 
2025-12-18 23:40:29.461580: Current learning rate: 0.00266 
2025-12-18 23:42:47.733479: train_loss -0.8625 
2025-12-18 23:42:47.733479: val_loss -0.8719 
2025-12-18 23:42:47.733479: Pseudo dice [0.9265, 0.9558, 0.9352] 
2025-12-18 23:42:47.744103: Epoch time: 138.28 s 
2025-12-18 23:42:48.447477:  
2025-12-18 23:42:48.447477: Epoch 771 
2025-12-18 23:42:48.455227: Current learning rate: 0.00265 
2025-12-18 23:45:06.603470: train_loss -0.8563 
2025-12-18 23:45:06.605472: val_loss -0.8744 
2025-12-18 23:45:06.607635: Pseudo dice [0.927, 0.9582, 0.9355] 
2025-12-18 23:45:06.616724: Epoch time: 138.16 s 
2025-12-18 23:45:07.286902:  
2025-12-18 23:45:07.286902: Epoch 772 
2025-12-18 23:45:07.286902: Current learning rate: 0.00264 
2025-12-18 23:47:25.406665: train_loss -0.8595 
2025-12-18 23:47:25.406665: val_loss -0.8724 
2025-12-18 23:47:25.412671: Pseudo dice [0.9247, 0.9552, 0.9383] 
2025-12-18 23:47:25.417630: Epoch time: 138.12 s 
2025-12-18 23:47:26.109785:  
2025-12-18 23:47:26.109785: Epoch 773 
2025-12-18 23:47:26.129067: Current learning rate: 0.00263 
2025-12-18 23:49:44.111626: train_loss -0.8593 
2025-12-18 23:49:44.111626: val_loss -0.8774 
2025-12-18 23:49:44.120857: Pseudo dice [0.9268, 0.9568, 0.9419] 
2025-12-18 23:49:44.126863: Epoch time: 138.0 s 
2025-12-18 23:49:44.898424:  
2025-12-18 23:49:44.898424: Epoch 774 
2025-12-18 23:49:44.917723: Current learning rate: 0.00262 
2025-12-18 23:52:03.182278: train_loss -0.8605 
2025-12-18 23:52:03.182278: val_loss -0.8842 
2025-12-18 23:52:03.189608: Pseudo dice [0.9326, 0.9603, 0.9435] 
2025-12-18 23:52:03.193613: Epoch time: 138.28 s 
2025-12-18 23:52:03.862028:  
2025-12-18 23:52:03.862028: Epoch 775 
2025-12-18 23:52:03.872536: Current learning rate: 0.00261 
2025-12-18 23:54:22.180191: train_loss -0.8584 
2025-12-18 23:54:22.180191: val_loss -0.8754 
2025-12-18 23:54:22.180191: Pseudo dice [0.9273, 0.9555, 0.9429] 
2025-12-18 23:54:22.195994: Epoch time: 138.32 s 
2025-12-18 23:54:23.019134:  
2025-12-18 23:54:23.019134: Epoch 776 
2025-12-18 23:54:23.019134: Current learning rate: 0.0026 
2025-12-18 23:56:41.275890: train_loss -0.8607 
2025-12-18 23:56:41.275890: val_loss -0.8756 
2025-12-18 23:56:41.281896: Pseudo dice [0.9269, 0.9551, 0.9414] 
2025-12-18 23:56:41.285900: Epoch time: 138.26 s 
2025-12-18 23:56:42.114562:  
2025-12-18 23:56:42.114562: Epoch 777 
2025-12-18 23:56:42.114562: Current learning rate: 0.00259 
2025-12-18 23:59:00.327641: train_loss -0.8564 
2025-12-18 23:59:00.329643: val_loss -0.8692 
2025-12-18 23:59:00.335649: Pseudo dice [0.9217, 0.9568, 0.9377] 
2025-12-18 23:59:00.341393: Epoch time: 138.21 s 
2025-12-18 23:59:01.055347:  
2025-12-18 23:59:01.055347: Epoch 778 
2025-12-18 23:59:01.071437: Current learning rate: 0.00258 
2025-12-19 00:01:19.362229: train_loss -0.8586 
2025-12-19 00:01:19.364232: val_loss -0.8758 
2025-12-19 00:01:19.371981: Pseudo dice [0.9259, 0.9588, 0.9406] 
2025-12-19 00:01:19.377987: Epoch time: 138.31 s 
2025-12-19 00:01:20.064939:  
2025-12-19 00:01:20.064939: Epoch 779 
2025-12-19 00:01:20.068960: Current learning rate: 0.00257 
2025-12-19 00:03:38.294489: train_loss -0.8585 
2025-12-19 00:03:38.294489: val_loss -0.8821 
2025-12-19 00:03:38.300495: Pseudo dice [0.9325, 0.9604, 0.9452] 
2025-12-19 00:03:38.307548: Epoch time: 138.23 s 
2025-12-19 00:03:38.310551: Yayy! New best EMA pseudo Dice: 0.9419 
2025-12-19 00:03:39.371040:  
2025-12-19 00:03:39.371040: Epoch 780 
2025-12-19 00:03:39.371040: Current learning rate: 0.00256 
2025-12-19 00:05:57.533255: train_loss -0.8567 
2025-12-19 00:05:57.533255: val_loss -0.8724 
2025-12-19 00:05:57.533255: Pseudo dice [0.9248, 0.9558, 0.9406] 
2025-12-19 00:05:57.549034: Epoch time: 138.16 s 
2025-12-19 00:05:58.199462:  
2025-12-19 00:05:58.199462: Epoch 781 
2025-12-19 00:05:58.215256: Current learning rate: 0.00255 
2025-12-19 00:08:16.530179: train_loss -0.8573 
2025-12-19 00:08:16.531967: val_loss -0.8758 
2025-12-19 00:08:16.531967: Pseudo dice [0.9268, 0.9552, 0.9433] 
2025-12-19 00:08:16.531967: Epoch time: 138.33 s 
2025-12-19 00:08:17.372407:  
2025-12-19 00:08:17.372407: Epoch 782 
2025-12-19 00:08:17.372407: Current learning rate: 0.00254 
2025-12-19 00:10:35.874387: train_loss -0.8594 
2025-12-19 00:10:35.874387: val_loss -0.8775 
2025-12-19 00:10:35.887468: Pseudo dice [0.9261, 0.9566, 0.9378] 
2025-12-19 00:10:35.892032: Epoch time: 138.5 s 
2025-12-19 00:10:36.573892:  
2025-12-19 00:10:36.573892: Epoch 783 
2025-12-19 00:10:36.575895: Current learning rate: 0.00253 
2025-12-19 00:12:54.758232: train_loss -0.8606 
2025-12-19 00:12:54.758232: val_loss -0.8706 
2025-12-19 00:12:54.762236: Pseudo dice [0.9227, 0.9558, 0.9367] 
2025-12-19 00:12:54.762236: Epoch time: 138.19 s 
2025-12-19 00:12:55.422688:  
2025-12-19 00:12:55.422688: Epoch 784 
2025-12-19 00:12:55.438578: Current learning rate: 0.00252 
2025-12-19 00:15:13.700640: train_loss -0.8619 
2025-12-19 00:15:13.700640: val_loss -0.875 
2025-12-19 00:15:13.716350: Pseudo dice [0.9258, 0.9566, 0.9457] 
2025-12-19 00:15:13.721531: Epoch time: 138.28 s 
2025-12-19 00:15:14.444734:  
2025-12-19 00:15:14.444734: Epoch 785 
2025-12-19 00:15:14.444734: Current learning rate: 0.00251 
2025-12-19 00:17:32.650534: train_loss -0.8574 
2025-12-19 00:17:32.650534: val_loss -0.8799 
2025-12-19 00:17:32.668256: Pseudo dice [0.9283, 0.9614, 0.9435] 
2025-12-19 00:17:32.668256: Epoch time: 138.21 s 
2025-12-19 00:17:33.394972:  
2025-12-19 00:17:33.394972: Epoch 786 
2025-12-19 00:17:33.394972: Current learning rate: 0.0025 
2025-12-19 00:19:51.532339: train_loss -0.8606 
2025-12-19 00:19:51.532339: val_loss -0.8743 
2025-12-19 00:19:51.540084: Pseudo dice [0.9262, 0.9544, 0.9431] 
2025-12-19 00:19:51.544088: Epoch time: 138.14 s 
2025-12-19 00:19:52.207555:  
2025-12-19 00:19:52.207555: Epoch 787 
2025-12-19 00:19:52.221574: Current learning rate: 0.00249 
2025-12-19 00:22:10.545717: train_loss -0.8562 
2025-12-19 00:22:10.545717: val_loss -0.8739 
2025-12-19 00:22:10.555730: Pseudo dice [0.9245, 0.9549, 0.9373] 
2025-12-19 00:22:10.563477: Epoch time: 138.34 s 
2025-12-19 00:22:11.400148:  
2025-12-19 00:22:11.400148: Epoch 788 
2025-12-19 00:22:11.400148: Current learning rate: 0.00248 
2025-12-19 00:24:29.442208: train_loss -0.8601 
2025-12-19 00:24:29.457969: val_loss -0.8733 
2025-12-19 00:24:29.457969: Pseudo dice [0.9259, 0.9568, 0.9352] 
2025-12-19 00:24:29.457969: Epoch time: 138.04 s 
2025-12-19 00:24:30.109756:  
2025-12-19 00:24:30.109756: Epoch 789 
2025-12-19 00:24:30.125685: Current learning rate: 0.00247 
2025-12-19 00:26:48.225134: train_loss -0.861 
2025-12-19 00:26:48.226875: val_loss -0.8764 
2025-12-19 00:26:48.232882: Pseudo dice [0.9265, 0.9565, 0.938] 
2025-12-19 00:26:48.236886: Epoch time: 138.12 s 
2025-12-19 00:26:48.984855:  
2025-12-19 00:26:48.984855: Epoch 790 
2025-12-19 00:26:49.000733: Current learning rate: 0.00245 
2025-12-19 00:29:07.036000: train_loss -0.8585 
2025-12-19 00:29:07.038002: val_loss -0.8846 
2025-12-19 00:29:07.045748: Pseudo dice [0.9318, 0.9615, 0.9438] 
2025-12-19 00:29:07.049752: Epoch time: 138.05 s 
2025-12-19 00:29:07.715431:  
2025-12-19 00:29:07.715431: Epoch 791 
2025-12-19 00:29:07.715431: Current learning rate: 0.00244 
2025-12-19 00:31:25.787392: train_loss -0.8572 
2025-12-19 00:31:25.789394: val_loss -0.8698 
2025-12-19 00:31:25.795138: Pseudo dice [0.9255, 0.955, 0.9377] 
2025-12-19 00:31:25.797140: Epoch time: 138.07 s 
2025-12-19 00:31:26.458252:  
2025-12-19 00:31:26.458252: Epoch 792 
2025-12-19 00:31:26.474179: Current learning rate: 0.00243 
2025-12-19 00:33:44.651338: train_loss -0.8541 
2025-12-19 00:33:44.653340: val_loss -0.8728 
2025-12-19 00:33:44.661087: Pseudo dice [0.9309, 0.9578, 0.9284] 
2025-12-19 00:33:44.668834: Epoch time: 138.19 s 
2025-12-19 00:33:45.446995:  
2025-12-19 00:33:45.446995: Epoch 793 
2025-12-19 00:33:45.462775: Current learning rate: 0.00242 
2025-12-19 00:36:03.711941: train_loss -0.8482 
2025-12-19 00:36:03.711941: val_loss -0.8774 
2025-12-19 00:36:03.727738: Pseudo dice [0.9307, 0.9631, 0.9374] 
2025-12-19 00:36:03.727738: Epoch time: 138.26 s 
2025-12-19 00:36:04.552678:  
2025-12-19 00:36:04.552678: Epoch 794 
2025-12-19 00:36:04.552678: Current learning rate: 0.00241 
2025-12-19 00:38:22.769963: train_loss -0.8591 
2025-12-19 00:38:22.769963: val_loss -0.8709 
2025-12-19 00:38:22.769963: Pseudo dice [0.9231, 0.9548, 0.943] 
2025-12-19 00:38:22.769963: Epoch time: 138.22 s 
2025-12-19 00:38:23.435684:  
2025-12-19 00:38:23.435684: Epoch 795 
2025-12-19 00:38:23.435684: Current learning rate: 0.0024 
2025-12-19 00:40:41.555727: train_loss -0.8609 
2025-12-19 00:40:41.557729: val_loss -0.8852 
2025-12-19 00:40:41.562317: Pseudo dice [0.9326, 0.9624, 0.9464] 
2025-12-19 00:40:41.562317: Epoch time: 138.12 s 
2025-12-19 00:40:42.320145:  
2025-12-19 00:40:42.320145: Epoch 796 
2025-12-19 00:40:42.336244: Current learning rate: 0.00239 
2025-12-19 00:43:00.494617: train_loss -0.8574 
2025-12-19 00:43:00.494617: val_loss -0.8789 
2025-12-19 00:43:00.502364: Pseudo dice [0.9271, 0.9574, 0.9431] 
2025-12-19 00:43:00.508369: Epoch time: 138.17 s 
2025-12-19 00:43:00.516116: Yayy! New best EMA pseudo Dice: 0.9419 
2025-12-19 00:43:01.445702:  
2025-12-19 00:43:01.445702: Epoch 797 
2025-12-19 00:43:01.445702: Current learning rate: 0.00238 
2025-12-19 00:45:19.769773: train_loss -0.8617 
2025-12-19 00:45:19.771775: val_loss -0.8743 
2025-12-19 00:45:19.771775: Pseudo dice [0.9256, 0.9557, 0.946] 
2025-12-19 00:45:19.778324: Epoch time: 138.33 s 
2025-12-19 00:45:19.778324: Yayy! New best EMA pseudo Dice: 0.942 
2025-12-19 00:45:20.729810:  
2025-12-19 00:45:20.731813: Epoch 798 
2025-12-19 00:45:20.731813: Current learning rate: 0.00237 
2025-12-19 00:47:38.952540: train_loss -0.859 
2025-12-19 00:47:38.954041: val_loss -0.8738 
2025-12-19 00:47:38.960303: Pseudo dice [0.9287, 0.9532, 0.9397] 
2025-12-19 00:47:38.964306: Epoch time: 138.22 s 
2025-12-19 00:47:39.842990:  
2025-12-19 00:47:39.844992: Epoch 799 
2025-12-19 00:47:39.844992: Current learning rate: 0.00236 
2025-12-19 00:49:59.100657: train_loss -0.8504 
2025-12-19 00:49:59.104160: val_loss -0.8652 
2025-12-19 00:49:59.104160: Pseudo dice [0.923, 0.9532, 0.9316] 
2025-12-19 00:49:59.104160: Epoch time: 139.26 s 
2025-12-19 00:50:00.036371:  
2025-12-19 00:50:00.038373: Epoch 800 
2025-12-19 00:50:00.044230: Current learning rate: 0.00235 
2025-12-19 00:52:18.821812: train_loss -0.8619 
2025-12-19 00:52:18.821812: val_loss -0.895 
2025-12-19 00:52:18.827818: Pseudo dice [0.941, 0.9636, 0.9475] 
2025-12-19 00:52:18.833645: Epoch time: 138.79 s 
2025-12-19 00:52:18.839651: Yayy! New best EMA pseudo Dice: 0.9422 
2025-12-19 00:52:19.779027:  
2025-12-19 00:52:19.779027: Epoch 801 
2025-12-19 00:52:19.779027: Current learning rate: 0.00234 
2025-12-19 00:54:38.514163: train_loss -0.8561 
2025-12-19 00:54:38.515171: val_loss -0.8773 
2025-12-19 00:54:38.518036: Pseudo dice [0.9258, 0.96, 0.9473] 
2025-12-19 00:54:38.518036: Epoch time: 138.74 s 
2025-12-19 00:54:38.518036: Yayy! New best EMA pseudo Dice: 0.9424 
2025-12-19 00:54:39.472028:  
2025-12-19 00:54:39.472028: Epoch 802 
2025-12-19 00:54:39.472028: Current learning rate: 0.00233 
2025-12-19 00:56:58.267587: train_loss -0.8556 
2025-12-19 00:56:58.267587: val_loss -0.8702 
2025-12-19 00:56:58.275333: Pseudo dice [0.9205, 0.9512, 0.9455] 
2025-12-19 00:56:58.279337: Epoch time: 138.8 s 
2025-12-19 00:56:59.046315:  
2025-12-19 00:56:59.046315: Epoch 803 
2025-12-19 00:56:59.046315: Current learning rate: 0.00232 
2025-12-19 00:59:17.580174: train_loss -0.8562 
2025-12-19 00:59:17.580174: val_loss -0.8803 
2025-12-19 00:59:17.589192: Pseudo dice [0.9319, 0.9599, 0.9362] 
2025-12-19 00:59:17.597205: Epoch time: 138.55 s 
2025-12-19 00:59:18.272507:  
2025-12-19 00:59:18.272507: Epoch 804 
2025-12-19 00:59:18.272507: Current learning rate: 0.00231 
2025-12-19 01:01:36.592858: train_loss -0.8562 
2025-12-19 01:01:36.592858: val_loss -0.8753 
2025-12-19 01:01:36.592858: Pseudo dice [0.9272, 0.9558, 0.9431] 
2025-12-19 01:01:36.610546: Epoch time: 138.32 s 
2025-12-19 01:01:37.443228:  
2025-12-19 01:01:37.443228: Epoch 805 
2025-12-19 01:01:37.449206: Current learning rate: 0.0023 
2025-12-19 01:03:55.703164: train_loss -0.8548 
2025-12-19 01:03:55.703164: val_loss -0.8712 
2025-12-19 01:03:55.708908: Pseudo dice [0.9216, 0.9531, 0.9441] 
2025-12-19 01:03:55.708908: Epoch time: 138.26 s 
2025-12-19 01:03:56.527824:  
2025-12-19 01:03:56.527824: Epoch 806 
2025-12-19 01:03:56.529515: Current learning rate: 0.00229 
2025-12-19 01:06:14.713365: train_loss -0.8592 
2025-12-19 01:06:14.713365: val_loss -0.8767 
2025-12-19 01:06:14.729281: Pseudo dice [0.9282, 0.9575, 0.944] 
2025-12-19 01:06:14.729281: Epoch time: 138.2 s 
2025-12-19 01:06:15.395682:  
2025-12-19 01:06:15.395682: Epoch 807 
2025-12-19 01:06:15.395682: Current learning rate: 0.00228 
2025-12-19 01:08:33.554083: train_loss -0.8588 
2025-12-19 01:08:33.554083: val_loss -0.8737 
2025-12-19 01:08:33.561325: Pseudo dice [0.9259, 0.9547, 0.9373] 
2025-12-19 01:08:33.567331: Epoch time: 138.16 s 
2025-12-19 01:08:34.251654:  
2025-12-19 01:08:34.251654: Epoch 808 
2025-12-19 01:08:34.251654: Current learning rate: 0.00226 
2025-12-19 01:10:52.857283: train_loss -0.8574 
2025-12-19 01:10:52.859285: val_loss -0.879 
2025-12-19 01:10:52.865597: Pseudo dice [0.9277, 0.9562, 0.9419] 
2025-12-19 01:10:52.869602: Epoch time: 138.61 s 
2025-12-19 01:10:53.603991:  
2025-12-19 01:10:53.603991: Epoch 809 
2025-12-19 01:10:53.611584: Current learning rate: 0.00225 
2025-12-19 01:13:11.714190: train_loss -0.8557 
2025-12-19 01:13:11.716009: val_loss -0.8821 
2025-12-19 01:13:11.722015: Pseudo dice [0.9292, 0.9597, 0.9439] 
2025-12-19 01:13:11.726020: Epoch time: 138.11 s 
2025-12-19 01:13:12.548405:  
2025-12-19 01:13:12.548405: Epoch 810 
2025-12-19 01:13:12.548405: Current learning rate: 0.00224 
2025-12-19 01:15:30.652410: train_loss -0.8581 
2025-12-19 01:15:30.652410: val_loss -0.8759 
2025-12-19 01:15:30.658416: Pseudo dice [0.9269, 0.9535, 0.9479] 
2025-12-19 01:15:30.664421: Epoch time: 138.1 s 
2025-12-19 01:15:31.336008:  
2025-12-19 01:15:31.336008: Epoch 811 
2025-12-19 01:15:31.341560: Current learning rate: 0.00223 
2025-12-19 01:17:49.532230: train_loss -0.8562 
2025-12-19 01:17:49.532230: val_loss -0.8797 
2025-12-19 01:17:49.538236: Pseudo dice [0.9295, 0.9554, 0.9488] 
2025-12-19 01:17:49.539976: Epoch time: 138.2 s 
2025-12-19 01:17:50.222353:  
2025-12-19 01:17:50.222353: Epoch 812 
2025-12-19 01:17:50.228523: Current learning rate: 0.00222 
2025-12-19 01:20:08.370044: train_loss -0.856 
2025-12-19 01:20:08.370044: val_loss -0.8761 
2025-12-19 01:20:08.379798: Pseudo dice [0.9238, 0.9556, 0.9483] 
2025-12-19 01:20:08.383802: Epoch time: 138.15 s 
2025-12-19 01:20:09.126480:  
2025-12-19 01:20:09.128220: Epoch 813 
2025-12-19 01:20:09.129224: Current learning rate: 0.00221 
2025-12-19 01:22:27.345412: train_loss -0.8563 
2025-12-19 01:22:27.345412: val_loss -0.8784 
2025-12-19 01:22:27.349245: Pseudo dice [0.93, 0.9559, 0.9374] 
2025-12-19 01:22:27.349245: Epoch time: 138.22 s 
2025-12-19 01:22:28.027162:  
2025-12-19 01:22:28.027162: Epoch 814 
2025-12-19 01:22:28.027162: Current learning rate: 0.0022 
2025-12-19 01:24:46.338979: train_loss -0.8576 
2025-12-19 01:24:46.338979: val_loss -0.8796 
2025-12-19 01:24:46.345319: Pseudo dice [0.9305, 0.957, 0.935] 
2025-12-19 01:24:46.347322: Epoch time: 138.31 s 
2025-12-19 01:24:47.106721:  
2025-12-19 01:24:47.106721: Epoch 815 
2025-12-19 01:24:47.106721: Current learning rate: 0.00219 
2025-12-19 01:27:05.355545: train_loss -0.8602 
2025-12-19 01:27:05.355545: val_loss -0.8789 
2025-12-19 01:27:05.355545: Pseudo dice [0.928, 0.9582, 0.9388] 
2025-12-19 01:27:05.355545: Epoch time: 138.25 s 
2025-12-19 01:27:06.178825:  
2025-12-19 01:27:06.178825: Epoch 816 
2025-12-19 01:27:06.194591: Current learning rate: 0.00218 
2025-12-19 01:29:24.465570: train_loss -0.8611 
2025-12-19 01:29:24.465570: val_loss -0.8663 
2025-12-19 01:29:24.465570: Pseudo dice [0.9233, 0.9472, 0.9333] 
2025-12-19 01:29:24.465570: Epoch time: 138.29 s 
2025-12-19 01:29:25.141377:  
2025-12-19 01:29:25.141377: Epoch 817 
2025-12-19 01:29:25.147768: Current learning rate: 0.00217 
2025-12-19 01:31:43.360452: train_loss -0.8635 
2025-12-19 01:31:43.362456: val_loss -0.8752 
2025-12-19 01:31:43.370465: Pseudo dice [0.9298, 0.9589, 0.9312] 
2025-12-19 01:31:43.376210: Epoch time: 138.22 s 
2025-12-19 01:31:44.037658:  
2025-12-19 01:31:44.037658: Epoch 818 
2025-12-19 01:31:44.053481: Current learning rate: 0.00216 
2025-12-19 01:34:02.277924: train_loss -0.8599 
2025-12-19 01:34:02.277924: val_loss -0.8653 
2025-12-19 01:34:02.285732: Pseudo dice [0.9187, 0.9573, 0.9363] 
2025-12-19 01:34:02.289736: Epoch time: 138.24 s 
2025-12-19 01:34:02.957198:  
2025-12-19 01:34:02.957198: Epoch 819 
2025-12-19 01:34:02.957198: Current learning rate: 0.00215 
2025-12-19 01:36:21.077157: train_loss -0.8594 
2025-12-19 01:36:21.077157: val_loss -0.8791 
2025-12-19 01:36:21.095093: Pseudo dice [0.9301, 0.959, 0.941] 
2025-12-19 01:36:21.099097: Epoch time: 138.12 s 
2025-12-19 01:36:21.728064:  
2025-12-19 01:36:21.728064: Epoch 820 
2025-12-19 01:36:21.743914: Current learning rate: 0.00214 
2025-12-19 01:38:39.862907: train_loss -0.8538 
2025-12-19 01:38:39.864910: val_loss -0.8694 
2025-12-19 01:38:39.870917: Pseudo dice [0.9234, 0.9558, 0.9374] 
2025-12-19 01:38:39.872919: Epoch time: 138.13 s 
2025-12-19 01:38:40.530190:  
2025-12-19 01:38:40.532192: Epoch 821 
2025-12-19 01:38:40.532192: Current learning rate: 0.00213 
2025-12-19 01:40:58.578146: train_loss -0.8608 
2025-12-19 01:40:58.580149: val_loss -0.8722 
2025-12-19 01:40:58.586157: Pseudo dice [0.9237, 0.9565, 0.9394] 
2025-12-19 01:40:58.591447: Epoch time: 138.05 s 
2025-12-19 01:40:59.404001:  
2025-12-19 01:40:59.404001: Epoch 822 
2025-12-19 01:40:59.404001: Current learning rate: 0.00212 
2025-12-19 01:43:17.434431: train_loss -0.8594 
2025-12-19 01:43:17.434431: val_loss -0.8714 
2025-12-19 01:43:17.445935: Pseudo dice [0.9245, 0.9513, 0.9385] 
2025-12-19 01:43:17.449939: Epoch time: 138.03 s 
2025-12-19 01:43:18.098128:  
2025-12-19 01:43:18.098128: Epoch 823 
2025-12-19 01:43:18.098128: Current learning rate: 0.0021 
2025-12-19 01:45:36.246262: train_loss -0.8636 
2025-12-19 01:45:36.246262: val_loss -0.8797 
2025-12-19 01:45:36.246262: Pseudo dice [0.9283, 0.9574, 0.9446] 
2025-12-19 01:45:36.262289: Epoch time: 138.15 s 
2025-12-19 01:45:36.976378:  
2025-12-19 01:45:36.976378: Epoch 824 
2025-12-19 01:45:36.976378: Current learning rate: 0.00209 
2025-12-19 01:47:55.230092: train_loss -0.8592 
2025-12-19 01:47:55.230092: val_loss -0.883 
2025-12-19 01:47:55.236098: Pseudo dice [0.9315, 0.9582, 0.9468] 
2025-12-19 01:47:55.242104: Epoch time: 138.26 s 
2025-12-19 01:47:55.889227:  
2025-12-19 01:47:55.889227: Epoch 825 
2025-12-19 01:47:55.889227: Current learning rate: 0.00208 
2025-12-19 01:50:13.961223: train_loss -0.8573 
2025-12-19 01:50:13.961223: val_loss -0.8858 
2025-12-19 01:50:13.961223: Pseudo dice [0.9336, 0.9597, 0.9428] 
2025-12-19 01:50:13.976980: Epoch time: 138.07 s 
2025-12-19 01:50:14.640506:  
2025-12-19 01:50:14.640506: Epoch 826 
2025-12-19 01:50:14.640506: Current learning rate: 0.00207 
2025-12-19 01:52:32.911507: train_loss -0.8602 
2025-12-19 01:52:32.911507: val_loss -0.8807 
2025-12-19 01:52:32.918514: Pseudo dice [0.929, 0.9567, 0.9482] 
2025-12-19 01:52:32.920727: Epoch time: 138.27 s 
2025-12-19 01:52:33.658146:  
2025-12-19 01:52:33.658146: Epoch 827 
2025-12-19 01:52:33.658146: Current learning rate: 0.00206 
2025-12-19 01:54:51.942712: train_loss -0.8607 
2025-12-19 01:54:51.942712: val_loss -0.8789 
2025-12-19 01:54:51.948718: Pseudo dice [0.9289, 0.9582, 0.9417] 
2025-12-19 01:54:51.954724: Epoch time: 138.28 s 
2025-12-19 01:54:52.579853:  
2025-12-19 01:54:52.579853: Epoch 828 
2025-12-19 01:54:52.595902: Current learning rate: 0.00205 
2025-12-19 01:57:10.839687: train_loss -0.8652 
2025-12-19 01:57:10.839687: val_loss -0.8899 
2025-12-19 01:57:10.855340: Pseudo dice [0.9358, 0.9629, 0.9398] 
2025-12-19 01:57:10.855340: Epoch time: 138.26 s 
2025-12-19 01:57:10.855340: Yayy! New best EMA pseudo Dice: 0.9425 
2025-12-19 01:57:11.997550:  
2025-12-19 01:57:11.997550: Epoch 829 
2025-12-19 01:57:11.997550: Current learning rate: 0.00204 
2025-12-19 01:59:30.152996: train_loss -0.8638 
2025-12-19 01:59:30.154819: val_loss -0.8837 
2025-12-19 01:59:30.160825: Pseudo dice [0.9315, 0.9574, 0.9453] 
2025-12-19 01:59:30.164829: Epoch time: 138.16 s 
2025-12-19 01:59:30.170835: Yayy! New best EMA pseudo Dice: 0.9427 
2025-12-19 01:59:31.097703:  
2025-12-19 01:59:31.097703: Epoch 830 
2025-12-19 01:59:31.097703: Current learning rate: 0.00203 
2025-12-19 02:01:49.278834: train_loss -0.8628 
2025-12-19 02:01:49.278834: val_loss -0.8766 
2025-12-19 02:01:49.284839: Pseudo dice [0.9291, 0.9571, 0.9327] 
2025-12-19 02:01:49.290584: Epoch time: 138.18 s 
2025-12-19 02:01:50.011681:  
2025-12-19 02:01:50.013422: Epoch 831 
2025-12-19 02:01:50.016190: Current learning rate: 0.00202 
2025-12-19 02:04:08.238538: train_loss -0.8593 
2025-12-19 02:04:08.238538: val_loss -0.8763 
2025-12-19 02:04:08.248051: Pseudo dice [0.927, 0.9583, 0.943] 
2025-12-19 02:04:08.254093: Epoch time: 138.23 s 
2025-12-19 02:04:08.897456:  
2025-12-19 02:04:08.897456: Epoch 832 
2025-12-19 02:04:08.900169: Current learning rate: 0.00201 
2025-12-19 02:06:26.997820: train_loss -0.8607 
2025-12-19 02:06:26.997820: val_loss -0.8826 
2025-12-19 02:06:27.003407: Pseudo dice [0.9294, 0.9596, 0.9408] 
2025-12-19 02:06:27.009413: Epoch time: 138.1 s 
2025-12-19 02:06:27.669174:  
2025-12-19 02:06:27.671177: Epoch 833 
2025-12-19 02:06:27.672920: Current learning rate: 0.002 
2025-12-19 02:08:45.896767: train_loss -0.8626 
2025-12-19 02:08:45.896767: val_loss -0.8756 
2025-12-19 02:08:45.896767: Pseudo dice [0.9267, 0.9533, 0.9488] 
2025-12-19 02:08:45.896767: Epoch time: 138.23 s 
2025-12-19 02:08:46.549844:  
2025-12-19 02:08:46.549844: Epoch 834 
2025-12-19 02:08:46.553963: Current learning rate: 0.00199 
2025-12-19 02:11:04.904953: train_loss -0.8601 
2025-12-19 02:11:04.904953: val_loss -0.879 
2025-12-19 02:11:04.914701: Pseudo dice [0.93, 0.956, 0.9386] 
2025-12-19 02:11:04.920707: Epoch time: 138.36 s 
2025-12-19 02:11:05.560389:  
2025-12-19 02:11:05.560389: Epoch 835 
2025-12-19 02:11:05.560389: Current learning rate: 0.00198 
2025-12-19 02:13:23.669363: train_loss -0.8587 
2025-12-19 02:13:23.669363: val_loss -0.8743 
2025-12-19 02:13:23.671365: Pseudo dice [0.9244, 0.9555, 0.9397] 
2025-12-19 02:13:23.684613: Epoch time: 138.11 s 
2025-12-19 02:13:24.383518:  
2025-12-19 02:13:24.383518: Epoch 836 
2025-12-19 02:13:24.399359: Current learning rate: 0.00196 
2025-12-19 02:15:42.534425: train_loss -0.8599 
2025-12-19 02:15:42.534425: val_loss -0.8816 
2025-12-19 02:15:42.550237: Pseudo dice [0.9331, 0.962, 0.9402] 
2025-12-19 02:15:42.550237: Epoch time: 138.15 s 
2025-12-19 02:15:43.184424:  
2025-12-19 02:15:43.184424: Epoch 837 
2025-12-19 02:15:43.184424: Current learning rate: 0.00195 
2025-12-19 02:18:01.414402: train_loss -0.8641 
2025-12-19 02:18:01.414402: val_loss -0.8762 
2025-12-19 02:18:01.414402: Pseudo dice [0.9237, 0.954, 0.941] 
2025-12-19 02:18:01.430304: Epoch time: 138.23 s 
2025-12-19 02:18:02.047481:  
2025-12-19 02:18:02.047481: Epoch 838 
2025-12-19 02:18:02.063249: Current learning rate: 0.00194 
2025-12-19 02:20:20.184736: train_loss -0.8648 
2025-12-19 02:20:20.184736: val_loss -0.8868 
2025-12-19 02:20:20.184736: Pseudo dice [0.9351, 0.9609, 0.9378] 
2025-12-19 02:20:20.184736: Epoch time: 138.14 s 
2025-12-19 02:20:20.821925:  
2025-12-19 02:20:20.821925: Epoch 839 
2025-12-19 02:20:20.831938: Current learning rate: 0.00193 
2025-12-19 02:22:38.935257: train_loss -0.8629 
2025-12-19 02:22:38.935257: val_loss -0.8849 
2025-12-19 02:22:38.935257: Pseudo dice [0.9339, 0.9595, 0.9392] 
2025-12-19 02:22:38.935257: Epoch time: 138.11 s 
2025-12-19 02:22:39.573977:  
2025-12-19 02:22:39.575979: Epoch 840 
2025-12-19 02:22:39.577721: Current learning rate: 0.00192 
2025-12-19 02:24:57.723215: train_loss -0.8651 
2025-12-19 02:24:57.723215: val_loss -0.8856 
2025-12-19 02:24:57.731002: Pseudo dice [0.9346, 0.9599, 0.9384] 
2025-12-19 02:24:57.737008: Epoch time: 138.15 s 
2025-12-19 02:24:57.739010: Yayy! New best EMA pseudo Dice: 0.9428 
2025-12-19 02:24:58.818444:  
2025-12-19 02:24:58.818444: Epoch 841 
2025-12-19 02:24:58.834486: Current learning rate: 0.00191 
2025-12-19 02:27:16.946901: train_loss -0.8626 
2025-12-19 02:27:16.948904: val_loss -0.8779 
2025-12-19 02:27:16.948904: Pseudo dice [0.925, 0.9545, 0.9425] 
2025-12-19 02:27:16.955315: Epoch time: 138.13 s 
2025-12-19 02:27:17.614735:  
2025-12-19 02:27:17.614735: Epoch 842 
2025-12-19 02:27:17.620754: Current learning rate: 0.0019 
2025-12-19 02:29:35.527150: train_loss -0.8669 
2025-12-19 02:29:35.527150: val_loss -0.8848 
2025-12-19 02:29:35.546907: Pseudo dice [0.9294, 0.9621, 0.945] 
2025-12-19 02:29:35.552913: Epoch time: 137.93 s 
2025-12-19 02:29:35.556916: Yayy! New best EMA pseudo Dice: 0.9429 
2025-12-19 02:29:36.479404:  
2025-12-19 02:29:36.479404: Epoch 843 
2025-12-19 02:29:36.493273: Current learning rate: 0.00189 
2025-12-19 02:31:54.695480: train_loss -0.8626 
2025-12-19 02:31:54.695480: val_loss -0.8791 
2025-12-19 02:31:54.703488: Pseudo dice [0.93, 0.9568, 0.9359] 
2025-12-19 02:31:54.707492: Epoch time: 138.22 s 
2025-12-19 02:31:55.346330:  
2025-12-19 02:31:55.346330: Epoch 844 
2025-12-19 02:31:55.353445: Current learning rate: 0.00188 
2025-12-19 02:34:13.527336: train_loss -0.8567 
2025-12-19 02:34:13.527336: val_loss -0.8821 
2025-12-19 02:34:13.527336: Pseudo dice [0.9317, 0.9572, 0.9476] 
2025-12-19 02:34:13.539997: Epoch time: 138.18 s 
2025-12-19 02:34:13.543295: Yayy! New best EMA pseudo Dice: 0.9429 
2025-12-19 02:34:14.509162:  
2025-12-19 02:34:14.509162: Epoch 845 
2025-12-19 02:34:14.509162: Current learning rate: 0.00187 
2025-12-19 02:36:32.710570: train_loss -0.8617 
2025-12-19 02:36:32.710570: val_loss -0.8755 
2025-12-19 02:36:32.719765: Pseudo dice [0.9279, 0.9561, 0.944] 
2025-12-19 02:36:32.726511: Epoch time: 138.2 s 
2025-12-19 02:36:33.557430:  
2025-12-19 02:36:33.557430: Epoch 846 
2025-12-19 02:36:33.573215: Current learning rate: 0.00186 
2025-12-19 02:38:51.741091: train_loss -0.8601 
2025-12-19 02:38:51.741091: val_loss -0.879 
2025-12-19 02:38:51.753095: Pseudo dice [0.9311, 0.9563, 0.9411] 
2025-12-19 02:38:51.758841: Epoch time: 138.18 s 
2025-12-19 02:38:52.388669:  
2025-12-19 02:38:52.388669: Epoch 847 
2025-12-19 02:38:52.404294: Current learning rate: 0.00185 
2025-12-19 02:41:10.675260: train_loss -0.8589 
2025-12-19 02:41:10.675260: val_loss -0.8795 
2025-12-19 02:41:10.675260: Pseudo dice [0.9281, 0.9569, 0.9457] 
2025-12-19 02:41:10.675260: Epoch time: 138.29 s 
2025-12-19 02:41:10.692944: Yayy! New best EMA pseudo Dice: 0.943 
2025-12-19 02:41:11.661896:  
2025-12-19 02:41:11.661896: Epoch 848 
2025-12-19 02:41:11.668558: Current learning rate: 0.00184 
2025-12-19 02:43:29.653173: train_loss -0.8635 
2025-12-19 02:43:29.653173: val_loss -0.8785 
2025-12-19 02:43:29.653173: Pseudo dice [0.9293, 0.9564, 0.9396] 
2025-12-19 02:43:29.663594: Epoch time: 137.99 s 
2025-12-19 02:43:30.291294:  
2025-12-19 02:43:30.291294: Epoch 849 
2025-12-19 02:43:30.291294: Current learning rate: 0.00182 
2025-12-19 02:45:48.533319: train_loss -0.8608 
2025-12-19 02:45:48.533319: val_loss -0.8707 
2025-12-19 02:45:48.535935: Pseudo dice [0.9201, 0.955, 0.9458] 
2025-12-19 02:45:48.535935: Epoch time: 138.24 s 
2025-12-19 02:45:49.438667:  
2025-12-19 02:45:49.438667: Epoch 850 
2025-12-19 02:45:49.438667: Current learning rate: 0.00181 
2025-12-19 02:48:07.718066: train_loss -0.8625 
2025-12-19 02:48:07.718066: val_loss -0.8768 
2025-12-19 02:48:07.729577: Pseudo dice [0.9286, 0.9554, 0.9341] 
2025-12-19 02:48:07.733581: Epoch time: 138.28 s 
2025-12-19 02:48:08.362493:  
2025-12-19 02:48:08.362493: Epoch 851 
2025-12-19 02:48:08.376302: Current learning rate: 0.0018 
2025-12-19 02:50:26.573678: train_loss -0.8649 
2025-12-19 02:50:26.573678: val_loss -0.8865 
2025-12-19 02:50:26.594398: Pseudo dice [0.9354, 0.9617, 0.9443] 
2025-12-19 02:50:26.600404: Epoch time: 138.21 s 
2025-12-19 02:50:27.484426:  
2025-12-19 02:50:27.484426: Epoch 852 
2025-12-19 02:50:27.490974: Current learning rate: 0.00179 
2025-12-19 02:52:45.527710: train_loss -0.8607 
2025-12-19 02:52:45.527710: val_loss -0.8909 
2025-12-19 02:52:45.543807: Pseudo dice [0.9371, 0.9597, 0.9481] 
2025-12-19 02:52:45.543807: Epoch time: 138.05 s 
2025-12-19 02:52:45.543807: Yayy! New best EMA pseudo Dice: 0.9433 
2025-12-19 02:52:46.462801:  
2025-12-19 02:52:46.462801: Epoch 853 
2025-12-19 02:52:46.478559: Current learning rate: 0.00178 
2025-12-19 02:55:04.943769: train_loss -0.862 
2025-12-19 02:55:04.943769: val_loss -0.8756 
2025-12-19 02:55:04.953017: Pseudo dice [0.9256, 0.9568, 0.9442] 
2025-12-19 02:55:04.959023: Epoch time: 138.48 s 
2025-12-19 02:55:05.575692:  
2025-12-19 02:55:05.575692: Epoch 854 
2025-12-19 02:55:05.591493: Current learning rate: 0.00177 
2025-12-19 02:57:23.657552: train_loss -0.8618 
2025-12-19 02:57:23.657552: val_loss -0.8815 
2025-12-19 02:57:23.665769: Pseudo dice [0.9337, 0.9588, 0.939] 
2025-12-19 02:57:23.673777: Epoch time: 138.08 s 
2025-12-19 02:57:24.299095:  
2025-12-19 02:57:24.299095: Epoch 855 
2025-12-19 02:57:24.299095: Current learning rate: 0.00176 
2025-12-19 02:59:42.417429: train_loss -0.859 
2025-12-19 02:59:42.417429: val_loss -0.8754 
2025-12-19 02:59:42.428935: Pseudo dice [0.9264, 0.9526, 0.9413] 
2025-12-19 02:59:42.432939: Epoch time: 138.12 s 
2025-12-19 02:59:43.050288:  
2025-12-19 02:59:43.050288: Epoch 856 
2025-12-19 02:59:43.066223: Current learning rate: 0.00175 
2025-12-19 03:02:01.217775: train_loss -0.862 
2025-12-19 03:02:01.217775: val_loss -0.8769 
2025-12-19 03:02:01.225522: Pseudo dice [0.9279, 0.9599, 0.941] 
2025-12-19 03:02:01.231528: Epoch time: 138.17 s 
2025-12-19 03:02:01.938953:  
2025-12-19 03:02:01.938953: Epoch 857 
2025-12-19 03:02:01.938953: Current learning rate: 0.00174 
2025-12-19 03:04:19.908613: train_loss -0.8684 
2025-12-19 03:04:19.908613: val_loss -0.8782 
2025-12-19 03:04:19.918360: Pseudo dice [0.9298, 0.9567, 0.9344] 
2025-12-19 03:04:19.924368: Epoch time: 137.97 s 
2025-12-19 03:04:20.546207:  
2025-12-19 03:04:20.546207: Epoch 858 
2025-12-19 03:04:20.546207: Current learning rate: 0.00173 
2025-12-19 03:06:38.671880: train_loss -0.8642 
2025-12-19 03:06:38.671880: val_loss -0.8807 
2025-12-19 03:06:38.679889: Pseudo dice [0.9244, 0.958, 0.9504] 
2025-12-19 03:06:38.687638: Epoch time: 138.13 s 
2025-12-19 03:06:39.497529:  
2025-12-19 03:06:39.497529: Epoch 859 
2025-12-19 03:06:39.497529: Current learning rate: 0.00172 
2025-12-19 03:08:57.661282: train_loss -0.8627 
2025-12-19 03:08:57.661282: val_loss -0.8787 
2025-12-19 03:08:57.667495: Pseudo dice [0.9278, 0.9568, 0.938] 
2025-12-19 03:08:57.667495: Epoch time: 138.16 s 
2025-12-19 03:08:58.304308:  
2025-12-19 03:08:58.304308: Epoch 860 
2025-12-19 03:08:58.310525: Current learning rate: 0.0017 
2025-12-19 03:11:16.581661: train_loss -0.8589 
2025-12-19 03:11:16.583664: val_loss -0.8812 
2025-12-19 03:11:16.583664: Pseudo dice [0.93, 0.9544, 0.9461] 
2025-12-19 03:11:16.592126: Epoch time: 138.28 s 
2025-12-19 03:11:17.218315:  
2025-12-19 03:11:17.218315: Epoch 861 
2025-12-19 03:11:17.225582: Current learning rate: 0.00169 
2025-12-19 03:13:35.413634: train_loss -0.8591 
2025-12-19 03:13:35.413634: val_loss -0.8708 
2025-12-19 03:13:35.429644: Pseudo dice [0.9227, 0.9534, 0.9368] 
2025-12-19 03:13:35.429644: Epoch time: 138.2 s 
2025-12-19 03:13:36.050171:  
2025-12-19 03:13:36.050171: Epoch 862 
2025-12-19 03:13:36.050171: Current learning rate: 0.00168 
2025-12-19 03:15:54.059896: train_loss -0.862 
2025-12-19 03:15:54.061898: val_loss -0.876 
2025-12-19 03:15:54.061898: Pseudo dice [0.9252, 0.957, 0.9445] 
2025-12-19 03:15:54.070140: Epoch time: 138.01 s 
2025-12-19 03:15:54.688085:  
2025-12-19 03:15:54.688085: Epoch 863 
2025-12-19 03:15:54.704083: Current learning rate: 0.00167 
2025-12-19 03:18:12.691835: train_loss -0.8638 
2025-12-19 03:18:12.693838: val_loss -0.8769 
2025-12-19 03:18:12.701849: Pseudo dice [0.9258, 0.9542, 0.9448] 
2025-12-19 03:18:12.709596: Epoch time: 138.0 s 
2025-12-19 03:18:13.342695:  
2025-12-19 03:18:13.342695: Epoch 864 
2025-12-19 03:18:13.347673: Current learning rate: 0.00166 
2025-12-19 03:20:31.438920: train_loss -0.8558 
2025-12-19 03:20:31.438920: val_loss -0.8779 
2025-12-19 03:20:31.446928: Pseudo dice [0.9268, 0.9566, 0.9424] 
2025-12-19 03:20:31.452935: Epoch time: 138.11 s 
2025-12-19 03:20:32.235466:  
2025-12-19 03:20:32.235466: Epoch 865 
2025-12-19 03:20:32.255150: Current learning rate: 0.00165 
2025-12-19 03:22:50.378555: train_loss -0.8604 
2025-12-19 03:22:50.380558: val_loss -0.889 
2025-12-19 03:22:50.386544: Pseudo dice [0.9345, 0.9608, 0.9439] 
2025-12-19 03:22:50.392675: Epoch time: 138.14 s 
2025-12-19 03:22:51.074853:  
2025-12-19 03:22:51.074853: Epoch 866 
2025-12-19 03:22:51.094642: Current learning rate: 0.00164 
2025-12-19 03:25:09.147047: train_loss -0.8647 
2025-12-19 03:25:09.148788: val_loss -0.8779 
2025-12-19 03:25:09.155059: Pseudo dice [0.9285, 0.9571, 0.9411] 
2025-12-19 03:25:09.159658: Epoch time: 138.07 s 
2025-12-19 03:25:09.782438:  
2025-12-19 03:25:09.782438: Epoch 867 
2025-12-19 03:25:09.798263: Current learning rate: 0.00163 
2025-12-19 03:27:27.787060: train_loss -0.8662 
2025-12-19 03:27:27.787060: val_loss -0.8786 
2025-12-19 03:27:27.793066: Pseudo dice [0.9271, 0.9582, 0.9452] 
2025-12-19 03:27:27.798878: Epoch time: 138.0 s 
2025-12-19 03:27:28.431392:  
2025-12-19 03:27:28.431392: Epoch 868 
2025-12-19 03:27:28.431392: Current learning rate: 0.00162 
2025-12-19 03:29:46.393107: train_loss -0.8622 
2025-12-19 03:29:46.393107: val_loss -0.888 
2025-12-19 03:29:46.408851: Pseudo dice [0.9352, 0.9612, 0.9465] 
2025-12-19 03:29:46.418362: Epoch time: 137.96 s 
2025-12-19 03:29:47.102689:  
2025-12-19 03:29:47.102689: Epoch 869 
2025-12-19 03:29:47.122911: Current learning rate: 0.00161 
2025-12-19 03:32:05.460600: train_loss -0.856 
2025-12-19 03:32:05.460600: val_loss -0.8821 
2025-12-19 03:32:05.476456: Pseudo dice [0.9288, 0.9523, 0.9488] 
2025-12-19 03:32:05.485965: Epoch time: 138.36 s 
2025-12-19 03:32:06.111192:  
2025-12-19 03:32:06.111192: Epoch 870 
2025-12-19 03:32:06.124981: Current learning rate: 0.00159 
2025-12-19 03:34:24.242687: train_loss -0.8621 
2025-12-19 03:34:24.258317: val_loss -0.8771 
2025-12-19 03:34:24.258317: Pseudo dice [0.9283, 0.9563, 0.9363] 
2025-12-19 03:34:24.270730: Epoch time: 138.13 s 
2025-12-19 03:34:25.113000:  
2025-12-19 03:34:25.113000: Epoch 871 
2025-12-19 03:34:25.122360: Current learning rate: 0.00158 
2025-12-19 03:36:43.264248: train_loss -0.8668 
2025-12-19 03:36:43.264248: val_loss -0.8798 
2025-12-19 03:36:43.280259: Pseudo dice [0.9288, 0.9599, 0.9414] 
2025-12-19 03:36:43.285582: Epoch time: 138.15 s 
2025-12-19 03:36:43.993959:  
2025-12-19 03:36:43.993959: Epoch 872 
2025-12-19 03:36:44.013330: Current learning rate: 0.00157 
2025-12-19 03:39:02.094033: train_loss -0.8609 
2025-12-19 03:39:02.094033: val_loss -0.8813 
2025-12-19 03:39:02.096036: Pseudo dice [0.9307, 0.96, 0.9394] 
2025-12-19 03:39:02.108035: Epoch time: 138.1 s 
2025-12-19 03:39:02.786263:  
2025-12-19 03:39:02.786263: Epoch 873 
2025-12-19 03:39:02.802339: Current learning rate: 0.00156 
2025-12-19 03:41:21.146148: train_loss -0.8647 
2025-12-19 03:41:21.146148: val_loss -0.8783 
2025-12-19 03:41:21.146148: Pseudo dice [0.9301, 0.9552, 0.9391] 
2025-12-19 03:41:21.158392: Epoch time: 138.36 s 
2025-12-19 03:41:21.826808:  
2025-12-19 03:41:21.826808: Epoch 874 
2025-12-19 03:41:21.842560: Current learning rate: 0.00155 
2025-12-19 03:43:40.112751: train_loss -0.8588 
2025-12-19 03:43:40.112751: val_loss -0.8749 
2025-12-19 03:43:40.128566: Pseudo dice [0.9246, 0.9574, 0.9463] 
2025-12-19 03:43:40.128566: Epoch time: 138.29 s 
2025-12-19 03:43:40.778148:  
2025-12-19 03:43:40.778148: Epoch 875 
2025-12-19 03:43:40.778148: Current learning rate: 0.00154 
2025-12-19 03:45:58.890755: train_loss -0.86 
2025-12-19 03:45:58.890755: val_loss -0.8738 
2025-12-19 03:45:58.890755: Pseudo dice [0.9258, 0.9548, 0.9372] 
2025-12-19 03:45:58.890755: Epoch time: 138.11 s 
2025-12-19 03:45:59.587633:  
2025-12-19 03:45:59.587633: Epoch 876 
2025-12-19 03:45:59.587633: Current learning rate: 0.00153 
2025-12-19 03:48:17.811875: train_loss -0.862 
2025-12-19 03:48:17.811875: val_loss -0.8752 
2025-12-19 03:48:17.821634: Pseudo dice [0.924, 0.9554, 0.9422] 
2025-12-19 03:48:17.828855: Epoch time: 138.22 s 
2025-12-19 03:48:18.513210:  
2025-12-19 03:48:18.513210: Epoch 877 
2025-12-19 03:48:18.533029: Current learning rate: 0.00152 
2025-12-19 03:50:36.699311: train_loss -0.8639 
2025-12-19 03:50:36.699311: val_loss -0.8777 
2025-12-19 03:50:36.710276: Pseudo dice [0.93, 0.9587, 0.9352] 
2025-12-19 03:50:36.714300: Epoch time: 138.19 s 
2025-12-19 03:50:37.585573:  
2025-12-19 03:50:37.585573: Epoch 878 
2025-12-19 03:50:37.590910: Current learning rate: 0.00151 
2025-12-19 03:52:55.728189: train_loss -0.8622 
2025-12-19 03:52:55.728189: val_loss -0.8775 
2025-12-19 03:52:55.736199: Pseudo dice [0.928, 0.9583, 0.9415] 
2025-12-19 03:52:55.743947: Epoch time: 138.16 s 
2025-12-19 03:52:56.436050:  
2025-12-19 03:52:56.438053: Epoch 879 
2025-12-19 03:52:56.441798: Current learning rate: 0.00149 
2025-12-19 03:55:14.692155: train_loss -0.8593 
2025-12-19 03:55:14.692155: val_loss -0.8708 
2025-12-19 03:55:14.692155: Pseudo dice [0.9249, 0.9568, 0.9407] 
2025-12-19 03:55:14.708158: Epoch time: 138.26 s 
2025-12-19 03:55:15.378248:  
2025-12-19 03:55:15.378248: Epoch 880 
2025-12-19 03:55:15.384986: Current learning rate: 0.00148 
2025-12-19 03:57:33.700719: train_loss -0.8601 
2025-12-19 03:57:33.700719: val_loss -0.879 
2025-12-19 03:57:33.708528: Pseudo dice [0.9302, 0.9578, 0.9377] 
2025-12-19 03:57:33.708528: Epoch time: 138.32 s 
2025-12-19 03:57:34.365685:  
2025-12-19 03:57:34.365685: Epoch 881 
2025-12-19 03:57:34.385602: Current learning rate: 0.00147 
2025-12-19 03:59:52.397183: train_loss -0.8639 
2025-12-19 03:59:52.397183: val_loss -0.8767 
2025-12-19 03:59:52.413291: Pseudo dice [0.9305, 0.9556, 0.9374] 
2025-12-19 03:59:52.413291: Epoch time: 138.03 s 
2025-12-19 03:59:53.033294:  
2025-12-19 03:59:53.033294: Epoch 882 
2025-12-19 03:59:53.047156: Current learning rate: 0.00146 
2025-12-19 04:02:11.226870: train_loss -0.8678 
2025-12-19 04:02:11.226870: val_loss -0.8822 
2025-12-19 04:02:11.235299: Pseudo dice [0.9317, 0.9584, 0.9417] 
2025-12-19 04:02:11.235299: Epoch time: 138.19 s 
2025-12-19 04:02:11.860486:  
2025-12-19 04:02:11.860486: Epoch 883 
2025-12-19 04:02:11.876561: Current learning rate: 0.00145 
2025-12-19 04:04:30.264688: train_loss -0.8628 
2025-12-19 04:04:30.266692: val_loss -0.8731 
2025-12-19 04:04:30.270855: Pseudo dice [0.9212, 0.9554, 0.9489] 
2025-12-19 04:04:30.270855: Epoch time: 138.4 s 
2025-12-19 04:04:30.948082:  
2025-12-19 04:04:30.948082: Epoch 884 
2025-12-19 04:04:30.948082: Current learning rate: 0.00144 
2025-12-19 04:06:48.970800: train_loss -0.8635 
2025-12-19 04:06:48.970800: val_loss -0.8883 
2025-12-19 04:06:48.986707: Pseudo dice [0.9343, 0.9611, 0.9469] 
2025-12-19 04:06:48.986707: Epoch time: 138.02 s 
2025-12-19 04:06:49.858785:  
2025-12-19 04:06:49.858785: Epoch 885 
2025-12-19 04:06:49.858785: Current learning rate: 0.00143 
2025-12-19 04:09:08.257237: train_loss -0.8641 
2025-12-19 04:09:08.257237: val_loss -0.8755 
2025-12-19 04:09:08.275308: Pseudo dice [0.9224, 0.9553, 0.9482] 
2025-12-19 04:09:08.277311: Epoch time: 138.4 s 
2025-12-19 04:09:08.908025:  
2025-12-19 04:09:08.908025: Epoch 886 
2025-12-19 04:09:08.923784: Current learning rate: 0.00142 
2025-12-19 04:11:27.186862: train_loss -0.8632 
2025-12-19 04:11:27.188604: val_loss -0.8835 
2025-12-19 04:11:27.196615: Pseudo dice [0.9305, 0.9625, 0.9415] 
2025-12-19 04:11:27.204363: Epoch time: 138.28 s 
2025-12-19 04:11:27.838708:  
2025-12-19 04:11:27.838708: Epoch 887 
2025-12-19 04:11:27.852850: Current learning rate: 0.00141 
2025-12-19 04:13:45.948037: train_loss -0.8612 
2025-12-19 04:13:45.950038: val_loss -0.8804 
2025-12-19 04:13:45.951040: Pseudo dice [0.9306, 0.9573, 0.9427] 
2025-12-19 04:13:45.951040: Epoch time: 138.11 s 
2025-12-19 04:13:46.632890:  
2025-12-19 04:13:46.632890: Epoch 888 
2025-12-19 04:13:46.648670: Current learning rate: 0.00139 
2025-12-19 04:16:04.859926: train_loss -0.8625 
2025-12-19 04:16:04.859926: val_loss -0.8837 
2025-12-19 04:16:04.865933: Pseudo dice [0.9309, 0.9557, 0.9405] 
2025-12-19 04:16:04.875942: Epoch time: 138.23 s 
2025-12-19 04:16:05.564994:  
2025-12-19 04:16:05.564994: Epoch 889 
2025-12-19 04:16:05.580690: Current learning rate: 0.00138 
2025-12-19 04:18:23.717078: train_loss -0.8644 
2025-12-19 04:18:23.717078: val_loss -0.8782 
2025-12-19 04:18:23.732841: Pseudo dice [0.9295, 0.959, 0.9366] 
2025-12-19 04:18:23.732841: Epoch time: 138.15 s 
2025-12-19 04:18:24.397108:  
2025-12-19 04:18:24.397108: Epoch 890 
2025-12-19 04:18:24.397108: Current learning rate: 0.00137 
2025-12-19 04:20:42.421927: train_loss -0.8634 
2025-12-19 04:20:42.421927: val_loss -0.8817 
2025-12-19 04:20:42.427933: Pseudo dice [0.9298, 0.96, 0.9453] 
2025-12-19 04:20:42.433677: Epoch time: 138.02 s 
2025-12-19 04:20:43.232967:  
2025-12-19 04:20:43.232967: Epoch 891 
2025-12-19 04:20:43.240481: Current learning rate: 0.00136 
2025-12-19 04:23:01.301424: train_loss -0.8606 
2025-12-19 04:23:01.301424: val_loss -0.8746 
2025-12-19 04:23:01.316571: Pseudo dice [0.9252, 0.9592, 0.9398] 
2025-12-19 04:23:01.324809: Epoch time: 138.07 s 
2025-12-19 04:23:01.949632:  
2025-12-19 04:23:01.949632: Epoch 892 
2025-12-19 04:23:01.949632: Current learning rate: 0.00135 
2025-12-19 04:25:19.964744: train_loss -0.8637 
2025-12-19 04:25:19.964744: val_loss -0.8858 
2025-12-19 04:25:19.984855: Pseudo dice [0.9325, 0.9601, 0.9461] 
2025-12-19 04:25:19.988859: Epoch time: 138.03 s 
2025-12-19 04:25:20.711083:  
2025-12-19 04:25:20.711083: Epoch 893 
2025-12-19 04:25:20.711083: Current learning rate: 0.00134 
2025-12-19 04:27:38.962700: train_loss -0.8643 
2025-12-19 04:27:38.962700: val_loss -0.8819 
2025-12-19 04:27:38.962700: Pseudo dice [0.9305, 0.9571, 0.9466] 
2025-12-19 04:27:38.962700: Epoch time: 138.25 s 
2025-12-19 04:27:39.581138:  
2025-12-19 04:27:39.581138: Epoch 894 
2025-12-19 04:27:39.596884: Current learning rate: 0.00133 
2025-12-19 04:29:57.577326: train_loss -0.865 
2025-12-19 04:29:57.577326: val_loss -0.8887 
2025-12-19 04:29:57.584448: Pseudo dice [0.9378, 0.9646, 0.9346] 
2025-12-19 04:29:57.587045: Epoch time: 138.0 s 
2025-12-19 04:29:57.587045: Yayy! New best EMA pseudo Dice: 0.9435 
2025-12-19 04:29:58.483844:  
2025-12-19 04:29:58.483844: Epoch 895 
2025-12-19 04:29:58.486126: Current learning rate: 0.00132 
2025-12-19 04:32:16.516346: train_loss -0.8641 
2025-12-19 04:32:16.516346: val_loss -0.8707 
2025-12-19 04:32:16.531980: Pseudo dice [0.9244, 0.9558, 0.9323] 
2025-12-19 04:32:16.531980: Epoch time: 138.03 s 
2025-12-19 04:32:17.306920:  
2025-12-19 04:32:17.306920: Epoch 896 
2025-12-19 04:32:17.322881: Current learning rate: 0.0013 
2025-12-19 04:34:35.463950: train_loss -0.8651 
2025-12-19 04:34:35.465451: val_loss -0.8807 
2025-12-19 04:34:35.471457: Pseudo dice [0.9311, 0.9564, 0.9431] 
2025-12-19 04:34:35.477463: Epoch time: 138.16 s 
2025-12-19 04:34:36.105571:  
2025-12-19 04:34:36.105571: Epoch 897 
2025-12-19 04:34:36.111472: Current learning rate: 0.00129 
2025-12-19 04:36:54.151491: train_loss -0.8629 
2025-12-19 04:36:54.151491: val_loss -0.8851 
2025-12-19 04:36:54.163243: Pseudo dice [0.9306, 0.9589, 0.9468] 
2025-12-19 04:36:54.167247: Epoch time: 138.05 s 
2025-12-19 04:36:55.061971:  
2025-12-19 04:36:55.061971: Epoch 898 
2025-12-19 04:36:55.061971: Current learning rate: 0.00128 
2025-12-19 04:39:13.121730: train_loss -0.8694 
2025-12-19 04:39:13.122731: val_loss -0.8846 
2025-12-19 04:39:13.128738: Pseudo dice [0.9311, 0.959, 0.9441] 
2025-12-19 04:39:13.134744: Epoch time: 138.06 s 
2025-12-19 04:39:13.921369:  
2025-12-19 04:39:13.921369: Epoch 899 
2025-12-19 04:39:13.927115: Current learning rate: 0.00127 
2025-12-19 04:41:31.994016: train_loss -0.8621 
2025-12-19 04:41:31.994016: val_loss -0.8774 
2025-12-19 04:41:31.994016: Pseudo dice [0.9286, 0.9563, 0.9432] 
2025-12-19 04:41:31.994016: Epoch time: 138.07 s 
2025-12-19 04:41:32.884217:  
2025-12-19 04:41:32.884217: Epoch 900 
2025-12-19 04:41:32.897363: Current learning rate: 0.00126 
2025-12-19 04:43:51.048600: train_loss -0.8629 
2025-12-19 04:43:51.048600: val_loss -0.8875 
2025-12-19 04:43:51.060207: Pseudo dice [0.9334, 0.9601, 0.9455] 
2025-12-19 04:43:51.067714: Epoch time: 138.16 s 
2025-12-19 04:43:51.071718: Yayy! New best EMA pseudo Dice: 0.9436 
2025-12-19 04:43:52.022224:  
2025-12-19 04:43:52.022224: Epoch 901 
2025-12-19 04:43:52.022224: Current learning rate: 0.00125 
2025-12-19 04:46:10.153082: train_loss -0.8601 
2025-12-19 04:46:10.153082: val_loss -0.877 
2025-12-19 04:46:10.164754: Pseudo dice [0.9262, 0.9581, 0.939] 
2025-12-19 04:46:10.170763: Epoch time: 138.13 s 
2025-12-19 04:46:10.910823:  
2025-12-19 04:46:10.910823: Epoch 902 
2025-12-19 04:46:10.926849: Current learning rate: 0.00124 
2025-12-19 04:48:29.024918: train_loss -0.8652 
2025-12-19 04:48:29.024918: val_loss -0.8668 
2025-12-19 04:48:29.032665: Pseudo dice [0.9213, 0.9507, 0.9425] 
2025-12-19 04:48:29.038169: Epoch time: 138.11 s 
2025-12-19 04:48:29.665444:  
2025-12-19 04:48:29.665444: Epoch 903 
2025-12-19 04:48:29.665444: Current learning rate: 0.00122 
2025-12-19 04:50:47.682156: train_loss -0.8625 
2025-12-19 04:50:47.682156: val_loss -0.8819 
2025-12-19 04:50:47.694172: Pseudo dice [0.9295, 0.9605, 0.9394] 
2025-12-19 04:50:47.703929: Epoch time: 138.02 s 
2025-12-19 04:50:48.491788:  
2025-12-19 04:50:48.491788: Epoch 904 
2025-12-19 04:50:48.491788: Current learning rate: 0.00121 
2025-12-19 04:53:06.470064: train_loss -0.8607 
2025-12-19 04:53:06.470064: val_loss -0.8924 
2025-12-19 04:53:06.477573: Pseudo dice [0.9358, 0.9636, 0.9455] 
2025-12-19 04:53:06.483417: Epoch time: 137.98 s 
2025-12-19 04:53:07.263455:  
2025-12-19 04:53:07.263455: Epoch 905 
2025-12-19 04:53:07.270410: Current learning rate: 0.0012 
2025-12-19 04:55:25.542592: train_loss -0.8652 
2025-12-19 04:55:25.544593: val_loss -0.8811 
2025-12-19 04:55:25.552340: Pseudo dice [0.9292, 0.9599, 0.9403] 
2025-12-19 04:55:25.556344: Epoch time: 138.3 s 
2025-12-19 04:55:26.179461:  
2025-12-19 04:55:26.179461: Epoch 906 
2025-12-19 04:55:26.195234: Current learning rate: 0.00119 
2025-12-19 04:57:44.341047: train_loss -0.865 
2025-12-19 04:57:44.341047: val_loss -0.8898 
2025-12-19 04:57:44.348906: Pseudo dice [0.9338, 0.9602, 0.9477] 
2025-12-19 04:57:44.354912: Epoch time: 138.16 s 
2025-12-19 04:57:44.360656: Yayy! New best EMA pseudo Dice: 0.9438 
2025-12-19 04:57:45.247082:  
2025-12-19 04:57:45.247082: Epoch 907 
2025-12-19 04:57:45.262826: Current learning rate: 0.00118 
2025-12-19 05:00:03.310493: train_loss -0.8618 
2025-12-19 05:00:03.310493: val_loss -0.8883 
2025-12-19 05:00:03.318505: Pseudo dice [0.932, 0.9622, 0.946] 
2025-12-19 05:00:03.321509: Epoch time: 138.06 s 
2025-12-19 05:00:03.330298: Yayy! New best EMA pseudo Dice: 0.9441 
2025-12-19 05:00:04.444468:  
2025-12-19 05:00:04.444468: Epoch 908 
2025-12-19 05:00:04.451969: Current learning rate: 0.00117 
2025-12-19 05:02:22.646405: train_loss -0.8624 
2025-12-19 05:02:22.646405: val_loss -0.8808 
2025-12-19 05:02:22.646405: Pseudo dice [0.9293, 0.955, 0.936] 
2025-12-19 05:02:22.658785: Epoch time: 138.2 s 
2025-12-19 05:02:23.283262:  
2025-12-19 05:02:23.283262: Epoch 909 
2025-12-19 05:02:23.287202: Current learning rate: 0.00116 
2025-12-19 05:04:41.576255: train_loss -0.8623 
2025-12-19 05:04:41.576255: val_loss -0.8858 
2025-12-19 05:04:41.576255: Pseudo dice [0.9332, 0.9585, 0.9438] 
2025-12-19 05:04:41.592037: Epoch time: 138.29 s 
2025-12-19 05:04:42.376357:  
2025-12-19 05:04:42.376357: Epoch 910 
2025-12-19 05:04:42.376357: Current learning rate: 0.00115 
2025-12-19 05:07:00.321654: train_loss -0.863 
2025-12-19 05:07:00.321654: val_loss -0.8832 
2025-12-19 05:07:00.328162: Pseudo dice [0.929, 0.9564, 0.9495] 
2025-12-19 05:07:00.333667: Epoch time: 137.95 s 
2025-12-19 05:07:01.062442:  
2025-12-19 05:07:01.062442: Epoch 911 
2025-12-19 05:07:01.070453: Current learning rate: 0.00113 
2025-12-19 05:09:19.404330: train_loss -0.8596 
2025-12-19 05:09:19.406332: val_loss -0.8828 
2025-12-19 05:09:19.412338: Pseudo dice [0.9356, 0.9559, 0.9406] 
2025-12-19 05:09:19.418082: Epoch time: 138.34 s 
2025-12-19 05:09:20.091559:  
2025-12-19 05:09:20.091559: Epoch 912 
2025-12-19 05:09:20.094414: Current learning rate: 0.00112 
2025-12-19 05:11:38.511692: train_loss -0.8568 
2025-12-19 05:11:38.511692: val_loss -0.8786 
2025-12-19 05:11:38.521666: Pseudo dice [0.9285, 0.9563, 0.9434] 
2025-12-19 05:11:38.529412: Epoch time: 138.42 s 
2025-12-19 05:11:39.189377:  
2025-12-19 05:11:39.189377: Epoch 913 
2025-12-19 05:11:39.189377: Current learning rate: 0.00111 
2025-12-19 05:13:57.274463: train_loss -0.8655 
2025-12-19 05:13:57.274463: val_loss -0.8727 
2025-12-19 05:13:57.281965: Pseudo dice [0.9232, 0.9531, 0.9418] 
2025-12-19 05:13:57.287973: Epoch time: 138.09 s 
2025-12-19 05:13:58.004317:  
2025-12-19 05:13:58.004317: Epoch 914 
2025-12-19 05:13:58.004317: Current learning rate: 0.0011 
2025-12-19 05:16:16.041046: train_loss -0.867 
2025-12-19 05:16:16.041046: val_loss -0.8868 
2025-12-19 05:16:16.041046: Pseudo dice [0.933, 0.9621, 0.9421] 
2025-12-19 05:16:16.057074: Epoch time: 138.04 s 
2025-12-19 05:16:16.706038:  
2025-12-19 05:16:16.706038: Epoch 915 
2025-12-19 05:16:16.706038: Current learning rate: 0.00109 
2025-12-19 05:18:34.698854: train_loss -0.8674 
2025-12-19 05:18:34.698854: val_loss -0.8852 
2025-12-19 05:18:34.706862: Pseudo dice [0.931, 0.9584, 0.9502] 
2025-12-19 05:18:34.712868: Epoch time: 137.99 s 
2025-12-19 05:18:35.501711:  
2025-12-19 05:18:35.501711: Epoch 916 
2025-12-19 05:18:35.517392: Current learning rate: 0.00108 
2025-12-19 05:20:53.920088: train_loss -0.8656 
2025-12-19 05:20:53.920088: val_loss -0.8834 
2025-12-19 05:20:53.928105: Pseudo dice [0.9324, 0.9593, 0.944] 
2025-12-19 05:20:53.932109: Epoch time: 138.42 s 
2025-12-19 05:20:54.663550:  
2025-12-19 05:20:54.663550: Epoch 917 
2025-12-19 05:20:54.663550: Current learning rate: 0.00106 
2025-12-19 05:23:12.721630: train_loss -0.8636 
2025-12-19 05:23:12.721630: val_loss -0.8805 
2025-12-19 05:23:12.721630: Pseudo dice [0.9309, 0.9579, 0.9369] 
2025-12-19 05:23:12.731263: Epoch time: 138.06 s 
2025-12-19 05:23:13.345296:  
2025-12-19 05:23:13.345296: Epoch 918 
2025-12-19 05:23:13.361070: Current learning rate: 0.00105 
2025-12-19 05:25:31.486924: train_loss -0.8627 
2025-12-19 05:25:31.486924: val_loss -0.8884 
2025-12-19 05:25:31.492932: Pseudo dice [0.9356, 0.9606, 0.9395] 
2025-12-19 05:25:31.498938: Epoch time: 138.14 s 
2025-12-19 05:25:32.124090:  
2025-12-19 05:25:32.124090: Epoch 919 
2025-12-19 05:25:32.128475: Current learning rate: 0.00104 
2025-12-19 05:27:50.197673: train_loss -0.8613 
2025-12-19 05:27:50.199679: val_loss -0.8885 
2025-12-19 05:27:50.205687: Pseudo dice [0.9387, 0.9608, 0.9344] 
2025-12-19 05:27:50.211431: Epoch time: 138.07 s 
2025-12-19 05:27:50.922110:  
2025-12-19 05:27:50.922110: Epoch 920 
2025-12-19 05:27:50.922110: Current learning rate: 0.00103 
2025-12-19 05:30:09.048125: train_loss -0.8661 
2025-12-19 05:30:09.048125: val_loss -0.8739 
2025-12-19 05:30:09.053869: Pseudo dice [0.9235, 0.9558, 0.9441] 
2025-12-19 05:30:09.061122: Epoch time: 138.13 s 
2025-12-19 05:30:09.696774:  
2025-12-19 05:30:09.696774: Epoch 921 
2025-12-19 05:30:09.696774: Current learning rate: 0.00102 
2025-12-19 05:32:27.856635: train_loss -0.8596 
2025-12-19 05:32:27.856635: val_loss -0.8787 
2025-12-19 05:32:27.862641: Pseudo dice [0.9276, 0.9604, 0.9391] 
2025-12-19 05:32:27.870224: Epoch time: 138.16 s 
2025-12-19 05:32:28.494462:  
2025-12-19 05:32:28.494462: Epoch 922 
2025-12-19 05:32:28.510544: Current learning rate: 0.00101 
2025-12-19 05:34:46.796740: train_loss -0.8591 
2025-12-19 05:34:46.796740: val_loss -0.8838 
2025-12-19 05:34:46.810255: Pseudo dice [0.933, 0.9589, 0.9393] 
2025-12-19 05:34:46.816262: Epoch time: 138.3 s 
2025-12-19 05:34:47.699792:  
2025-12-19 05:34:47.699792: Epoch 923 
2025-12-19 05:34:47.699792: Current learning rate: 0.001 
2025-12-19 05:37:05.915381: train_loss -0.8642 
2025-12-19 05:37:05.915381: val_loss -0.8803 
2025-12-19 05:37:05.921629: Pseudo dice [0.9318, 0.9575, 0.9389] 
2025-12-19 05:37:05.927634: Epoch time: 138.22 s 
2025-12-19 05:37:06.559080:  
2025-12-19 05:37:06.559080: Epoch 924 
2025-12-19 05:37:06.560822: Current learning rate: 0.00098 
2025-12-19 05:39:24.485443: train_loss -0.8683 
2025-12-19 05:39:24.485443: val_loss -0.8854 
2025-12-19 05:39:24.501274: Pseudo dice [0.9325, 0.9618, 0.9462] 
2025-12-19 05:39:24.501274: Epoch time: 137.93 s 
2025-12-19 05:39:25.119738:  
2025-12-19 05:39:25.119738: Epoch 925 
2025-12-19 05:39:25.135376: Current learning rate: 0.00097 
2025-12-19 05:41:43.259551: train_loss -0.8659 
2025-12-19 05:41:43.259551: val_loss -0.8898 
2025-12-19 05:41:43.279475: Pseudo dice [0.9345, 0.9611, 0.9463] 
2025-12-19 05:41:43.285482: Epoch time: 138.14 s 
2025-12-19 05:41:43.291228: Yayy! New best EMA pseudo Dice: 0.9442 
2025-12-19 05:41:44.270873:  
2025-12-19 05:41:44.270873: Epoch 926 
2025-12-19 05:41:44.279799: Current learning rate: 0.00096 
2025-12-19 05:44:02.424746: train_loss -0.8616 
2025-12-19 05:44:02.424746: val_loss -0.8849 
2025-12-19 05:44:02.432247: Pseudo dice [0.9334, 0.9584, 0.9435] 
2025-12-19 05:44:02.438253: Epoch time: 138.15 s 
2025-12-19 05:44:02.443997: Yayy! New best EMA pseudo Dice: 0.9443 
2025-12-19 05:44:03.347096:  
2025-12-19 05:44:03.347096: Epoch 927 
2025-12-19 05:44:03.363012: Current learning rate: 0.00095 
2025-12-19 05:46:21.653628: train_loss -0.8616 
2025-12-19 05:46:21.653628: val_loss -0.8914 
2025-12-19 05:46:21.659634: Pseudo dice [0.9374, 0.9647, 0.9416] 
2025-12-19 05:46:21.667643: Epoch time: 138.31 s 
2025-12-19 05:46:21.672148: Yayy! New best EMA pseudo Dice: 0.9446 
2025-12-19 05:46:22.591284:  
2025-12-19 05:46:22.591284: Epoch 928 
2025-12-19 05:46:22.591284: Current learning rate: 0.00094 
2025-12-19 05:48:40.765960: train_loss -0.8616 
2025-12-19 05:48:40.765960: val_loss -0.8784 
2025-12-19 05:48:40.773710: Pseudo dice [0.9299, 0.9559, 0.9394] 
2025-12-19 05:48:40.773710: Epoch time: 138.17 s 
2025-12-19 05:48:41.572497:  
2025-12-19 05:48:41.572497: Epoch 929 
2025-12-19 05:48:41.572497: Current learning rate: 0.00092 
2025-12-19 05:50:59.656133: train_loss -0.8661 
2025-12-19 05:50:59.656133: val_loss -0.8855 
2025-12-19 05:50:59.656133: Pseudo dice [0.9332, 0.9593, 0.941] 
2025-12-19 05:50:59.672110: Epoch time: 138.1 s 
2025-12-19 05:51:00.300669:  
2025-12-19 05:51:00.300669: Epoch 930 
2025-12-19 05:51:00.307710: Current learning rate: 0.00091 
2025-12-19 05:53:18.433895: train_loss -0.865 
2025-12-19 05:53:18.433895: val_loss -0.8705 
2025-12-19 05:53:18.444406: Pseudo dice [0.9199, 0.9513, 0.9497] 
2025-12-19 05:53:18.449913: Epoch time: 138.14 s 
2025-12-19 05:53:19.144812:  
2025-12-19 05:53:19.144812: Epoch 931 
2025-12-19 05:53:19.155796: Current learning rate: 0.0009 
2025-12-19 05:55:37.387280: train_loss -0.8675 
2025-12-19 05:55:37.387280: val_loss -0.8833 
2025-12-19 05:55:37.397218: Pseudo dice [0.9315, 0.9582, 0.942] 
2025-12-19 05:55:37.403224: Epoch time: 138.24 s 
2025-12-19 05:55:38.067588:  
2025-12-19 05:55:38.067588: Epoch 932 
2025-12-19 05:55:38.067588: Current learning rate: 0.00089 
2025-12-19 05:57:56.169238: train_loss -0.8661 
2025-12-19 05:57:56.170979: val_loss -0.8843 
2025-12-19 05:57:56.177700: Pseudo dice [0.9333, 0.9588, 0.9318] 
2025-12-19 05:57:56.181704: Epoch time: 138.1 s 
2025-12-19 05:57:56.803693:  
2025-12-19 05:57:56.803693: Epoch 933 
2025-12-19 05:57:56.819437: Current learning rate: 0.00088 
2025-12-19 06:00:14.993037: train_loss -0.868 
2025-12-19 06:00:14.993037: val_loss -0.8808 
2025-12-19 06:00:15.009083: Pseudo dice [0.9276, 0.9559, 0.944] 
2025-12-19 06:00:15.013087: Epoch time: 138.19 s 
2025-12-19 06:00:15.673620:  
2025-12-19 06:00:15.673620: Epoch 934 
2025-12-19 06:00:15.694865: Current learning rate: 0.00087 
2025-12-19 06:02:33.793569: train_loss -0.8611 
2025-12-19 06:02:33.796754: val_loss -0.869 
2025-12-19 06:02:33.802762: Pseudo dice [0.9243, 0.9536, 0.9373] 
2025-12-19 06:02:33.810772: Epoch time: 138.12 s 
2025-12-19 06:02:34.662982:  
2025-12-19 06:02:34.662982: Epoch 935 
2025-12-19 06:02:34.662982: Current learning rate: 0.00085 
2025-12-19 06:04:52.767054: train_loss -0.8648 
2025-12-19 06:04:52.767054: val_loss -0.878 
2025-12-19 06:04:52.773061: Pseudo dice [0.9283, 0.955, 0.9398] 
2025-12-19 06:04:52.780183: Epoch time: 138.1 s 
2025-12-19 06:04:53.405394:  
2025-12-19 06:04:53.405394: Epoch 936 
2025-12-19 06:04:53.405394: Current learning rate: 0.00084 
2025-12-19 06:07:11.660577: train_loss -0.8603 
2025-12-19 06:07:11.660577: val_loss -0.8855 
2025-12-19 06:07:11.660577: Pseudo dice [0.9342, 0.9601, 0.9408] 
2025-12-19 06:07:11.660577: Epoch time: 138.26 s 
2025-12-19 06:07:12.290960:  
2025-12-19 06:07:12.290960: Epoch 937 
2025-12-19 06:07:12.306696: Current learning rate: 0.00083 
2025-12-19 06:09:30.690598: train_loss -0.8674 
2025-12-19 06:09:30.690598: val_loss -0.8844 
2025-12-19 06:09:30.700348: Pseudo dice [0.9328, 0.958, 0.9455] 
2025-12-19 06:09:30.710100: Epoch time: 138.4 s 
2025-12-19 06:09:31.414872:  
2025-12-19 06:09:31.414872: Epoch 938 
2025-12-19 06:09:31.414872: Current learning rate: 0.00082 
2025-12-19 06:11:49.783672: train_loss -0.8653 
2025-12-19 06:11:49.783672: val_loss -0.875 
2025-12-19 06:11:49.797180: Pseudo dice [0.9269, 0.9561, 0.9398] 
2025-12-19 06:11:49.804731: Epoch time: 138.37 s 
2025-12-19 06:11:50.438452:  
2025-12-19 06:11:50.438452: Epoch 939 
2025-12-19 06:11:50.441200: Current learning rate: 0.00081 
2025-12-19 06:14:08.703309: train_loss -0.864 
2025-12-19 06:14:08.705312: val_loss -0.8818 
2025-12-19 06:14:08.713060: Pseudo dice [0.9315, 0.9595, 0.941] 
2025-12-19 06:14:08.721069: Epoch time: 138.27 s 
2025-12-19 06:14:09.345860:  
2025-12-19 06:14:09.345860: Epoch 940 
2025-12-19 06:14:09.345860: Current learning rate: 0.00079 
2025-12-19 06:16:27.398955: train_loss -0.8671 
2025-12-19 06:16:27.398955: val_loss -0.877 
2025-12-19 06:16:27.406963: Pseudo dice [0.9257, 0.9542, 0.9428] 
2025-12-19 06:16:27.411023: Epoch time: 138.05 s 
2025-12-19 06:16:28.037168:  
2025-12-19 06:16:28.040677: Epoch 941 
2025-12-19 06:16:28.040677: Current learning rate: 0.00078 
2025-12-19 06:18:46.212415: train_loss -0.8695 
2025-12-19 06:18:46.212415: val_loss -0.8756 
2025-12-19 06:18:46.222921: Pseudo dice [0.9247, 0.9546, 0.947] 
2025-12-19 06:18:46.228427: Epoch time: 138.18 s 
2025-12-19 06:18:47.034250:  
2025-12-19 06:18:47.034250: Epoch 942 
2025-12-19 06:18:47.034250: Current learning rate: 0.00077 
2025-12-19 06:21:05.002068: train_loss -0.8648 
2025-12-19 06:21:05.002068: val_loss -0.8824 
2025-12-19 06:21:05.002068: Pseudo dice [0.9307, 0.9579, 0.9431] 
2025-12-19 06:21:05.017798: Epoch time: 137.98 s 
2025-12-19 06:21:05.635331:  
2025-12-19 06:21:05.635331: Epoch 943 
2025-12-19 06:21:05.635331: Current learning rate: 0.00076 
2025-12-19 06:23:23.761329: train_loss -0.8687 
2025-12-19 06:23:23.763332: val_loss -0.8754 
2025-12-19 06:23:23.773080: Pseudo dice [0.9251, 0.9561, 0.9444] 
2025-12-19 06:23:23.781088: Epoch time: 138.13 s 
2025-12-19 06:23:24.429775:  
2025-12-19 06:23:24.429775: Epoch 944 
2025-12-19 06:23:24.435930: Current learning rate: 0.00075 
2025-12-19 06:25:42.449858: train_loss -0.8688 
2025-12-19 06:25:42.449858: val_loss -0.8843 
2025-12-19 06:25:42.453862: Pseudo dice [0.9306, 0.9576, 0.9531] 
2025-12-19 06:25:42.461941: Epoch time: 138.02 s 
2025-12-19 06:25:43.086443:  
2025-12-19 06:25:43.086443: Epoch 945 
2025-12-19 06:25:43.086443: Current learning rate: 0.00074 
2025-12-19 06:28:01.185405: train_loss -0.8645 
2025-12-19 06:28:01.185405: val_loss -0.8789 
2025-12-19 06:28:01.191136: Pseudo dice [0.9286, 0.9581, 0.9438] 
2025-12-19 06:28:01.197142: Epoch time: 138.1 s 
2025-12-19 06:28:01.823019:  
2025-12-19 06:28:01.823019: Epoch 946 
2025-12-19 06:28:01.823019: Current learning rate: 0.00072 
2025-12-19 06:30:20.007633: train_loss -0.8682 
2025-12-19 06:30:20.007633: val_loss -0.8787 
2025-12-19 06:30:20.017391: Pseudo dice [0.93, 0.9582, 0.9366] 
2025-12-19 06:30:20.027164: Epoch time: 138.18 s 
2025-12-19 06:30:20.697646:  
2025-12-19 06:30:20.697646: Epoch 947 
2025-12-19 06:30:20.697646: Current learning rate: 0.00071 
2025-12-19 06:32:38.837785: train_loss -0.8633 
2025-12-19 06:32:38.837785: val_loss -0.8844 
2025-12-19 06:32:38.843530: Pseudo dice [0.9307, 0.9576, 0.9478] 
2025-12-19 06:32:38.849535: Epoch time: 138.14 s 
2025-12-19 06:32:39.487550:  
2025-12-19 06:32:39.487550: Epoch 948 
2025-12-19 06:32:39.487550: Current learning rate: 0.0007 
2025-12-19 06:34:57.748695: train_loss -0.8648 
2025-12-19 06:34:57.762645: val_loss -0.8847 
2025-12-19 06:34:57.762645: Pseudo dice [0.9309, 0.9605, 0.9448] 
2025-12-19 06:34:57.762645: Epoch time: 138.26 s 
2025-12-19 06:34:58.586730:  
2025-12-19 06:34:58.586730: Epoch 949 
2025-12-19 06:34:58.586730: Current learning rate: 0.00069 
2025-12-19 06:37:16.653780: train_loss -0.8698 
2025-12-19 06:37:16.653780: val_loss -0.8802 
2025-12-19 06:37:16.669567: Pseudo dice [0.9287, 0.954, 0.9451] 
2025-12-19 06:37:16.669567: Epoch time: 138.07 s 
2025-12-19 06:37:17.619200:  
2025-12-19 06:37:17.619200: Epoch 950 
2025-12-19 06:37:17.619200: Current learning rate: 0.00067 
2025-12-19 06:39:35.628320: train_loss -0.867 
2025-12-19 06:39:35.628320: val_loss -0.8854 
2025-12-19 06:39:35.632325: Pseudo dice [0.9337, 0.9608, 0.938] 
2025-12-19 06:39:35.632325: Epoch time: 138.01 s 
2025-12-19 06:39:36.267363:  
2025-12-19 06:39:36.267363: Epoch 951 
2025-12-19 06:39:36.267363: Current learning rate: 0.00066 
2025-12-19 06:41:54.568153: train_loss -0.8641 
2025-12-19 06:41:54.570156: val_loss -0.8894 
2025-12-19 06:41:54.575902: Pseudo dice [0.9353, 0.9615, 0.9423] 
2025-12-19 06:41:54.583647: Epoch time: 138.3 s 
2025-12-19 06:41:55.207321:  
2025-12-19 06:41:55.207321: Epoch 952 
2025-12-19 06:41:55.207321: Current learning rate: 0.00065 
2025-12-19 06:44:13.419553: train_loss -0.8647 
2025-12-19 06:44:13.421556: val_loss -0.8838 
2025-12-19 06:44:13.429928: Pseudo dice [0.9288, 0.9594, 0.9519] 
2025-12-19 06:44:13.437936: Epoch time: 138.21 s 
2025-12-19 06:44:14.151040:  
2025-12-19 06:44:14.151040: Epoch 953 
2025-12-19 06:44:14.166978: Current learning rate: 0.00064 
2025-12-19 06:46:32.257999: train_loss -0.8666 
2025-12-19 06:46:32.257999: val_loss -0.8875 
2025-12-19 06:46:32.266246: Pseudo dice [0.9343, 0.9619, 0.94] 
2025-12-19 06:46:32.266246: Epoch time: 138.11 s 
2025-12-19 06:46:32.904303:  
2025-12-19 06:46:32.904303: Epoch 954 
2025-12-19 06:46:32.904303: Current learning rate: 0.00063 
2025-12-19 06:48:51.041558: train_loss -0.866 
2025-12-19 06:48:51.043561: val_loss -0.8875 
2025-12-19 06:48:51.049568: Pseudo dice [0.9338, 0.9582, 0.9402] 
2025-12-19 06:48:51.055312: Epoch time: 138.15 s 
2025-12-19 06:48:51.848262:  
2025-12-19 06:48:51.848262: Epoch 955 
2025-12-19 06:48:51.848262: Current learning rate: 0.00061 
2025-12-19 06:51:09.860536: train_loss -0.8685 
2025-12-19 06:51:09.860536: val_loss -0.8833 
2025-12-19 06:51:09.868545: Pseudo dice [0.9303, 0.9549, 0.9454] 
2025-12-19 06:51:09.874288: Epoch time: 138.01 s 
2025-12-19 06:51:10.634307:  
2025-12-19 06:51:10.634307: Epoch 956 
2025-12-19 06:51:10.650241: Current learning rate: 0.0006 
2025-12-19 06:53:28.857978: train_loss -0.8677 
2025-12-19 06:53:28.859981: val_loss -0.8863 
2025-12-19 06:53:28.867221: Pseudo dice [0.9301, 0.9566, 0.9518] 
2025-12-19 06:53:28.867221: Epoch time: 138.22 s 
2025-12-19 06:53:29.564720:  
2025-12-19 06:53:29.564720: Epoch 957 
2025-12-19 06:53:29.564720: Current learning rate: 0.00059 
2025-12-19 06:55:47.699803: train_loss -0.8727 
2025-12-19 06:55:47.699803: val_loss -0.8825 
2025-12-19 06:55:47.707548: Pseudo dice [0.9309, 0.9601, 0.9449] 
2025-12-19 06:55:47.713554: Epoch time: 138.14 s 
2025-12-19 06:55:48.403736:  
2025-12-19 06:55:48.403736: Epoch 958 
2025-12-19 06:55:48.419646: Current learning rate: 0.00058 
2025-12-19 06:58:06.567202: train_loss -0.8634 
2025-12-19 06:58:06.567202: val_loss -0.8743 
2025-12-19 06:58:06.575212: Pseudo dice [0.9249, 0.9534, 0.9451] 
2025-12-19 06:58:06.578955: Epoch time: 138.16 s 
2025-12-19 06:58:07.335862:  
2025-12-19 06:58:07.335862: Epoch 959 
2025-12-19 06:58:07.351774: Current learning rate: 0.00056 
2025-12-19 07:00:25.373215: train_loss -0.8673 
2025-12-19 07:00:25.375217: val_loss -0.891 
2025-12-19 07:00:25.380960: Pseudo dice [0.9357, 0.959, 0.9501] 
2025-12-19 07:00:25.384964: Epoch time: 138.04 s 
2025-12-19 07:00:26.018128:  
2025-12-19 07:00:26.018128: Epoch 960 
2025-12-19 07:00:26.018128: Current learning rate: 0.00055 
2025-12-19 07:02:44.157502: train_loss -0.8649 
2025-12-19 07:02:44.157502: val_loss -0.8862 
2025-12-19 07:02:44.173222: Pseudo dice [0.9306, 0.9591, 0.9434] 
2025-12-19 07:02:44.173222: Epoch time: 138.14 s 
2025-12-19 07:02:44.853733:  
2025-12-19 07:02:44.853733: Epoch 961 
2025-12-19 07:02:44.869495: Current learning rate: 0.00054 
2025-12-19 07:05:03.209992: train_loss -0.8659 
2025-12-19 07:05:03.209992: val_loss -0.8919 
2025-12-19 07:05:03.213734: Pseudo dice [0.9386, 0.9616, 0.9421] 
2025-12-19 07:05:03.223243: Epoch time: 138.35 s 
2025-12-19 07:05:03.229250: Yayy! New best EMA pseudo Dice: 0.9448 
2025-12-19 07:05:04.447283:  
2025-12-19 07:05:04.447283: Epoch 962 
2025-12-19 07:05:04.447283: Current learning rate: 0.00053 
2025-12-19 07:07:22.532253: train_loss -0.8641 
2025-12-19 07:07:22.534255: val_loss -0.8773 
2025-12-19 07:07:22.540000: Pseudo dice [0.9266, 0.96, 0.9419] 
2025-12-19 07:07:22.546007: Epoch time: 138.08 s 
2025-12-19 07:07:23.275955:  
2025-12-19 07:07:23.275955: Epoch 963 
2025-12-19 07:07:23.293728: Current learning rate: 0.00051 
2025-12-19 07:09:41.844095: train_loss -0.8641 
2025-12-19 07:09:41.844095: val_loss -0.8815 
2025-12-19 07:09:41.851846: Pseudo dice [0.9281, 0.9573, 0.9423] 
2025-12-19 07:09:41.864857: Epoch time: 138.57 s 
2025-12-19 07:09:42.548236:  
2025-12-19 07:09:42.548236: Epoch 964 
2025-12-19 07:09:42.548236: Current learning rate: 0.0005 
2025-12-19 07:12:00.772732: train_loss -0.8697 
2025-12-19 07:12:00.772732: val_loss -0.8814 
2025-12-19 07:12:00.778738: Pseudo dice [0.9271, 0.9573, 0.9466] 
2025-12-19 07:12:00.784482: Epoch time: 138.22 s 
2025-12-19 07:12:01.510458:  
2025-12-19 07:12:01.510458: Epoch 965 
2025-12-19 07:12:01.510458: Current learning rate: 0.00049 
2025-12-19 07:14:19.722011: train_loss -0.8681 
2025-12-19 07:14:19.722011: val_loss -0.8816 
2025-12-19 07:14:19.733562: Pseudo dice [0.9288, 0.9592, 0.9459] 
2025-12-19 07:14:19.739643: Epoch time: 138.21 s 
2025-12-19 07:14:20.402038:  
2025-12-19 07:14:20.402038: Epoch 966 
2025-12-19 07:14:20.417829: Current learning rate: 0.00048 
2025-12-19 07:16:38.344476: train_loss -0.8693 
2025-12-19 07:16:38.346477: val_loss -0.8847 
2025-12-19 07:16:38.353264: Pseudo dice [0.9331, 0.9583, 0.9445] 
2025-12-19 07:16:38.353264: Epoch time: 137.94 s 
2025-12-19 07:16:38.983158:  
2025-12-19 07:16:38.983158: Epoch 967 
2025-12-19 07:16:38.998918: Current learning rate: 0.00046 
2025-12-19 07:18:57.185287: train_loss -0.8662 
2025-12-19 07:18:57.185287: val_loss -0.8808 
2025-12-19 07:18:57.193295: Pseudo dice [0.928, 0.957, 0.9441] 
2025-12-19 07:18:57.199589: Epoch time: 138.2 s 
2025-12-19 07:18:58.034077:  
2025-12-19 07:18:58.034077: Epoch 968 
2025-12-19 07:18:58.034077: Current learning rate: 0.00045 
2025-12-19 07:21:16.213401: train_loss -0.8686 
2025-12-19 07:21:16.215404: val_loss -0.8774 
2025-12-19 07:21:16.223151: Pseudo dice [0.9299, 0.9575, 0.9319] 
2025-12-19 07:21:16.232294: Epoch time: 138.18 s 
2025-12-19 07:21:16.872577:  
2025-12-19 07:21:16.872577: Epoch 969 
2025-12-19 07:21:16.886596: Current learning rate: 0.00044 
2025-12-19 07:23:35.137047: train_loss -0.8655 
2025-12-19 07:23:35.138788: val_loss -0.8883 
2025-12-19 07:23:35.144793: Pseudo dice [0.9363, 0.9636, 0.9384] 
2025-12-19 07:23:35.150799: Epoch time: 138.26 s 
2025-12-19 07:23:35.788311:  
2025-12-19 07:23:35.788311: Epoch 970 
2025-12-19 07:23:35.788311: Current learning rate: 0.00043 
2025-12-19 07:25:53.909625: train_loss -0.8661 
2025-12-19 07:25:53.909625: val_loss -0.8811 
2025-12-19 07:25:53.921382: Pseudo dice [0.9261, 0.9591, 0.9466] 
2025-12-19 07:25:53.929131: Epoch time: 138.12 s 
2025-12-19 07:25:54.586886:  
2025-12-19 07:25:54.586886: Epoch 971 
2025-12-19 07:25:54.586886: Current learning rate: 0.00041 
2025-12-19 07:28:12.680146: train_loss -0.8667 
2025-12-19 07:28:12.680146: val_loss -0.877 
2025-12-19 07:28:12.688538: Pseudo dice [0.9283, 0.9563, 0.9387] 
2025-12-19 07:28:12.696045: Epoch time: 138.1 s 
2025-12-19 07:28:13.328250:  
2025-12-19 07:28:13.328250: Epoch 972 
2025-12-19 07:28:13.328250: Current learning rate: 0.0004 
2025-12-19 07:30:31.504641: train_loss -0.8678 
2025-12-19 07:30:31.504641: val_loss -0.8839 
2025-12-19 07:30:31.504641: Pseudo dice [0.9309, 0.9577, 0.9518] 
2025-12-19 07:30:31.504641: Epoch time: 138.18 s 
2025-12-19 07:30:32.138703:  
2025-12-19 07:30:32.138703: Epoch 973 
2025-12-19 07:30:32.138703: Current learning rate: 0.00039 
2025-12-19 07:32:50.401731: train_loss -0.8655 
2025-12-19 07:32:50.401731: val_loss -0.8745 
2025-12-19 07:32:50.411482: Pseudo dice [0.9226, 0.9555, 0.9468] 
2025-12-19 07:32:50.419490: Epoch time: 138.26 s 
2025-12-19 07:32:51.441308:  
2025-12-19 07:32:51.441308: Epoch 974 
2025-12-19 07:32:51.441308: Current learning rate: 0.00037 
2025-12-19 07:35:09.560045: train_loss -0.8689 
2025-12-19 07:35:09.560045: val_loss -0.8796 
2025-12-19 07:35:09.575963: Pseudo dice [0.927, 0.956, 0.9484] 
2025-12-19 07:35:09.575963: Epoch time: 138.12 s 
2025-12-19 07:35:10.209042:  
2025-12-19 07:35:10.209042: Epoch 975 
2025-12-19 07:35:10.209042: Current learning rate: 0.00036 
2025-12-19 07:37:28.431905: train_loss -0.8667 
2025-12-19 07:37:28.431905: val_loss -0.875 
2025-12-19 07:37:28.431905: Pseudo dice [0.9224, 0.9515, 0.9445] 
2025-12-19 07:37:28.447652: Epoch time: 138.22 s 
2025-12-19 07:37:29.081496:  
2025-12-19 07:37:29.081496: Epoch 976 
2025-12-19 07:37:29.081496: Current learning rate: 0.00035 
2025-12-19 07:39:47.293460: train_loss -0.8647 
2025-12-19 07:39:47.293460: val_loss -0.8851 
2025-12-19 07:39:47.295462: Pseudo dice [0.9325, 0.9596, 0.9403] 
2025-12-19 07:39:47.307099: Epoch time: 138.21 s 
2025-12-19 07:39:48.093551:  
2025-12-19 07:39:48.093551: Epoch 977 
2025-12-19 07:39:48.097941: Current learning rate: 0.00034 
2025-12-19 07:42:06.426389: train_loss -0.8675 
2025-12-19 07:42:06.426389: val_loss -0.8847 
2025-12-19 07:42:06.440151: Pseudo dice [0.9338, 0.9611, 0.9407] 
2025-12-19 07:42:06.447898: Epoch time: 138.33 s 
2025-12-19 07:42:07.087984:  
2025-12-19 07:42:07.087984: Epoch 978 
2025-12-19 07:42:07.087984: Current learning rate: 0.00032 
2025-12-19 07:44:25.199426: train_loss -0.8716 
2025-12-19 07:44:25.199426: val_loss -0.8866 
2025-12-19 07:44:25.215063: Pseudo dice [0.9341, 0.9613, 0.936] 
2025-12-19 07:44:25.215063: Epoch time: 138.13 s 
2025-12-19 07:44:25.847386:  
2025-12-19 07:44:25.847386: Epoch 979 
2025-12-19 07:44:25.863102: Current learning rate: 0.00031 
2025-12-19 07:46:44.034494: train_loss -0.8644 
2025-12-19 07:46:44.034494: val_loss -0.8894 
2025-12-19 07:46:44.050299: Pseudo dice [0.9305, 0.9628, 0.9486] 
2025-12-19 07:46:44.050299: Epoch time: 138.19 s 
2025-12-19 07:46:45.008024:  
2025-12-19 07:46:45.010026: Epoch 980 
2025-12-19 07:46:45.010026: Current learning rate: 0.0003 
2025-12-19 07:49:03.092555: train_loss -0.8708 
2025-12-19 07:49:03.092555: val_loss -0.8884 
2025-12-19 07:49:03.104311: Pseudo dice [0.9309, 0.962, 0.9519] 
2025-12-19 07:49:03.110055: Epoch time: 138.08 s 
2025-12-19 07:49:03.745475:  
2025-12-19 07:49:03.745475: Epoch 981 
2025-12-19 07:49:03.759702: Current learning rate: 0.00028 
2025-12-19 07:51:21.939102: train_loss -0.8647 
2025-12-19 07:51:21.940844: val_loss -0.8846 
2025-12-19 07:51:21.948853: Pseudo dice [0.9307, 0.962, 0.9432] 
2025-12-19 07:51:21.958603: Epoch time: 138.19 s 
2025-12-19 07:51:22.592422:  
2025-12-19 07:51:22.592422: Epoch 982 
2025-12-19 07:51:22.592422: Current learning rate: 0.00027 
2025-12-19 07:53:40.818166: train_loss -0.8672 
2025-12-19 07:53:40.820169: val_loss -0.8732 
2025-12-19 07:53:40.829920: Pseudo dice [0.9218, 0.9533, 0.9495] 
2025-12-19 07:53:40.837667: Epoch time: 138.23 s 
2025-12-19 07:53:41.599513:  
2025-12-19 07:53:41.599513: Epoch 983 
2025-12-19 07:53:41.599513: Current learning rate: 0.00026 
2025-12-19 07:55:59.658710: train_loss -0.8706 
2025-12-19 07:55:59.660712: val_loss -0.8785 
2025-12-19 07:55:59.666718: Pseudo dice [0.9288, 0.9546, 0.9477] 
2025-12-19 07:55:59.672461: Epoch time: 138.06 s 
2025-12-19 07:56:00.307935:  
2025-12-19 07:56:00.307935: Epoch 984 
2025-12-19 07:56:00.324044: Current learning rate: 0.00024 
2025-12-19 07:58:18.315069: train_loss -0.868 
2025-12-19 07:58:18.315069: val_loss -0.8902 
2025-12-19 07:58:18.317072: Pseudo dice [0.9344, 0.9623, 0.9417] 
2025-12-19 07:58:18.317072: Epoch time: 138.01 s 
2025-12-19 07:58:19.042184:  
2025-12-19 07:58:19.042184: Epoch 985 
2025-12-19 07:58:19.057948: Current learning rate: 0.00023 
2025-12-19 08:00:37.356374: train_loss -0.8682 
2025-12-19 08:00:37.356374: val_loss -0.8784 
2025-12-19 08:00:37.362380: Pseudo dice [0.9241, 0.9574, 0.9483] 
2025-12-19 08:00:37.368386: Epoch time: 138.31 s 
2025-12-19 08:00:38.378362:  
2025-12-19 08:00:38.378362: Epoch 986 
2025-12-19 08:00:38.378362: Current learning rate: 0.00021 
2025-12-19 08:02:56.483520: train_loss -0.8689 
2025-12-19 08:02:56.483520: val_loss -0.8764 
2025-12-19 08:02:56.491735: Pseudo dice [0.9255, 0.9551, 0.9534] 
2025-12-19 08:02:56.496975: Epoch time: 138.11 s 
2025-12-19 08:02:57.218793:  
2025-12-19 08:02:57.218793: Epoch 987 
2025-12-19 08:02:57.232224: Current learning rate: 0.0002 
2025-12-19 08:05:15.426075: train_loss -0.8664 
2025-12-19 08:05:15.427901: val_loss -0.8787 
2025-12-19 08:05:15.431905: Pseudo dice [0.9269, 0.9583, 0.9434] 
2025-12-19 08:05:15.431905: Epoch time: 138.21 s 
2025-12-19 08:05:16.138127:  
2025-12-19 08:05:16.138127: Epoch 988 
2025-12-19 08:05:16.153881: Current learning rate: 0.00019 
2025-12-19 08:07:34.199299: train_loss -0.8702 
2025-12-19 08:07:34.199299: val_loss -0.8823 
2025-12-19 08:07:34.209047: Pseudo dice [0.9259, 0.957, 0.9505] 
2025-12-19 08:07:34.213051: Epoch time: 138.06 s 
2025-12-19 08:07:34.935933:  
2025-12-19 08:07:34.935933: Epoch 989 
2025-12-19 08:07:34.949940: Current learning rate: 0.00017 
2025-12-19 08:09:54.179106: train_loss -0.8644 
2025-12-19 08:09:54.179106: val_loss -0.8804 
2025-12-19 08:09:54.179106: Pseudo dice [0.9303, 0.9543, 0.9432] 
2025-12-19 08:09:54.179106: Epoch time: 139.24 s 
2025-12-19 08:09:54.900539:  
2025-12-19 08:09:54.900539: Epoch 990 
2025-12-19 08:09:54.916224: Current learning rate: 0.00016 
2025-12-19 08:12:13.169602: train_loss -0.868 
2025-12-19 08:12:13.169602: val_loss -0.8823 
2025-12-19 08:12:13.172606: Pseudo dice [0.9275, 0.9588, 0.9516] 
2025-12-19 08:12:13.172606: Epoch time: 138.27 s 
2025-12-19 08:12:13.812536:  
2025-12-19 08:12:13.812536: Epoch 991 
2025-12-19 08:12:13.828441: Current learning rate: 0.00014 
2025-12-19 08:14:32.096805: train_loss -0.8673 
2025-12-19 08:14:32.098545: val_loss -0.8829 
2025-12-19 08:14:32.108293: Pseudo dice [0.9338, 0.958, 0.942] 
2025-12-19 08:14:32.116300: Epoch time: 138.28 s 
2025-12-19 08:14:32.852508:  
2025-12-19 08:14:32.852508: Epoch 992 
2025-12-19 08:14:32.868563: Current learning rate: 0.00013 
2025-12-19 08:16:51.053445: train_loss -0.8679 
2025-12-19 08:16:51.053445: val_loss -0.8863 
2025-12-19 08:16:51.053445: Pseudo dice [0.9336, 0.9573, 0.9465] 
2025-12-19 08:16:51.071323: Epoch time: 138.2 s 
2025-12-19 08:16:51.868578:  
2025-12-19 08:16:51.868578: Epoch 993 
2025-12-19 08:16:51.884475: Current learning rate: 0.00011 
2025-12-19 08:19:10.013692: train_loss -0.872 
2025-12-19 08:19:10.013692: val_loss -0.8898 
2025-12-19 08:19:10.023701: Pseudo dice [0.9358, 0.9629, 0.9415] 
2025-12-19 08:19:10.031460: Epoch time: 138.15 s 
2025-12-19 08:19:10.668734:  
2025-12-19 08:19:10.668734: Epoch 994 
2025-12-19 08:19:10.668734: Current learning rate: 0.0001 
2025-12-19 08:21:28.938999: train_loss -0.864 
2025-12-19 08:21:28.938999: val_loss -0.8799 
2025-12-19 08:21:28.944744: Pseudo dice [0.9258, 0.9567, 0.9488] 
2025-12-19 08:21:28.951869: Epoch time: 138.27 s 
2025-12-19 08:21:29.750031:  
2025-12-19 08:21:29.750031: Epoch 995 
2025-12-19 08:21:29.750031: Current learning rate: 8e-05 
2025-12-19 08:23:47.924504: train_loss -0.8702 
2025-12-19 08:23:47.924504: val_loss -0.8818 
2025-12-19 08:23:47.943885: Pseudo dice [0.9274, 0.9592, 0.9428] 
2025-12-19 08:23:47.943885: Epoch time: 138.17 s 
2025-12-19 08:23:48.588402:  
2025-12-19 08:23:48.588402: Epoch 996 
2025-12-19 08:23:48.588402: Current learning rate: 7e-05 
2025-12-19 08:26:06.824187: train_loss -0.867 
2025-12-19 08:26:06.824187: val_loss -0.8866 
2025-12-19 08:26:06.839938: Pseudo dice [0.9319, 0.9572, 0.9483] 
2025-12-19 08:26:06.839938: Epoch time: 138.24 s 
2025-12-19 08:26:07.473414:  
2025-12-19 08:26:07.473414: Epoch 997 
2025-12-19 08:26:07.489185: Current learning rate: 5e-05 
2025-12-19 08:28:25.583501: train_loss -0.8674 
2025-12-19 08:28:25.585503: val_loss -0.8886 
2025-12-19 08:28:25.591247: Pseudo dice [0.934, 0.9631, 0.9472] 
2025-12-19 08:28:25.594711: Epoch time: 138.11 s 
2025-12-19 08:28:25.600649: Yayy! New best EMA pseudo Dice: 0.9449 
2025-12-19 08:28:26.527335:  
2025-12-19 08:28:26.527335: Epoch 998 
2025-12-19 08:28:26.541259: Current learning rate: 4e-05 
2025-12-19 08:30:44.639422: train_loss -0.8685 
2025-12-19 08:30:44.639422: val_loss -0.8862 
2025-12-19 08:30:44.643426: Pseudo dice [0.9299, 0.9619, 0.9513] 
2025-12-19 08:30:44.643426: Epoch time: 138.11 s 
2025-12-19 08:30:44.659058: Yayy! New best EMA pseudo Dice: 0.9452 
2025-12-19 08:30:45.788004:  
2025-12-19 08:30:45.788004: Epoch 999 
2025-12-19 08:30:45.790007: Current learning rate: 2e-05 
2025-12-19 08:33:04.043484: train_loss -0.8649 
2025-12-19 08:33:04.045486: val_loss -0.8807 
2025-12-19 08:33:04.055235: Pseudo dice [0.9325, 0.9585, 0.9351] 
2025-12-19 08:33:04.063244: Epoch time: 138.26 s 
2025-12-19 08:33:05.090122: Training done. 
2025-12-19 08:33:05.163525: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-19 08:33:05.163525: The split file contains 5 splits. 
2025-12-19 08:33:05.179626: Desired fold for training: 2 
2025-12-19 08:33:05.197919: This split has 400 training and 100 validation cases. 
2025-12-19 08:33:05.211366: predicting OAS30014_MR_d0196_7 
2025-12-19 08:33:05.479931: OAS30014_MR_d0196_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:33:25.455577: predicting OAS30014_MR_d0196_8 
2025-12-19 08:33:25.455577: OAS30014_MR_d0196_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:33:42.204875: predicting OAS30017_MR_d0054_3 
2025-12-19 08:33:42.222891: OAS30017_MR_d0054_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:33:58.958171: predicting OAS30017_MR_d0054_4 
2025-12-19 08:33:58.973857: OAS30017_MR_d0054_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:34:15.719516: predicting OAS30017_MR_d0054_5 
2025-12-19 08:34:15.719516: OAS30017_MR_d0054_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:34:32.462546: predicting OAS30025_MR_d0210_10 
2025-12-19 08:34:32.475166: OAS30025_MR_d0210_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:34:49.227192: predicting OAS30036_MR_d0059_9 
2025-12-19 08:34:49.240566: OAS30036_MR_d0059_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:35:05.963352: predicting OAS30039_MR_d1203_2 
2025-12-19 08:35:05.986114: OAS30039_MR_d1203_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:35:22.732595: predicting OAS30039_MR_d1203_4 
2025-12-19 08:35:22.743263: OAS30039_MR_d1203_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:35:39.490876: predicting OAS30039_MR_d1203_5 
2025-12-19 08:35:39.508557: OAS30039_MR_d1203_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:35:56.273760: predicting OAS30039_MR_d1203_7 
2025-12-19 08:35:56.295452: OAS30039_MR_d1203_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:36:13.043492: predicting OAS30039_MR_d1203_9 
2025-12-19 08:36:13.055324: OAS30039_MR_d1203_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:36:29.815817: predicting OAS30052_MR_d0693_3 
2025-12-19 08:36:29.824446: OAS30052_MR_d0693_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:36:46.554788: predicting OAS30052_MR_d0693_7 
2025-12-19 08:36:46.577798: OAS30052_MR_d0693_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:37:03.301434: predicting OAS30083_MR_d0465_10 
2025-12-19 08:37:03.315829: OAS30083_MR_d0465_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:37:20.052633: predicting OAS30087_MR_d0260_9 
2025-12-19 08:37:20.068430: OAS30087_MR_d0260_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:37:36.799148: predicting OAS30099_MR_d0032_5 
2025-12-19 08:37:36.806815: OAS30099_MR_d0032_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:37:53.535245: predicting OAS30102_MR_d0024_4 
2025-12-19 08:37:53.557173: OAS30102_MR_d0024_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:38:10.289899: predicting OAS30104_MR_d0328_4 
2025-12-19 08:38:10.314343: OAS30104_MR_d0328_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:38:27.055836: predicting OAS30104_MR_d0328_7 
2025-12-19 08:38:27.073947: OAS30104_MR_d0328_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:38:43.807440: predicting OAS30107_MR_d0387_1 
2025-12-19 08:38:43.815455: OAS30107_MR_d0387_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:39:00.541993: predicting OAS30107_MR_d0387_2 
2025-12-19 08:39:00.557802: OAS30107_MR_d0387_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:39:17.329958: predicting OAS30107_MR_d0387_7 
2025-12-19 08:39:17.340092: OAS30107_MR_d0387_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:39:34.076544: predicting OAS30125_MR_d0201_6 
2025-12-19 08:39:34.086637: OAS30125_MR_d0201_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:39:50.814892: predicting OAS30127_MR_d0098_1 
2025-12-19 08:39:50.826841: OAS30127_MR_d0098_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:40:07.546544: predicting OAS30127_MR_d0098_10 
2025-12-19 08:40:07.564497: OAS30127_MR_d0098_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:40:24.333075: predicting OAS30127_MR_d0098_5 
2025-12-19 08:40:24.343697: OAS30127_MR_d0098_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:40:41.086072: predicting OAS30127_MR_d0098_7 
2025-12-19 08:40:41.110837: OAS30127_MR_d0098_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:40:57.889864: predicting OAS30127_MR_d0098_9 
2025-12-19 08:40:57.899881: OAS30127_MR_d0098_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:41:14.647813: predicting OAS30134_MR_d0080_2 
2025-12-19 08:41:14.657616: OAS30134_MR_d0080_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:41:31.391556: predicting OAS30140_MR_d0172_5 
2025-12-19 08:41:31.401313: OAS30140_MR_d0172_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:41:48.122048: predicting OAS30147_MR_d0048_1 
2025-12-19 08:41:48.141811: OAS30147_MR_d0048_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:42:04.872485: predicting OAS30147_MR_d0048_3 
2025-12-19 08:42:04.884445: OAS30147_MR_d0048_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:42:21.658775: predicting OAS30147_MR_d0048_4 
2025-12-19 08:42:21.658775: OAS30147_MR_d0048_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:42:38.401988: predicting OAS30147_MR_d0048_7 
2025-12-19 08:42:38.410982: OAS30147_MR_d0048_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:42:55.145530: predicting OAS30147_MR_d0048_9 
2025-12-19 08:42:55.164698: OAS30147_MR_d0048_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:43:11.912992: predicting OAS30167_MR_d0111_5 
2025-12-19 08:43:11.921374: OAS30167_MR_d0111_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:43:28.649956: predicting OAS30176_MR_d0000_2 
2025-12-19 08:43:28.662444: OAS30176_MR_d0000_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:43:45.373481: predicting OAS30176_MR_d0000_9 
2025-12-19 08:43:45.396047: OAS30176_MR_d0000_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:44:02.151570: predicting OAS30195_MR_d1596_7 
2025-12-19 08:44:02.164924: OAS30195_MR_d1596_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:44:18.956748: predicting OAS30226_MR_d0183_2 
2025-12-19 08:44:18.967911: OAS30226_MR_d0183_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:44:35.695157: predicting OAS30226_MR_d0183_9 
2025-12-19 08:44:35.705988: OAS30226_MR_d0183_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:44:52.472626: predicting OAS30234_MR_d2098_9 
2025-12-19 08:44:52.492356: OAS30234_MR_d2098_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:45:09.222697: predicting OAS30238_MR_d0037_3 
2025-12-19 08:45:09.230901: OAS30238_MR_d0037_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:45:26.004443: predicting OAS30238_MR_d0037_9 
2025-12-19 08:45:26.017911: OAS30238_MR_d0037_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:45:42.743142: predicting OAS30250_MR_d0389_3 
2025-12-19 08:45:42.752913: OAS30250_MR_d0389_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:45:59.476436: predicting OAS30250_MR_d0389_4 
2025-12-19 08:45:59.486454: OAS30250_MR_d0389_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:46:16.216479: predicting OAS30250_MR_d0389_6 
2025-12-19 08:46:16.229818: OAS30250_MR_d0389_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:46:32.952113: predicting OAS30262_MR_d0037_5 
2025-12-19 08:46:32.974146: OAS30262_MR_d0037_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:46:49.710545: predicting OAS30262_MR_d0037_6 
2025-12-19 08:46:49.718268: OAS30262_MR_d0037_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:47:06.464904: predicting OAS30274_MR_d3332_1 
2025-12-19 08:47:06.486142: OAS30274_MR_d3332_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:47:23.247147: predicting OAS30274_MR_d3332_3 
2025-12-19 08:47:23.264893: OAS30274_MR_d3332_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:47:39.995805: predicting OAS30274_MR_d3332_5 
2025-12-19 08:47:40.006696: OAS30274_MR_d3332_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:47:56.734012: predicting OAS30292_MR_d0165_2 
2025-12-19 08:47:56.757675: OAS30292_MR_d0165_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:48:13.483404: predicting OAS30292_MR_d0165_6 
2025-12-19 08:48:13.499048: OAS30292_MR_d0165_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:48:30.220617: predicting OAS30300_MR_d0100_6 
2025-12-19 08:48:30.236640: OAS30300_MR_d0100_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:48:46.967800: predicting OAS30300_MR_d0100_8 
2025-12-19 08:48:46.979009: OAS30300_MR_d0100_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:49:03.709458: predicting OAS30302_MR_d0262_10 
2025-12-19 08:49:03.727299: OAS30302_MR_d0262_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:49:20.447858: predicting OAS30302_MR_d0262_7 
2025-12-19 08:49:20.467681: OAS30302_MR_d0262_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:49:37.179617: predicting OAS30306_MR_d0028_1 
2025-12-19 08:49:37.204069: OAS30306_MR_d0028_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:49:53.964109: predicting OAS30306_MR_d0028_8 
2025-12-19 08:49:53.979865: OAS30306_MR_d0028_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:50:10.746253: predicting OAS30321_MR_d3003_1 
2025-12-19 08:50:10.764360: OAS30321_MR_d3003_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:50:27.490380: predicting OAS30321_MR_d3003_4 
2025-12-19 08:50:27.506009: OAS30321_MR_d3003_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:50:44.241111: predicting OAS30321_MR_d3003_6 
2025-12-19 08:50:44.251182: OAS30321_MR_d3003_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:51:00.997309: predicting OAS30321_MR_d3003_8 
2025-12-19 08:51:01.009213: OAS30321_MR_d3003_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:51:17.730018: predicting OAS30321_MR_d3003_9 
2025-12-19 08:51:17.752109: OAS30321_MR_d3003_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:51:34.482194: predicting OAS30325_MR_d0032_8 
2025-12-19 08:51:34.495774: OAS30325_MR_d0032_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:51:51.273049: predicting OAS30343_MR_d4178_4 
2025-12-19 08:51:51.285925: OAS30343_MR_d4178_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:52:08.043189: predicting OAS30343_MR_d4178_9 
2025-12-19 08:52:08.051059: OAS30343_MR_d4178_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:52:24.822605: predicting OAS30349_MR_d0699_1 
2025-12-19 08:52:24.832517: OAS30349_MR_d0699_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:52:41.562523: predicting OAS30349_MR_d0699_4 
2025-12-19 08:52:41.570538: OAS30349_MR_d0699_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:52:58.327792: predicting OAS30349_MR_d0699_8 
2025-12-19 08:52:58.341914: OAS30349_MR_d0699_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:53:15.082111: predicting OAS30350_MR_d0018_5 
2025-12-19 08:53:15.097251: OAS30350_MR_d0018_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:53:31.835168: predicting OAS30352_MR_d0099_4 
2025-12-19 08:53:31.844034: OAS30352_MR_d0099_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:53:48.611955: predicting OAS30352_MR_d0099_6 
2025-12-19 08:53:48.619922: OAS30352_MR_d0099_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:54:05.358206: predicting OAS30354_MR_d0056_1 
2025-12-19 08:54:05.380130: OAS30354_MR_d0056_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:54:22.117763: predicting OAS30354_MR_d0056_2 
2025-12-19 08:54:22.127949: OAS30354_MR_d0056_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:54:38.862920: predicting OAS30354_MR_d0056_9 
2025-12-19 08:54:38.872002: OAS30354_MR_d0056_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:54:55.597474: predicting OAS30355_MR_d0048_3 
2025-12-19 08:54:55.606545: OAS30355_MR_d0048_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:55:12.358996: predicting OAS30355_MR_d0048_6 
2025-12-19 08:55:12.371765: OAS30355_MR_d0048_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:55:29.106082: predicting OAS30361_MR_d1457_3 
2025-12-19 08:55:29.119380: OAS30361_MR_d1457_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:55:45.872919: predicting OAS30361_MR_d1457_7 
2025-12-19 08:55:45.890583: OAS30361_MR_d1457_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:56:02.619496: predicting OAS30367_MR_d1540_2 
2025-12-19 08:56:02.643171: OAS30367_MR_d1540_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:56:19.386618: predicting OAS30367_MR_d1540_6 
2025-12-19 08:56:19.397636: OAS30367_MR_d1540_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:56:36.142198: predicting OAS30367_MR_d1540_8 
2025-12-19 08:56:36.151541: OAS30367_MR_d1540_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:56:52.894622: predicting OAS30369_MR_d4058_10 
2025-12-19 08:56:52.904459: OAS30369_MR_d4058_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:57:09.697634: predicting OAS30369_MR_d4058_2 
2025-12-19 08:57:09.708275: OAS30369_MR_d4058_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:57:26.452096: predicting OAS30371_MR_d0338_3 
2025-12-19 08:57:26.452096: OAS30371_MR_d0338_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:57:43.190436: predicting OAS30371_MR_d0338_5 
2025-12-19 08:57:43.208295: OAS30371_MR_d0338_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:57:59.936004: predicting OAS30371_MR_d0338_7 
2025-12-19 08:57:59.952044: OAS30371_MR_d0338_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:58:16.718182: predicting OAS30373_MR_d1211_8 
2025-12-19 08:58:16.737833: OAS30373_MR_d1211_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:58:33.501601: predicting OAS30379_MR_d2106_2 
2025-12-19 08:58:33.518740: OAS30379_MR_d2106_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:58:50.312766: predicting OAS30379_MR_d2106_3 
2025-12-19 08:58:50.322093: OAS30379_MR_d2106_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:59:07.093355: predicting OAS30379_MR_d2106_7 
2025-12-19 08:59:07.105470: OAS30379_MR_d2106_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:59:23.892780: predicting OAS30379_MR_d2106_8 
2025-12-19 08:59:23.903430: OAS30379_MR_d2106_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:59:40.676071: predicting OAS30380_MR_d3446_2 
2025-12-19 08:59:40.688038: OAS30380_MR_d3446_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 08:59:57.433002: predicting OAS30380_MR_d3446_6 
2025-12-19 08:59:57.450710: OAS30380_MR_d3446_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 09:00:14.165278: predicting OAS30383_MR_d0134_6 
2025-12-19 09:00:14.186544: OAS30383_MR_d0134_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 09:00:30.954693: predicting OAS30383_MR_d0134_9 
2025-12-19 09:00:30.964202: OAS30383_MR_d0134_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 09:00:47.701690: predicting OAS30388_MR_d0073_8 
2025-12-19 09:00:47.724864: OAS30388_MR_d0073_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-19 09:01:29.042474: Validation complete 
2025-12-19 09:01:29.042474: Mean Validation Dice:  0.932712131954295 
