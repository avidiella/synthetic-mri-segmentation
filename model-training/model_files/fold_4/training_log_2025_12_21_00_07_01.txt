
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-12-21 00:07:01.388072: do_dummy_2d_data_aug: False 
2025-12-21 00:07:01.403735: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-21 00:07:01.403735: The split file contains 5 splits. 
2025-12-21 00:07:01.403735: Desired fold for training: 4 
2025-12-21 00:07:01.403735: This split has 400 training and 100 validation cases. 
2025-12-21 00:07:34.389931: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [202, 202, 202], 'spacing': [1.2667700813876164, 1.2667700813876164, 1.2667700813876164], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset500_MRI', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [256, 256, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1.0000001192092896, 'mean': 0.422696590423584, 'median': 0.4194243550300598, 'min': 0.0027002037968486547, 'percentile_00_5': 0.05628390982747078, 'percentile_99_5': 0.8565635681152344, 'std': 0.19347868859767914}}} 
 
2025-12-21 00:07:34.389931: unpacking dataset... 
2025-12-21 00:07:34.968829: unpacking done... 
2025-12-21 00:07:34.968829: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-12-21 00:07:35.007991:  
2025-12-21 00:07:35.007991: Epoch 0 
2025-12-21 00:07:35.007991: Current learning rate: 0.01 
2025-12-21 00:10:03.804550: train_loss 0.2137 
2025-12-21 00:10:03.804550: val_loss 0.0404 
2025-12-21 00:10:03.806553: Pseudo dice [0.4974, 0.5511, 0.0] 
2025-12-21 00:10:03.806553: Epoch time: 148.81 s 
2025-12-21 00:10:03.806553: Yayy! New best EMA pseudo Dice: 0.3495 
2025-12-21 00:10:04.675283:  
2025-12-21 00:10:04.675283: Epoch 1 
2025-12-21 00:10:04.675283: Current learning rate: 0.00999 
2025-12-21 00:12:22.884391: train_loss -0.0337 
2025-12-21 00:12:22.884391: val_loss -0.0878 
2025-12-21 00:12:22.886132: Pseudo dice [0.5355, 0.5695, 0.3855] 
2025-12-21 00:12:22.886132: Epoch time: 138.21 s 
2025-12-21 00:12:22.886132: Yayy! New best EMA pseudo Dice: 0.3643 
2025-12-21 00:12:23.898476:  
2025-12-21 00:12:23.898476: Epoch 2 
2025-12-21 00:12:23.898476: Current learning rate: 0.00998 
2025-12-21 00:14:42.343448: train_loss -0.1303 
2025-12-21 00:14:42.343448: val_loss -0.1565 
2025-12-21 00:14:42.345454: Pseudo dice [0.5659, 0.5627, 0.4579] 
2025-12-21 00:14:42.347462: Epoch time: 138.44 s 
2025-12-21 00:14:42.349467: Yayy! New best EMA pseudo Dice: 0.3807 
2025-12-21 00:14:43.293688:  
2025-12-21 00:14:43.293688: Epoch 3 
2025-12-21 00:14:43.293688: Current learning rate: 0.00997 
2025-12-21 00:17:01.485509: train_loss -0.1977 
2025-12-21 00:17:01.485509: val_loss -0.1733 
2025-12-21 00:17:01.487511: Pseudo dice [0.5757, 0.6109, 0.4575] 
2025-12-21 00:17:01.487511: Epoch time: 138.19 s 
2025-12-21 00:17:01.489513: Yayy! New best EMA pseudo Dice: 0.3974 
2025-12-21 00:17:02.558919:  
2025-12-21 00:17:02.558919: Epoch 4 
2025-12-21 00:17:02.558919: Current learning rate: 0.00996 
2025-12-21 00:19:20.754849: train_loss -0.2553 
2025-12-21 00:19:20.754849: val_loss -0.2672 
2025-12-21 00:19:20.754849: Pseudo dice [0.6161, 0.6664, 0.5643] 
2025-12-21 00:19:20.754849: Epoch time: 138.2 s 
2025-12-21 00:19:20.754849: Yayy! New best EMA pseudo Dice: 0.4193 
2025-12-21 00:19:21.657997:  
2025-12-21 00:19:21.657997: Epoch 5 
2025-12-21 00:19:21.657997: Current learning rate: 0.00995 
2025-12-21 00:21:39.537123: train_loss -0.2987 
2025-12-21 00:21:39.537123: val_loss -0.3387 
2025-12-21 00:21:39.537123: Pseudo dice [0.6602, 0.6868, 0.621] 
2025-12-21 00:21:39.537123: Epoch time: 137.88 s 
2025-12-21 00:21:39.537123: Yayy! New best EMA pseudo Dice: 0.4429 
2025-12-21 00:21:40.422580:  
2025-12-21 00:21:40.422580: Epoch 6 
2025-12-21 00:21:40.422580: Current learning rate: 0.00995 
2025-12-21 00:23:58.437121: train_loss -0.3725 
2025-12-21 00:23:58.439125: val_loss -0.3923 
2025-12-21 00:23:58.439125: Pseudo dice [0.6819, 0.7541, 0.6276] 
2025-12-21 00:23:58.439125: Epoch time: 138.01 s 
2025-12-21 00:23:58.439125: Yayy! New best EMA pseudo Dice: 0.4674 
2025-12-21 00:23:59.688591:  
2025-12-21 00:23:59.688591: Epoch 7 
2025-12-21 00:23:59.688591: Current learning rate: 0.00994 
2025-12-21 00:26:17.682140: train_loss -0.4071 
2025-12-21 00:26:17.684143: val_loss -0.4384 
2025-12-21 00:26:17.684143: Pseudo dice [0.7249, 0.769, 0.6648] 
2025-12-21 00:26:17.684143: Epoch time: 138.01 s 
2025-12-21 00:26:17.686409: Yayy! New best EMA pseudo Dice: 0.4926 
2025-12-21 00:26:18.598138:  
2025-12-21 00:26:18.598138: Epoch 8 
2025-12-21 00:26:18.598138: Current learning rate: 0.00993 
2025-12-21 00:28:36.732919: train_loss -0.45 
2025-12-21 00:28:36.732919: val_loss -0.4811 
2025-12-21 00:28:36.732919: Pseudo dice [0.7517, 0.8094, 0.6794] 
2025-12-21 00:28:36.732919: Epoch time: 138.13 s 
2025-12-21 00:28:36.732919: Yayy! New best EMA pseudo Dice: 0.5181 
2025-12-21 00:28:37.653718:  
2025-12-21 00:28:37.653718: Epoch 9 
2025-12-21 00:28:37.653718: Current learning rate: 0.00992 
2025-12-21 00:30:55.391314: train_loss -0.4992 
2025-12-21 00:30:55.391314: val_loss -0.5199 
2025-12-21 00:30:55.393054: Pseudo dice [0.7659, 0.8293, 0.7228] 
2025-12-21 00:30:55.393054: Epoch time: 137.74 s 
2025-12-21 00:30:55.395056: Yayy! New best EMA pseudo Dice: 0.5435 
2025-12-21 00:30:56.454962:  
2025-12-21 00:30:56.454962: Epoch 10 
2025-12-21 00:30:56.456965: Current learning rate: 0.00991 
2025-12-21 00:33:14.256952: train_loss -0.5279 
2025-12-21 00:33:14.258955: val_loss -0.5469 
2025-12-21 00:33:14.259956: Pseudo dice [0.803, 0.8419, 0.7075] 
2025-12-21 00:33:14.259956: Epoch time: 137.8 s 
2025-12-21 00:33:14.259956: Yayy! New best EMA pseudo Dice: 0.5676 
2025-12-21 00:33:15.161855:  
2025-12-21 00:33:15.161855: Epoch 11 
2025-12-21 00:33:15.161855: Current learning rate: 0.0099 
2025-12-21 00:35:33.174048: train_loss -0.5248 
2025-12-21 00:35:33.174048: val_loss -0.5583 
2025-12-21 00:35:33.176051: Pseudo dice [0.7976, 0.8535, 0.7248] 
2025-12-21 00:35:33.176051: Epoch time: 138.01 s 
2025-12-21 00:35:33.178053: Yayy! New best EMA pseudo Dice: 0.59 
2025-12-21 00:35:34.050233:  
2025-12-21 00:35:34.050233: Epoch 12 
2025-12-21 00:35:34.050233: Current learning rate: 0.00989 
2025-12-21 00:37:51.947515: train_loss -0.5542 
2025-12-21 00:37:51.947515: val_loss -0.5922 
2025-12-21 00:37:51.949518: Pseudo dice [0.8112, 0.8583, 0.7538] 
2025-12-21 00:37:51.949518: Epoch time: 137.9 s 
2025-12-21 00:37:51.949518: Yayy! New best EMA pseudo Dice: 0.6118 
2025-12-21 00:37:53.191362:  
2025-12-21 00:37:53.191362: Epoch 13 
2025-12-21 00:37:53.191362: Current learning rate: 0.00988 
2025-12-21 00:40:11.132426: train_loss -0.5733 
2025-12-21 00:40:11.132426: val_loss -0.5835 
2025-12-21 00:40:11.134428: Pseudo dice [0.8002, 0.8538, 0.7789] 
2025-12-21 00:40:11.135431: Epoch time: 137.96 s 
2025-12-21 00:40:11.135431: Yayy! New best EMA pseudo Dice: 0.6317 
2025-12-21 00:40:12.045023:  
2025-12-21 00:40:12.045023: Epoch 14 
2025-12-21 00:40:12.047025: Current learning rate: 0.00987 
2025-12-21 00:42:29.912091: train_loss -0.6031 
2025-12-21 00:42:29.912091: val_loss -0.6008 
2025-12-21 00:42:29.914094: Pseudo dice [0.8088, 0.8699, 0.7756] 
2025-12-21 00:42:29.914094: Epoch time: 137.87 s 
2025-12-21 00:42:29.914094: Yayy! New best EMA pseudo Dice: 0.6503 
2025-12-21 00:42:30.832515:  
2025-12-21 00:42:30.832515: Epoch 15 
2025-12-21 00:42:30.834517: Current learning rate: 0.00986 
2025-12-21 00:44:48.858289: train_loss -0.6063 
2025-12-21 00:44:48.858289: val_loss -0.6228 
2025-12-21 00:44:48.860291: Pseudo dice [0.8232, 0.8727, 0.7982] 
2025-12-21 00:44:48.860291: Epoch time: 138.03 s 
2025-12-21 00:44:48.862294: Yayy! New best EMA pseudo Dice: 0.6684 
2025-12-21 00:44:49.915221:  
2025-12-21 00:44:49.915221: Epoch 16 
2025-12-21 00:44:49.915221: Current learning rate: 0.00986 
2025-12-21 00:47:07.754199: train_loss -0.6233 
2025-12-21 00:47:07.754199: val_loss -0.6225 
2025-12-21 00:47:07.756202: Pseudo dice [0.8295, 0.8729, 0.7675] 
2025-12-21 00:47:07.758204: Epoch time: 137.84 s 
2025-12-21 00:47:07.758204: Yayy! New best EMA pseudo Dice: 0.6839 
2025-12-21 00:47:08.658463:  
2025-12-21 00:47:08.658463: Epoch 17 
2025-12-21 00:47:08.658463: Current learning rate: 0.00985 
2025-12-21 00:49:26.444012: train_loss -0.6343 
2025-12-21 00:49:26.444012: val_loss -0.6364 
2025-12-21 00:49:26.444012: Pseudo dice [0.8339, 0.8803, 0.7975] 
2025-12-21 00:49:26.444012: Epoch time: 137.79 s 
2025-12-21 00:49:26.444012: Yayy! New best EMA pseudo Dice: 0.6993 
2025-12-21 00:49:27.357311:  
2025-12-21 00:49:27.359250: Epoch 18 
2025-12-21 00:49:27.359250: Current learning rate: 0.00984 
2025-12-21 00:51:45.215656: train_loss -0.6405 
2025-12-21 00:51:45.215656: val_loss -0.6461 
2025-12-21 00:51:45.215656: Pseudo dice [0.8356, 0.8798, 0.808] 
2025-12-21 00:51:45.215656: Epoch time: 137.86 s 
2025-12-21 00:51:45.215656: Yayy! New best EMA pseudo Dice: 0.7135 
2025-12-21 00:51:46.454872:  
2025-12-21 00:51:46.456875: Epoch 19 
2025-12-21 00:51:46.456875: Current learning rate: 0.00983 
2025-12-21 00:54:04.470508: train_loss -0.6545 
2025-12-21 00:54:04.470508: val_loss -0.6611 
2025-12-21 00:54:04.472511: Pseudo dice [0.8414, 0.8844, 0.8257] 
2025-12-21 00:54:04.472511: Epoch time: 138.02 s 
2025-12-21 00:54:04.474512: Yayy! New best EMA pseudo Dice: 0.7272 
2025-12-21 00:54:05.363715:  
2025-12-21 00:54:05.363715: Epoch 20 
2025-12-21 00:54:05.366158: Current learning rate: 0.00982 
2025-12-21 00:56:23.223639: train_loss -0.6639 
2025-12-21 00:56:23.223639: val_loss -0.6632 
2025-12-21 00:56:23.239681: Pseudo dice [0.8452, 0.8855, 0.8122] 
2025-12-21 00:56:23.239681: Epoch time: 137.86 s 
2025-12-21 00:56:23.239681: Yayy! New best EMA pseudo Dice: 0.7392 
2025-12-21 00:56:24.149620:  
2025-12-21 00:56:24.149620: Epoch 21 
2025-12-21 00:56:24.149620: Current learning rate: 0.00981 
2025-12-21 00:58:41.954263: train_loss -0.6725 
2025-12-21 00:58:41.956265: val_loss -0.6757 
2025-12-21 00:58:41.956265: Pseudo dice [0.8516, 0.8917, 0.797] 
2025-12-21 00:58:41.958268: Epoch time: 137.8 s 
2025-12-21 00:58:41.958268: Yayy! New best EMA pseudo Dice: 0.75 
2025-12-21 00:58:42.962697:  
2025-12-21 00:58:42.962697: Epoch 22 
2025-12-21 00:58:42.962697: Current learning rate: 0.0098 
2025-12-21 01:01:01.022724: train_loss -0.6775 
2025-12-21 01:01:01.024727: val_loss -0.677 
2025-12-21 01:01:01.024727: Pseudo dice [0.8476, 0.8919, 0.8321] 
2025-12-21 01:01:01.026730: Epoch time: 138.06 s 
2025-12-21 01:01:01.026730: Yayy! New best EMA pseudo Dice: 0.7607 
2025-12-21 01:01:01.910780:  
2025-12-21 01:01:01.910780: Epoch 23 
2025-12-21 01:01:01.910780: Current learning rate: 0.00979 
2025-12-21 01:03:19.862274: train_loss -0.6805 
2025-12-21 01:03:19.864277: val_loss -0.6954 
2025-12-21 01:03:19.864277: Pseudo dice [0.8591, 0.9, 0.8403] 
2025-12-21 01:03:19.866199: Epoch time: 137.95 s 
2025-12-21 01:03:19.866199: Yayy! New best EMA pseudo Dice: 0.7713 
2025-12-21 01:03:20.741822:  
2025-12-21 01:03:20.741822: Epoch 24 
2025-12-21 01:03:20.741822: Current learning rate: 0.00978 
2025-12-21 01:05:38.855836: train_loss -0.6896 
2025-12-21 01:05:38.855836: val_loss -0.677 
2025-12-21 01:05:38.857576: Pseudo dice [0.8469, 0.8899, 0.8314] 
2025-12-21 01:05:38.859579: Epoch time: 138.11 s 
2025-12-21 01:05:38.859579: Yayy! New best EMA pseudo Dice: 0.7797 
2025-12-21 01:05:40.086702:  
2025-12-21 01:05:40.086702: Epoch 25 
2025-12-21 01:05:40.086702: Current learning rate: 0.00977 
2025-12-21 01:07:57.976605: train_loss -0.6946 
2025-12-21 01:07:57.978607: val_loss -0.7113 
2025-12-21 01:07:57.980609: Pseudo dice [0.871, 0.9106, 0.8326] 
2025-12-21 01:07:57.980609: Epoch time: 137.89 s 
2025-12-21 01:07:57.980609: Yayy! New best EMA pseudo Dice: 0.7889 
2025-12-21 01:07:58.855897:  
2025-12-21 01:07:58.855897: Epoch 26 
2025-12-21 01:07:58.855897: Current learning rate: 0.00977 
2025-12-21 01:10:17.179848: train_loss -0.7004 
2025-12-21 01:10:17.179848: val_loss -0.7186 
2025-12-21 01:10:17.181853: Pseudo dice [0.8693, 0.9103, 0.8425] 
2025-12-21 01:10:17.181853: Epoch time: 138.33 s 
2025-12-21 01:10:17.183855: Yayy! New best EMA pseudo Dice: 0.7974 
2025-12-21 01:10:18.060783:  
2025-12-21 01:10:18.060783: Epoch 27 
2025-12-21 01:10:18.060783: Current learning rate: 0.00976 
2025-12-21 01:12:36.131841: train_loss -0.7075 
2025-12-21 01:12:36.131841: val_loss -0.7131 
2025-12-21 01:12:36.133843: Pseudo dice [0.8667, 0.9026, 0.8515] 
2025-12-21 01:12:36.133843: Epoch time: 138.07 s 
2025-12-21 01:12:36.135845: Yayy! New best EMA pseudo Dice: 0.805 
2025-12-21 01:12:37.183084:  
2025-12-21 01:12:37.183084: Epoch 28 
2025-12-21 01:12:37.183084: Current learning rate: 0.00975 
2025-12-21 01:14:55.188346: train_loss -0.7111 
2025-12-21 01:14:55.190348: val_loss -0.7345 
2025-12-21 01:14:55.192350: Pseudo dice [0.8713, 0.9154, 0.8565] 
2025-12-21 01:14:55.192350: Epoch time: 138.02 s 
2025-12-21 01:14:55.194352: Yayy! New best EMA pseudo Dice: 0.8126 
2025-12-21 01:14:56.080967:  
2025-12-21 01:14:56.080967: Epoch 29 
2025-12-21 01:14:56.080967: Current learning rate: 0.00974 
2025-12-21 01:17:13.959143: train_loss -0.7066 
2025-12-21 01:17:13.959143: val_loss -0.6734 
2025-12-21 01:17:13.959143: Pseudo dice [0.8367, 0.8814, 0.8365] 
2025-12-21 01:17:13.975061: Epoch time: 137.88 s 
2025-12-21 01:17:13.975061: Yayy! New best EMA pseudo Dice: 0.8165 
2025-12-21 01:17:14.885704:  
2025-12-21 01:17:14.885704: Epoch 30 
2025-12-21 01:17:14.885704: Current learning rate: 0.00973 
2025-12-21 01:19:32.661488: train_loss -0.724 
2025-12-21 01:19:32.661488: val_loss -0.703 
2025-12-21 01:19:32.677216: Pseudo dice [0.8452, 0.8917, 0.8614] 
2025-12-21 01:19:32.677216: Epoch time: 137.78 s 
2025-12-21 01:19:32.677216: Yayy! New best EMA pseudo Dice: 0.8215 
2025-12-21 01:19:33.752834:  
2025-12-21 01:19:33.752834: Epoch 31 
2025-12-21 01:19:33.753839: Current learning rate: 0.00972 
2025-12-21 01:21:51.529657: train_loss -0.7243 
2025-12-21 01:21:51.531660: val_loss -0.727 
2025-12-21 01:21:51.531660: Pseudo dice [0.8702, 0.9096, 0.8564] 
2025-12-21 01:21:51.531660: Epoch time: 137.79 s 
2025-12-21 01:21:51.531660: Yayy! New best EMA pseudo Dice: 0.8272 
2025-12-21 01:21:52.416843:  
2025-12-21 01:21:52.416843: Epoch 32 
2025-12-21 01:21:52.416843: Current learning rate: 0.00971 
2025-12-21 01:24:10.447987: train_loss -0.7258 
2025-12-21 01:24:10.447987: val_loss -0.7087 
2025-12-21 01:24:10.449989: Pseudo dice [0.8589, 0.8963, 0.8553] 
2025-12-21 01:24:10.450990: Epoch time: 138.03 s 
2025-12-21 01:24:10.450990: Yayy! New best EMA pseudo Dice: 0.8315 
2025-12-21 01:24:11.338925:  
2025-12-21 01:24:11.338925: Epoch 33 
2025-12-21 01:24:11.354705: Current learning rate: 0.0097 
2025-12-21 01:26:29.088120: train_loss -0.7352 
2025-12-21 01:26:29.088120: val_loss -0.7324 
2025-12-21 01:26:29.088120: Pseudo dice [0.8689, 0.9071, 0.8607] 
2025-12-21 01:26:29.088120: Epoch time: 137.75 s 
2025-12-21 01:26:29.088120: Yayy! New best EMA pseudo Dice: 0.8362 
2025-12-21 01:26:30.157952:  
2025-12-21 01:26:30.157952: Epoch 34 
2025-12-21 01:26:30.157952: Current learning rate: 0.00969 
2025-12-21 01:28:48.112607: train_loss -0.7344 
2025-12-21 01:28:48.114609: val_loss -0.7411 
2025-12-21 01:28:48.116611: Pseudo dice [0.8776, 0.9206, 0.8604] 
2025-12-21 01:28:48.116611: Epoch time: 137.96 s 
2025-12-21 01:28:48.116611: Yayy! New best EMA pseudo Dice: 0.8412 
2025-12-21 01:28:49.001624:  
2025-12-21 01:28:49.001624: Epoch 35 
2025-12-21 01:28:49.001624: Current learning rate: 0.00968 
2025-12-21 01:31:06.847506: train_loss -0.7359 
2025-12-21 01:31:06.849509: val_loss -0.7029 
2025-12-21 01:31:06.849509: Pseudo dice [0.8445, 0.8912, 0.8699] 
2025-12-21 01:31:06.851512: Epoch time: 137.85 s 
2025-12-21 01:31:06.851512: Yayy! New best EMA pseudo Dice: 0.844 
2025-12-21 01:31:07.922681:  
2025-12-21 01:31:07.922681: Epoch 36 
2025-12-21 01:31:07.922681: Current learning rate: 0.00968 
2025-12-21 01:33:25.747952: train_loss -0.7428 
2025-12-21 01:33:25.747952: val_loss -0.778 
2025-12-21 01:33:25.749955: Pseudo dice [0.9016, 0.931, 0.8774] 
2025-12-21 01:33:25.749955: Epoch time: 137.83 s 
2025-12-21 01:33:25.751958: Yayy! New best EMA pseudo Dice: 0.8499 
2025-12-21 01:33:26.815282:  
2025-12-21 01:33:26.815282: Epoch 37 
2025-12-21 01:33:26.817285: Current learning rate: 0.00967 
2025-12-21 01:35:44.730342: train_loss -0.7422 
2025-12-21 01:35:44.730342: val_loss -0.756 
2025-12-21 01:35:44.734085: Pseudo dice [0.887, 0.9181, 0.8661] 
2025-12-21 01:35:44.734085: Epoch time: 137.92 s 
2025-12-21 01:35:44.736087: Yayy! New best EMA pseudo Dice: 0.854 
2025-12-21 01:35:45.638263:  
2025-12-21 01:35:45.638263: Epoch 38 
2025-12-21 01:35:45.638263: Current learning rate: 0.00966 
2025-12-21 01:38:03.549651: train_loss -0.7439 
2025-12-21 01:38:03.549651: val_loss -0.7663 
2025-12-21 01:38:03.553246: Pseudo dice [0.8845, 0.9227, 0.8812] 
2025-12-21 01:38:03.555249: Epoch time: 137.91 s 
2025-12-21 01:38:03.555249: Yayy! New best EMA pseudo Dice: 0.8582 
2025-12-21 01:38:04.468801:  
2025-12-21 01:38:04.468801: Epoch 39 
2025-12-21 01:38:04.468801: Current learning rate: 0.00965 
2025-12-21 01:40:22.442265: train_loss -0.7395 
2025-12-21 01:40:22.442265: val_loss -0.7703 
2025-12-21 01:40:22.444268: Pseudo dice [0.8914, 0.9317, 0.8748] 
2025-12-21 01:40:22.446159: Epoch time: 137.97 s 
2025-12-21 01:40:22.446159: Yayy! New best EMA pseudo Dice: 0.8623 
2025-12-21 01:40:23.483113:  
2025-12-21 01:40:23.483113: Epoch 40 
2025-12-21 01:40:23.483113: Current learning rate: 0.00964 
2025-12-21 01:42:41.344076: train_loss -0.744 
2025-12-21 01:42:41.344076: val_loss -0.7451 
2025-12-21 01:42:41.344076: Pseudo dice [0.8735, 0.9116, 0.8738] 
2025-12-21 01:42:41.344076: Epoch time: 137.86 s 
2025-12-21 01:42:41.351377: Yayy! New best EMA pseudo Dice: 0.8647 
2025-12-21 01:42:42.275232:  
2025-12-21 01:42:42.275232: Epoch 41 
2025-12-21 01:42:42.275232: Current learning rate: 0.00963 
2025-12-21 01:45:00.174499: train_loss -0.7454 
2025-12-21 01:45:00.174499: val_loss -0.7635 
2025-12-21 01:45:00.176502: Pseudo dice [0.877, 0.9171, 0.8771] 
2025-12-21 01:45:00.176502: Epoch time: 137.9 s 
2025-12-21 01:45:00.178504: Yayy! New best EMA pseudo Dice: 0.8673 
2025-12-21 01:45:01.235835:  
2025-12-21 01:45:01.235835: Epoch 42 
2025-12-21 01:45:01.235835: Current learning rate: 0.00962 
2025-12-21 01:47:19.225559: train_loss -0.7512 
2025-12-21 01:47:19.227561: val_loss -0.76 
2025-12-21 01:47:19.227561: Pseudo dice [0.8814, 0.9202, 0.8696] 
2025-12-21 01:47:19.229563: Epoch time: 137.99 s 
2025-12-21 01:47:19.229563: Yayy! New best EMA pseudo Dice: 0.8696 
2025-12-21 01:47:20.255534:  
2025-12-21 01:47:20.255534: Epoch 43 
2025-12-21 01:47:20.268571: Current learning rate: 0.00961 
2025-12-21 01:49:38.131317: train_loss -0.7571 
2025-12-21 01:49:38.131317: val_loss -0.7853 
2025-12-21 01:49:38.131317: Pseudo dice [0.8982, 0.9307, 0.881] 
2025-12-21 01:49:38.131317: Epoch time: 137.88 s 
2025-12-21 01:49:38.131317: Yayy! New best EMA pseudo Dice: 0.8729 
2025-12-21 01:49:39.015544:  
2025-12-21 01:49:39.015544: Epoch 44 
2025-12-21 01:49:39.015544: Current learning rate: 0.0096 
2025-12-21 01:51:57.123634: train_loss -0.7545 
2025-12-21 01:51:57.123634: val_loss -0.7772 
2025-12-21 01:51:57.123634: Pseudo dice [0.8932, 0.9322, 0.8799] 
2025-12-21 01:51:57.123634: Epoch time: 138.11 s 
2025-12-21 01:51:57.123634: Yayy! New best EMA pseudo Dice: 0.8758 
2025-12-21 01:51:58.016456:  
2025-12-21 01:51:58.016456: Epoch 45 
2025-12-21 01:51:58.016456: Current learning rate: 0.00959 
2025-12-21 01:54:15.877929: train_loss -0.7661 
2025-12-21 01:54:15.877929: val_loss -0.78 
2025-12-21 01:54:15.879932: Pseudo dice [0.8975, 0.9246, 0.8791] 
2025-12-21 01:54:15.881935: Epoch time: 137.86 s 
2025-12-21 01:54:15.883938: Yayy! New best EMA pseudo Dice: 0.8783 
2025-12-21 01:54:16.945509:  
2025-12-21 01:54:16.945509: Epoch 46 
2025-12-21 01:54:16.945509: Current learning rate: 0.00959 
2025-12-21 01:56:34.868566: train_loss -0.7481 
2025-12-21 01:56:34.868566: val_loss -0.7323 
2025-12-21 01:56:34.868566: Pseudo dice [0.8719, 0.9033, 0.8542] 
2025-12-21 01:56:34.868566: Epoch time: 137.92 s 
2025-12-21 01:56:35.488670:  
2025-12-21 01:56:35.488670: Epoch 47 
2025-12-21 01:56:35.488670: Current learning rate: 0.00958 
2025-12-21 01:58:53.263906: train_loss -0.7135 
2025-12-21 01:58:53.263906: val_loss -0.7243 
2025-12-21 01:58:53.263906: Pseudo dice [0.8614, 0.8971, 0.8712] 
2025-12-21 01:58:53.263906: Epoch time: 137.78 s 
2025-12-21 01:58:54.040739:  
2025-12-21 01:58:54.040739: Epoch 48 
2025-12-21 01:58:54.040739: Current learning rate: 0.00957 
2025-12-21 02:01:11.860886: train_loss -0.7417 
2025-12-21 02:01:11.860886: val_loss -0.7724 
2025-12-21 02:01:11.860886: Pseudo dice [0.887, 0.9249, 0.8753] 
2025-12-21 02:01:11.860886: Epoch time: 137.82 s 
2025-12-21 02:01:11.860886: Yayy! New best EMA pseudo Dice: 0.8797 
2025-12-21 02:01:12.882561:  
2025-12-21 02:01:12.882561: Epoch 49 
2025-12-21 02:01:12.884564: Current learning rate: 0.00956 
2025-12-21 02:03:30.780850: train_loss -0.7576 
2025-12-21 02:03:30.780850: val_loss -0.7608 
2025-12-21 02:03:30.780850: Pseudo dice [0.8771, 0.9183, 0.8762] 
2025-12-21 02:03:30.780850: Epoch time: 137.9 s 
2025-12-21 02:03:31.016942: Yayy! New best EMA pseudo Dice: 0.8808 
2025-12-21 02:03:31.903753:  
2025-12-21 02:03:31.903753: Epoch 50 
2025-12-21 02:03:31.903753: Current learning rate: 0.00955 
2025-12-21 02:05:49.808812: train_loss -0.7593 
2025-12-21 02:05:49.810814: val_loss -0.7828 
2025-12-21 02:05:49.810814: Pseudo dice [0.8936, 0.9241, 0.8804] 
2025-12-21 02:05:49.813270: Epoch time: 137.91 s 
2025-12-21 02:05:49.813270: Yayy! New best EMA pseudo Dice: 0.8827 
2025-12-21 02:05:50.695833:  
2025-12-21 02:05:50.695833: Epoch 51 
2025-12-21 02:05:50.695833: Current learning rate: 0.00954 
2025-12-21 02:08:08.528747: train_loss -0.7653 
2025-12-21 02:08:08.528747: val_loss -0.7813 
2025-12-21 02:08:08.528747: Pseudo dice [0.884, 0.9208, 0.8987] 
2025-12-21 02:08:08.528747: Epoch time: 137.83 s 
2025-12-21 02:08:08.528747: Yayy! New best EMA pseudo Dice: 0.8845 
2025-12-21 02:08:09.543699:  
2025-12-21 02:08:09.543699: Epoch 52 
2025-12-21 02:08:09.543699: Current learning rate: 0.00953 
2025-12-21 02:10:27.850508: train_loss -0.7648 
2025-12-21 02:10:27.852510: val_loss -0.7643 
2025-12-21 02:10:27.854513: Pseudo dice [0.8765, 0.9183, 0.8793] 
2025-12-21 02:10:27.854513: Epoch time: 138.31 s 
2025-12-21 02:10:27.856514: Yayy! New best EMA pseudo Dice: 0.8852 
2025-12-21 02:10:28.912570:  
2025-12-21 02:10:28.912570: Epoch 53 
2025-12-21 02:10:28.912570: Current learning rate: 0.00952 
2025-12-21 02:12:46.870794: train_loss -0.7692 
2025-12-21 02:12:46.872535: val_loss -0.7657 
2025-12-21 02:12:46.872535: Pseudo dice [0.8737, 0.9135, 0.887] 
2025-12-21 02:12:46.872535: Epoch time: 137.96 s 
2025-12-21 02:12:46.872535: Yayy! New best EMA pseudo Dice: 0.8858 
2025-12-21 02:12:47.762710:  
2025-12-21 02:12:47.762710: Epoch 54 
2025-12-21 02:12:47.762710: Current learning rate: 0.00951 
2025-12-21 02:15:05.750652: train_loss -0.7657 
2025-12-21 02:15:05.752655: val_loss -0.79 
2025-12-21 02:15:05.754396: Pseudo dice [0.8979, 0.9243, 0.8844] 
2025-12-21 02:15:05.754396: Epoch time: 137.99 s 
2025-12-21 02:15:05.756399: Yayy! New best EMA pseudo Dice: 0.8875 
2025-12-21 02:15:06.814789:  
2025-12-21 02:15:06.814789: Epoch 55 
2025-12-21 02:15:06.814789: Current learning rate: 0.0095 
2025-12-21 02:17:24.775497: train_loss -0.7772 
2025-12-21 02:17:24.775497: val_loss -0.7635 
2025-12-21 02:17:24.777499: Pseudo dice [0.8771, 0.9142, 0.8946] 
2025-12-21 02:17:24.779501: Epoch time: 137.96 s 
2025-12-21 02:17:24.779501: Yayy! New best EMA pseudo Dice: 0.8882 
2025-12-21 02:17:25.673306:  
2025-12-21 02:17:25.673306: Epoch 56 
2025-12-21 02:17:25.673306: Current learning rate: 0.00949 
2025-12-21 02:19:43.630508: train_loss -0.7795 
2025-12-21 02:19:43.632511: val_loss -0.8013 
2025-12-21 02:19:43.632511: Pseudo dice [0.8981, 0.9337, 0.8963] 
2025-12-21 02:19:43.635660: Epoch time: 137.96 s 
2025-12-21 02:19:43.635660: Yayy! New best EMA pseudo Dice: 0.8904 
2025-12-21 02:19:44.510220:  
2025-12-21 02:19:44.510220: Epoch 57 
2025-12-21 02:19:44.510220: Current learning rate: 0.00949 
2025-12-21 02:22:02.338337: train_loss -0.7736 
2025-12-21 02:22:02.340340: val_loss -0.7405 
2025-12-21 02:22:02.341343: Pseudo dice [0.8671, 0.9034, 0.8746] 
2025-12-21 02:22:02.343216: Epoch time: 137.83 s 
2025-12-21 02:22:03.053729:  
2025-12-21 02:22:03.053729: Epoch 58 
2025-12-21 02:22:03.053729: Current learning rate: 0.00948 
2025-12-21 02:24:21.125225: train_loss -0.765 
2025-12-21 02:24:21.125225: val_loss -0.7994 
2025-12-21 02:24:21.125225: Pseudo dice [0.8986, 0.9261, 0.9065] 
2025-12-21 02:24:21.125225: Epoch time: 138.09 s 
2025-12-21 02:24:21.125225: Yayy! New best EMA pseudo Dice: 0.8916 
2025-12-21 02:24:22.011628:  
2025-12-21 02:24:22.011628: Epoch 59 
2025-12-21 02:24:22.011628: Current learning rate: 0.00947 
2025-12-21 02:26:39.749867: train_loss -0.7808 
2025-12-21 02:26:39.751871: val_loss -0.7843 
2025-12-21 02:26:39.753874: Pseudo dice [0.8875, 0.9265, 0.8868] 
2025-12-21 02:26:39.753874: Epoch time: 137.74 s 
2025-12-21 02:26:39.753874: Yayy! New best EMA pseudo Dice: 0.8925 
2025-12-21 02:26:40.821831:  
2025-12-21 02:26:40.821831: Epoch 60 
2025-12-21 02:26:40.821831: Current learning rate: 0.00946 
2025-12-21 02:28:58.771948: train_loss -0.776 
2025-12-21 02:28:58.775491: val_loss -0.813 
2025-12-21 02:28:58.775491: Pseudo dice [0.9052, 0.9423, 0.8953] 
2025-12-21 02:28:58.775491: Epoch time: 137.95 s 
2025-12-21 02:28:58.775491: Yayy! New best EMA pseudo Dice: 0.8946 
2025-12-21 02:28:59.696447:  
2025-12-21 02:28:59.696447: Epoch 61 
2025-12-21 02:28:59.696447: Current learning rate: 0.00945 
2025-12-21 02:31:17.494765: train_loss -0.7467 
2025-12-21 02:31:17.494765: val_loss -0.7767 
2025-12-21 02:31:17.494765: Pseudo dice [0.8854, 0.9218, 0.8922] 
2025-12-21 02:31:17.498557: Epoch time: 137.8 s 
2025-12-21 02:31:17.498557: Yayy! New best EMA pseudo Dice: 0.8951 
2025-12-21 02:31:18.411923:  
2025-12-21 02:31:18.411923: Epoch 62 
2025-12-21 02:31:18.411923: Current learning rate: 0.00944 
2025-12-21 02:33:36.306980: train_loss -0.7635 
2025-12-21 02:33:36.306980: val_loss -0.7777 
2025-12-21 02:33:36.308982: Pseudo dice [0.8863, 0.9212, 0.8843] 
2025-12-21 02:33:36.308982: Epoch time: 137.9 s 
2025-12-21 02:33:36.310984: Yayy! New best EMA pseudo Dice: 0.8954 
2025-12-21 02:33:37.205008:  
2025-12-21 02:33:37.205008: Epoch 63 
2025-12-21 02:33:37.205008: Current learning rate: 0.00943 
2025-12-21 02:35:55.048161: train_loss -0.7768 
2025-12-21 02:35:55.048161: val_loss -0.7893 
2025-12-21 02:35:55.048161: Pseudo dice [0.8928, 0.9325, 0.8852] 
2025-12-21 02:35:55.048161: Epoch time: 137.84 s 
2025-12-21 02:35:55.048161: Yayy! New best EMA pseudo Dice: 0.8962 
2025-12-21 02:35:55.944333:  
2025-12-21 02:35:55.944333: Epoch 64 
2025-12-21 02:35:55.944333: Current learning rate: 0.00942 
2025-12-21 02:38:13.904901: train_loss -0.777 
2025-12-21 02:38:13.906903: val_loss -0.7842 
2025-12-21 02:38:13.910909: Pseudo dice [0.8811, 0.925, 0.8991] 
2025-12-21 02:38:13.912914: Epoch time: 137.96 s 
2025-12-21 02:38:13.914659: Yayy! New best EMA pseudo Dice: 0.8967 
2025-12-21 02:38:14.967848:  
2025-12-21 02:38:14.967848: Epoch 65 
2025-12-21 02:38:14.967848: Current learning rate: 0.00941 
2025-12-21 02:40:32.846717: train_loss -0.7753 
2025-12-21 02:40:32.848720: val_loss -0.7763 
2025-12-21 02:40:32.848720: Pseudo dice [0.8837, 0.9189, 0.8912] 
2025-12-21 02:40:32.851017: Epoch time: 137.88 s 
2025-12-21 02:40:32.851017: Yayy! New best EMA pseudo Dice: 0.8968 
2025-12-21 02:40:33.756749:  
2025-12-21 02:40:33.756749: Epoch 66 
2025-12-21 02:40:33.756749: Current learning rate: 0.0094 
2025-12-21 02:42:51.668239: train_loss -0.7791 
2025-12-21 02:42:51.668239: val_loss -0.7766 
2025-12-21 02:42:51.668239: Pseudo dice [0.8783, 0.9171, 0.9127] 
2025-12-21 02:42:51.668239: Epoch time: 137.91 s 
2025-12-21 02:42:51.668239: Yayy! New best EMA pseudo Dice: 0.8974 
2025-12-21 02:42:52.575573:  
2025-12-21 02:42:52.575573: Epoch 67 
2025-12-21 02:42:52.575573: Current learning rate: 0.00939 
2025-12-21 02:45:10.601299: train_loss -0.7779 
2025-12-21 02:45:10.601299: val_loss -0.7806 
2025-12-21 02:45:10.603301: Pseudo dice [0.8907, 0.923, 0.8997] 
2025-12-21 02:45:10.605303: Epoch time: 138.03 s 
2025-12-21 02:45:10.605303: Yayy! New best EMA pseudo Dice: 0.8981 
2025-12-21 02:45:11.501077:  
2025-12-21 02:45:11.501077: Epoch 68 
2025-12-21 02:45:11.501077: Current learning rate: 0.00939 
2025-12-21 02:47:29.325450: train_loss -0.7873 
2025-12-21 02:47:29.325450: val_loss -0.7778 
2025-12-21 02:47:29.325450: Pseudo dice [0.8813, 0.9183, 0.8909] 
2025-12-21 02:47:29.341523: Epoch time: 137.82 s 
2025-12-21 02:47:29.976127:  
2025-12-21 02:47:29.976127: Epoch 69 
2025-12-21 02:47:29.976127: Current learning rate: 0.00938 
2025-12-21 02:49:47.979252: train_loss -0.7812 
2025-12-21 02:49:47.979252: val_loss -0.7786 
2025-12-21 02:49:47.979252: Pseudo dice [0.8848, 0.9176, 0.8872] 
2025-12-21 02:49:47.979252: Epoch time: 138.0 s 
2025-12-21 02:49:48.628468:  
2025-12-21 02:49:48.628468: Epoch 70 
2025-12-21 02:49:48.644234: Current learning rate: 0.00937 
2025-12-21 02:52:06.542110: train_loss -0.7616 
2025-12-21 02:52:06.542110: val_loss -0.7621 
2025-12-21 02:52:06.542110: Pseudo dice [0.877, 0.9127, 0.8825] 
2025-12-21 02:52:06.542110: Epoch time: 137.91 s 
2025-12-21 02:52:07.349376:  
2025-12-21 02:52:07.349376: Epoch 71 
2025-12-21 02:52:07.349376: Current learning rate: 0.00936 
2025-12-21 02:54:25.139472: train_loss -0.7771 
2025-12-21 02:54:25.139472: val_loss -0.8143 
2025-12-21 02:54:25.141474: Pseudo dice [0.9054, 0.9414, 0.8943] 
2025-12-21 02:54:25.141474: Epoch time: 137.79 s 
2025-12-21 02:54:25.143476: Yayy! New best EMA pseudo Dice: 0.8988 
2025-12-21 02:54:26.003169:  
2025-12-21 02:54:26.003169: Epoch 72 
2025-12-21 02:54:26.003169: Current learning rate: 0.00935 
2025-12-21 02:56:43.945709: train_loss -0.7852 
2025-12-21 02:56:43.947711: val_loss -0.7887 
2025-12-21 02:56:43.949713: Pseudo dice [0.8864, 0.9183, 0.8928] 
2025-12-21 02:56:43.951715: Epoch time: 137.94 s 
2025-12-21 02:56:43.953720: Yayy! New best EMA pseudo Dice: 0.8988 
2025-12-21 02:56:44.862936:  
2025-12-21 02:56:44.862936: Epoch 73 
2025-12-21 02:56:44.862936: Current learning rate: 0.00934 
2025-12-21 02:59:02.853680: train_loss -0.795 
2025-12-21 02:59:02.853680: val_loss -0.8269 
2025-12-21 02:59:02.857684: Pseudo dice [0.9189, 0.9437, 0.8939] 
2025-12-21 02:59:02.857684: Epoch time: 137.99 s 
2025-12-21 02:59:02.859686: Yayy! New best EMA pseudo Dice: 0.9008 
2025-12-21 02:59:03.759512:  
2025-12-21 02:59:03.759512: Epoch 74 
2025-12-21 02:59:03.759512: Current learning rate: 0.00933 
2025-12-21 03:01:21.580298: train_loss -0.7927 
2025-12-21 03:01:21.580298: val_loss -0.82 
2025-12-21 03:01:21.580298: Pseudo dice [0.9067, 0.9366, 0.9193] 
2025-12-21 03:01:21.580298: Epoch time: 137.82 s 
2025-12-21 03:01:21.580298: Yayy! New best EMA pseudo Dice: 0.9028 
2025-12-21 03:01:22.518624:  
2025-12-21 03:01:22.518624: Epoch 75 
2025-12-21 03:01:22.518624: Current learning rate: 0.00932 
2025-12-21 03:03:40.443808: train_loss -0.7891 
2025-12-21 03:03:40.445811: val_loss -0.8072 
2025-12-21 03:03:40.445811: Pseudo dice [0.9054, 0.9353, 0.8983] 
2025-12-21 03:03:40.448990: Epoch time: 137.93 s 
2025-12-21 03:03:40.448990: Yayy! New best EMA pseudo Dice: 0.9039 
2025-12-21 03:03:41.362157:  
2025-12-21 03:03:41.362157: Epoch 76 
2025-12-21 03:03:41.362157: Current learning rate: 0.00931 
2025-12-21 03:05:59.327783: train_loss -0.7925 
2025-12-21 03:05:59.329785: val_loss -0.7944 
2025-12-21 03:05:59.331787: Pseudo dice [0.8889, 0.9251, 0.9007] 
2025-12-21 03:05:59.331787: Epoch time: 137.97 s 
2025-12-21 03:05:59.333527: Yayy! New best EMA pseudo Dice: 0.904 
2025-12-21 03:06:00.434002:  
2025-12-21 03:06:00.434002: Epoch 77 
2025-12-21 03:06:00.434002: Current learning rate: 0.0093 
2025-12-21 03:08:18.370146: train_loss -0.7952 
2025-12-21 03:08:18.370146: val_loss -0.8167 
2025-12-21 03:08:18.385908: Pseudo dice [0.9058, 0.94, 0.8997] 
2025-12-21 03:08:18.385908: Epoch time: 137.94 s 
2025-12-21 03:08:18.385908: Yayy! New best EMA pseudo Dice: 0.9051 
2025-12-21 03:08:19.304371:  
2025-12-21 03:08:19.304371: Epoch 78 
2025-12-21 03:08:19.304371: Current learning rate: 0.0093 
2025-12-21 03:10:37.645746: train_loss -0.7944 
2025-12-21 03:10:37.645746: val_loss -0.8051 
2025-12-21 03:10:37.647748: Pseudo dice [0.8975, 0.932, 0.8979] 
2025-12-21 03:10:37.647748: Epoch time: 138.34 s 
2025-12-21 03:10:37.649750: Yayy! New best EMA pseudo Dice: 0.9055 
2025-12-21 03:10:38.558198:  
2025-12-21 03:10:38.558198: Epoch 79 
2025-12-21 03:10:38.558198: Current learning rate: 0.00929 
2025-12-21 03:12:56.500283: train_loss -0.7919 
2025-12-21 03:12:56.500283: val_loss -0.7972 
2025-12-21 03:12:56.516122: Pseudo dice [0.8933, 0.9266, 0.9013] 
2025-12-21 03:12:56.516122: Epoch time: 137.94 s 
2025-12-21 03:12:56.516122: Yayy! New best EMA pseudo Dice: 0.9056 
2025-12-21 03:12:57.440036:  
2025-12-21 03:12:57.440036: Epoch 80 
2025-12-21 03:12:57.440036: Current learning rate: 0.00928 
2025-12-21 03:15:15.479517: train_loss -0.793 
2025-12-21 03:15:15.479517: val_loss -0.7886 
2025-12-21 03:15:15.481523: Pseudo dice [0.8902, 0.9291, 0.8888] 
2025-12-21 03:15:15.483526: Epoch time: 138.04 s 
2025-12-21 03:15:16.146753:  
2025-12-21 03:15:16.146753: Epoch 81 
2025-12-21 03:15:16.146753: Current learning rate: 0.00927 
2025-12-21 03:17:34.016249: train_loss -0.7915 
2025-12-21 03:17:34.016249: val_loss -0.7863 
2025-12-21 03:17:34.018252: Pseudo dice [0.8909, 0.9264, 0.8891] 
2025-12-21 03:17:34.020829: Epoch time: 137.87 s 
2025-12-21 03:17:34.828668:  
2025-12-21 03:17:34.828668: Epoch 82 
2025-12-21 03:17:34.828668: Current learning rate: 0.00926 
2025-12-21 03:19:52.725755: train_loss -0.7929 
2025-12-21 03:19:52.725755: val_loss -0.8061 
2025-12-21 03:19:52.725755: Pseudo dice [0.9013, 0.934, 0.8939] 
2025-12-21 03:19:52.725755: Epoch time: 137.9 s 
2025-12-21 03:19:53.343986:  
2025-12-21 03:19:53.343986: Epoch 83 
2025-12-21 03:19:53.343986: Current learning rate: 0.00925 
2025-12-21 03:22:11.185674: train_loss -0.7995 
2025-12-21 03:22:11.187676: val_loss -0.8356 
2025-12-21 03:22:11.191683: Pseudo dice [0.9173, 0.9443, 0.9149] 
2025-12-21 03:22:11.191683: Epoch time: 137.84 s 
2025-12-21 03:22:11.193905: Yayy! New best EMA pseudo Dice: 0.9075 
2025-12-21 03:22:12.072384:  
2025-12-21 03:22:12.072384: Epoch 84 
2025-12-21 03:22:12.072384: Current learning rate: 0.00924 
2025-12-21 03:24:30.109237: train_loss -0.7975 
2025-12-21 03:24:30.109237: val_loss -0.7844 
2025-12-21 03:24:30.112982: Pseudo dice [0.8858, 0.9219, 0.8969] 
2025-12-21 03:24:30.114985: Epoch time: 138.04 s 
2025-12-21 03:24:30.742764:  
2025-12-21 03:24:30.742764: Epoch 85 
2025-12-21 03:24:30.758715: Current learning rate: 0.00923 
2025-12-21 03:26:48.742177: train_loss -0.8018 
2025-12-21 03:26:48.742177: val_loss -0.8075 
2025-12-21 03:26:48.742177: Pseudo dice [0.8954, 0.934, 0.909] 
2025-12-21 03:26:48.742177: Epoch time: 138.0 s 
2025-12-21 03:26:49.373533:  
2025-12-21 03:26:49.373533: Epoch 86 
2025-12-21 03:26:49.373533: Current learning rate: 0.00922 
2025-12-21 03:29:07.397904: train_loss -0.7847 
2025-12-21 03:29:07.399906: val_loss -0.7586 
2025-12-21 03:29:07.401909: Pseudo dice [0.8766, 0.9088, 0.9058] 
2025-12-21 03:29:07.401909: Epoch time: 138.02 s 
2025-12-21 03:29:08.177597:  
2025-12-21 03:29:08.177597: Epoch 87 
2025-12-21 03:29:08.177597: Current learning rate: 0.00921 
2025-12-21 03:31:26.013586: train_loss -0.7823 
2025-12-21 03:31:26.013586: val_loss -0.8061 
2025-12-21 03:31:26.017033: Pseudo dice [0.9057, 0.9317, 0.8941] 
2025-12-21 03:31:26.017033: Epoch time: 137.84 s 
2025-12-21 03:31:26.816898:  
2025-12-21 03:31:26.818900: Epoch 88 
2025-12-21 03:31:26.818900: Current learning rate: 0.0092 
2025-12-21 03:33:44.869175: train_loss -0.7954 
2025-12-21 03:33:44.871177: val_loss -0.8052 
2025-12-21 03:33:44.873179: Pseudo dice [0.9005, 0.935, 0.8989] 
2025-12-21 03:33:44.875181: Epoch time: 138.05 s 
2025-12-21 03:33:45.518675:  
2025-12-21 03:33:45.518675: Epoch 89 
2025-12-21 03:33:45.518675: Current learning rate: 0.0092 
2025-12-21 03:36:03.533588: train_loss -0.7959 
2025-12-21 03:36:03.535590: val_loss -0.8206 
2025-12-21 03:36:03.537592: Pseudo dice [0.905, 0.9338, 0.9131] 
2025-12-21 03:36:03.537592: Epoch time: 138.02 s 
2025-12-21 03:36:03.537592: Yayy! New best EMA pseudo Dice: 0.9083 
2025-12-21 03:36:04.592597:  
2025-12-21 03:36:04.592597: Epoch 90 
2025-12-21 03:36:04.592597: Current learning rate: 0.00919 
2025-12-21 03:38:22.412688: train_loss -0.8047 
2025-12-21 03:38:22.412688: val_loss -0.828 
2025-12-21 03:38:22.412688: Pseudo dice [0.915, 0.9448, 0.9065] 
2025-12-21 03:38:22.422260: Epoch time: 137.82 s 
2025-12-21 03:38:22.422260: Yayy! New best EMA pseudo Dice: 0.9097 
2025-12-21 03:38:23.317609:  
2025-12-21 03:38:23.317609: Epoch 91 
2025-12-21 03:38:23.317609: Current learning rate: 0.00918 
2025-12-21 03:40:41.208250: train_loss -0.8059 
2025-12-21 03:40:41.208250: val_loss -0.8335 
2025-12-21 03:40:41.208250: Pseudo dice [0.911, 0.9449, 0.9166] 
2025-12-21 03:40:41.208250: Epoch time: 137.89 s 
2025-12-21 03:40:41.224212: Yayy! New best EMA pseudo Dice: 0.9111 
2025-12-21 03:40:42.078810:  
2025-12-21 03:40:42.078810: Epoch 92 
2025-12-21 03:40:42.078810: Current learning rate: 0.00917 
2025-12-21 03:42:59.957395: train_loss -0.802 
2025-12-21 03:42:59.957395: val_loss -0.8071 
2025-12-21 03:42:59.959397: Pseudo dice [0.8939, 0.9293, 0.9074] 
2025-12-21 03:42:59.961400: Epoch time: 137.88 s 
2025-12-21 03:43:00.661609:  
2025-12-21 03:43:00.661609: Epoch 93 
2025-12-21 03:43:00.677723: Current learning rate: 0.00916 
2025-12-21 03:45:18.767899: train_loss -0.8002 
2025-12-21 03:45:18.767899: val_loss -0.8275 
2025-12-21 03:45:18.769902: Pseudo dice [0.9088, 0.9439, 0.909] 
2025-12-21 03:45:18.771905: Epoch time: 138.11 s 
2025-12-21 03:45:18.773907: Yayy! New best EMA pseudo Dice: 0.912 
2025-12-21 03:45:19.656358:  
2025-12-21 03:45:19.658360: Epoch 94 
2025-12-21 03:45:19.658360: Current learning rate: 0.00915 
2025-12-21 03:47:37.449721: train_loss -0.8071 
2025-12-21 03:47:37.449721: val_loss -0.7873 
2025-12-21 03:47:37.451724: Pseudo dice [0.8989, 0.9252, 0.883] 
2025-12-21 03:47:37.453727: Epoch time: 137.79 s 
2025-12-21 03:47:38.244441:  
2025-12-21 03:47:38.244441: Epoch 95 
2025-12-21 03:47:38.244441: Current learning rate: 0.00914 
2025-12-21 03:49:56.150432: train_loss -0.7791 
2025-12-21 03:49:56.150432: val_loss -0.8073 
2025-12-21 03:49:56.152434: Pseudo dice [0.8952, 0.9372, 0.9121] 
2025-12-21 03:49:56.152434: Epoch time: 137.91 s 
2025-12-21 03:49:56.867121:  
2025-12-21 03:49:56.867121: Epoch 96 
2025-12-21 03:49:56.872888: Current learning rate: 0.00913 
2025-12-21 03:52:14.765784: train_loss -0.7899 
2025-12-21 03:52:14.765784: val_loss -0.8068 
2025-12-21 03:52:14.767787: Pseudo dice [0.8992, 0.9315, 0.9018] 
2025-12-21 03:52:14.769789: Epoch time: 137.9 s 
2025-12-21 03:52:15.388520:  
2025-12-21 03:52:15.390260: Epoch 97 
2025-12-21 03:52:15.390260: Current learning rate: 0.00912 
2025-12-21 03:54:33.520335: train_loss -0.8028 
2025-12-21 03:54:33.520335: val_loss -0.813 
2025-12-21 03:54:33.524342: Pseudo dice [0.8982, 0.9402, 0.9063] 
2025-12-21 03:54:33.526345: Epoch time: 138.13 s 
2025-12-21 03:54:34.147421:  
2025-12-21 03:54:34.147421: Epoch 98 
2025-12-21 03:54:34.147421: Current learning rate: 0.00911 
2025-12-21 03:56:52.484117: train_loss -0.8032 
2025-12-21 03:56:52.484117: val_loss -0.8298 
2025-12-21 03:56:52.486120: Pseudo dice [0.9111, 0.9473, 0.9126] 
2025-12-21 03:56:52.488121: Epoch time: 138.34 s 
2025-12-21 03:56:52.490123: Yayy! New best EMA pseudo Dice: 0.9129 
2025-12-21 03:56:53.460493:  
2025-12-21 03:56:53.460493: Epoch 99 
2025-12-21 03:56:53.460493: Current learning rate: 0.0091 
2025-12-21 03:59:11.429938: train_loss -0.8081 
2025-12-21 03:59:11.429938: val_loss -0.8254 
2025-12-21 03:59:11.429938: Pseudo dice [0.9044, 0.9397, 0.9189] 
2025-12-21 03:59:11.429938: Epoch time: 137.99 s 
2025-12-21 03:59:11.667166: Yayy! New best EMA pseudo Dice: 0.9137 
2025-12-21 03:59:12.556192:  
2025-12-21 03:59:12.556192: Epoch 100 
2025-12-21 03:59:12.556192: Current learning rate: 0.0091 
2025-12-21 04:01:30.535384: train_loss -0.8066 
2025-12-21 04:01:30.535384: val_loss -0.7975 
2025-12-21 04:01:30.541391: Pseudo dice [0.8906, 0.9316, 0.8951] 
2025-12-21 04:01:30.541391: Epoch time: 137.98 s 
2025-12-21 04:01:31.339824:  
2025-12-21 04:01:31.341826: Epoch 101 
2025-12-21 04:01:31.341826: Current learning rate: 0.00909 
2025-12-21 04:03:49.430133: train_loss -0.8047 
2025-12-21 04:03:49.430133: val_loss -0.8345 
2025-12-21 04:03:49.430133: Pseudo dice [0.9133, 0.9425, 0.9144] 
2025-12-21 04:03:49.430133: Epoch time: 138.09 s 
2025-12-21 04:03:49.430133: Yayy! New best EMA pseudo Dice: 0.914 
2025-12-21 04:03:50.446555:  
2025-12-21 04:03:50.446555: Epoch 102 
2025-12-21 04:03:50.446555: Current learning rate: 0.00908 
2025-12-21 04:06:08.389098: train_loss -0.8069 
2025-12-21 04:06:08.391100: val_loss -0.7961 
2025-12-21 04:06:08.393103: Pseudo dice [0.8814, 0.9231, 0.9195] 
2025-12-21 04:06:08.395106: Epoch time: 137.94 s 
2025-12-21 04:06:09.019680:  
2025-12-21 04:06:09.021683: Epoch 103 
2025-12-21 04:06:09.021683: Current learning rate: 0.00907 
2025-12-21 04:08:27.003091: train_loss -0.8121 
2025-12-21 04:08:27.005093: val_loss -0.8235 
2025-12-21 04:08:27.007095: Pseudo dice [0.9015, 0.9416, 0.9148] 
2025-12-21 04:08:27.009098: Epoch time: 137.98 s 
2025-12-21 04:08:27.639632:  
2025-12-21 04:08:27.639632: Epoch 104 
2025-12-21 04:08:27.639632: Current learning rate: 0.00906 
2025-12-21 04:10:45.915492: train_loss -0.8114 
2025-12-21 04:10:45.915492: val_loss -0.8249 
2025-12-21 04:10:45.915492: Pseudo dice [0.9097, 0.9401, 0.916] 
2025-12-21 04:10:45.915492: Epoch time: 138.28 s 
2025-12-21 04:10:45.920084: Yayy! New best EMA pseudo Dice: 0.9148 
2025-12-21 04:10:46.949121:  
2025-12-21 04:10:46.952638: Epoch 105 
2025-12-21 04:10:46.952638: Current learning rate: 0.00905 
2025-12-21 04:13:04.879066: train_loss -0.8106 
2025-12-21 04:13:04.879066: val_loss -0.8336 
2025-12-21 04:13:04.879066: Pseudo dice [0.9105, 0.9464, 0.9165] 
2025-12-21 04:13:04.879066: Epoch time: 137.93 s 
2025-12-21 04:13:04.879066: Yayy! New best EMA pseudo Dice: 0.9157 
2025-12-21 04:13:05.780181:  
2025-12-21 04:13:05.780181: Epoch 106 
2025-12-21 04:13:05.780181: Current learning rate: 0.00904 
2025-12-21 04:15:23.745410: train_loss -0.8097 
2025-12-21 04:15:23.745410: val_loss -0.8276 
2025-12-21 04:15:23.747412: Pseudo dice [0.9037, 0.9397, 0.9161] 
2025-12-21 04:15:23.747412: Epoch time: 137.97 s 
2025-12-21 04:15:23.747412: Yayy! New best EMA pseudo Dice: 0.9161 
2025-12-21 04:15:24.816746:  
2025-12-21 04:15:24.816746: Epoch 107 
2025-12-21 04:15:24.816746: Current learning rate: 0.00903 
2025-12-21 04:17:42.746026: train_loss -0.8135 
2025-12-21 04:17:42.746026: val_loss -0.8308 
2025-12-21 04:17:42.746026: Pseudo dice [0.9075, 0.9431, 0.9218] 
2025-12-21 04:17:42.746026: Epoch time: 137.93 s 
2025-12-21 04:17:42.746026: Yayy! New best EMA pseudo Dice: 0.9169 
2025-12-21 04:17:43.741293:  
2025-12-21 04:17:43.741293: Epoch 108 
2025-12-21 04:17:43.741293: Current learning rate: 0.00902 
2025-12-21 04:20:01.589663: train_loss -0.8124 
2025-12-21 04:20:01.589663: val_loss -0.8324 
2025-12-21 04:20:01.589663: Pseudo dice [0.9119, 0.9489, 0.9132] 
2025-12-21 04:20:01.589663: Epoch time: 137.85 s 
2025-12-21 04:20:01.589663: Yayy! New best EMA pseudo Dice: 0.9177 
2025-12-21 04:20:02.481107:  
2025-12-21 04:20:02.481107: Epoch 109 
2025-12-21 04:20:02.481107: Current learning rate: 0.00901 
2025-12-21 04:22:20.378206: train_loss -0.813 
2025-12-21 04:22:20.378206: val_loss -0.834 
2025-12-21 04:22:20.380025: Pseudo dice [0.9138, 0.9446, 0.9137] 
2025-12-21 04:22:20.382027: Epoch time: 137.9 s 
2025-12-21 04:22:20.384029: Yayy! New best EMA pseudo Dice: 0.9183 
2025-12-21 04:22:21.279586:  
2025-12-21 04:22:21.279586: Epoch 110 
2025-12-21 04:22:21.279586: Current learning rate: 0.009 
2025-12-21 04:24:39.187354: train_loss -0.8143 
2025-12-21 04:24:39.187354: val_loss -0.8128 
2025-12-21 04:24:39.189356: Pseudo dice [0.8988, 0.9353, 0.9084] 
2025-12-21 04:24:39.191096: Epoch time: 137.91 s 
2025-12-21 04:24:39.929216:  
2025-12-21 04:24:39.929216: Epoch 111 
2025-12-21 04:24:39.932567: Current learning rate: 0.009 
2025-12-21 04:26:57.934510: train_loss -0.8103 
2025-12-21 04:26:57.934510: val_loss -0.8485 
2025-12-21 04:26:57.934510: Pseudo dice [0.9225, 0.9518, 0.9159] 
2025-12-21 04:26:57.934510: Epoch time: 138.02 s 
2025-12-21 04:26:57.934510: Yayy! New best EMA pseudo Dice: 0.9191 
2025-12-21 04:26:58.825694:  
2025-12-21 04:26:58.825694: Epoch 112 
2025-12-21 04:26:58.825694: Current learning rate: 0.00899 
2025-12-21 04:29:16.658491: train_loss -0.8109 
2025-12-21 04:29:16.658491: val_loss -0.8396 
2025-12-21 04:29:16.662456: Pseudo dice [0.9164, 0.9488, 0.9169] 
2025-12-21 04:29:16.664459: Epoch time: 137.83 s 
2025-12-21 04:29:16.666461: Yayy! New best EMA pseudo Dice: 0.92 
2025-12-21 04:29:17.746808:  
2025-12-21 04:29:17.746808: Epoch 113 
2025-12-21 04:29:17.746808: Current learning rate: 0.00898 
2025-12-21 04:31:35.581198: train_loss -0.8167 
2025-12-21 04:31:35.585485: val_loss -0.8185 
2025-12-21 04:31:35.585485: Pseudo dice [0.9022, 0.9365, 0.9086] 
2025-12-21 04:31:35.588383: Epoch time: 137.83 s 
2025-12-21 04:31:36.292577:  
2025-12-21 04:31:36.292577: Epoch 114 
2025-12-21 04:31:36.292577: Current learning rate: 0.00897 
2025-12-21 04:33:54.264463: train_loss -0.8147 
2025-12-21 04:33:54.264463: val_loss -0.836 
2025-12-21 04:33:54.266465: Pseudo dice [0.9152, 0.9492, 0.9062] 
2025-12-21 04:33:54.268468: Epoch time: 137.97 s 
2025-12-21 04:33:54.899418:  
2025-12-21 04:33:54.899418: Epoch 115 
2025-12-21 04:33:54.899418: Current learning rate: 0.00896 
2025-12-21 04:36:12.735974: train_loss -0.8093 
2025-12-21 04:36:12.735974: val_loss -0.8233 
2025-12-21 04:36:12.735974: Pseudo dice [0.9064, 0.939, 0.9153] 
2025-12-21 04:36:12.739747: Epoch time: 137.84 s 
2025-12-21 04:36:12.741750: Yayy! New best EMA pseudo Dice: 0.92 
2025-12-21 04:36:13.617772:  
2025-12-21 04:36:13.617772: Epoch 116 
2025-12-21 04:36:13.620305: Current learning rate: 0.00895 
2025-12-21 04:38:31.600079: train_loss -0.8071 
2025-12-21 04:38:31.602447: val_loss -0.8129 
2025-12-21 04:38:31.602447: Pseudo dice [0.902, 0.9324, 0.9125] 
2025-12-21 04:38:31.605637: Epoch time: 137.98 s 
2025-12-21 04:38:32.243199:  
2025-12-21 04:38:32.243199: Epoch 117 
2025-12-21 04:38:32.245542: Current learning rate: 0.00894 
2025-12-21 04:40:50.142964: train_loss -0.8106 
2025-12-21 04:40:50.142964: val_loss -0.8283 
2025-12-21 04:40:50.144966: Pseudo dice [0.9123, 0.9415, 0.9163] 
2025-12-21 04:40:50.146968: Epoch time: 137.9 s 
2025-12-21 04:40:50.803458:  
2025-12-21 04:40:50.803458: Epoch 118 
2025-12-21 04:40:50.803458: Current learning rate: 0.00893 
2025-12-21 04:43:08.739775: train_loss -0.807 
2025-12-21 04:43:08.741777: val_loss -0.8106 
2025-12-21 04:43:08.745525: Pseudo dice [0.9015, 0.9363, 0.9031] 
2025-12-21 04:43:08.747528: Epoch time: 137.94 s 
2025-12-21 04:43:09.584449:  
2025-12-21 04:43:09.584449: Epoch 119 
2025-12-21 04:43:09.584449: Current learning rate: 0.00892 
2025-12-21 04:45:27.663033: train_loss -0.811 
2025-12-21 04:45:27.665035: val_loss -0.8432 
2025-12-21 04:45:27.666775: Pseudo dice [0.9229, 0.9487, 0.9077] 
2025-12-21 04:45:27.666775: Epoch time: 138.08 s 
2025-12-21 04:45:27.669606: Yayy! New best EMA pseudo Dice: 0.92 
2025-12-21 04:45:28.537440:  
2025-12-21 04:45:28.539443: Epoch 120 
2025-12-21 04:45:28.539443: Current learning rate: 0.00891 
2025-12-21 04:47:46.483991: train_loss -0.8153 
2025-12-21 04:47:46.485993: val_loss -0.8306 
2025-12-21 04:47:46.487996: Pseudo dice [0.9108, 0.9413, 0.9084] 
2025-12-21 04:47:46.487996: Epoch time: 137.95 s 
2025-12-21 04:47:46.491084: Yayy! New best EMA pseudo Dice: 0.92 
2025-12-21 04:47:47.388817:  
2025-12-21 04:47:47.388817: Epoch 121 
2025-12-21 04:47:47.388817: Current learning rate: 0.0089 
2025-12-21 04:50:05.446152: train_loss -0.7911 
2025-12-21 04:50:05.448153: val_loss -0.7375 
2025-12-21 04:50:05.450156: Pseudo dice [0.8604, 0.9007, 0.8899] 
2025-12-21 04:50:05.450156: Epoch time: 138.06 s 
2025-12-21 04:50:06.093598:  
2025-12-21 04:50:06.093598: Epoch 122 
2025-12-21 04:50:06.093598: Current learning rate: 0.00889 
2025-12-21 04:52:23.997229: train_loss -0.7884 
2025-12-21 04:52:23.997229: val_loss -0.8 
2025-12-21 04:52:24.008891: Pseudo dice [0.8964, 0.9283, 0.9183] 
2025-12-21 04:52:24.010893: Epoch time: 137.9 s 
2025-12-21 04:52:24.645159:  
2025-12-21 04:52:24.645159: Epoch 123 
2025-12-21 04:52:24.646140: Current learning rate: 0.00889 
2025-12-21 04:54:42.552345: train_loss -0.8096 
2025-12-21 04:54:42.552345: val_loss -0.8155 
2025-12-21 04:54:42.556199: Pseudo dice [0.9031, 0.9352, 0.9039] 
2025-12-21 04:54:42.556199: Epoch time: 137.92 s 
2025-12-21 04:54:43.201458:  
2025-12-21 04:54:43.201458: Epoch 124 
2025-12-21 04:54:43.201458: Current learning rate: 0.00888 
2025-12-21 04:57:01.129638: train_loss -0.8057 
2025-12-21 04:57:01.129638: val_loss -0.8223 
2025-12-21 04:57:01.131642: Pseudo dice [0.9014, 0.9405, 0.9197] 
2025-12-21 04:57:01.133645: Epoch time: 137.93 s 
2025-12-21 04:57:01.990354:  
2025-12-21 04:57:01.990354: Epoch 125 
2025-12-21 04:57:01.990354: Current learning rate: 0.00887 
2025-12-21 04:59:19.847258: train_loss -0.8012 
2025-12-21 04:59:19.849260: val_loss -0.8374 
2025-12-21 04:59:19.851262: Pseudo dice [0.9111, 0.9497, 0.9103] 
2025-12-21 04:59:19.853264: Epoch time: 137.86 s 
2025-12-21 04:59:20.488953:  
2025-12-21 04:59:20.488953: Epoch 126 
2025-12-21 04:59:20.488953: Current learning rate: 0.00886 
2025-12-21 05:01:38.578087: train_loss -0.8084 
2025-12-21 05:01:38.578087: val_loss -0.8355 
2025-12-21 05:01:38.578087: Pseudo dice [0.9128, 0.9435, 0.9179] 
2025-12-21 05:01:38.578087: Epoch time: 138.09 s 
2025-12-21 05:01:39.212649:  
2025-12-21 05:01:39.212649: Epoch 127 
2025-12-21 05:01:39.212649: Current learning rate: 0.00885 
2025-12-21 05:03:56.949729: train_loss -0.8107 
2025-12-21 05:03:56.949729: val_loss -0.8337 
2025-12-21 05:03:56.953736: Pseudo dice [0.911, 0.9411, 0.914] 
2025-12-21 05:03:56.955738: Epoch time: 137.74 s 
2025-12-21 05:03:57.762934:  
2025-12-21 05:03:57.762934: Epoch 128 
2025-12-21 05:03:57.762934: Current learning rate: 0.00884 
2025-12-21 05:06:15.709572: train_loss -0.8168 
2025-12-21 05:06:15.709572: val_loss -0.835 
2025-12-21 05:06:15.709572: Pseudo dice [0.9156, 0.9467, 0.9043] 
2025-12-21 05:06:15.709572: Epoch time: 137.95 s 
2025-12-21 05:06:16.346319:  
2025-12-21 05:06:16.346319: Epoch 129 
2025-12-21 05:06:16.346319: Current learning rate: 0.00883 
2025-12-21 05:08:34.214648: train_loss -0.812 
2025-12-21 05:08:34.214648: val_loss -0.8244 
2025-12-21 05:08:34.216650: Pseudo dice [0.9014, 0.9369, 0.9273] 
2025-12-21 05:08:34.218651: Epoch time: 137.87 s 
2025-12-21 05:08:34.859930:  
2025-12-21 05:08:34.859930: Epoch 130 
2025-12-21 05:08:34.859930: Current learning rate: 0.00882 
2025-12-21 05:10:53.223937: train_loss -0.8134 
2025-12-21 05:10:53.223937: val_loss -0.8334 
2025-12-21 05:10:53.227679: Pseudo dice [0.9096, 0.9391, 0.9194] 
2025-12-21 05:10:53.229681: Epoch time: 138.36 s 
2025-12-21 05:10:54.180310:  
2025-12-21 05:10:54.180310: Epoch 131 
2025-12-21 05:10:54.180310: Current learning rate: 0.00881 
2025-12-21 05:13:12.252054: train_loss -0.814 
2025-12-21 05:13:12.252054: val_loss -0.8204 
2025-12-21 05:13:12.252054: Pseudo dice [0.9002, 0.9394, 0.906] 
2025-12-21 05:13:12.252054: Epoch time: 138.07 s 
2025-12-21 05:13:12.896940:  
2025-12-21 05:13:12.896940: Epoch 132 
2025-12-21 05:13:12.896940: Current learning rate: 0.0088 
2025-12-21 05:15:30.834666: train_loss -0.8083 
2025-12-21 05:15:30.834666: val_loss -0.8166 
2025-12-21 05:15:30.838343: Pseudo dice [0.9047, 0.937, 0.9147] 
2025-12-21 05:15:30.840345: Epoch time: 137.94 s 
2025-12-21 05:15:31.468567:  
2025-12-21 05:15:31.468567: Epoch 133 
2025-12-21 05:15:31.468567: Current learning rate: 0.00879 
2025-12-21 05:17:49.310548: train_loss -0.8166 
2025-12-21 05:17:49.310548: val_loss -0.8264 
2025-12-21 05:17:49.312550: Pseudo dice [0.9116, 0.9409, 0.8972] 
2025-12-21 05:17:49.314291: Epoch time: 137.84 s 
2025-12-21 05:17:50.074034:  
2025-12-21 05:17:50.074034: Epoch 134 
2025-12-21 05:17:50.075775: Current learning rate: 0.00879 
2025-12-21 05:20:07.942352: train_loss -0.8163 
2025-12-21 05:20:07.942352: val_loss -0.8289 
2025-12-21 05:20:07.942352: Pseudo dice [0.9066, 0.9388, 0.9222] 
2025-12-21 05:20:07.942352: Epoch time: 137.87 s 
2025-12-21 05:20:08.575224:  
2025-12-21 05:20:08.591036: Epoch 135 
2025-12-21 05:20:08.591036: Current learning rate: 0.00878 
2025-12-21 05:22:26.466424: train_loss -0.8098 
2025-12-21 05:22:26.466424: val_loss -0.8362 
2025-12-21 05:22:26.466424: Pseudo dice [0.9104, 0.9388, 0.9287] 
2025-12-21 05:22:26.482507: Epoch time: 137.89 s 
2025-12-21 05:22:27.131711:  
2025-12-21 05:22:27.131711: Epoch 136 
2025-12-21 05:22:27.131711: Current learning rate: 0.00877 
2025-12-21 05:24:44.987877: train_loss -0.8165 
2025-12-21 05:24:44.987877: val_loss -0.8481 
2025-12-21 05:24:44.993886: Pseudo dice [0.9217, 0.9523, 0.9192] 
2025-12-21 05:24:44.995888: Epoch time: 137.87 s 
2025-12-21 05:24:44.997893: Yayy! New best EMA pseudo Dice: 0.9209 
2025-12-21 05:24:45.873706:  
2025-12-21 05:24:45.873706: Epoch 137 
2025-12-21 05:24:45.873706: Current learning rate: 0.00876 
2025-12-21 05:27:03.884983: train_loss -0.8166 
2025-12-21 05:27:03.884983: val_loss -0.8321 
2025-12-21 05:27:03.884983: Pseudo dice [0.9059, 0.9406, 0.9188] 
2025-12-21 05:27:03.884983: Epoch time: 138.01 s 
2025-12-21 05:27:03.900783: Yayy! New best EMA pseudo Dice: 0.921 
2025-12-21 05:27:04.791445:  
2025-12-21 05:27:04.791445: Epoch 138 
2025-12-21 05:27:04.791445: Current learning rate: 0.00875 
2025-12-21 05:29:22.792122: train_loss -0.8181 
2025-12-21 05:29:22.792122: val_loss -0.8275 
2025-12-21 05:29:22.796127: Pseudo dice [0.9052, 0.9391, 0.9166] 
2025-12-21 05:29:22.796127: Epoch time: 138.0 s 
2025-12-21 05:29:23.431605:  
2025-12-21 05:29:23.447540: Epoch 139 
2025-12-21 05:29:23.447540: Current learning rate: 0.00874 
2025-12-21 05:31:41.376281: train_loss -0.8143 
2025-12-21 05:31:41.376281: val_loss -0.8207 
2025-12-21 05:31:41.378283: Pseudo dice [0.9018, 0.9358, 0.9175] 
2025-12-21 05:31:41.378283: Epoch time: 137.94 s 
2025-12-21 05:31:42.022801:  
2025-12-21 05:31:42.022801: Epoch 140 
2025-12-21 05:31:42.022801: Current learning rate: 0.00873 
2025-12-21 05:34:00.033511: train_loss -0.8196 
2025-12-21 05:34:00.033511: val_loss -0.8356 
2025-12-21 05:34:00.035514: Pseudo dice [0.9136, 0.9461, 0.9133] 
2025-12-21 05:34:00.037515: Epoch time: 138.01 s 
2025-12-21 05:34:00.037515: Yayy! New best EMA pseudo Dice: 0.921 
2025-12-21 05:34:00.897543:  
2025-12-21 05:34:00.897543: Epoch 141 
2025-12-21 05:34:00.913368: Current learning rate: 0.00872 
2025-12-21 05:36:18.782104: train_loss -0.8158 
2025-12-21 05:36:18.782104: val_loss -0.843 
2025-12-21 05:36:18.782104: Pseudo dice [0.9177, 0.9461, 0.9292] 
2025-12-21 05:36:18.782104: Epoch time: 137.88 s 
2025-12-21 05:36:18.782104: Yayy! New best EMA pseudo Dice: 0.922 
2025-12-21 05:36:19.852144:  
2025-12-21 05:36:19.852144: Epoch 142 
2025-12-21 05:36:19.867892: Current learning rate: 0.00871 
2025-12-21 05:38:37.764145: train_loss -0.8178 
2025-12-21 05:38:37.764145: val_loss -0.8459 
2025-12-21 05:38:37.776900: Pseudo dice [0.9193, 0.9502, 0.9167] 
2025-12-21 05:38:37.776900: Epoch time: 137.91 s 
2025-12-21 05:38:37.780199: Yayy! New best EMA pseudo Dice: 0.9227 
2025-12-21 05:38:38.668256:  
2025-12-21 05:38:38.668256: Epoch 143 
2025-12-21 05:38:38.668256: Current learning rate: 0.0087 
2025-12-21 05:40:56.444218: train_loss -0.818 
2025-12-21 05:40:56.446083: val_loss -0.8449 
2025-12-21 05:40:56.446083: Pseudo dice [0.9143, 0.9466, 0.9291] 
2025-12-21 05:40:56.446083: Epoch time: 137.78 s 
2025-12-21 05:40:56.446083: Yayy! New best EMA pseudo Dice: 0.9234 
2025-12-21 05:40:57.355216:  
2025-12-21 05:40:57.355216: Epoch 144 
2025-12-21 05:40:57.357219: Current learning rate: 0.00869 
2025-12-21 05:43:15.074841: train_loss -0.8203 
2025-12-21 05:43:15.074841: val_loss -0.8336 
2025-12-21 05:43:15.076583: Pseudo dice [0.9068, 0.9397, 0.9198] 
2025-12-21 05:43:15.076583: Epoch time: 137.72 s 
2025-12-21 05:43:15.727347:  
2025-12-21 05:43:15.727347: Epoch 145 
2025-12-21 05:43:15.727347: Current learning rate: 0.00868 
2025-12-21 05:45:33.698749: train_loss -0.8206 
2025-12-21 05:45:33.698749: val_loss -0.827 
2025-12-21 05:45:33.698749: Pseudo dice [0.9017, 0.9399, 0.9247] 
2025-12-21 05:45:33.698749: Epoch time: 137.97 s 
2025-12-21 05:45:34.354024:  
2025-12-21 05:45:34.354024: Epoch 146 
2025-12-21 05:45:34.354024: Current learning rate: 0.00868 
2025-12-21 05:47:52.255085: train_loss -0.8188 
2025-12-21 05:47:52.257087: val_loss -0.8409 
2025-12-21 05:47:52.259089: Pseudo dice [0.9206, 0.9479, 0.9123] 
2025-12-21 05:47:52.260830: Epoch time: 137.9 s 
2025-12-21 05:47:52.260830: Yayy! New best EMA pseudo Dice: 0.9236 
2025-12-21 05:47:53.132910:  
2025-12-21 05:47:53.132910: Epoch 147 
2025-12-21 05:47:53.132910: Current learning rate: 0.00867 
2025-12-21 05:50:11.063017: train_loss -0.8201 
2025-12-21 05:50:11.063017: val_loss -0.8461 
2025-12-21 05:50:11.067023: Pseudo dice [0.9185, 0.9514, 0.9177] 
2025-12-21 05:50:11.069026: Epoch time: 137.93 s 
2025-12-21 05:50:11.071029: Yayy! New best EMA pseudo Dice: 0.9241 
2025-12-21 05:50:12.328966:  
2025-12-21 05:50:12.328966: Epoch 148 
2025-12-21 05:50:12.328966: Current learning rate: 0.00866 
2025-12-21 05:52:30.118115: train_loss -0.8105 
2025-12-21 05:52:30.118115: val_loss -0.8411 
2025-12-21 05:52:30.118115: Pseudo dice [0.9122, 0.9454, 0.9208] 
2025-12-21 05:52:30.126763: Epoch time: 137.79 s 
2025-12-21 05:52:30.128766: Yayy! New best EMA pseudo Dice: 0.9243 
2025-12-21 05:52:31.057296:  
2025-12-21 05:52:31.057296: Epoch 149 
2025-12-21 05:52:31.057296: Current learning rate: 0.00865 
2025-12-21 05:54:49.083815: train_loss -0.8197 
2025-12-21 05:54:49.085817: val_loss -0.8389 
2025-12-21 05:54:49.087819: Pseudo dice [0.9155, 0.9476, 0.9089] 
2025-12-21 05:54:49.089821: Epoch time: 138.03 s 
2025-12-21 05:54:49.977719:  
2025-12-21 05:54:49.977719: Epoch 150 
2025-12-21 05:54:49.977719: Current learning rate: 0.00864 
2025-12-21 05:57:07.993537: train_loss -0.8256 
2025-12-21 05:57:07.993537: val_loss -0.8316 
2025-12-21 05:57:07.997541: Pseudo dice [0.9107, 0.9398, 0.9061] 
2025-12-21 05:57:07.999544: Epoch time: 138.02 s 
2025-12-21 05:57:08.767317:  
2025-12-21 05:57:08.767317: Epoch 151 
2025-12-21 05:57:08.767317: Current learning rate: 0.00863 
2025-12-21 05:59:26.497189: train_loss -0.8223 
2025-12-21 05:59:26.497189: val_loss -0.8389 
2025-12-21 05:59:26.512841: Pseudo dice [0.9114, 0.943, 0.9187] 
2025-12-21 05:59:26.512841: Epoch time: 137.73 s 
2025-12-21 05:59:27.162438:  
2025-12-21 05:59:27.162438: Epoch 152 
2025-12-21 05:59:27.162438: Current learning rate: 0.00862 
2025-12-21 06:01:44.972989: train_loss -0.8219 
2025-12-21 06:01:44.972989: val_loss -0.8506 
2025-12-21 06:01:44.974991: Pseudo dice [0.9219, 0.9472, 0.9251] 
2025-12-21 06:01:44.976993: Epoch time: 137.81 s 
2025-12-21 06:01:44.978995: Yayy! New best EMA pseudo Dice: 0.9246 
2025-12-21 06:01:45.862153:  
2025-12-21 06:01:45.864156: Epoch 153 
2025-12-21 06:01:45.864156: Current learning rate: 0.00861 
2025-12-21 06:04:03.873173: train_loss -0.8084 
2025-12-21 06:04:03.873173: val_loss -0.8097 
2025-12-21 06:04:03.875175: Pseudo dice [0.9013, 0.9307, 0.9098] 
2025-12-21 06:04:03.877177: Epoch time: 138.01 s 
2025-12-21 06:04:04.684340:  
2025-12-21 06:04:04.684340: Epoch 154 
2025-12-21 06:04:04.684340: Current learning rate: 0.0086 
2025-12-21 06:06:22.617383: train_loss -0.8123 
2025-12-21 06:06:22.617383: val_loss -0.8364 
2025-12-21 06:06:22.619385: Pseudo dice [0.9132, 0.9404, 0.9233] 
2025-12-21 06:06:22.621387: Epoch time: 137.93 s 
2025-12-21 06:06:23.260461:  
2025-12-21 06:06:23.260461: Epoch 155 
2025-12-21 06:06:23.260461: Current learning rate: 0.00859 
2025-12-21 06:08:41.341550: train_loss -0.8108 
2025-12-21 06:08:41.341550: val_loss -0.8235 
2025-12-21 06:08:41.345387: Pseudo dice [0.9047, 0.9416, 0.9195] 
2025-12-21 06:08:41.347390: Epoch time: 138.08 s 
2025-12-21 06:08:42.006307:  
2025-12-21 06:08:42.006307: Epoch 156 
2025-12-21 06:08:42.006307: Current learning rate: 0.00858 
2025-12-21 06:11:00.281232: train_loss -0.8242 
2025-12-21 06:11:00.281232: val_loss -0.8321 
2025-12-21 06:11:00.289949: Pseudo dice [0.9056, 0.9395, 0.9289] 
2025-12-21 06:11:00.289949: Epoch time: 138.27 s 
2025-12-21 06:11:01.053808:  
2025-12-21 06:11:01.053808: Epoch 157 
2025-12-21 06:11:01.053808: Current learning rate: 0.00858 
2025-12-21 06:13:18.820998: train_loss -0.8188 
2025-12-21 06:13:18.823002: val_loss -0.824 
2025-12-21 06:13:18.827007: Pseudo dice [0.9043, 0.935, 0.9128] 
2025-12-21 06:13:18.829010: Epoch time: 137.77 s 
2025-12-21 06:13:19.479234:  
2025-12-21 06:13:19.479234: Epoch 158 
2025-12-21 06:13:19.479234: Current learning rate: 0.00857 
2025-12-21 06:15:37.454806: train_loss -0.8169 
2025-12-21 06:15:37.454806: val_loss -0.811 
2025-12-21 06:15:37.456809: Pseudo dice [0.9031, 0.9389, 0.9167] 
2025-12-21 06:15:37.458811: Epoch time: 137.98 s 
2025-12-21 06:15:38.272460:  
2025-12-21 06:15:38.272460: Epoch 159 
2025-12-21 06:15:38.272460: Current learning rate: 0.00856 
2025-12-21 06:17:56.193266: train_loss -0.8154 
2025-12-21 06:17:56.193266: val_loss -0.8288 
2025-12-21 06:17:56.195007: Pseudo dice [0.9062, 0.9384, 0.9189] 
2025-12-21 06:17:56.195007: Epoch time: 137.92 s 
2025-12-21 06:17:56.949706:  
2025-12-21 06:17:56.949706: Epoch 160 
2025-12-21 06:17:56.949706: Current learning rate: 0.00855 
2025-12-21 06:20:14.792757: train_loss -0.8203 
2025-12-21 06:20:14.794760: val_loss -0.8327 
2025-12-21 06:20:14.797043: Pseudo dice [0.9125, 0.9426, 0.9189] 
2025-12-21 06:20:14.799934: Epoch time: 137.85 s 
2025-12-21 06:20:15.447983:  
2025-12-21 06:20:15.447983: Epoch 161 
2025-12-21 06:20:15.447983: Current learning rate: 0.00854 
2025-12-21 06:22:33.351009: train_loss -0.8177 
2025-12-21 06:22:33.351009: val_loss -0.8474 
2025-12-21 06:22:33.353011: Pseudo dice [0.9209, 0.9475, 0.9247] 
2025-12-21 06:22:33.357019: Epoch time: 137.9 s 
2025-12-21 06:22:34.005737:  
2025-12-21 06:22:34.005737: Epoch 162 
2025-12-21 06:22:34.005737: Current learning rate: 0.00853 
2025-12-21 06:24:51.948159: train_loss -0.8168 
2025-12-21 06:24:51.948159: val_loss -0.8025 
2025-12-21 06:24:51.948159: Pseudo dice [0.8927, 0.9264, 0.9148] 
2025-12-21 06:24:51.948159: Epoch time: 137.94 s 
2025-12-21 06:24:52.613366:  
2025-12-21 06:24:52.613366: Epoch 163 
2025-12-21 06:24:52.613366: Current learning rate: 0.00852 
2025-12-21 06:27:10.662506: train_loss -0.8163 
2025-12-21 06:27:10.662506: val_loss -0.8169 
2025-12-21 06:27:10.678465: Pseudo dice [0.9018, 0.9333, 0.9142] 
2025-12-21 06:27:10.678465: Epoch time: 138.05 s 
2025-12-21 06:27:11.314337:  
2025-12-21 06:27:11.314337: Epoch 164 
2025-12-21 06:27:11.314337: Current learning rate: 0.00851 
2025-12-21 06:29:29.291563: train_loss -0.8166 
2025-12-21 06:29:29.293566: val_loss -0.8452 
2025-12-21 06:29:29.295568: Pseudo dice [0.9245, 0.9495, 0.9064] 
2025-12-21 06:29:29.297571: Epoch time: 137.98 s 
2025-12-21 06:29:30.099766:  
2025-12-21 06:29:30.099766: Epoch 165 
2025-12-21 06:29:30.099766: Current learning rate: 0.0085 
2025-12-21 06:31:47.825740: train_loss -0.8209 
2025-12-21 06:31:47.826242: val_loss -0.8508 
2025-12-21 06:31:47.826745: Pseudo dice [0.9164, 0.952, 0.93] 
2025-12-21 06:31:47.826745: Epoch time: 137.73 s 
2025-12-21 06:31:48.466821:  
2025-12-21 06:31:48.466821: Epoch 166 
2025-12-21 06:31:48.466821: Current learning rate: 0.00849 
2025-12-21 06:34:06.178474: train_loss -0.8244 
2025-12-21 06:34:06.178474: val_loss -0.8428 
2025-12-21 06:34:06.178474: Pseudo dice [0.9176, 0.9465, 0.921] 
2025-12-21 06:34:06.178474: Epoch time: 137.71 s 
2025-12-21 06:34:06.827912:  
2025-12-21 06:34:06.827912: Epoch 167 
2025-12-21 06:34:06.827912: Current learning rate: 0.00848 
2025-12-21 06:36:24.708897: train_loss -0.8221 
2025-12-21 06:36:24.710900: val_loss -0.8249 
2025-12-21 06:36:24.710900: Pseudo dice [0.9028, 0.9337, 0.9156] 
2025-12-21 06:36:24.710900: Epoch time: 137.88 s 
2025-12-21 06:36:25.413543:  
2025-12-21 06:36:25.413543: Epoch 168 
2025-12-21 06:36:25.413543: Current learning rate: 0.00847 
2025-12-21 06:38:43.259479: train_loss -0.8269 
2025-12-21 06:38:43.261482: val_loss -0.8487 
2025-12-21 06:38:43.263485: Pseudo dice [0.9186, 0.9464, 0.9316] 
2025-12-21 06:38:43.265225: Epoch time: 137.85 s 
2025-12-21 06:38:43.914055:  
2025-12-21 06:38:43.914055: Epoch 169 
2025-12-21 06:38:43.914055: Current learning rate: 0.00847 
2025-12-21 06:41:02.064478: train_loss -0.824 
2025-12-21 06:41:02.066219: val_loss -0.8384 
2025-12-21 06:41:02.070224: Pseudo dice [0.9125, 0.9482, 0.9203] 
2025-12-21 06:41:02.072227: Epoch time: 138.15 s 
2025-12-21 06:41:02.731422:  
2025-12-21 06:41:02.731422: Epoch 170 
2025-12-21 06:41:02.731422: Current learning rate: 0.00846 
2025-12-21 06:43:20.594735: train_loss -0.8275 
2025-12-21 06:43:20.594735: val_loss -0.8486 
2025-12-21 06:43:20.603797: Pseudo dice [0.918, 0.9478, 0.9272] 
2025-12-21 06:43:20.603797: Epoch time: 137.88 s 
2025-12-21 06:43:20.603797: Yayy! New best EMA pseudo Dice: 0.925 
2025-12-21 06:43:21.854597:  
2025-12-21 06:43:21.854597: Epoch 171 
2025-12-21 06:43:21.854597: Current learning rate: 0.00845 
2025-12-21 06:45:39.750698: train_loss -0.8208 
2025-12-21 06:45:39.750698: val_loss -0.8488 
2025-12-21 06:45:39.759250: Pseudo dice [0.9156, 0.9519, 0.9277] 
2025-12-21 06:45:39.759250: Epoch time: 137.9 s 
2025-12-21 06:45:39.759250: Yayy! New best EMA pseudo Dice: 0.9257 
2025-12-21 06:45:40.670433:  
2025-12-21 06:45:40.670433: Epoch 172 
2025-12-21 06:45:40.670433: Current learning rate: 0.00844 
2025-12-21 06:47:58.506942: train_loss -0.8249 
2025-12-21 06:47:58.508945: val_loss -0.8463 
2025-12-21 06:47:58.510949: Pseudo dice [0.9169, 0.9467, 0.9257] 
2025-12-21 06:47:58.512689: Epoch time: 137.84 s 
2025-12-21 06:47:58.514692: Yayy! New best EMA pseudo Dice: 0.9261 
2025-12-21 06:47:59.415754:  
2025-12-21 06:47:59.415754: Epoch 173 
2025-12-21 06:47:59.415754: Current learning rate: 0.00843 
2025-12-21 06:50:17.354433: train_loss -0.8234 
2025-12-21 06:50:17.354433: val_loss -0.8363 
2025-12-21 06:50:17.354433: Pseudo dice [0.9092, 0.9365, 0.928] 
2025-12-21 06:50:17.359597: Epoch time: 137.94 s 
2025-12-21 06:50:18.097091:  
2025-12-21 06:50:18.097091: Epoch 174 
2025-12-21 06:50:18.097091: Current learning rate: 0.00842 
2025-12-21 06:52:35.807996: train_loss -0.8228 
2025-12-21 06:52:35.807996: val_loss -0.8441 
2025-12-21 06:52:35.809998: Pseudo dice [0.9157, 0.9413, 0.9275] 
2025-12-21 06:52:35.812002: Epoch time: 137.71 s 
2025-12-21 06:52:35.814004: Yayy! New best EMA pseudo Dice: 0.9262 
2025-12-21 06:52:36.719626:  
2025-12-21 06:52:36.719626: Epoch 175 
2025-12-21 06:52:36.735327: Current learning rate: 0.00841 
2025-12-21 06:54:54.831028: train_loss -0.8235 
2025-12-21 06:54:54.833030: val_loss -0.8411 
2025-12-21 06:54:54.837035: Pseudo dice [0.916, 0.9459, 0.9192] 
2025-12-21 06:54:54.841040: Epoch time: 138.11 s 
2025-12-21 06:54:54.843043: Yayy! New best EMA pseudo Dice: 0.9263 
2025-12-21 06:54:55.941341:  
2025-12-21 06:54:55.941341: Epoch 176 
2025-12-21 06:54:55.941341: Current learning rate: 0.0084 
2025-12-21 06:57:13.602004: train_loss -0.8237 
2025-12-21 06:57:13.603745: val_loss -0.8597 
2025-12-21 06:57:13.605748: Pseudo dice [0.9239, 0.9535, 0.9385] 
2025-12-21 06:57:13.607750: Epoch time: 137.66 s 
2025-12-21 06:57:13.609752: Yayy! New best EMA pseudo Dice: 0.9275 
2025-12-21 06:57:14.710943:  
2025-12-21 06:57:14.712684: Epoch 177 
2025-12-21 06:57:14.712684: Current learning rate: 0.00839 
2025-12-21 06:59:32.587392: train_loss -0.8265 
2025-12-21 06:59:32.587392: val_loss -0.831 
2025-12-21 06:59:32.587392: Pseudo dice [0.9046, 0.9429, 0.9219] 
2025-12-21 06:59:32.587392: Epoch time: 137.88 s 
2025-12-21 06:59:33.233515:  
2025-12-21 06:59:33.233515: Epoch 178 
2025-12-21 06:59:33.233515: Current learning rate: 0.00838 
2025-12-21 07:01:51.237979: train_loss -0.8205 
2025-12-21 07:01:51.253945: val_loss -0.8113 
2025-12-21 07:01:51.253945: Pseudo dice [0.893, 0.9306, 0.9156] 
2025-12-21 07:01:51.253945: Epoch time: 138.0 s 
2025-12-21 07:01:51.902301:  
2025-12-21 07:01:51.902301: Epoch 179 
2025-12-21 07:01:51.902301: Current learning rate: 0.00837 
2025-12-21 07:04:09.757290: train_loss -0.8318 
2025-12-21 07:04:09.757290: val_loss -0.8585 
2025-12-21 07:04:09.757290: Pseudo dice [0.9247, 0.9534, 0.9239] 
2025-12-21 07:04:09.757290: Epoch time: 137.87 s 
2025-12-21 07:04:10.517078:  
2025-12-21 07:04:10.517078: Epoch 180 
2025-12-21 07:04:10.517078: Current learning rate: 0.00836 
2025-12-21 07:06:28.454338: train_loss -0.8319 
2025-12-21 07:06:28.454338: val_loss -0.8481 
2025-12-21 07:06:28.458081: Pseudo dice [0.9231, 0.9497, 0.9205] 
2025-12-21 07:06:28.458081: Epoch time: 137.94 s 
2025-12-21 07:06:29.107295:  
2025-12-21 07:06:29.107295: Epoch 181 
2025-12-21 07:06:29.123244: Current learning rate: 0.00836 
2025-12-21 07:08:47.215820: train_loss -0.8247 
2025-12-21 07:08:47.215820: val_loss -0.8525 
2025-12-21 07:08:47.215820: Pseudo dice [0.9236, 0.9516, 0.9153] 
2025-12-21 07:08:47.215820: Epoch time: 138.11 s 
2025-12-21 07:08:48.042814:  
2025-12-21 07:08:48.042814: Epoch 182 
2025-12-21 07:08:48.042814: Current learning rate: 0.00835 
2025-12-21 07:11:06.344431: train_loss -0.8257 
2025-12-21 07:11:06.344431: val_loss -0.8546 
2025-12-21 07:11:06.344431: Pseudo dice [0.9215, 0.946, 0.9258] 
2025-12-21 07:11:06.344431: Epoch time: 138.3 s 
2025-12-21 07:11:06.360432: Yayy! New best EMA pseudo Dice: 0.9277 
2025-12-21 07:11:07.325689:  
2025-12-21 07:11:07.325689: Epoch 183 
2025-12-21 07:11:07.325689: Current learning rate: 0.00834 
2025-12-21 07:13:25.301532: train_loss -0.8269 
2025-12-21 07:13:25.303537: val_loss -0.8463 
2025-12-21 07:13:25.307285: Pseudo dice [0.9184, 0.9465, 0.9281] 
2025-12-21 07:13:25.309287: Epoch time: 137.98 s 
2025-12-21 07:13:25.311289: Yayy! New best EMA pseudo Dice: 0.928 
2025-12-21 07:13:26.210828:  
2025-12-21 07:13:26.210828: Epoch 184 
2025-12-21 07:13:26.210828: Current learning rate: 0.00833 
2025-12-21 07:15:44.344748: train_loss -0.8234 
2025-12-21 07:15:44.344748: val_loss -0.8312 
2025-12-21 07:15:44.360442: Pseudo dice [0.9119, 0.9399, 0.9112] 
2025-12-21 07:15:44.360442: Epoch time: 138.13 s 
2025-12-21 07:15:45.007727:  
2025-12-21 07:15:45.007727: Epoch 185 
2025-12-21 07:15:45.007727: Current learning rate: 0.00832 
2025-12-21 07:18:03.063769: train_loss -0.8262 
2025-12-21 07:18:03.063769: val_loss -0.8563 
2025-12-21 07:18:03.063769: Pseudo dice [0.9233, 0.9511, 0.9298] 
2025-12-21 07:18:03.063769: Epoch time: 138.06 s 
2025-12-21 07:18:03.063769: Yayy! New best EMA pseudo Dice: 0.928 
2025-12-21 07:18:03.998459:  
2025-12-21 07:18:03.998459: Epoch 186 
2025-12-21 07:18:03.998459: Current learning rate: 0.00831 
2025-12-21 07:20:22.054327: train_loss -0.8255 
2025-12-21 07:20:22.054327: val_loss -0.8647 
2025-12-21 07:20:22.060335: Pseudo dice [0.9264, 0.9554, 0.9312] 
2025-12-21 07:20:22.062338: Epoch time: 138.06 s 
2025-12-21 07:20:22.062338: Yayy! New best EMA pseudo Dice: 0.929 
2025-12-21 07:20:22.972230:  
2025-12-21 07:20:22.972230: Epoch 187 
2025-12-21 07:20:22.972230: Current learning rate: 0.0083 
2025-12-21 07:22:40.728629: train_loss -0.8289 
2025-12-21 07:22:40.728629: val_loss -0.8481 
2025-12-21 07:22:40.730631: Pseudo dice [0.9191, 0.9473, 0.9244] 
2025-12-21 07:22:40.730631: Epoch time: 137.76 s 
2025-12-21 07:22:40.735878: Yayy! New best EMA pseudo Dice: 0.9291 
2025-12-21 07:22:41.832029:  
2025-12-21 07:22:41.832029: Epoch 188 
2025-12-21 07:22:41.832029: Current learning rate: 0.00829 
2025-12-21 07:24:59.629142: train_loss -0.8336 
2025-12-21 07:24:59.629142: val_loss -0.8491 
2025-12-21 07:24:59.629142: Pseudo dice [0.9172, 0.9479, 0.9318] 
2025-12-21 07:24:59.629142: Epoch time: 137.8 s 
2025-12-21 07:24:59.629142: Yayy! New best EMA pseudo Dice: 0.9294 
2025-12-21 07:25:00.547119:  
2025-12-21 07:25:00.547119: Epoch 189 
2025-12-21 07:25:00.557455: Current learning rate: 0.00828 
2025-12-21 07:27:18.298160: train_loss -0.8303 
2025-12-21 07:27:18.298160: val_loss -0.845 
2025-12-21 07:27:18.300163: Pseudo dice [0.9179, 0.9482, 0.9119] 
2025-12-21 07:27:18.302165: Epoch time: 137.75 s 
2025-12-21 07:27:18.956692:  
2025-12-21 07:27:18.956692: Epoch 190 
2025-12-21 07:27:18.956692: Current learning rate: 0.00827 
2025-12-21 07:29:36.877980: train_loss -0.8282 
2025-12-21 07:29:36.879982: val_loss -0.8523 
2025-12-21 07:29:36.881825: Pseudo dice [0.9236, 0.9474, 0.9237] 
2025-12-21 07:29:36.883827: Epoch time: 137.92 s 
2025-12-21 07:29:37.529400:  
2025-12-21 07:29:37.529400: Epoch 191 
2025-12-21 07:29:37.529400: Current learning rate: 0.00826 
2025-12-21 07:31:55.360260: train_loss -0.8274 
2025-12-21 07:31:55.360260: val_loss -0.8391 
2025-12-21 07:31:55.363999: Pseudo dice [0.9089, 0.9379, 0.9321] 
2025-12-21 07:31:55.366001: Epoch time: 137.83 s 
2025-12-21 07:31:56.020464:  
2025-12-21 07:31:56.020464: Epoch 192 
2025-12-21 07:31:56.020464: Current learning rate: 0.00825 
2025-12-21 07:34:13.859871: train_loss -0.8339 
2025-12-21 07:34:13.861873: val_loss -0.854 
2025-12-21 07:34:13.863613: Pseudo dice [0.9239, 0.949, 0.9297] 
2025-12-21 07:34:13.865615: Epoch time: 137.84 s 
2025-12-21 07:34:13.867616: Yayy! New best EMA pseudo Dice: 0.9296 
2025-12-21 07:34:14.755046:  
2025-12-21 07:34:14.755046: Epoch 193 
2025-12-21 07:34:14.755046: Current learning rate: 0.00824 
2025-12-21 07:36:32.693829: train_loss -0.8225 
2025-12-21 07:36:32.693829: val_loss -0.8529 
2025-12-21 07:36:32.693829: Pseudo dice [0.922, 0.9525, 0.9229] 
2025-12-21 07:36:32.702103: Epoch time: 137.94 s 
2025-12-21 07:36:32.704106: Yayy! New best EMA pseudo Dice: 0.9298 
2025-12-21 07:36:33.840116:  
2025-12-21 07:36:33.840116: Epoch 194 
2025-12-21 07:36:33.840116: Current learning rate: 0.00824 
2025-12-21 07:38:51.799920: train_loss -0.8316 
2025-12-21 07:38:51.799920: val_loss -0.8494 
2025-12-21 07:38:51.799920: Pseudo dice [0.9187, 0.9472, 0.9282] 
2025-12-21 07:38:51.807178: Epoch time: 137.96 s 
2025-12-21 07:38:51.809180: Yayy! New best EMA pseudo Dice: 0.93 
2025-12-21 07:38:52.735621:  
2025-12-21 07:38:52.735621: Epoch 195 
2025-12-21 07:38:52.735621: Current learning rate: 0.00823 
2025-12-21 07:41:10.517476: train_loss -0.8355 
2025-12-21 07:41:10.517476: val_loss -0.8516 
2025-12-21 07:41:10.521481: Pseudo dice [0.9195, 0.9466, 0.928] 
2025-12-21 07:41:10.523482: Epoch time: 137.78 s 
2025-12-21 07:41:10.525484: Yayy! New best EMA pseudo Dice: 0.9301 
2025-12-21 07:41:11.452216:  
2025-12-21 07:41:11.452216: Epoch 196 
2025-12-21 07:41:11.452216: Current learning rate: 0.00822 
2025-12-21 07:43:29.249518: train_loss -0.8305 
2025-12-21 07:43:29.249518: val_loss -0.8372 
2025-12-21 07:43:29.252112: Pseudo dice [0.9102, 0.9404, 0.9245] 
2025-12-21 07:43:29.252112: Epoch time: 137.8 s 
2025-12-21 07:43:29.911006:  
2025-12-21 07:43:29.914516: Epoch 197 
2025-12-21 07:43:29.914516: Current learning rate: 0.00821 
2025-12-21 07:45:47.811336: train_loss -0.8281 
2025-12-21 07:45:47.813076: val_loss -0.8492 
2025-12-21 07:45:47.813076: Pseudo dice [0.9184, 0.9524, 0.9193] 
2025-12-21 07:45:47.817779: Epoch time: 137.9 s 
2025-12-21 07:45:48.486347:  
2025-12-21 07:45:48.486347: Epoch 198 
2025-12-21 07:45:48.488992: Current learning rate: 0.0082 
2025-12-21 07:48:06.369680: train_loss -0.8299 
2025-12-21 07:48:06.369680: val_loss -0.8229 
2025-12-21 07:48:06.385317: Pseudo dice [0.9014, 0.9299, 0.921] 
2025-12-21 07:48:06.385317: Epoch time: 137.89 s 
2025-12-21 07:48:07.044654:  
2025-12-21 07:48:07.046656: Epoch 199 
2025-12-21 07:48:07.046656: Current learning rate: 0.00819 
2025-12-21 07:50:24.784239: train_loss -0.8335 
2025-12-21 07:50:24.784239: val_loss -0.8372 
2025-12-21 07:50:24.787871: Pseudo dice [0.9119, 0.9415, 0.9165] 
2025-12-21 07:50:24.789875: Epoch time: 137.74 s 
2025-12-21 07:50:26.051174:  
2025-12-21 07:50:26.051174: Epoch 200 
2025-12-21 07:50:26.051174: Current learning rate: 0.00818 
2025-12-21 07:52:43.917813: train_loss -0.8279 
2025-12-21 07:52:43.917813: val_loss -0.8439 
2025-12-21 07:52:43.917813: Pseudo dice [0.9158, 0.9499, 0.9203] 
2025-12-21 07:52:43.930797: Epoch time: 137.87 s 
2025-12-21 07:52:44.599653:  
2025-12-21 07:52:44.599653: Epoch 201 
2025-12-21 07:52:44.599653: Current learning rate: 0.00817 
2025-12-21 07:55:02.583364: train_loss -0.836 
2025-12-21 07:55:02.585366: val_loss -0.8648 
2025-12-21 07:55:02.587368: Pseudo dice [0.924, 0.9521, 0.9354] 
2025-12-21 07:55:02.589369: Epoch time: 137.98 s 
2025-12-21 07:55:03.239238:  
2025-12-21 07:55:03.239238: Epoch 202 
2025-12-21 07:55:03.239238: Current learning rate: 0.00816 
2025-12-21 07:57:20.960049: train_loss -0.8347 
2025-12-21 07:57:20.960049: val_loss -0.8697 
2025-12-21 07:57:20.962052: Pseudo dice [0.9298, 0.9576, 0.9311] 
2025-12-21 07:57:20.966489: Epoch time: 137.72 s 
2025-12-21 07:57:21.748429:  
2025-12-21 07:57:21.750431: Epoch 203 
2025-12-21 07:57:21.750431: Current learning rate: 0.00815 
2025-12-21 07:59:39.632785: train_loss -0.8303 
2025-12-21 07:59:39.632785: val_loss -0.8329 
2025-12-21 07:59:39.636788: Pseudo dice [0.9061, 0.9385, 0.9234] 
2025-12-21 07:59:39.638529: Epoch time: 137.89 s 
2025-12-21 07:59:40.294236:  
2025-12-21 07:59:40.294236: Epoch 204 
2025-12-21 07:59:40.297241: Current learning rate: 0.00814 
2025-12-21 08:01:58.127683: train_loss -0.8318 
2025-12-21 08:01:58.127683: val_loss -0.8558 
2025-12-21 08:01:58.129685: Pseudo dice [0.9182, 0.9557, 0.9328] 
2025-12-21 08:01:58.131687: Epoch time: 137.83 s 
2025-12-21 08:01:58.960002:  
2025-12-21 08:01:58.960002: Epoch 205 
2025-12-21 08:01:58.960002: Current learning rate: 0.00813 
2025-12-21 08:04:16.869021: train_loss -0.8326 
2025-12-21 08:04:16.869021: val_loss -0.8429 
2025-12-21 08:04:16.873026: Pseudo dice [0.9139, 0.9437, 0.9309] 
2025-12-21 08:04:16.874768: Epoch time: 137.91 s 
2025-12-21 08:04:17.563689:  
2025-12-21 08:04:17.563689: Epoch 206 
2025-12-21 08:04:17.569855: Current learning rate: 0.00813 
2025-12-21 08:06:35.354836: train_loss -0.8347 
2025-12-21 08:06:35.354836: val_loss -0.8424 
2025-12-21 08:06:35.358261: Pseudo dice [0.9125, 0.9409, 0.9257] 
2025-12-21 08:06:35.360263: Epoch time: 137.79 s 
2025-12-21 08:06:35.981830:  
2025-12-21 08:06:35.981830: Epoch 207 
2025-12-21 08:06:35.981830: Current learning rate: 0.00812 
2025-12-21 08:08:54.040458: train_loss -0.8316 
2025-12-21 08:08:54.040458: val_loss -0.8573 
2025-12-21 08:08:54.044462: Pseudo dice [0.9234, 0.9532, 0.9295] 
2025-12-21 08:08:54.045464: Epoch time: 138.06 s 
2025-12-21 08:08:54.678358:  
2025-12-21 08:08:54.678358: Epoch 208 
2025-12-21 08:08:54.678358: Current learning rate: 0.00811 
2025-12-21 08:11:12.899852: train_loss -0.8239 
2025-12-21 08:11:12.901857: val_loss -0.8457 
2025-12-21 08:11:12.903860: Pseudo dice [0.9162, 0.9488, 0.9192] 
2025-12-21 08:11:12.907603: Epoch time: 138.22 s 
2025-12-21 08:11:13.567534:  
2025-12-21 08:11:13.567534: Epoch 209 
2025-12-21 08:11:13.571279: Current learning rate: 0.0081 
2025-12-21 08:13:31.588362: train_loss -0.823 
2025-12-21 08:13:31.588362: val_loss -0.8389 
2025-12-21 08:13:31.606660: Pseudo dice [0.9108, 0.9407, 0.9254] 
2025-12-21 08:13:31.608663: Epoch time: 138.02 s 
2025-12-21 08:13:32.238164:  
2025-12-21 08:13:32.238164: Epoch 210 
2025-12-21 08:13:32.238164: Current learning rate: 0.00809 
2025-12-21 08:15:50.079767: train_loss -0.8306 
2025-12-21 08:15:50.079767: val_loss -0.8467 
2025-12-21 08:15:50.079767: Pseudo dice [0.921, 0.9485, 0.9196] 
2025-12-21 08:15:50.085215: Epoch time: 137.84 s 
2025-12-21 08:15:50.720602:  
2025-12-21 08:15:50.720602: Epoch 211 
2025-12-21 08:15:50.722939: Current learning rate: 0.00808 
2025-12-21 08:18:08.602732: train_loss -0.834 
2025-12-21 08:18:08.602732: val_loss -0.837 
2025-12-21 08:18:08.604734: Pseudo dice [0.9147, 0.9476, 0.9147] 
2025-12-21 08:18:08.606736: Epoch time: 137.88 s 
2025-12-21 08:18:09.420748:  
2025-12-21 08:18:09.420748: Epoch 212 
2025-12-21 08:18:09.420748: Current learning rate: 0.00807 
2025-12-21 08:20:27.194003: train_loss -0.8262 
2025-12-21 08:20:27.194003: val_loss -0.8542 
2025-12-21 08:20:27.196006: Pseudo dice [0.9226, 0.948, 0.9315] 
2025-12-21 08:20:27.199508: Epoch time: 137.78 s 
2025-12-21 08:20:27.840547:  
2025-12-21 08:20:27.840547: Epoch 213 
2025-12-21 08:20:27.840547: Current learning rate: 0.00806 
2025-12-21 08:22:45.739163: train_loss -0.8365 
2025-12-21 08:22:45.741166: val_loss -0.8148 
2025-12-21 08:22:45.743170: Pseudo dice [0.8974, 0.9359, 0.9231] 
2025-12-21 08:22:45.746914: Epoch time: 137.9 s 
2025-12-21 08:22:46.376557:  
2025-12-21 08:22:46.392479: Epoch 214 
2025-12-21 08:22:46.392479: Current learning rate: 0.00805 
2025-12-21 08:25:04.358809: train_loss -0.828 
2025-12-21 08:25:04.358809: val_loss -0.8354 
2025-12-21 08:25:04.358809: Pseudo dice [0.9059, 0.9416, 0.9224] 
2025-12-21 08:25:04.368994: Epoch time: 137.98 s 
2025-12-21 08:25:05.007154:  
2025-12-21 08:25:05.007154: Epoch 215 
2025-12-21 08:25:05.008895: Current learning rate: 0.00804 
2025-12-21 08:27:22.718882: train_loss -0.8322 
2025-12-21 08:27:22.718882: val_loss -0.8502 
2025-12-21 08:27:22.720885: Pseudo dice [0.9209, 0.9493, 0.9229] 
2025-12-21 08:27:22.720885: Epoch time: 137.71 s 
2025-12-21 08:27:23.364853:  
2025-12-21 08:27:23.364853: Epoch 216 
2025-12-21 08:27:23.364853: Current learning rate: 0.00803 
2025-12-21 08:29:41.252512: train_loss -0.8265 
2025-12-21 08:29:41.252512: val_loss -0.8434 
2025-12-21 08:29:41.256254: Pseudo dice [0.9148, 0.9436, 0.9234] 
2025-12-21 08:29:41.260260: Epoch time: 137.89 s 
2025-12-21 08:29:41.905729:  
2025-12-21 08:29:41.905729: Epoch 217 
2025-12-21 08:29:41.905729: Current learning rate: 0.00802 
2025-12-21 08:31:59.917571: train_loss -0.828 
2025-12-21 08:31:59.917571: val_loss -0.8472 
2025-12-21 08:31:59.917571: Pseudo dice [0.9127, 0.9481, 0.9302] 
2025-12-21 08:31:59.921311: Epoch time: 138.01 s 
2025-12-21 08:32:00.732193:  
2025-12-21 08:32:00.732193: Epoch 218 
2025-12-21 08:32:00.732193: Current learning rate: 0.00801 
2025-12-21 08:34:18.667448: train_loss -0.8304 
2025-12-21 08:34:18.667448: val_loss -0.8432 
2025-12-21 08:34:18.669451: Pseudo dice [0.9136, 0.945, 0.9277] 
2025-12-21 08:34:18.673188: Epoch time: 137.94 s 
2025-12-21 08:34:19.302535:  
2025-12-21 08:34:19.302535: Epoch 219 
2025-12-21 08:34:19.302535: Current learning rate: 0.00801 
2025-12-21 08:36:37.233749: train_loss -0.8271 
2025-12-21 08:36:37.235752: val_loss -0.8521 
2025-12-21 08:36:37.237755: Pseudo dice [0.9165, 0.9475, 0.9199] 
2025-12-21 08:36:37.239757: Epoch time: 137.93 s 
2025-12-21 08:36:38.044648:  
2025-12-21 08:36:38.044648: Epoch 220 
2025-12-21 08:36:38.060475: Current learning rate: 0.008 
2025-12-21 08:38:55.959365: train_loss -0.8325 
2025-12-21 08:38:55.961367: val_loss -0.8553 
2025-12-21 08:38:55.965966: Pseudo dice [0.9222, 0.9521, 0.9277] 
2025-12-21 08:38:55.971476: Epoch time: 137.91 s 
2025-12-21 08:38:56.611327:  
2025-12-21 08:38:56.611327: Epoch 221 
2025-12-21 08:38:56.611327: Current learning rate: 0.00799 
2025-12-21 08:41:14.634765: train_loss -0.8308 
2025-12-21 08:41:14.634765: val_loss -0.8509 
2025-12-21 08:41:14.639771: Pseudo dice [0.9198, 0.9544, 0.916] 
2025-12-21 08:41:14.643776: Epoch time: 138.02 s 
2025-12-21 08:41:15.287461:  
2025-12-21 08:41:15.287461: Epoch 222 
2025-12-21 08:41:15.287461: Current learning rate: 0.00798 
2025-12-21 08:43:33.235998: train_loss -0.8353 
2025-12-21 08:43:33.235998: val_loss -0.8624 
2025-12-21 08:43:33.238000: Pseudo dice [0.9267, 0.9545, 0.9276] 
2025-12-21 08:43:33.239741: Epoch time: 137.95 s 
2025-12-21 08:43:33.981361:  
2025-12-21 08:43:33.981361: Epoch 223 
2025-12-21 08:43:33.983935: Current learning rate: 0.00797 
2025-12-21 08:45:51.684257: train_loss -0.8327 
2025-12-21 08:45:51.684257: val_loss -0.8412 
2025-12-21 08:45:51.684257: Pseudo dice [0.9104, 0.9415, 0.9228] 
2025-12-21 08:45:51.695400: Epoch time: 137.72 s 
2025-12-21 08:45:52.491538:  
2025-12-21 08:45:52.491538: Epoch 224 
2025-12-21 08:45:52.491538: Current learning rate: 0.00796 
2025-12-21 08:48:10.484014: train_loss -0.8256 
2025-12-21 08:48:10.486017: val_loss -0.857 
2025-12-21 08:48:10.488019: Pseudo dice [0.9239, 0.9514, 0.9215] 
2025-12-21 08:48:10.491769: Epoch time: 137.99 s 
2025-12-21 08:48:11.132849:  
2025-12-21 08:48:11.132849: Epoch 225 
2025-12-21 08:48:11.132849: Current learning rate: 0.00795 
2025-12-21 08:50:28.880582: train_loss -0.831 
2025-12-21 08:50:28.880582: val_loss -0.8562 
2025-12-21 08:50:28.880582: Pseudo dice [0.9252, 0.9562, 0.9129] 
2025-12-21 08:50:28.880582: Epoch time: 137.75 s 
2025-12-21 08:50:29.672829:  
2025-12-21 08:50:29.672829: Epoch 226 
2025-12-21 08:50:29.674832: Current learning rate: 0.00794 
2025-12-21 08:52:47.415727: train_loss -0.8378 
2025-12-21 08:52:47.415727: val_loss -0.8473 
2025-12-21 08:52:47.419732: Pseudo dice [0.9121, 0.9459, 0.9328] 
2025-12-21 08:52:47.421472: Epoch time: 137.74 s 
2025-12-21 08:52:48.044219:  
2025-12-21 08:52:48.044219: Epoch 227 
2025-12-21 08:52:48.059849: Current learning rate: 0.00793 
2025-12-21 08:55:06.047002: train_loss -0.834 
2025-12-21 08:55:06.047002: val_loss -0.8438 
2025-12-21 08:55:06.047002: Pseudo dice [0.9142, 0.9428, 0.934] 
2025-12-21 08:55:06.060507: Epoch time: 138.0 s 
2025-12-21 08:55:06.684528:  
2025-12-21 08:55:06.684528: Epoch 228 
2025-12-21 08:55:06.684528: Current learning rate: 0.00792 
2025-12-21 08:57:25.648463: train_loss -0.8383 
2025-12-21 08:57:25.664293: val_loss -0.8608 
2025-12-21 08:57:25.664293: Pseudo dice [0.9216, 0.9526, 0.9391] 
2025-12-21 08:57:25.667792: Epoch time: 138.97 s 
2025-12-21 08:57:25.669795: Yayy! New best EMA pseudo Dice: 0.9307 
2025-12-21 08:57:26.664636:  
2025-12-21 08:57:26.664636: Epoch 229 
2025-12-21 08:57:26.664636: Current learning rate: 0.00791 
2025-12-21 08:59:45.368671: train_loss -0.8298 
2025-12-21 08:59:45.368671: val_loss -0.853 
2025-12-21 08:59:45.368671: Pseudo dice [0.9193, 0.9469, 0.9222] 
2025-12-21 08:59:45.368671: Epoch time: 138.71 s 
2025-12-21 08:59:45.990458:  
2025-12-21 08:59:45.990458: Epoch 230 
2025-12-21 08:59:45.990458: Current learning rate: 0.0079 
2025-12-21 09:02:04.541201: train_loss -0.8339 
2025-12-21 09:02:04.541201: val_loss -0.8433 
2025-12-21 09:02:04.545205: Pseudo dice [0.9103, 0.948, 0.9254] 
2025-12-21 09:02:04.547045: Epoch time: 138.55 s 
2025-12-21 09:02:05.343411:  
2025-12-21 09:02:05.343411: Epoch 231 
2025-12-21 09:02:05.343411: Current learning rate: 0.00789 
2025-12-21 09:04:24.072331: train_loss -0.832 
2025-12-21 09:04:24.074335: val_loss -0.8431 
2025-12-21 09:04:24.076338: Pseudo dice [0.91, 0.945, 0.9272] 
2025-12-21 09:04:24.078340: Epoch time: 138.73 s 
2025-12-21 09:04:24.853197:  
2025-12-21 09:04:24.853197: Epoch 232 
2025-12-21 09:04:24.853197: Current learning rate: 0.00789 
2025-12-21 09:06:43.567759: train_loss -0.8303 
2025-12-21 09:06:43.567759: val_loss -0.8382 
2025-12-21 09:06:43.571763: Pseudo dice [0.9119, 0.9439, 0.9154] 
2025-12-21 09:06:43.573503: Epoch time: 138.71 s 
2025-12-21 09:06:44.200133:  
2025-12-21 09:06:44.200133: Epoch 233 
2025-12-21 09:06:44.200133: Current learning rate: 0.00788 
2025-12-21 09:09:03.120419: train_loss -0.8358 
2025-12-21 09:09:03.122161: val_loss -0.8487 
2025-12-21 09:09:03.124163: Pseudo dice [0.9137, 0.9466, 0.9317] 
2025-12-21 09:09:03.128168: Epoch time: 138.92 s 
2025-12-21 09:09:03.747493:  
2025-12-21 09:09:03.747493: Epoch 234 
2025-12-21 09:09:03.747493: Current learning rate: 0.00787 
2025-12-21 09:11:22.283614: train_loss -0.8361 
2025-12-21 09:11:22.283614: val_loss -0.8481 
2025-12-21 09:11:22.299592: Pseudo dice [0.9177, 0.9479, 0.9201] 
2025-12-21 09:11:22.299592: Epoch time: 138.54 s 
2025-12-21 09:11:22.949270:  
2025-12-21 09:11:22.949270: Epoch 235 
2025-12-21 09:11:22.949270: Current learning rate: 0.00786 
2025-12-21 09:13:41.252000: train_loss -0.8312 
2025-12-21 09:13:41.252000: val_loss -0.851 
2025-12-21 09:13:41.252000: Pseudo dice [0.9209, 0.9495, 0.9154] 
2025-12-21 09:13:41.258139: Epoch time: 138.3 s 
2025-12-21 09:13:41.870133:  
2025-12-21 09:13:41.870133: Epoch 236 
2025-12-21 09:13:41.870133: Current learning rate: 0.00785 
2025-12-21 09:16:00.265984: train_loss -0.8266 
2025-12-21 09:16:00.265984: val_loss -0.8499 
2025-12-21 09:16:00.269988: Pseudo dice [0.9182, 0.9487, 0.9248] 
2025-12-21 09:16:00.271990: Epoch time: 138.4 s 
2025-12-21 09:16:01.072122:  
2025-12-21 09:16:01.072122: Epoch 237 
2025-12-21 09:16:01.073125: Current learning rate: 0.00784 
2025-12-21 09:18:19.281341: train_loss -0.8292 
2025-12-21 09:18:19.281341: val_loss -0.857 
2025-12-21 09:18:19.286603: Pseudo dice [0.918, 0.9537, 0.9315] 
2025-12-21 09:18:19.290582: Epoch time: 138.21 s 
2025-12-21 09:18:19.939419:  
2025-12-21 09:18:19.939419: Epoch 238 
2025-12-21 09:18:19.939419: Current learning rate: 0.00783 
2025-12-21 09:20:37.837101: train_loss -0.8383 
2025-12-21 09:20:37.837101: val_loss -0.866 
2025-12-21 09:20:37.853060: Pseudo dice [0.9273, 0.956, 0.934] 
2025-12-21 09:20:37.853060: Epoch time: 137.9 s 
2025-12-21 09:20:37.853060: Yayy! New best EMA pseudo Dice: 0.9309 
2025-12-21 09:20:38.708763:  
2025-12-21 09:20:38.708763: Epoch 239 
2025-12-21 09:20:38.708763: Current learning rate: 0.00782 
2025-12-21 09:22:56.508838: train_loss -0.8426 
2025-12-21 09:22:56.508838: val_loss -0.861 
2025-12-21 09:22:56.512842: Pseudo dice [0.9219, 0.9516, 0.9366] 
2025-12-21 09:22:56.514344: Epoch time: 137.8 s 
2025-12-21 09:22:56.514344: Yayy! New best EMA pseudo Dice: 0.9315 
2025-12-21 09:22:57.416503:  
2025-12-21 09:22:57.416503: Epoch 240 
2025-12-21 09:22:57.416503: Current learning rate: 0.00781 
2025-12-21 09:25:15.366156: train_loss -0.8349 
2025-12-21 09:25:15.366156: val_loss -0.8508 
2025-12-21 09:25:15.366156: Pseudo dice [0.9166, 0.9513, 0.926] 
2025-12-21 09:25:15.366156: Epoch time: 137.95 s 
2025-12-21 09:25:16.115482:  
2025-12-21 09:25:16.115482: Epoch 241 
2025-12-21 09:25:16.115482: Current learning rate: 0.0078 
2025-12-21 09:27:34.086083: train_loss -0.8324 
2025-12-21 09:27:34.086083: val_loss -0.8526 
2025-12-21 09:27:34.096648: Pseudo dice [0.9159, 0.9468, 0.9283] 
2025-12-21 09:27:34.100508: Epoch time: 137.97 s 
2025-12-21 09:27:34.736386:  
2025-12-21 09:27:34.736386: Epoch 242 
2025-12-21 09:27:34.736386: Current learning rate: 0.00779 
2025-12-21 09:29:52.622767: train_loss -0.8258 
2025-12-21 09:29:52.622767: val_loss -0.8681 
2025-12-21 09:29:52.638876: Pseudo dice [0.9288, 0.9614, 0.9281] 
2025-12-21 09:29:52.638876: Epoch time: 137.89 s 
2025-12-21 09:29:52.638876: Yayy! New best EMA pseudo Dice: 0.9321 
2025-12-21 09:29:53.684799:  
2025-12-21 09:29:53.684799: Epoch 243 
2025-12-21 09:29:53.684799: Current learning rate: 0.00778 
2025-12-21 09:32:11.697230: train_loss -0.8272 
2025-12-21 09:32:11.697230: val_loss -0.848 
2025-12-21 09:32:11.701234: Pseudo dice [0.9182, 0.9481, 0.9171] 
2025-12-21 09:32:11.703236: Epoch time: 138.01 s 
2025-12-21 09:32:12.466113:  
2025-12-21 09:32:12.482197: Epoch 244 
2025-12-21 09:32:12.484435: Current learning rate: 0.00777 
2025-12-21 09:34:30.361091: train_loss -0.8262 
2025-12-21 09:34:30.362890: val_loss -0.8148 
2025-12-21 09:34:30.364893: Pseudo dice [0.8965, 0.9318, 0.9164] 
2025-12-21 09:34:30.366895: Epoch time: 137.89 s 
2025-12-21 09:34:31.002134:  
2025-12-21 09:34:31.002134: Epoch 245 
2025-12-21 09:34:31.004714: Current learning rate: 0.00777 
2025-12-21 09:36:48.772638: train_loss -0.8245 
2025-12-21 09:36:48.772638: val_loss -0.8447 
2025-12-21 09:36:48.772638: Pseudo dice [0.9159, 0.944, 0.9259] 
2025-12-21 09:36:48.779591: Epoch time: 137.77 s 
2025-12-21 09:36:49.408780:  
2025-12-21 09:36:49.408780: Epoch 246 
2025-12-21 09:36:49.408780: Current learning rate: 0.00776 
2025-12-21 09:39:07.296077: train_loss -0.8299 
2025-12-21 09:39:07.298085: val_loss -0.8569 
2025-12-21 09:39:07.300088: Pseudo dice [0.9237, 0.9483, 0.9381] 
2025-12-21 09:39:07.304092: Epoch time: 137.89 s 
2025-12-21 09:39:08.060960:  
2025-12-21 09:39:08.060960: Epoch 247 
2025-12-21 09:39:08.060960: Current learning rate: 0.00775 
2025-12-21 09:41:25.987833: train_loss -0.8375 
2025-12-21 09:41:25.987833: val_loss -0.8422 
2025-12-21 09:41:26.003601: Pseudo dice [0.9107, 0.9398, 0.9358] 
2025-12-21 09:41:26.007104: Epoch time: 137.94 s 
2025-12-21 09:41:26.636344:  
2025-12-21 09:41:26.636344: Epoch 248 
2025-12-21 09:41:26.636344: Current learning rate: 0.00774 
2025-12-21 09:43:44.345814: train_loss -0.8416 
2025-12-21 09:43:44.345814: val_loss -0.8225 
2025-12-21 09:43:44.361538: Pseudo dice [0.9046, 0.9379, 0.9068] 
2025-12-21 09:43:44.361538: Epoch time: 137.71 s 
2025-12-21 09:43:45.137590:  
2025-12-21 09:43:45.137590: Epoch 249 
2025-12-21 09:43:45.137590: Current learning rate: 0.00773 
2025-12-21 09:46:03.072028: train_loss -0.8388 
2025-12-21 09:46:03.072028: val_loss -0.8486 
2025-12-21 09:46:03.072028: Pseudo dice [0.9165, 0.9469, 0.9302] 
2025-12-21 09:46:03.072028: Epoch time: 137.93 s 
2025-12-21 09:46:04.021233:  
2025-12-21 09:46:04.021233: Epoch 250 
2025-12-21 09:46:04.021233: Current learning rate: 0.00772 
2025-12-21 09:48:21.973897: train_loss -0.8353 
2025-12-21 09:48:21.973897: val_loss -0.8547 
2025-12-21 09:48:21.977639: Pseudo dice [0.9212, 0.9482, 0.9368] 
2025-12-21 09:48:21.979494: Epoch time: 137.95 s 
2025-12-21 09:48:22.609727:  
2025-12-21 09:48:22.609727: Epoch 251 
2025-12-21 09:48:22.613111: Current learning rate: 0.00771 
2025-12-21 09:50:40.448169: train_loss -0.8301 
2025-12-21 09:50:40.450172: val_loss -0.8189 
2025-12-21 09:50:40.452175: Pseudo dice [0.8948, 0.9324, 0.9296] 
2025-12-21 09:50:40.454178: Epoch time: 137.84 s 
2025-12-21 09:50:41.087573:  
2025-12-21 09:50:41.087573: Epoch 252 
2025-12-21 09:50:41.089576: Current learning rate: 0.0077 
2025-12-21 09:52:59.088219: train_loss -0.827 
2025-12-21 09:52:59.088219: val_loss -0.8519 
2025-12-21 09:52:59.104255: Pseudo dice [0.9211, 0.95, 0.9328] 
2025-12-21 09:52:59.108785: Epoch time: 138.0 s 
2025-12-21 09:52:59.746727:  
2025-12-21 09:52:59.746727: Epoch 253 
2025-12-21 09:52:59.746727: Current learning rate: 0.00769 
2025-12-21 09:55:17.647071: train_loss -0.8234 
2025-12-21 09:55:17.647071: val_loss -0.8471 
2025-12-21 09:55:17.651016: Pseudo dice [0.9139, 0.9465, 0.9339] 
2025-12-21 09:55:17.653019: Epoch time: 137.9 s 
2025-12-21 09:55:18.318710:  
2025-12-21 09:55:18.320712: Epoch 254 
2025-12-21 09:55:18.320712: Current learning rate: 0.00768 
2025-12-21 09:57:36.389287: train_loss -0.8322 
2025-12-21 09:57:36.389287: val_loss -0.8159 
2025-12-21 09:57:36.393030: Pseudo dice [0.8986, 0.9295, 0.9195] 
2025-12-21 09:57:36.393030: Epoch time: 138.07 s 
2025-12-21 09:57:37.192507:  
2025-12-21 09:57:37.192507: Epoch 255 
2025-12-21 09:57:37.192507: Current learning rate: 0.00767 
2025-12-21 09:59:55.105769: train_loss -0.8306 
2025-12-21 09:59:55.105769: val_loss -0.8398 
2025-12-21 09:59:55.109776: Pseudo dice [0.9113, 0.9427, 0.9298] 
2025-12-21 09:59:55.111972: Epoch time: 137.91 s 
2025-12-21 09:59:55.741128:  
2025-12-21 09:59:55.741128: Epoch 256 
2025-12-21 09:59:55.741128: Current learning rate: 0.00766 
2025-12-21 10:02:13.642671: train_loss -0.8355 
2025-12-21 10:02:13.642671: val_loss -0.8314 
2025-12-21 10:02:13.646675: Pseudo dice [0.906, 0.9425, 0.9203] 
2025-12-21 10:02:13.648677: Epoch time: 137.9 s 
2025-12-21 10:02:14.268667:  
2025-12-21 10:02:14.268667: Epoch 257 
2025-12-21 10:02:14.284627: Current learning rate: 0.00765 
2025-12-21 10:04:32.320287: train_loss -0.8349 
2025-12-21 10:04:32.320287: val_loss -0.8568 
2025-12-21 10:04:32.322289: Pseudo dice [0.9237, 0.9508, 0.9269] 
2025-12-21 10:04:32.326293: Epoch time: 138.05 s 
2025-12-21 10:04:32.946814:  
2025-12-21 10:04:32.946814: Epoch 258 
2025-12-21 10:04:32.946814: Current learning rate: 0.00764 
2025-12-21 10:06:50.876733: train_loss -0.8362 
2025-12-21 10:06:50.876733: val_loss -0.8632 
2025-12-21 10:06:50.892422: Pseudo dice [0.9265, 0.9544, 0.9329] 
2025-12-21 10:06:50.892422: Epoch time: 137.93 s 
2025-12-21 10:06:51.509765:  
2025-12-21 10:06:51.509765: Epoch 259 
2025-12-21 10:06:51.509765: Current learning rate: 0.00764 
2025-12-21 10:09:09.769590: train_loss -0.8376 
2025-12-21 10:09:09.769590: val_loss -0.8144 
2025-12-21 10:09:09.769590: Pseudo dice [0.8919, 0.9261, 0.9253] 
2025-12-21 10:09:09.769590: Epoch time: 138.26 s 
2025-12-21 10:09:10.402131:  
2025-12-21 10:09:10.402131: Epoch 260 
2025-12-21 10:09:10.402131: Current learning rate: 0.00763 
2025-12-21 10:11:28.529488: train_loss -0.8298 
2025-12-21 10:11:28.529488: val_loss -0.8393 
2025-12-21 10:11:28.531490: Pseudo dice [0.9127, 0.9446, 0.9274] 
2025-12-21 10:11:28.535494: Epoch time: 138.13 s 
2025-12-21 10:11:29.153255:  
2025-12-21 10:11:29.153255: Epoch 261 
2025-12-21 10:11:29.153255: Current learning rate: 0.00762 
2025-12-21 10:13:47.139173: train_loss -0.8219 
2025-12-21 10:13:47.139173: val_loss -0.8215 
2025-12-21 10:13:47.139173: Pseudo dice [0.9036, 0.935, 0.9241] 
2025-12-21 10:13:47.139173: Epoch time: 137.99 s 
2025-12-21 10:13:47.953237:  
2025-12-21 10:13:47.953237: Epoch 262 
2025-12-21 10:13:47.953237: Current learning rate: 0.00761 
2025-12-21 10:16:05.963736: train_loss -0.8087 
2025-12-21 10:16:05.963736: val_loss -0.8276 
2025-12-21 10:16:05.967525: Pseudo dice [0.9045, 0.9383, 0.9254] 
2025-12-21 10:16:05.969527: Epoch time: 138.01 s 
2025-12-21 10:16:06.594291:  
2025-12-21 10:16:06.594291: Epoch 263 
2025-12-21 10:16:06.594291: Current learning rate: 0.0076 
2025-12-21 10:18:24.349025: train_loss -0.8272 
2025-12-21 10:18:24.351027: val_loss -0.8516 
2025-12-21 10:18:24.355030: Pseudo dice [0.9237, 0.9496, 0.9179] 
2025-12-21 10:18:24.357032: Epoch time: 137.75 s 
2025-12-21 10:18:25.117146:  
2025-12-21 10:18:25.117146: Epoch 264 
2025-12-21 10:18:25.127830: Current learning rate: 0.00759 
2025-12-21 10:20:43.218935: train_loss -0.8288 
2025-12-21 10:20:43.218935: val_loss -0.8459 
2025-12-21 10:20:43.230047: Pseudo dice [0.9161, 0.9438, 0.9288] 
2025-12-21 10:20:43.232049: Epoch time: 138.1 s 
2025-12-21 10:20:43.892794:  
2025-12-21 10:20:43.892794: Epoch 265 
2025-12-21 10:20:43.902926: Current learning rate: 0.00758 
2025-12-21 10:23:01.580369: train_loss -0.8333 
2025-12-21 10:23:01.580369: val_loss -0.8405 
2025-12-21 10:23:01.596047: Pseudo dice [0.9133, 0.9478, 0.9155] 
2025-12-21 10:23:01.596047: Epoch time: 137.69 s 
2025-12-21 10:23:02.228738:  
2025-12-21 10:23:02.230741: Epoch 266 
2025-12-21 10:23:02.230741: Current learning rate: 0.00757 
2025-12-21 10:25:20.172001: train_loss -0.8241 
2025-12-21 10:25:20.172001: val_loss -0.8216 
2025-12-21 10:25:20.175746: Pseudo dice [0.8979, 0.9381, 0.9293] 
2025-12-21 10:25:20.179751: Epoch time: 137.94 s 
2025-12-21 10:25:20.948397:  
2025-12-21 10:25:20.948397: Epoch 267 
2025-12-21 10:25:20.948397: Current learning rate: 0.00756 
2025-12-21 10:27:38.928850: train_loss -0.8268 
2025-12-21 10:27:38.928850: val_loss -0.8526 
2025-12-21 10:27:38.932854: Pseudo dice [0.9181, 0.9494, 0.9243] 
2025-12-21 10:27:38.932854: Epoch time: 137.98 s 
2025-12-21 10:27:39.740571:  
2025-12-21 10:27:39.740571: Epoch 268 
2025-12-21 10:27:39.740571: Current learning rate: 0.00755 
2025-12-21 10:29:57.678244: train_loss -0.8295 
2025-12-21 10:29:57.678244: val_loss -0.8556 
2025-12-21 10:29:57.681702: Pseudo dice [0.9203, 0.9505, 0.9296] 
2025-12-21 10:29:57.685706: Epoch time: 137.94 s 
2025-12-21 10:29:58.309647:  
2025-12-21 10:29:58.309647: Epoch 269 
2025-12-21 10:29:58.309647: Current learning rate: 0.00754 
2025-12-21 10:32:16.309625: train_loss -0.8377 
2025-12-21 10:32:16.309625: val_loss -0.8669 
2025-12-21 10:32:16.311626: Pseudo dice [0.9332, 0.956, 0.9258] 
2025-12-21 10:32:16.316042: Epoch time: 138.0 s 
2025-12-21 10:32:17.045491:  
2025-12-21 10:32:17.045491: Epoch 270 
2025-12-21 10:32:17.047494: Current learning rate: 0.00753 
2025-12-21 10:34:35.050798: train_loss -0.8343 
2025-12-21 10:34:35.050798: val_loss -0.873 
2025-12-21 10:34:35.054803: Pseudo dice [0.9333, 0.957, 0.9333] 
2025-12-21 10:34:35.058807: Epoch time: 138.01 s 
2025-12-21 10:34:35.702698:  
2025-12-21 10:34:35.702698: Epoch 271 
2025-12-21 10:34:35.702698: Current learning rate: 0.00752 
2025-12-21 10:36:53.666497: train_loss -0.8329 
2025-12-21 10:36:53.666497: val_loss -0.8662 
2025-12-21 10:36:53.674513: Pseudo dice [0.9279, 0.9552, 0.9311] 
2025-12-21 10:36:53.676253: Epoch time: 137.97 s 
2025-12-21 10:36:54.311651:  
2025-12-21 10:36:54.311651: Epoch 272 
2025-12-21 10:36:54.311651: Current learning rate: 0.00751 
2025-12-21 10:39:12.281512: train_loss -0.8344 
2025-12-21 10:39:12.281512: val_loss -0.8483 
2025-12-21 10:39:12.285516: Pseudo dice [0.9157, 0.9428, 0.9278] 
2025-12-21 10:39:12.288913: Epoch time: 137.97 s 
2025-12-21 10:39:13.064185:  
2025-12-21 10:39:13.064185: Epoch 273 
2025-12-21 10:39:13.064185: Current learning rate: 0.00751 
2025-12-21 10:41:30.974445: train_loss -0.8378 
2025-12-21 10:41:30.977948: val_loss -0.8457 
2025-12-21 10:41:30.979950: Pseudo dice [0.9132, 0.9439, 0.9342] 
2025-12-21 10:41:30.981952: Epoch time: 137.91 s 
2025-12-21 10:41:31.779516:  
2025-12-21 10:41:31.779516: Epoch 274 
2025-12-21 10:41:31.779516: Current learning rate: 0.0075 
2025-12-21 10:43:49.648578: train_loss -0.84 
2025-12-21 10:43:49.648578: val_loss -0.8535 
2025-12-21 10:43:49.652582: Pseudo dice [0.9149, 0.9495, 0.9275] 
2025-12-21 10:43:49.654583: Epoch time: 137.87 s 
2025-12-21 10:43:50.275941:  
2025-12-21 10:43:50.275941: Epoch 275 
2025-12-21 10:43:50.275941: Current learning rate: 0.00749 
2025-12-21 10:46:08.218065: train_loss -0.8339 
2025-12-21 10:46:08.221951: val_loss -0.8704 
2025-12-21 10:46:08.225957: Pseudo dice [0.9297, 0.953, 0.9395] 
2025-12-21 10:46:08.229961: Epoch time: 137.94 s 
2025-12-21 10:46:08.855467:  
2025-12-21 10:46:08.855467: Epoch 276 
2025-12-21 10:46:08.855467: Current learning rate: 0.00748 
2025-12-21 10:48:26.841901: train_loss -0.8346 
2025-12-21 10:48:26.841901: val_loss -0.86 
2025-12-21 10:48:26.841901: Pseudo dice [0.9241, 0.9497, 0.9353] 
2025-12-21 10:48:26.841901: Epoch time: 137.99 s 
2025-12-21 10:48:27.474857:  
2025-12-21 10:48:27.474857: Epoch 277 
2025-12-21 10:48:27.490786: Current learning rate: 0.00747 
2025-12-21 10:50:45.374282: train_loss -0.8347 
2025-12-21 10:50:45.374282: val_loss -0.8534 
2025-12-21 10:50:45.378026: Pseudo dice [0.9165, 0.9448, 0.9353] 
2025-12-21 10:50:45.378026: Epoch time: 137.9 s 
2025-12-21 10:50:46.008204:  
2025-12-21 10:50:46.008204: Epoch 278 
2025-12-21 10:50:46.008204: Current learning rate: 0.00746 
2025-12-21 10:53:04.104450: train_loss -0.8361 
2025-12-21 10:53:04.104450: val_loss -0.8647 
2025-12-21 10:53:04.104450: Pseudo dice [0.9285, 0.9539, 0.9209] 
2025-12-21 10:53:04.104450: Epoch time: 138.1 s 
2025-12-21 10:53:04.104450: Yayy! New best EMA pseudo Dice: 0.9323 
2025-12-21 10:53:04.977254:  
2025-12-21 10:53:04.977254: Epoch 279 
2025-12-21 10:53:04.977254: Current learning rate: 0.00745 
2025-12-21 10:55:23.021196: train_loss -0.8383 
2025-12-21 10:55:23.023199: val_loss -0.8589 
2025-12-21 10:55:23.024940: Pseudo dice [0.922, 0.9474, 0.9319] 
2025-12-21 10:55:23.028438: Epoch time: 138.05 s 
2025-12-21 10:55:23.032442: Yayy! New best EMA pseudo Dice: 0.9324 
2025-12-21 10:55:24.106347:  
2025-12-21 10:55:24.106347: Epoch 280 
2025-12-21 10:55:24.109350: Current learning rate: 0.00744 
2025-12-21 10:57:42.043749: train_loss -0.8389 
2025-12-21 10:57:42.045751: val_loss -0.86 
2025-12-21 10:57:42.049755: Pseudo dice [0.9241, 0.9506, 0.9256] 
2025-12-21 10:57:42.051758: Epoch time: 137.94 s 
2025-12-21 10:57:42.053761: Yayy! New best EMA pseudo Dice: 0.9325 
2025-12-21 10:57:42.965699:  
2025-12-21 10:57:42.965699: Epoch 281 
2025-12-21 10:57:42.965699: Current learning rate: 0.00743 
2025-12-21 11:00:01.057251: train_loss -0.8375 
2025-12-21 11:00:01.059254: val_loss -0.8493 
2025-12-21 11:00:01.059254: Pseudo dice [0.9131, 0.9444, 0.934] 
2025-12-21 11:00:01.059254: Epoch time: 138.09 s 
2025-12-21 11:00:01.692494:  
2025-12-21 11:00:01.694496: Epoch 282 
2025-12-21 11:00:01.694496: Current learning rate: 0.00742 
2025-12-21 11:02:19.639783: train_loss -0.8424 
2025-12-21 11:02:19.639783: val_loss -0.838 
2025-12-21 11:02:19.639783: Pseudo dice [0.9047, 0.9444, 0.9323] 
2025-12-21 11:02:19.652086: Epoch time: 137.95 s 
2025-12-21 11:02:20.290174:  
2025-12-21 11:02:20.290174: Epoch 283 
2025-12-21 11:02:20.290174: Current learning rate: 0.00741 
2025-12-21 11:04:38.424343: train_loss -0.8397 
2025-12-21 11:04:38.424343: val_loss -0.8491 
2025-12-21 11:04:38.428347: Pseudo dice [0.9164, 0.9452, 0.9327] 
2025-12-21 11:04:38.430349: Epoch time: 138.14 s 
2025-12-21 11:04:39.097104:  
2025-12-21 11:04:39.097104: Epoch 284 
2025-12-21 11:04:39.097104: Current learning rate: 0.0074 
2025-12-21 11:06:57.184355: train_loss -0.8372 
2025-12-21 11:06:57.184355: val_loss -0.8529 
2025-12-21 11:06:57.195925: Pseudo dice [0.9192, 0.9496, 0.9308] 
2025-12-21 11:06:57.197928: Epoch time: 138.09 s 
2025-12-21 11:06:57.834678:  
2025-12-21 11:06:57.834678: Epoch 285 
2025-12-21 11:06:57.834678: Current learning rate: 0.00739 
2025-12-21 11:09:15.992819: train_loss -0.836 
2025-12-21 11:09:15.992819: val_loss -0.8679 
2025-12-21 11:09:16.000162: Pseudo dice [0.9303, 0.9561, 0.9321] 
2025-12-21 11:09:16.002164: Epoch time: 138.16 s 
2025-12-21 11:09:16.004166: Yayy! New best EMA pseudo Dice: 0.9327 
2025-12-21 11:09:17.071867:  
2025-12-21 11:09:17.071867: Epoch 286 
2025-12-21 11:09:17.071867: Current learning rate: 0.00738 
2025-12-21 11:11:35.074668: train_loss -0.8367 
2025-12-21 11:11:35.074668: val_loss -0.8395 
2025-12-21 11:11:35.074668: Pseudo dice [0.9069, 0.9394, 0.9346] 
2025-12-21 11:11:35.074668: Epoch time: 138.0 s 
2025-12-21 11:11:35.713383:  
2025-12-21 11:11:35.713383: Epoch 287 
2025-12-21 11:11:35.713383: Current learning rate: 0.00738 
2025-12-21 11:13:53.682053: train_loss -0.8298 
2025-12-21 11:13:53.682053: val_loss -0.8698 
2025-12-21 11:13:53.686058: Pseudo dice [0.9301, 0.9554, 0.9338] 
2025-12-21 11:13:53.686058: Epoch time: 137.97 s 
2025-12-21 11:13:53.686058: Yayy! New best EMA pseudo Dice: 0.9329 
2025-12-21 11:13:54.610805:  
2025-12-21 11:13:54.610805: Epoch 288 
2025-12-21 11:13:54.610805: Current learning rate: 0.00737 
2025-12-21 11:16:12.544002: train_loss -0.8357 
2025-12-21 11:16:12.544002: val_loss -0.8661 
2025-12-21 11:16:12.548006: Pseudo dice [0.928, 0.9536, 0.9369] 
2025-12-21 11:16:12.550009: Epoch time: 137.93 s 
2025-12-21 11:16:12.552259: Yayy! New best EMA pseudo Dice: 0.9335 
2025-12-21 11:16:13.458719:  
2025-12-21 11:16:13.458719: Epoch 289 
2025-12-21 11:16:13.458719: Current learning rate: 0.00736 
2025-12-21 11:18:31.362436: train_loss -0.8311 
2025-12-21 11:18:31.362436: val_loss -0.8565 
2025-12-21 11:18:31.367981: Pseudo dice [0.9201, 0.9514, 0.9344] 
2025-12-21 11:18:31.369983: Epoch time: 137.91 s 
2025-12-21 11:18:31.371985: Yayy! New best EMA pseudo Dice: 0.9337 
2025-12-21 11:18:32.280037:  
2025-12-21 11:18:32.280037: Epoch 290 
2025-12-21 11:18:32.296097: Current learning rate: 0.00735 
2025-12-21 11:20:50.312850: train_loss -0.8381 
2025-12-21 11:20:50.312850: val_loss -0.8529 
2025-12-21 11:20:50.316854: Pseudo dice [0.919, 0.9533, 0.9229] 
2025-12-21 11:20:50.318856: Epoch time: 138.03 s 
2025-12-21 11:20:50.953070:  
2025-12-21 11:20:50.953070: Epoch 291 
2025-12-21 11:20:50.953070: Current learning rate: 0.00734 
2025-12-21 11:23:08.981228: train_loss -0.8363 
2025-12-21 11:23:08.981228: val_loss -0.8455 
2025-12-21 11:23:08.983231: Pseudo dice [0.9173, 0.9382, 0.9246] 
2025-12-21 11:23:08.989792: Epoch time: 138.03 s 
2025-12-21 11:23:09.835256:  
2025-12-21 11:23:09.835256: Epoch 292 
2025-12-21 11:23:09.835256: Current learning rate: 0.00733 
2025-12-21 11:25:27.897825: train_loss -0.8417 
2025-12-21 11:25:27.897825: val_loss -0.8722 
2025-12-21 11:25:27.902008: Pseudo dice [0.9323, 0.9557, 0.9315] 
2025-12-21 11:25:27.902008: Epoch time: 138.08 s 
2025-12-21 11:25:28.536037:  
2025-12-21 11:25:28.536037: Epoch 293 
2025-12-21 11:25:28.536037: Current learning rate: 0.00732 
2025-12-21 11:27:46.364721: train_loss -0.8423 
2025-12-21 11:27:46.380410: val_loss -0.8684 
2025-12-21 11:27:46.382412: Pseudo dice [0.9287, 0.959, 0.9294] 
2025-12-21 11:27:46.384415: Epoch time: 137.83 s 
2025-12-21 11:27:46.388419: Yayy! New best EMA pseudo Dice: 0.9341 
2025-12-21 11:27:47.251224:  
2025-12-21 11:27:47.251224: Epoch 294 
2025-12-21 11:27:47.266925: Current learning rate: 0.00731 
2025-12-21 11:30:05.054093: train_loss -0.8408 
2025-12-21 11:30:05.054093: val_loss -0.8464 
2025-12-21 11:30:05.060107: Pseudo dice [0.916, 0.9466, 0.9228] 
2025-12-21 11:30:05.063851: Epoch time: 137.8 s 
2025-12-21 11:30:05.697790:  
2025-12-21 11:30:05.697790: Epoch 295 
2025-12-21 11:30:05.697790: Current learning rate: 0.0073 
2025-12-21 11:32:23.733169: train_loss -0.839 
2025-12-21 11:32:23.733169: val_loss -0.8524 
2025-12-21 11:32:23.733169: Pseudo dice [0.9194, 0.9526, 0.9268] 
2025-12-21 11:32:23.733169: Epoch time: 138.04 s 
2025-12-21 11:32:24.376707:  
2025-12-21 11:32:24.376707: Epoch 296 
2025-12-21 11:32:24.376707: Current learning rate: 0.00729 
2025-12-21 11:34:42.243343: train_loss -0.8377 
2025-12-21 11:34:42.245345: val_loss -0.8494 
2025-12-21 11:34:42.249351: Pseudo dice [0.9156, 0.9451, 0.9293] 
2025-12-21 11:34:42.251354: Epoch time: 137.87 s 
2025-12-21 11:34:42.925571:  
2025-12-21 11:34:42.925571: Epoch 297 
2025-12-21 11:34:42.925571: Current learning rate: 0.00728 
2025-12-21 11:37:00.979109: train_loss -0.8332 
2025-12-21 11:37:00.980849: val_loss -0.85 
2025-12-21 11:37:00.984853: Pseudo dice [0.916, 0.9477, 0.927] 
2025-12-21 11:37:00.986855: Epoch time: 138.05 s 
2025-12-21 11:37:01.789858:  
2025-12-21 11:37:01.789858: Epoch 298 
2025-12-21 11:37:01.789858: Current learning rate: 0.00727 
2025-12-21 11:39:19.670851: train_loss -0.8304 
2025-12-21 11:39:19.670851: val_loss -0.8656 
2025-12-21 11:39:19.674855: Pseudo dice [0.9287, 0.9599, 0.9199] 
2025-12-21 11:39:19.678596: Epoch time: 137.88 s 
2025-12-21 11:39:20.504602:  
2025-12-21 11:39:20.504602: Epoch 299 
2025-12-21 11:39:20.504602: Current learning rate: 0.00726 
2025-12-21 11:41:38.389230: train_loss -0.8327 
2025-12-21 11:41:38.389230: val_loss -0.8712 
2025-12-21 11:41:38.404960: Pseudo dice [0.9277, 0.9573, 0.9378] 
2025-12-21 11:41:38.404960: Epoch time: 137.88 s 
2025-12-21 11:41:39.277612:  
2025-12-21 11:41:39.277612: Epoch 300 
2025-12-21 11:41:39.277612: Current learning rate: 0.00725 
2025-12-21 11:43:57.202331: train_loss -0.8407 
2025-12-21 11:43:57.202331: val_loss -0.8613 
2025-12-21 11:43:57.204337: Pseudo dice [0.922, 0.9537, 0.9352] 
2025-12-21 11:43:57.204337: Epoch time: 137.92 s 
2025-12-21 11:43:57.204337: Yayy! New best EMA pseudo Dice: 0.9342 
2025-12-21 11:43:58.124349:  
2025-12-21 11:43:58.124349: Epoch 301 
2025-12-21 11:43:58.124349: Current learning rate: 0.00724 
2025-12-21 11:46:16.037428: train_loss -0.8396 
2025-12-21 11:46:16.037428: val_loss -0.8626 
2025-12-21 11:46:16.041709: Pseudo dice [0.9225, 0.9511, 0.9336] 
2025-12-21 11:46:16.043712: Epoch time: 137.91 s 
2025-12-21 11:46:16.045715: Yayy! New best EMA pseudo Dice: 0.9344 
2025-12-21 11:46:17.149917:  
2025-12-21 11:46:17.151920: Epoch 302 
2025-12-21 11:46:17.151920: Current learning rate: 0.00724 
2025-12-21 11:48:35.156805: train_loss -0.8395 
2025-12-21 11:48:35.156805: val_loss -0.8644 
2025-12-21 11:48:35.156805: Pseudo dice [0.9229, 0.9487, 0.9446] 
2025-12-21 11:48:35.172839: Epoch time: 138.01 s 
2025-12-21 11:48:35.172839: Yayy! New best EMA pseudo Dice: 0.9348 
2025-12-21 11:48:36.077414:  
2025-12-21 11:48:36.077414: Epoch 303 
2025-12-21 11:48:36.077414: Current learning rate: 0.00723 
2025-12-21 11:50:54.140265: train_loss -0.8438 
2025-12-21 11:50:54.140265: val_loss -0.8428 
2025-12-21 11:50:54.144269: Pseudo dice [0.9043, 0.9396, 0.936] 
2025-12-21 11:50:54.148273: Epoch time: 138.06 s 
2025-12-21 11:50:54.943008:  
2025-12-21 11:50:54.943008: Epoch 304 
2025-12-21 11:50:54.958963: Current learning rate: 0.00722 
2025-12-21 11:53:13.012535: train_loss -0.8402 
2025-12-21 11:53:13.014275: val_loss -0.865 
2025-12-21 11:53:13.020296: Pseudo dice [0.923, 0.9533, 0.9365] 
2025-12-21 11:53:13.024310: Epoch time: 138.07 s 
2025-12-21 11:53:13.788510:  
2025-12-21 11:53:13.788510: Epoch 305 
2025-12-21 11:53:13.792170: Current learning rate: 0.00721 
2025-12-21 11:55:32.017223: train_loss -0.8354 
2025-12-21 11:55:32.017223: val_loss -0.8697 
2025-12-21 11:55:32.033205: Pseudo dice [0.9276, 0.9557, 0.937] 
2025-12-21 11:55:32.033205: Epoch time: 138.24 s 
2025-12-21 11:55:32.033205: Yayy! New best EMA pseudo Dice: 0.9349 
2025-12-21 11:55:32.909351:  
2025-12-21 11:55:32.909351: Epoch 306 
2025-12-21 11:55:32.911647: Current learning rate: 0.0072 
2025-12-21 11:57:50.798608: train_loss -0.8419 
2025-12-21 11:57:50.798608: val_loss -0.8657 
2025-12-21 11:57:50.802522: Pseudo dice [0.9306, 0.956, 0.9245] 
2025-12-21 11:57:50.802522: Epoch time: 137.89 s 
2025-12-21 11:57:50.802522: Yayy! New best EMA pseudo Dice: 0.9351 
2025-12-21 11:57:51.701800:  
2025-12-21 11:57:51.701800: Epoch 307 
2025-12-21 11:57:51.701800: Current learning rate: 0.00719 
2025-12-21 12:00:09.686876: train_loss -0.8376 
2025-12-21 12:00:09.686876: val_loss -0.8698 
2025-12-21 12:00:09.690880: Pseudo dice [0.9288, 0.9581, 0.9321] 
2025-12-21 12:00:09.692882: Epoch time: 137.99 s 
2025-12-21 12:00:09.696886: Yayy! New best EMA pseudo Dice: 0.9356 
2025-12-21 12:00:10.753808:  
2025-12-21 12:00:10.753808: Epoch 308 
2025-12-21 12:00:10.758512: Current learning rate: 0.00718 
2025-12-21 12:02:28.752738: train_loss -0.8425 
2025-12-21 12:02:28.752738: val_loss -0.8663 
2025-12-21 12:02:28.756742: Pseudo dice [0.9234, 0.953, 0.936] 
2025-12-21 12:02:28.758744: Epoch time: 138.0 s 
2025-12-21 12:02:28.760485: Yayy! New best EMA pseudo Dice: 0.9358 
2025-12-21 12:02:29.831937:  
2025-12-21 12:02:29.831937: Epoch 309 
2025-12-21 12:02:29.831937: Current learning rate: 0.00717 
2025-12-21 12:04:47.846361: train_loss -0.839 
2025-12-21 12:04:47.848364: val_loss -0.8671 
2025-12-21 12:04:47.852369: Pseudo dice [0.9289, 0.9525, 0.9303] 
2025-12-21 12:04:47.854371: Epoch time: 138.01 s 
2025-12-21 12:04:47.858375: Yayy! New best EMA pseudo Dice: 0.9359 
2025-12-21 12:04:48.745526:  
2025-12-21 12:04:48.745526: Epoch 310 
2025-12-21 12:04:48.761561: Current learning rate: 0.00716 
2025-12-21 12:07:06.692546: train_loss -0.8399 
2025-12-21 12:07:06.692546: val_loss -0.8513 
2025-12-21 12:07:06.696550: Pseudo dice [0.9145, 0.9474, 0.934] 
2025-12-21 12:07:06.698551: Epoch time: 137.95 s 
2025-12-21 12:07:07.467482:  
2025-12-21 12:07:07.469486: Epoch 311 
2025-12-21 12:07:07.469486: Current learning rate: 0.00715 
2025-12-21 12:09:25.767579: train_loss -0.8399 
2025-12-21 12:09:25.767579: val_loss -0.868 
2025-12-21 12:09:25.773123: Pseudo dice [0.9241, 0.9564, 0.9358] 
2025-12-21 12:09:25.775125: Epoch time: 138.3 s 
2025-12-21 12:09:26.428420:  
2025-12-21 12:09:26.428420: Epoch 312 
2025-12-21 12:09:26.428420: Current learning rate: 0.00714 
2025-12-21 12:11:44.407958: train_loss -0.8343 
2025-12-21 12:11:44.407958: val_loss -0.8541 
2025-12-21 12:11:44.412229: Pseudo dice [0.9151, 0.9477, 0.9337] 
2025-12-21 12:11:44.415233: Epoch time: 137.98 s 
2025-12-21 12:11:45.062668:  
2025-12-21 12:11:45.062668: Epoch 313 
2025-12-21 12:11:45.064671: Current learning rate: 0.00713 
2025-12-21 12:14:03.119748: train_loss -0.8384 
2025-12-21 12:14:03.121751: val_loss -0.8641 
2025-12-21 12:14:03.121751: Pseudo dice [0.9208, 0.9515, 0.9364] 
2025-12-21 12:14:03.121751: Epoch time: 138.06 s 
2025-12-21 12:14:03.938896:  
2025-12-21 12:14:03.938896: Epoch 314 
2025-12-21 12:14:03.946270: Current learning rate: 0.00712 
2025-12-21 12:16:21.774854: train_loss -0.844 
2025-12-21 12:16:21.776856: val_loss -0.8615 
2025-12-21 12:16:21.778858: Pseudo dice [0.9239, 0.9516, 0.9271] 
2025-12-21 12:16:21.782358: Epoch time: 137.84 s 
2025-12-21 12:16:22.589432:  
2025-12-21 12:16:22.589432: Epoch 315 
2025-12-21 12:16:22.589432: Current learning rate: 0.00711 
2025-12-21 12:18:40.589475: train_loss -0.8288 
2025-12-21 12:18:40.591478: val_loss -0.8609 
2025-12-21 12:18:40.591478: Pseudo dice [0.9213, 0.9528, 0.9288] 
2025-12-21 12:18:40.591478: Epoch time: 138.0 s 
2025-12-21 12:18:41.243063:  
2025-12-21 12:18:41.243063: Epoch 316 
2025-12-21 12:18:41.243063: Current learning rate: 0.0071 
2025-12-21 12:20:59.231233: train_loss -0.8321 
2025-12-21 12:20:59.231233: val_loss -0.8457 
2025-12-21 12:20:59.236981: Pseudo dice [0.9111, 0.9421, 0.9322] 
2025-12-21 12:20:59.240991: Epoch time: 137.99 s 
2025-12-21 12:20:59.994403:  
2025-12-21 12:20:59.994403: Epoch 317 
2025-12-21 12:20:59.994403: Current learning rate: 0.0071 
2025-12-21 12:23:18.044915: train_loss -0.8398 
2025-12-21 12:23:18.044915: val_loss -0.8691 
2025-12-21 12:23:18.048919: Pseudo dice [0.927, 0.9577, 0.9277] 
2025-12-21 12:23:18.051924: Epoch time: 138.05 s 
2025-12-21 12:23:18.684139:  
2025-12-21 12:23:18.684139: Epoch 318 
2025-12-21 12:23:18.684139: Current learning rate: 0.00709 
2025-12-21 12:25:36.631607: train_loss -0.8422 
2025-12-21 12:25:36.631607: val_loss -0.8717 
2025-12-21 12:25:36.631607: Pseudo dice [0.9295, 0.9575, 0.932] 
2025-12-21 12:25:36.631607: Epoch time: 137.95 s 
2025-12-21 12:25:37.274118:  
2025-12-21 12:25:37.274118: Epoch 319 
2025-12-21 12:25:37.274118: Current learning rate: 0.00708 
2025-12-21 12:27:55.307791: train_loss -0.8319 
2025-12-21 12:27:55.307791: val_loss -0.844 
2025-12-21 12:27:55.313345: Pseudo dice [0.9143, 0.9449, 0.9301] 
2025-12-21 12:27:55.315348: Epoch time: 138.03 s 
2025-12-21 12:27:56.076955:  
2025-12-21 12:27:56.076955: Epoch 320 
2025-12-21 12:27:56.087807: Current learning rate: 0.00707 
2025-12-21 12:30:13.979008: train_loss -0.8365 
2025-12-21 12:30:13.979008: val_loss -0.8491 
2025-12-21 12:30:13.983176: Pseudo dice [0.9206, 0.9504, 0.9167] 
2025-12-21 12:30:13.984992: Epoch time: 137.9 s 
2025-12-21 12:30:14.784549:  
2025-12-21 12:30:14.784549: Epoch 321 
2025-12-21 12:30:14.784549: Current learning rate: 0.00706 
2025-12-21 12:32:32.472912: train_loss -0.8487 
2025-12-21 12:32:32.472912: val_loss -0.8637 
2025-12-21 12:32:32.472912: Pseudo dice [0.9222, 0.9516, 0.9369] 
2025-12-21 12:32:32.472912: Epoch time: 137.69 s 
2025-12-21 12:32:33.125555:  
2025-12-21 12:32:33.125555: Epoch 322 
2025-12-21 12:32:33.125555: Current learning rate: 0.00705 
2025-12-21 12:34:50.879588: train_loss -0.8451 
2025-12-21 12:34:50.879588: val_loss -0.8349 
2025-12-21 12:34:50.879588: Pseudo dice [0.9063, 0.9431, 0.926] 
2025-12-21 12:34:50.886549: Epoch time: 137.76 s 
2025-12-21 12:34:51.605283:  
2025-12-21 12:34:51.605283: Epoch 323 
2025-12-21 12:34:51.619588: Current learning rate: 0.00704 
2025-12-21 12:37:09.480507: train_loss -0.8404 
2025-12-21 12:37:09.480507: val_loss -0.8485 
2025-12-21 12:37:09.484511: Pseudo dice [0.9102, 0.9398, 0.9394] 
2025-12-21 12:37:09.488015: Epoch time: 137.88 s 
2025-12-21 12:37:10.122117:  
2025-12-21 12:37:10.137760: Epoch 324 
2025-12-21 12:37:10.137760: Current learning rate: 0.00703 
2025-12-21 12:39:28.149970: train_loss -0.8405 
2025-12-21 12:39:28.149970: val_loss -0.8663 
2025-12-21 12:39:28.149970: Pseudo dice [0.9286, 0.9544, 0.931] 
2025-12-21 12:39:28.149970: Epoch time: 138.03 s 
2025-12-21 12:39:28.783436:  
2025-12-21 12:39:28.783436: Epoch 325 
2025-12-21 12:39:28.783436: Current learning rate: 0.00702 
2025-12-21 12:41:46.799082: train_loss -0.8409 
2025-12-21 12:41:46.799082: val_loss -0.8547 
2025-12-21 12:41:46.804829: Pseudo dice [0.9143, 0.9486, 0.9389] 
2025-12-21 12:41:46.808835: Epoch time: 138.02 s 
2025-12-21 12:41:47.434681:  
2025-12-21 12:41:47.434681: Epoch 326 
2025-12-21 12:41:47.450480: Current learning rate: 0.00701 
2025-12-21 12:44:05.235622: train_loss -0.842 
2025-12-21 12:44:05.237487: val_loss -0.8569 
2025-12-21 12:44:05.241124: Pseudo dice [0.9168, 0.9502, 0.9364] 
2025-12-21 12:44:05.243127: Epoch time: 137.8 s 
2025-12-21 12:44:06.057292:  
2025-12-21 12:44:06.057292: Epoch 327 
2025-12-21 12:44:06.057292: Current learning rate: 0.007 
2025-12-21 12:46:24.092143: train_loss -0.8387 
2025-12-21 12:46:24.092143: val_loss -0.8508 
2025-12-21 12:46:24.108178: Pseudo dice [0.9168, 0.9475, 0.9241] 
2025-12-21 12:46:24.108178: Epoch time: 138.03 s 
2025-12-21 12:46:24.759569:  
2025-12-21 12:46:24.761309: Epoch 328 
2025-12-21 12:46:24.761309: Current learning rate: 0.00699 
2025-12-21 12:48:42.675581: train_loss -0.844 
2025-12-21 12:48:42.675581: val_loss -0.8626 
2025-12-21 12:48:42.677584: Pseudo dice [0.9176, 0.9507, 0.9407] 
2025-12-21 12:48:42.682876: Epoch time: 137.92 s 
2025-12-21 12:48:43.332799:  
2025-12-21 12:48:43.332799: Epoch 329 
2025-12-21 12:48:43.335289: Current learning rate: 0.00698 
2025-12-21 12:51:01.370615: train_loss -0.8436 
2025-12-21 12:51:01.372617: val_loss -0.8652 
2025-12-21 12:51:01.378364: Pseudo dice [0.9271, 0.9556, 0.9215] 
2025-12-21 12:51:01.380366: Epoch time: 138.04 s 
2025-12-21 12:51:02.017025:  
2025-12-21 12:51:02.017025: Epoch 330 
2025-12-21 12:51:02.033027: Current learning rate: 0.00697 
2025-12-21 12:53:20.144976: train_loss -0.8424 
2025-12-21 12:53:20.144976: val_loss -0.8667 
2025-12-21 12:53:20.148461: Pseudo dice [0.9236, 0.9499, 0.9426] 
2025-12-21 12:53:20.152465: Epoch time: 138.13 s 
2025-12-21 12:53:20.800309:  
2025-12-21 12:53:20.800309: Epoch 331 
2025-12-21 12:53:20.800309: Current learning rate: 0.00696 
2025-12-21 12:55:39.021054: train_loss -0.8451 
2025-12-21 12:55:39.021054: val_loss -0.858 
2025-12-21 12:55:39.025058: Pseudo dice [0.9161, 0.946, 0.9403] 
2025-12-21 12:55:39.029012: Epoch time: 138.22 s 
2025-12-21 12:55:39.678469:  
2025-12-21 12:55:39.678469: Epoch 332 
2025-12-21 12:55:39.678469: Current learning rate: 0.00696 
2025-12-21 12:57:57.753935: train_loss -0.8411 
2025-12-21 12:57:57.753935: val_loss -0.8617 
2025-12-21 12:57:57.761764: Pseudo dice [0.9245, 0.9531, 0.9321] 
2025-12-21 12:57:57.763767: Epoch time: 138.08 s 
2025-12-21 12:57:58.403671:  
2025-12-21 12:57:58.403671: Epoch 333 
2025-12-21 12:57:58.403671: Current learning rate: 0.00695 
2025-12-21 13:00:16.454846: train_loss -0.8376 
2025-12-21 13:00:16.454846: val_loss -0.861 
2025-12-21 13:00:16.458850: Pseudo dice [0.9194, 0.948, 0.9412] 
2025-12-21 13:00:16.460852: Epoch time: 138.05 s 
2025-12-21 13:00:17.278310:  
2025-12-21 13:00:17.278310: Epoch 334 
2025-12-21 13:00:17.278310: Current learning rate: 0.00694 
2025-12-21 13:02:35.263957: train_loss -0.8419 
2025-12-21 13:02:35.265960: val_loss -0.8431 
2025-12-21 13:02:35.269467: Pseudo dice [0.9077, 0.9411, 0.9319] 
2025-12-21 13:02:35.271470: Epoch time: 137.99 s 
2025-12-21 13:02:35.916353:  
2025-12-21 13:02:35.916353: Epoch 335 
2025-12-21 13:02:35.916353: Current learning rate: 0.00693 
2025-12-21 13:04:53.836101: train_loss -0.8435 
2025-12-21 13:04:53.836101: val_loss -0.8586 
2025-12-21 13:04:53.836101: Pseudo dice [0.9191, 0.9499, 0.935] 
2025-12-21 13:04:53.836101: Epoch time: 137.92 s 
2025-12-21 13:04:54.486542:  
2025-12-21 13:04:54.486542: Epoch 336 
2025-12-21 13:04:54.486542: Current learning rate: 0.00692 
2025-12-21 13:07:12.397713: train_loss -0.8383 
2025-12-21 13:07:12.397713: val_loss -0.8641 
2025-12-21 13:07:12.401717: Pseudo dice [0.9229, 0.9503, 0.9359] 
2025-12-21 13:07:12.403719: Epoch time: 137.91 s 
2025-12-21 13:07:13.126886:  
2025-12-21 13:07:13.126886: Epoch 337 
2025-12-21 13:07:13.126886: Current learning rate: 0.00691 
2025-12-21 13:09:31.377246: train_loss -0.8418 
2025-12-21 13:09:31.377246: val_loss -0.8535 
2025-12-21 13:09:31.381251: Pseudo dice [0.913, 0.9451, 0.9342] 
2025-12-21 13:09:31.381251: Epoch time: 138.25 s 
2025-12-21 13:09:32.047284:  
2025-12-21 13:09:32.047284: Epoch 338 
2025-12-21 13:09:32.047284: Current learning rate: 0.0069 
2025-12-21 13:11:50.263608: train_loss -0.8394 
2025-12-21 13:11:50.263608: val_loss -0.8747 
2025-12-21 13:11:50.267612: Pseudo dice [0.9298, 0.9538, 0.9394] 
2025-12-21 13:11:50.269614: Epoch time: 138.22 s 
2025-12-21 13:11:51.091604:  
2025-12-21 13:11:51.091604: Epoch 339 
2025-12-21 13:11:51.091604: Current learning rate: 0.00689 
2025-12-21 13:14:09.047779: train_loss -0.8384 
2025-12-21 13:14:09.047779: val_loss -0.8422 
2025-12-21 13:14:09.047779: Pseudo dice [0.9033, 0.9414, 0.9369] 
2025-12-21 13:14:09.063734: Epoch time: 137.96 s 
2025-12-21 13:14:09.754899:  
2025-12-21 13:14:09.754899: Epoch 340 
2025-12-21 13:14:09.754899: Current learning rate: 0.00688 
2025-12-21 13:16:27.538400: train_loss -0.8448 
2025-12-21 13:16:27.538400: val_loss -0.8501 
2025-12-21 13:16:27.538400: Pseudo dice [0.9163, 0.948, 0.922] 
2025-12-21 13:16:27.538400: Epoch time: 137.78 s 
2025-12-21 13:16:28.193322:  
2025-12-21 13:16:28.195325: Epoch 341 
2025-12-21 13:16:28.195325: Current learning rate: 0.00687 
2025-12-21 13:18:46.114049: train_loss -0.8336 
2025-12-21 13:18:46.114049: val_loss -0.869 
2025-12-21 13:18:46.114049: Pseudo dice [0.9302, 0.9583, 0.9264] 
2025-12-21 13:18:46.114049: Epoch time: 137.92 s 
2025-12-21 13:18:46.769969:  
2025-12-21 13:18:46.769969: Epoch 342 
2025-12-21 13:18:46.769969: Current learning rate: 0.00686 
2025-12-21 13:21:04.533012: train_loss -0.822 
2025-12-21 13:21:04.533012: val_loss -0.8325 
2025-12-21 13:21:04.538018: Pseudo dice [0.9085, 0.9409, 0.9197] 
2025-12-21 13:21:04.542023: Epoch time: 137.77 s 
2025-12-21 13:21:05.355807:  
2025-12-21 13:21:05.355807: Epoch 343 
2025-12-21 13:21:05.355807: Current learning rate: 0.00685 
2025-12-21 13:23:23.236966: train_loss -0.8245 
2025-12-21 13:23:23.236966: val_loss -0.8602 
2025-12-21 13:23:23.240970: Pseudo dice [0.9281, 0.9554, 0.9298] 
2025-12-21 13:23:23.242973: Epoch time: 137.88 s 
2025-12-21 13:23:23.890097:  
2025-12-21 13:23:23.890097: Epoch 344 
2025-12-21 13:23:23.890097: Current learning rate: 0.00684 
2025-12-21 13:25:41.810021: train_loss -0.832 
2025-12-21 13:25:41.812024: val_loss -0.8612 
2025-12-21 13:25:41.816029: Pseudo dice [0.9289, 0.9537, 0.9235] 
2025-12-21 13:25:41.818031: Epoch time: 137.92 s 
2025-12-21 13:25:42.469700:  
2025-12-21 13:25:42.469700: Epoch 345 
2025-12-21 13:25:42.469700: Current learning rate: 0.00683 
2025-12-21 13:28:00.514692: train_loss -0.8329 
2025-12-21 13:28:00.514692: val_loss -0.8579 
2025-12-21 13:28:00.518697: Pseudo dice [0.9213, 0.9525, 0.9282] 
2025-12-21 13:28:00.520698: Epoch time: 138.04 s 
2025-12-21 13:28:01.265973:  
2025-12-21 13:28:01.265973: Epoch 346 
2025-12-21 13:28:01.270220: Current learning rate: 0.00682 
2025-12-21 13:30:19.185736: train_loss -0.8407 
2025-12-21 13:30:19.185736: val_loss -0.8668 
2025-12-21 13:30:19.185736: Pseudo dice [0.9267, 0.9549, 0.9345] 
2025-12-21 13:30:19.201084: Epoch time: 137.92 s 
2025-12-21 13:30:19.853747:  
2025-12-21 13:30:19.853747: Epoch 347 
2025-12-21 13:30:19.853747: Current learning rate: 0.00681 
2025-12-21 13:32:37.781008: train_loss -0.8374 
2025-12-21 13:32:37.783010: val_loss -0.8567 
2025-12-21 13:32:37.787014: Pseudo dice [0.92, 0.9471, 0.9347] 
2025-12-21 13:32:37.790760: Epoch time: 137.93 s 
2025-12-21 13:32:38.442642:  
2025-12-21 13:32:38.444644: Epoch 348 
2025-12-21 13:32:38.444644: Current learning rate: 0.0068 
2025-12-21 13:34:56.488838: train_loss -0.8281 
2025-12-21 13:34:56.488838: val_loss -0.8248 
2025-12-21 13:34:56.502342: Pseudo dice [0.9059, 0.941, 0.9162] 
2025-12-21 13:34:56.504344: Epoch time: 138.05 s 
2025-12-21 13:34:57.230565:  
2025-12-21 13:34:57.230565: Epoch 349 
2025-12-21 13:34:57.248888: Current learning rate: 0.0068 
2025-12-21 13:37:15.159390: train_loss -0.7939 
2025-12-21 13:37:15.159390: val_loss -0.8148 
2025-12-21 13:37:15.165006: Pseudo dice [0.9078, 0.9366, 0.9074] 
2025-12-21 13:37:15.169011: Epoch time: 137.93 s 
2025-12-21 13:37:16.070189:  
2025-12-21 13:37:16.070189: Epoch 350 
2025-12-21 13:37:16.070189: Current learning rate: 0.00679 
2025-12-21 13:39:34.107594: train_loss -0.8025 
2025-12-21 13:39:34.107594: val_loss -0.845 
2025-12-21 13:39:34.125111: Pseudo dice [0.9216, 0.9506, 0.9256] 
2025-12-21 13:39:34.129116: Epoch time: 138.04 s 
2025-12-21 13:39:34.930887:  
2025-12-21 13:39:34.930887: Epoch 351 
2025-12-21 13:39:34.930887: Current learning rate: 0.00678 
2025-12-21 13:41:52.695105: train_loss -0.8172 
2025-12-21 13:41:52.695105: val_loss -0.8374 
2025-12-21 13:41:52.701041: Pseudo dice [0.9137, 0.9471, 0.9131] 
2025-12-21 13:41:52.703044: Epoch time: 137.76 s 
2025-12-21 13:41:53.345185:  
2025-12-21 13:41:53.345185: Epoch 352 
2025-12-21 13:41:53.345185: Current learning rate: 0.00677 
2025-12-21 13:44:11.347115: train_loss -0.8191 
2025-12-21 13:44:11.347115: val_loss -0.8463 
2025-12-21 13:44:11.358127: Pseudo dice [0.9123, 0.9483, 0.9325] 
2025-12-21 13:44:11.362980: Epoch time: 138.0 s 
2025-12-21 13:44:12.013527:  
2025-12-21 13:44:12.013527: Epoch 353 
2025-12-21 13:44:12.013527: Current learning rate: 0.00676 
2025-12-21 13:46:29.920510: train_loss -0.8304 
2025-12-21 13:46:29.920510: val_loss -0.8358 
2025-12-21 13:46:29.927196: Pseudo dice [0.9084, 0.9368, 0.9237] 
2025-12-21 13:46:29.931201: Epoch time: 137.91 s 
2025-12-21 13:46:30.583578:  
2025-12-21 13:46:30.583578: Epoch 354 
2025-12-21 13:46:30.583578: Current learning rate: 0.00675 
2025-12-21 13:48:48.427278: train_loss -0.8368 
2025-12-21 13:48:48.429280: val_loss -0.8332 
2025-12-21 13:48:48.433285: Pseudo dice [0.9031, 0.9346, 0.9292] 
2025-12-21 13:48:48.439293: Epoch time: 137.84 s 
2025-12-21 13:48:49.086511:  
2025-12-21 13:48:49.086511: Epoch 355 
2025-12-21 13:48:49.102144: Current learning rate: 0.00674 
2025-12-21 13:51:07.309236: train_loss -0.835 
2025-12-21 13:51:07.309236: val_loss -0.8747 
2025-12-21 13:51:07.314755: Pseudo dice [0.9322, 0.9603, 0.9349] 
2025-12-21 13:51:07.318759: Epoch time: 138.22 s 
2025-12-21 13:51:07.966918:  
2025-12-21 13:51:07.966918: Epoch 356 
2025-12-21 13:51:07.969185: Current learning rate: 0.00673 
2025-12-21 13:53:25.851294: train_loss -0.8296 
2025-12-21 13:53:25.854795: val_loss -0.8688 
2025-12-21 13:53:25.854795: Pseudo dice [0.927, 0.9538, 0.9367] 
2025-12-21 13:53:25.854795: Epoch time: 137.88 s 
2025-12-21 13:53:26.670112:  
2025-12-21 13:53:26.670112: Epoch 357 
2025-12-21 13:53:26.670112: Current learning rate: 0.00672 
2025-12-21 13:55:44.506145: train_loss -0.8309 
2025-12-21 13:55:44.508148: val_loss -0.8506 
2025-12-21 13:55:44.508148: Pseudo dice [0.9154, 0.9457, 0.9304] 
2025-12-21 13:55:44.508148: Epoch time: 137.84 s 
2025-12-21 13:55:45.157415:  
2025-12-21 13:55:45.157415: Epoch 358 
2025-12-21 13:55:45.159922: Current learning rate: 0.00671 
2025-12-21 13:58:03.128656: train_loss -0.8326 
2025-12-21 13:58:03.128656: val_loss -0.8684 
2025-12-21 13:58:03.136405: Pseudo dice [0.9282, 0.9546, 0.9332] 
2025-12-21 13:58:03.140411: Epoch time: 137.97 s 
2025-12-21 13:58:03.778409:  
2025-12-21 13:58:03.794164: Epoch 359 
2025-12-21 13:58:03.796943: Current learning rate: 0.0067 
2025-12-21 14:00:21.701547: train_loss -0.8471 
2025-12-21 14:00:21.701547: val_loss -0.8655 
2025-12-21 14:00:21.701547: Pseudo dice [0.9246, 0.9572, 0.9311] 
2025-12-21 14:00:21.710918: Epoch time: 137.92 s 
2025-12-21 14:00:22.416197:  
2025-12-21 14:00:22.416197: Epoch 360 
2025-12-21 14:00:22.430000: Current learning rate: 0.00669 
2025-12-21 14:02:40.287225: train_loss -0.8408 
2025-12-21 14:02:40.287225: val_loss -0.867 
2025-12-21 14:02:40.295236: Pseudo dice [0.924, 0.9546, 0.9367] 
2025-12-21 14:02:40.300986: Epoch time: 137.87 s 
2025-12-21 14:02:40.949672:  
2025-12-21 14:02:40.949672: Epoch 361 
2025-12-21 14:02:40.949672: Current learning rate: 0.00668 
2025-12-21 14:04:58.936064: train_loss -0.8399 
2025-12-21 14:04:58.936064: val_loss -0.8542 
2025-12-21 14:04:58.936064: Pseudo dice [0.9187, 0.9477, 0.9323] 
2025-12-21 14:04:58.950687: Epoch time: 137.99 s 
2025-12-21 14:04:59.585669:  
2025-12-21 14:04:59.585669: Epoch 362 
2025-12-21 14:04:59.585669: Current learning rate: 0.00667 
2025-12-21 14:07:17.543704: train_loss -0.8381 
2025-12-21 14:07:17.543704: val_loss -0.8614 
2025-12-21 14:07:17.547446: Pseudo dice [0.9249, 0.954, 0.916] 
2025-12-21 14:07:17.549449: Epoch time: 137.96 s 
2025-12-21 14:07:18.327044:  
2025-12-21 14:07:18.327044: Epoch 363 
2025-12-21 14:07:18.336464: Current learning rate: 0.00666 
2025-12-21 14:09:36.665069: train_loss -0.8434 
2025-12-21 14:09:36.667072: val_loss -0.8698 
2025-12-21 14:09:36.668813: Pseudo dice [0.9283, 0.9532, 0.9356] 
2025-12-21 14:09:36.668813: Epoch time: 138.34 s 
2025-12-21 14:09:37.509807:  
2025-12-21 14:09:37.509807: Epoch 364 
2025-12-21 14:09:37.525662: Current learning rate: 0.00665 
2025-12-21 14:11:55.688962: train_loss -0.8448 
2025-12-21 14:11:55.688962: val_loss -0.861 
2025-12-21 14:11:55.690965: Pseudo dice [0.9194, 0.951, 0.93] 
2025-12-21 14:11:55.690965: Epoch time: 138.18 s 
2025-12-21 14:11:56.347743:  
2025-12-21 14:11:56.347743: Epoch 365 
2025-12-21 14:11:56.347743: Current learning rate: 0.00665 
2025-12-21 14:14:14.295190: train_loss -0.8466 
2025-12-21 14:14:14.295190: val_loss -0.8632 
2025-12-21 14:14:14.295190: Pseudo dice [0.9247, 0.9558, 0.9357] 
2025-12-21 14:14:14.295190: Epoch time: 137.96 s 
2025-12-21 14:14:15.134621:  
2025-12-21 14:14:15.134621: Epoch 366 
2025-12-21 14:14:15.134621: Current learning rate: 0.00664 
2025-12-21 14:16:33.177858: train_loss -0.8428 
2025-12-21 14:16:33.177858: val_loss -0.856 
2025-12-21 14:16:33.181863: Pseudo dice [0.9162, 0.9503, 0.9327] 
2025-12-21 14:16:33.185442: Epoch time: 138.04 s 
2025-12-21 14:16:33.833100:  
2025-12-21 14:16:33.833100: Epoch 367 
2025-12-21 14:16:33.848305: Current learning rate: 0.00663 
2025-12-21 14:18:51.810994: train_loss -0.8412 
2025-12-21 14:18:51.810994: val_loss -0.8647 
2025-12-21 14:18:51.814058: Pseudo dice [0.9231, 0.9538, 0.9345] 
2025-12-21 14:18:51.818495: Epoch time: 137.98 s 
2025-12-21 14:18:52.474286:  
2025-12-21 14:18:52.474286: Epoch 368 
2025-12-21 14:18:52.474286: Current learning rate: 0.00662 
2025-12-21 14:21:10.435001: train_loss -0.8414 
2025-12-21 14:21:10.435001: val_loss -0.8453 
2025-12-21 14:21:10.439563: Pseudo dice [0.9082, 0.9437, 0.935] 
2025-12-21 14:21:10.441566: Epoch time: 137.96 s 
2025-12-21 14:21:11.356695:  
2025-12-21 14:21:11.356695: Epoch 369 
2025-12-21 14:21:11.372677: Current learning rate: 0.00661 
2025-12-21 14:23:29.315326: train_loss -0.8399 
2025-12-21 14:23:29.315326: val_loss -0.8407 
2025-12-21 14:23:29.330626: Pseudo dice [0.9078, 0.9437, 0.9309] 
2025-12-21 14:23:29.330626: Epoch time: 137.96 s 
2025-12-21 14:23:29.979430:  
2025-12-21 14:23:29.979430: Epoch 370 
2025-12-21 14:23:29.979430: Current learning rate: 0.0066 
2025-12-21 14:25:48.012082: train_loss -0.8402 
2025-12-21 14:25:48.012082: val_loss -0.8436 
2025-12-21 14:25:48.017036: Pseudo dice [0.9059, 0.9428, 0.9357] 
2025-12-21 14:25:48.017036: Epoch time: 138.03 s 
2025-12-21 14:25:48.672363:  
2025-12-21 14:25:48.672363: Epoch 371 
2025-12-21 14:25:48.672363: Current learning rate: 0.00659 
2025-12-21 14:28:06.599633: train_loss -0.8467 
2025-12-21 14:28:06.599633: val_loss -0.8649 
2025-12-21 14:28:06.601635: Pseudo dice [0.9221, 0.9539, 0.9357] 
2025-12-21 14:28:06.601635: Epoch time: 137.93 s 
2025-12-21 14:28:07.354017:  
2025-12-21 14:28:07.354017: Epoch 372 
2025-12-21 14:28:07.354017: Current learning rate: 0.00658 
2025-12-21 14:30:25.398865: train_loss -0.8348 
2025-12-21 14:30:25.414638: val_loss -0.8516 
2025-12-21 14:30:25.418545: Pseudo dice [0.9203, 0.9495, 0.9274] 
2025-12-21 14:30:25.418545: Epoch time: 138.04 s 
2025-12-21 14:30:26.064887:  
2025-12-21 14:30:26.064887: Epoch 373 
2025-12-21 14:30:26.064887: Current learning rate: 0.00657 
2025-12-21 14:32:43.839560: train_loss -0.8342 
2025-12-21 14:32:43.839560: val_loss -0.8634 
2025-12-21 14:32:43.843304: Pseudo dice [0.9248, 0.9533, 0.9307] 
2025-12-21 14:32:43.843304: Epoch time: 137.79 s 
2025-12-21 14:32:44.508963:  
2025-12-21 14:32:44.508963: Epoch 374 
2025-12-21 14:32:44.524766: Current learning rate: 0.00656 
2025-12-21 14:35:02.571709: train_loss -0.8408 
2025-12-21 14:35:02.571709: val_loss -0.8613 
2025-12-21 14:35:02.576716: Pseudo dice [0.9204, 0.9493, 0.9327] 
2025-12-21 14:35:02.580722: Epoch time: 138.06 s 
2025-12-21 14:35:03.525366:  
2025-12-21 14:35:03.525366: Epoch 375 
2025-12-21 14:35:03.525366: Current learning rate: 0.00655 
2025-12-21 14:37:21.390001: train_loss -0.8449 
2025-12-21 14:37:21.392004: val_loss -0.8588 
2025-12-21 14:37:21.396009: Pseudo dice [0.9172, 0.9474, 0.9382] 
2025-12-21 14:37:21.399752: Epoch time: 137.86 s 
2025-12-21 14:37:22.048140:  
2025-12-21 14:37:22.048140: Epoch 376 
2025-12-21 14:37:22.064097: Current learning rate: 0.00654 
2025-12-21 14:39:39.979552: train_loss -0.8433 
2025-12-21 14:39:39.979552: val_loss -0.8656 
2025-12-21 14:39:39.988016: Pseudo dice [0.9263, 0.9526, 0.9315] 
2025-12-21 14:39:39.991860: Epoch time: 137.93 s 
2025-12-21 14:39:40.676471:  
2025-12-21 14:39:40.676471: Epoch 377 
2025-12-21 14:39:40.692139: Current learning rate: 0.00653 
2025-12-21 14:41:58.521606: train_loss -0.8451 
2025-12-21 14:41:58.521606: val_loss -0.8525 
2025-12-21 14:41:58.528360: Pseudo dice [0.9141, 0.9452, 0.9345] 
2025-12-21 14:41:58.528360: Epoch time: 137.85 s 
2025-12-21 14:41:59.187874:  
2025-12-21 14:41:59.187874: Epoch 378 
2025-12-21 14:41:59.187874: Current learning rate: 0.00652 
2025-12-21 14:44:17.431822: train_loss -0.8407 
2025-12-21 14:44:17.431822: val_loss -0.8721 
2025-12-21 14:44:17.449549: Pseudo dice [0.9291, 0.9562, 0.9356] 
2025-12-21 14:44:17.449549: Epoch time: 138.24 s 
2025-12-21 14:44:18.112329:  
2025-12-21 14:44:18.112329: Epoch 379 
2025-12-21 14:44:18.112329: Current learning rate: 0.00651 
2025-12-21 14:46:36.182077: train_loss -0.8416 
2025-12-21 14:46:36.182077: val_loss -0.8615 
2025-12-21 14:46:36.197473: Pseudo dice [0.9228, 0.9494, 0.936] 
2025-12-21 14:46:36.199476: Epoch time: 138.07 s 
2025-12-21 14:46:36.843419:  
2025-12-21 14:46:36.843419: Epoch 380 
2025-12-21 14:46:36.843419: Current learning rate: 0.0065 
2025-12-21 14:48:54.895124: train_loss -0.8351 
2025-12-21 14:48:54.895124: val_loss -0.8531 
2025-12-21 14:48:54.911141: Pseudo dice [0.9223, 0.9479, 0.9199] 
2025-12-21 14:48:54.911141: Epoch time: 138.05 s 
2025-12-21 14:48:55.560033:  
2025-12-21 14:48:55.560033: Epoch 381 
2025-12-21 14:48:55.560033: Current learning rate: 0.00649 
2025-12-21 14:51:13.541375: train_loss -0.8435 
2025-12-21 14:51:13.541375: val_loss -0.86 
2025-12-21 14:51:13.543116: Pseudo dice [0.9209, 0.9497, 0.9295] 
2025-12-21 14:51:13.543116: Epoch time: 137.98 s 
2025-12-21 14:51:14.208935:  
2025-12-21 14:51:14.208935: Epoch 382 
2025-12-21 14:51:14.208935: Current learning rate: 0.00648 
2025-12-21 14:53:32.195480: train_loss -0.8452 
2025-12-21 14:53:32.195480: val_loss -0.8592 
2025-12-21 14:53:32.195480: Pseudo dice [0.9185, 0.9531, 0.9313] 
2025-12-21 14:53:32.211479: Epoch time: 137.99 s 
2025-12-21 14:53:32.863412:  
2025-12-21 14:53:32.863412: Epoch 383 
2025-12-21 14:53:32.863412: Current learning rate: 0.00648 
2025-12-21 14:55:50.840130: train_loss -0.8461 
2025-12-21 14:55:50.840130: val_loss -0.8661 
2025-12-21 14:55:50.856196: Pseudo dice [0.9242, 0.9548, 0.9373] 
2025-12-21 14:55:50.856196: Epoch time: 137.98 s 
2025-12-21 14:55:51.507067:  
2025-12-21 14:55:51.507067: Epoch 384 
2025-12-21 14:55:51.507067: Current learning rate: 0.00647 
2025-12-21 14:58:09.453808: train_loss -0.8389 
2025-12-21 14:58:09.453808: val_loss -0.8654 
2025-12-21 14:58:09.457813: Pseudo dice [0.924, 0.9475, 0.9382] 
2025-12-21 14:58:09.461818: Epoch time: 137.95 s 
2025-12-21 14:58:10.129791:  
2025-12-21 14:58:10.129791: Epoch 385 
2025-12-21 14:58:10.129791: Current learning rate: 0.00646 
2025-12-21 15:00:27.953935: train_loss -0.849 
2025-12-21 15:00:27.953935: val_loss -0.8462 
2025-12-21 15:00:27.957939: Pseudo dice [0.9103, 0.9412, 0.9296] 
2025-12-21 15:00:27.961682: Epoch time: 137.82 s 
2025-12-21 15:00:28.753853:  
2025-12-21 15:00:28.753853: Epoch 386 
2025-12-21 15:00:28.753853: Current learning rate: 0.00645 
2025-12-21 15:02:46.637960: train_loss -0.8455 
2025-12-21 15:02:46.637960: val_loss -0.8804 
2025-12-21 15:02:46.637960: Pseudo dice [0.9358, 0.9602, 0.9377] 
2025-12-21 15:02:46.653893: Epoch time: 137.88 s 
2025-12-21 15:02:47.445433:  
2025-12-21 15:02:47.445433: Epoch 387 
2025-12-21 15:02:47.461435: Current learning rate: 0.00644 
2025-12-21 15:05:05.484916: train_loss -0.8403 
2025-12-21 15:05:05.484916: val_loss -0.8663 
2025-12-21 15:05:05.486919: Pseudo dice [0.9231, 0.9532, 0.9361] 
2025-12-21 15:05:05.486919: Epoch time: 138.04 s 
2025-12-21 15:05:06.144847:  
2025-12-21 15:05:06.144847: Epoch 388 
2025-12-21 15:05:06.144847: Current learning rate: 0.00643 
2025-12-21 15:07:24.081120: train_loss -0.8446 
2025-12-21 15:07:24.081120: val_loss -0.873 
2025-12-21 15:07:24.086126: Pseudo dice [0.9293, 0.9563, 0.9357] 
2025-12-21 15:07:24.086126: Epoch time: 137.94 s 
2025-12-21 15:07:24.879305:  
2025-12-21 15:07:24.879305: Epoch 389 
2025-12-21 15:07:24.895334: Current learning rate: 0.00642 
2025-12-21 15:09:43.027495: train_loss -0.8434 
2025-12-21 15:09:43.027495: val_loss -0.8561 
2025-12-21 15:09:43.036739: Pseudo dice [0.9156, 0.9452, 0.9344] 
2025-12-21 15:09:43.040743: Epoch time: 138.15 s 
2025-12-21 15:09:43.692179:  
2025-12-21 15:09:43.692179: Epoch 390 
2025-12-21 15:09:43.707810: Current learning rate: 0.00641 
2025-12-21 15:12:01.720296: train_loss -0.8454 
2025-12-21 15:12:01.720296: val_loss -0.8605 
2025-12-21 15:12:01.726043: Pseudo dice [0.9197, 0.9515, 0.9318] 
2025-12-21 15:12:01.730049: Epoch time: 138.03 s 
2025-12-21 15:12:02.390773:  
2025-12-21 15:12:02.390773: Epoch 391 
2025-12-21 15:12:02.390773: Current learning rate: 0.0064 
2025-12-21 15:14:20.298078: train_loss -0.8391 
2025-12-21 15:14:20.298078: val_loss -0.8522 
2025-12-21 15:14:20.303826: Pseudo dice [0.9188, 0.9464, 0.9233] 
2025-12-21 15:14:20.305829: Epoch time: 137.91 s 
2025-12-21 15:14:21.111259:  
2025-12-21 15:14:21.111259: Epoch 392 
2025-12-21 15:14:21.111259: Current learning rate: 0.00639 
2025-12-21 15:16:39.031919: train_loss -0.8436 
2025-12-21 15:16:39.031919: val_loss -0.8704 
2025-12-21 15:16:39.047900: Pseudo dice [0.9239, 0.9541, 0.9364] 
2025-12-21 15:16:39.047900: Epoch time: 137.92 s 
2025-12-21 15:16:39.872922:  
2025-12-21 15:16:39.872922: Epoch 393 
2025-12-21 15:16:39.872922: Current learning rate: 0.00638 
2025-12-21 15:18:57.749968: train_loss -0.849 
2025-12-21 15:18:57.749968: val_loss -0.8707 
2025-12-21 15:18:57.749968: Pseudo dice [0.927, 0.9554, 0.9332] 
2025-12-21 15:18:57.749968: Epoch time: 137.88 s 
2025-12-21 15:18:58.413545:  
2025-12-21 15:18:58.413545: Epoch 394 
2025-12-21 15:18:58.413545: Current learning rate: 0.00637 
2025-12-21 15:21:16.479795: train_loss -0.8404 
2025-12-21 15:21:16.479795: val_loss -0.8704 
2025-12-21 15:21:16.481797: Pseudo dice [0.9265, 0.9548, 0.936] 
2025-12-21 15:21:16.481797: Epoch time: 138.07 s 
2025-12-21 15:21:17.210413:  
2025-12-21 15:21:17.210413: Epoch 395 
2025-12-21 15:21:17.228276: Current learning rate: 0.00636 
2025-12-21 15:23:35.387284: train_loss -0.8465 
2025-12-21 15:23:35.387284: val_loss -0.8676 
2025-12-21 15:23:35.387284: Pseudo dice [0.9228, 0.9535, 0.9349] 
2025-12-21 15:23:35.401099: Epoch time: 138.18 s 
2025-12-21 15:23:36.052310:  
2025-12-21 15:23:36.052310: Epoch 396 
2025-12-21 15:23:36.052310: Current learning rate: 0.00635 
2025-12-21 15:25:53.801772: train_loss -0.8461 
2025-12-21 15:25:53.803775: val_loss -0.8655 
2025-12-21 15:25:53.803775: Pseudo dice [0.928, 0.9525, 0.9322] 
2025-12-21 15:25:53.803775: Epoch time: 137.75 s 
2025-12-21 15:25:53.803775: Yayy! New best EMA pseudo Dice: 0.936 
2025-12-21 15:25:54.702931:  
2025-12-21 15:25:54.702931: Epoch 397 
2025-12-21 15:25:54.702931: Current learning rate: 0.00634 
2025-12-21 15:28:12.588122: train_loss -0.8485 
2025-12-21 15:28:12.588122: val_loss -0.8704 
2025-12-21 15:28:12.592125: Pseudo dice [0.9243, 0.9507, 0.9425] 
2025-12-21 15:28:12.596129: Epoch time: 137.89 s 
2025-12-21 15:28:12.599960: Yayy! New best EMA pseudo Dice: 0.9363 
2025-12-21 15:28:13.575854:  
2025-12-21 15:28:13.575854: Epoch 398 
2025-12-21 15:28:13.592741: Current learning rate: 0.00633 
2025-12-21 15:30:31.757443: train_loss -0.8425 
2025-12-21 15:30:31.759445: val_loss -0.853 
2025-12-21 15:30:31.763450: Pseudo dice [0.9152, 0.9472, 0.9377] 
2025-12-21 15:30:31.767307: Epoch time: 138.18 s 
2025-12-21 15:30:32.605681:  
2025-12-21 15:30:32.607422: Epoch 399 
2025-12-21 15:30:32.607422: Current learning rate: 0.00632 
2025-12-21 15:32:50.612806: train_loss -0.8457 
2025-12-21 15:32:50.614546: val_loss -0.8622 
2025-12-21 15:32:50.614546: Pseudo dice [0.9235, 0.9482, 0.9347] 
2025-12-21 15:32:50.614546: Epoch time: 138.01 s 
2025-12-21 15:32:51.528563:  
2025-12-21 15:32:51.528563: Epoch 400 
2025-12-21 15:32:51.528563: Current learning rate: 0.00631 
2025-12-21 15:35:09.466793: train_loss -0.8487 
2025-12-21 15:35:09.466793: val_loss -0.8762 
2025-12-21 15:35:09.470609: Pseudo dice [0.9322, 0.9585, 0.9342] 
2025-12-21 15:35:09.474613: Epoch time: 137.94 s 
2025-12-21 15:35:09.478617: Yayy! New best EMA pseudo Dice: 0.9366 
2025-12-21 15:35:10.568059:  
2025-12-21 15:35:10.568059: Epoch 401 
2025-12-21 15:35:10.583829: Current learning rate: 0.0063 
2025-12-21 15:37:28.391340: train_loss -0.8488 
2025-12-21 15:37:28.393144: val_loss -0.8578 
2025-12-21 15:37:28.397148: Pseudo dice [0.9189, 0.9542, 0.9369] 
2025-12-21 15:37:28.399150: Epoch time: 137.82 s 
2025-12-21 15:37:28.403154: Yayy! New best EMA pseudo Dice: 0.9366 
2025-12-21 15:37:29.345723:  
2025-12-21 15:37:29.347725: Epoch 402 
2025-12-21 15:37:29.349467: Current learning rate: 0.0063 
2025-12-21 15:39:47.125787: train_loss -0.8413 
2025-12-21 15:39:47.127791: val_loss -0.8612 
2025-12-21 15:39:47.134236: Pseudo dice [0.918, 0.9532, 0.9349] 
2025-12-21 15:39:47.136239: Epoch time: 137.78 s 
2025-12-21 15:39:47.801086:  
2025-12-21 15:39:47.801086: Epoch 403 
2025-12-21 15:39:47.801086: Current learning rate: 0.00629 
2025-12-21 15:42:05.785554: train_loss -0.8408 
2025-12-21 15:42:05.785554: val_loss -0.8771 
2025-12-21 15:42:05.798621: Pseudo dice [0.93, 0.9573, 0.9379] 
2025-12-21 15:42:05.801625: Epoch time: 137.98 s 
2025-12-21 15:42:05.805442: Yayy! New best EMA pseudo Dice: 0.937 
2025-12-21 15:42:07.036550:  
2025-12-21 15:42:07.036550: Epoch 404 
2025-12-21 15:42:07.052513: Current learning rate: 0.00628 
2025-12-21 15:44:24.955930: train_loss -0.844 
2025-12-21 15:44:24.955930: val_loss -0.855 
2025-12-21 15:44:24.971730: Pseudo dice [0.9203, 0.9437, 0.9333] 
2025-12-21 15:44:24.971730: Epoch time: 137.92 s 
2025-12-21 15:44:25.620685:  
2025-12-21 15:44:25.620685: Epoch 405 
2025-12-21 15:44:25.620685: Current learning rate: 0.00627 
2025-12-21 15:46:43.539892: train_loss -0.8412 
2025-12-21 15:46:43.539892: val_loss -0.8625 
2025-12-21 15:46:43.543897: Pseudo dice [0.9251, 0.9549, 0.9326] 
2025-12-21 15:46:43.546901: Epoch time: 137.92 s 
2025-12-21 15:46:44.200879:  
2025-12-21 15:46:44.200879: Epoch 406 
2025-12-21 15:46:44.200879: Current learning rate: 0.00626 
2025-12-21 15:49:02.127982: train_loss -0.8417 
2025-12-21 15:49:02.127982: val_loss -0.8672 
2025-12-21 15:49:02.127982: Pseudo dice [0.9289, 0.9555, 0.9312] 
2025-12-21 15:49:02.139487: Epoch time: 137.93 s 
2025-12-21 15:49:02.797175:  
2025-12-21 15:49:02.797175: Epoch 407 
2025-12-21 15:49:02.797175: Current learning rate: 0.00625 
2025-12-21 15:51:20.640376: train_loss -0.8481 
2025-12-21 15:51:20.642378: val_loss -0.8529 
2025-12-21 15:51:20.648473: Pseudo dice [0.9147, 0.9471, 0.9335] 
2025-12-21 15:51:20.652478: Epoch time: 137.84 s 
2025-12-21 15:51:21.321679:  
2025-12-21 15:51:21.321679: Epoch 408 
2025-12-21 15:51:21.321679: Current learning rate: 0.00624 
2025-12-21 15:53:39.260115: train_loss -0.8429 
2025-12-21 15:53:39.262118: val_loss -0.8588 
2025-12-21 15:53:39.263861: Pseudo dice [0.9177, 0.9512, 0.931] 
2025-12-21 15:53:39.263861: Epoch time: 137.94 s 
2025-12-21 15:53:39.928653:  
2025-12-21 15:53:39.928653: Epoch 409 
2025-12-21 15:53:39.928653: Current learning rate: 0.00623 
2025-12-21 15:55:57.803555: train_loss -0.8364 
2025-12-21 15:55:57.803555: val_loss -0.8592 
2025-12-21 15:55:57.814829: Pseudo dice [0.9228, 0.9471, 0.9331] 
2025-12-21 15:55:57.818834: Epoch time: 137.87 s 
2025-12-21 15:55:58.648856:  
2025-12-21 15:55:58.648856: Epoch 410 
2025-12-21 15:55:58.648856: Current learning rate: 0.00622 
2025-12-21 15:58:16.671811: train_loss -0.834 
2025-12-21 15:58:16.671811: val_loss -0.8622 
2025-12-21 15:58:16.673814: Pseudo dice [0.9238, 0.9526, 0.9363] 
2025-12-21 15:58:16.680775: Epoch time: 138.02 s 
2025-12-21 15:58:17.309235:  
2025-12-21 15:58:17.311237: Epoch 411 
2025-12-21 15:58:17.311237: Current learning rate: 0.00621 
2025-12-21 16:00:35.269405: train_loss -0.8429 
2025-12-21 16:00:35.269405: val_loss -0.8714 
2025-12-21 16:00:35.269405: Pseudo dice [0.9284, 0.9556, 0.9391] 
2025-12-21 16:00:35.285069: Epoch time: 137.96 s 
2025-12-21 16:00:35.904889:  
2025-12-21 16:00:35.904889: Epoch 412 
2025-12-21 16:00:35.904889: Current learning rate: 0.0062 
2025-12-21 16:02:53.737102: train_loss -0.8441 
2025-12-21 16:02:53.737102: val_loss -0.8711 
2025-12-21 16:02:53.737102: Pseudo dice [0.9286, 0.9582, 0.9404] 
2025-12-21 16:02:53.752901: Epoch time: 137.83 s 
2025-12-21 16:02:53.752901: Yayy! New best EMA pseudo Dice: 0.9371 
2025-12-21 16:02:54.610949:  
2025-12-21 16:02:54.610949: Epoch 413 
2025-12-21 16:02:54.619354: Current learning rate: 0.00619 
2025-12-21 16:05:12.590559: train_loss -0.8498 
2025-12-21 16:05:12.590559: val_loss -0.8701 
2025-12-21 16:05:12.596565: Pseudo dice [0.9294, 0.9568, 0.933] 
2025-12-21 16:05:12.600569: Epoch time: 137.98 s 
2025-12-21 16:05:12.604311: Yayy! New best EMA pseudo Dice: 0.9374 
2025-12-21 16:05:13.523066:  
2025-12-21 16:05:13.523066: Epoch 414 
2025-12-21 16:05:13.523066: Current learning rate: 0.00618 
2025-12-21 16:07:31.428684: train_loss -0.8433 
2025-12-21 16:07:31.428684: val_loss -0.8695 
2025-12-21 16:07:31.432688: Pseudo dice [0.9246, 0.9541, 0.9431] 
2025-12-21 16:07:31.434428: Epoch time: 137.91 s 
2025-12-21 16:07:31.439397: Yayy! New best EMA pseudo Dice: 0.9377 
2025-12-21 16:07:32.355482:  
2025-12-21 16:07:32.355482: Epoch 415 
2025-12-21 16:07:32.355482: Current learning rate: 0.00617 
2025-12-21 16:09:50.907614: train_loss -0.8421 
2025-12-21 16:09:50.909616: val_loss -0.8545 
2025-12-21 16:09:50.915626: Pseudo dice [0.9148, 0.9461, 0.9389] 
2025-12-21 16:09:50.919370: Epoch time: 138.55 s 
2025-12-21 16:09:51.751378:  
2025-12-21 16:09:51.751378: Epoch 416 
2025-12-21 16:09:51.751378: Current learning rate: 0.00616 
2025-12-21 16:12:09.757672: train_loss -0.8401 
2025-12-21 16:12:09.757672: val_loss -0.8669 
2025-12-21 16:12:09.763678: Pseudo dice [0.9233, 0.9574, 0.9323] 
2025-12-21 16:12:09.767683: Epoch time: 138.01 s 
2025-12-21 16:12:10.400550:  
2025-12-21 16:12:10.400550: Epoch 417 
2025-12-21 16:12:10.400550: Current learning rate: 0.00615 
2025-12-21 16:14:28.262204: train_loss -0.8447 
2025-12-21 16:14:28.262204: val_loss -0.8604 
2025-12-21 16:14:28.267658: Pseudo dice [0.9165, 0.9446, 0.9461] 
2025-12-21 16:14:28.271663: Epoch time: 137.86 s 
2025-12-21 16:14:28.894776:  
2025-12-21 16:14:28.894776: Epoch 418 
2025-12-21 16:14:28.910429: Current learning rate: 0.00614 
2025-12-21 16:16:46.799559: train_loss -0.8384 
2025-12-21 16:16:46.799559: val_loss -0.8624 
2025-12-21 16:16:46.805168: Pseudo dice [0.9235, 0.9501, 0.9393] 
2025-12-21 16:16:46.807169: Epoch time: 137.9 s 
2025-12-21 16:16:47.433215:  
2025-12-21 16:16:47.433215: Epoch 419 
2025-12-21 16:16:47.433215: Current learning rate: 0.00613 
2025-12-21 16:19:05.662814: train_loss -0.8353 
2025-12-21 16:19:05.662814: val_loss -0.8533 
2025-12-21 16:19:05.662814: Pseudo dice [0.9198, 0.9486, 0.9237] 
2025-12-21 16:19:05.662814: Epoch time: 138.23 s 
2025-12-21 16:19:06.302748:  
2025-12-21 16:19:06.306576: Epoch 420 
2025-12-21 16:19:06.309595: Current learning rate: 0.00612 
2025-12-21 16:21:24.889766: train_loss -0.8432 
2025-12-21 16:21:24.889766: val_loss -0.8647 
2025-12-21 16:21:24.893772: Pseudo dice [0.9283, 0.9556, 0.9198] 
2025-12-21 16:21:24.898216: Epoch time: 138.59 s 
2025-12-21 16:21:25.529736:  
2025-12-21 16:21:25.529736: Epoch 421 
2025-12-21 16:21:25.529736: Current learning rate: 0.00612 
2025-12-21 16:23:43.932185: train_loss -0.8409 
2025-12-21 16:23:43.932185: val_loss -0.8704 
2025-12-21 16:23:43.940632: Pseudo dice [0.9262, 0.9557, 0.9315] 
2025-12-21 16:23:43.940632: Epoch time: 138.4 s 
2025-12-21 16:23:44.733822:  
2025-12-21 16:23:44.733822: Epoch 422 
2025-12-21 16:23:44.733822: Current learning rate: 0.00611 
2025-12-21 16:26:03.187827: train_loss -0.8447 
2025-12-21 16:26:03.187827: val_loss -0.8723 
2025-12-21 16:26:03.187827: Pseudo dice [0.929, 0.9589, 0.9353] 
2025-12-21 16:26:03.187827: Epoch time: 138.45 s 
2025-12-21 16:26:03.836648:  
2025-12-21 16:26:03.836648: Epoch 423 
2025-12-21 16:26:03.836648: Current learning rate: 0.0061 
2025-12-21 16:28:22.249602: train_loss -0.8394 
2025-12-21 16:28:22.249602: val_loss -0.8696 
2025-12-21 16:28:22.256894: Pseudo dice [0.9273, 0.9548, 0.937] 
2025-12-21 16:28:22.256894: Epoch time: 138.43 s 
2025-12-21 16:28:22.885140:  
2025-12-21 16:28:22.885140: Epoch 424 
2025-12-21 16:28:22.885140: Current learning rate: 0.00609 
2025-12-21 16:30:41.052885: train_loss -0.8481 
2025-12-21 16:30:41.052885: val_loss -0.8779 
2025-12-21 16:30:41.058891: Pseudo dice [0.9326, 0.959, 0.9316] 
2025-12-21 16:30:41.062895: Epoch time: 138.17 s 
2025-12-21 16:30:41.685546:  
2025-12-21 16:30:41.685546: Epoch 425 
2025-12-21 16:30:41.701299: Current learning rate: 0.00608 
2025-12-21 16:32:59.643138: train_loss -0.8461 
2025-12-21 16:32:59.643138: val_loss -0.8709 
2025-12-21 16:32:59.643138: Pseudo dice [0.9284, 0.9573, 0.9321] 
2025-12-21 16:32:59.651153: Epoch time: 137.96 s 
2025-12-21 16:32:59.651153: Yayy! New best EMA pseudo Dice: 0.9378 
2025-12-21 16:33:00.514623:  
2025-12-21 16:33:00.514623: Epoch 426 
2025-12-21 16:33:00.514623: Current learning rate: 0.00607 
2025-12-21 16:35:18.562937: train_loss -0.8479 
2025-12-21 16:35:18.564940: val_loss -0.8698 
2025-12-21 16:35:18.568944: Pseudo dice [0.9281, 0.9574, 0.9311] 
2025-12-21 16:35:18.571687: Epoch time: 138.05 s 
2025-12-21 16:35:18.575691: Yayy! New best EMA pseudo Dice: 0.9379 
2025-12-21 16:35:19.490209:  
2025-12-21 16:35:19.490209: Epoch 427 
2025-12-21 16:35:19.490209: Current learning rate: 0.00606 
2025-12-21 16:37:37.287493: train_loss -0.8461 
2025-12-21 16:37:37.287493: val_loss -0.8742 
2025-12-21 16:37:37.303380: Pseudo dice [0.9272, 0.9549, 0.9434] 
2025-12-21 16:37:37.307941: Epoch time: 137.8 s 
2025-12-21 16:37:37.307941: Yayy! New best EMA pseudo Dice: 0.9383 
2025-12-21 16:37:38.368821:  
2025-12-21 16:37:38.368821: Epoch 428 
2025-12-21 16:37:38.376814: Current learning rate: 0.00605 
2025-12-21 16:39:56.273439: train_loss -0.8418 
2025-12-21 16:39:56.273439: val_loss -0.873 
2025-12-21 16:39:56.291200: Pseudo dice [0.9289, 0.9568, 0.9346] 
2025-12-21 16:39:56.291200: Epoch time: 137.9 s 
2025-12-21 16:39:56.297669: Yayy! New best EMA pseudo Dice: 0.9385 
2025-12-21 16:39:57.211799:  
2025-12-21 16:39:57.211799: Epoch 429 
2025-12-21 16:39:57.216365: Current learning rate: 0.00604 
2025-12-21 16:42:15.289882: train_loss -0.8377 
2025-12-21 16:42:15.289882: val_loss -0.8645 
2025-12-21 16:42:15.300363: Pseudo dice [0.9225, 0.9534, 0.9353] 
2025-12-21 16:42:15.300363: Epoch time: 138.08 s 
2025-12-21 16:42:15.955909:  
2025-12-21 16:42:15.955909: Epoch 430 
2025-12-21 16:42:15.958565: Current learning rate: 0.00603 
2025-12-21 16:44:34.113009: train_loss -0.8442 
2025-12-21 16:44:34.113009: val_loss -0.8654 
2025-12-21 16:44:34.118515: Pseudo dice [0.9255, 0.9543, 0.9329] 
2025-12-21 16:44:34.122354: Epoch time: 138.16 s 
2025-12-21 16:44:34.761312:  
2025-12-21 16:44:34.761312: Epoch 431 
2025-12-21 16:44:34.761312: Current learning rate: 0.00602 
2025-12-21 16:46:52.791536: train_loss -0.8406 
2025-12-21 16:46:52.793539: val_loss -0.8744 
2025-12-21 16:46:52.793539: Pseudo dice [0.9331, 0.9569, 0.939] 
2025-12-21 16:46:52.793539: Epoch time: 138.03 s 
2025-12-21 16:46:52.793539: Yayy! New best EMA pseudo Dice: 0.9387 
2025-12-21 16:46:53.678686:  
2025-12-21 16:46:53.678686: Epoch 432 
2025-12-21 16:46:53.678686: Current learning rate: 0.00601 
2025-12-21 16:49:11.745090: train_loss -0.8456 
2025-12-21 16:49:11.745090: val_loss -0.8804 
2025-12-21 16:49:11.745090: Pseudo dice [0.9333, 0.957, 0.9374] 
2025-12-21 16:49:11.758940: Epoch time: 138.07 s 
2025-12-21 16:49:11.760942: Yayy! New best EMA pseudo Dice: 0.9391 
2025-12-21 16:49:12.726409:  
2025-12-21 16:49:12.726409: Epoch 433 
2025-12-21 16:49:12.742410: Current learning rate: 0.006 
2025-12-21 16:51:30.708327: train_loss -0.8456 
2025-12-21 16:51:30.708327: val_loss -0.8744 
2025-12-21 16:51:30.708327: Pseudo dice [0.9287, 0.9617, 0.9336] 
2025-12-21 16:51:30.722055: Epoch time: 137.98 s 
2025-12-21 16:51:30.722055: Yayy! New best EMA pseudo Dice: 0.9393 
2025-12-21 16:51:31.819169:  
2025-12-21 16:51:31.819169: Epoch 434 
2025-12-21 16:51:31.835169: Current learning rate: 0.00599 
2025-12-21 16:53:50.033618: train_loss -0.8472 
2025-12-21 16:53:50.041617: val_loss -0.8632 
2025-12-21 16:53:50.047489: Pseudo dice [0.9209, 0.9499, 0.9411] 
2025-12-21 16:53:50.049491: Epoch time: 138.21 s 
2025-12-21 16:53:50.676337:  
2025-12-21 16:53:50.676337: Epoch 435 
2025-12-21 16:53:50.676337: Current learning rate: 0.00598 
2025-12-21 16:56:08.937778: train_loss -0.8412 
2025-12-21 16:56:08.939780: val_loss -0.8744 
2025-12-21 16:56:08.943254: Pseudo dice [0.9316, 0.9571, 0.9309] 
2025-12-21 16:56:08.943254: Epoch time: 138.26 s 
2025-12-21 16:56:09.613075:  
2025-12-21 16:56:09.613075: Epoch 436 
2025-12-21 16:56:09.613075: Current learning rate: 0.00597 
2025-12-21 16:58:27.678575: train_loss -0.8452 
2025-12-21 16:58:27.678575: val_loss -0.8842 
2025-12-21 16:58:27.685649: Pseudo dice [0.9345, 0.9618, 0.9425] 
2025-12-21 16:58:27.689890: Epoch time: 138.07 s 
2025-12-21 16:58:27.692408: Yayy! New best EMA pseudo Dice: 0.9399 
2025-12-21 16:58:28.582648:  
2025-12-21 16:58:28.582648: Epoch 437 
2025-12-21 16:58:28.586634: Current learning rate: 0.00596 
2025-12-21 17:00:46.560299: train_loss -0.8499 
2025-12-21 17:00:46.560299: val_loss -0.8604 
2025-12-21 17:00:46.560299: Pseudo dice [0.922, 0.951, 0.9323] 
2025-12-21 17:00:46.560299: Epoch time: 137.98 s 
2025-12-21 17:00:47.238801:  
2025-12-21 17:00:47.238801: Epoch 438 
2025-12-21 17:00:47.238801: Current learning rate: 0.00595 
2025-12-21 17:03:05.350413: train_loss -0.8442 
2025-12-21 17:03:05.350413: val_loss -0.8613 
2025-12-21 17:03:05.366394: Pseudo dice [0.9201, 0.9531, 0.9363] 
2025-12-21 17:03:05.366394: Epoch time: 138.11 s 
2025-12-21 17:03:06.034987:  
2025-12-21 17:03:06.034987: Epoch 439 
2025-12-21 17:03:06.034987: Current learning rate: 0.00594 
2025-12-21 17:05:24.135991: train_loss -0.8492 
2025-12-21 17:05:24.135991: val_loss -0.878 
2025-12-21 17:05:24.141437: Pseudo dice [0.9304, 0.9615, 0.9388] 
2025-12-21 17:05:24.141437: Epoch time: 138.1 s 
2025-12-21 17:05:24.990745:  
2025-12-21 17:05:24.990745: Epoch 440 
2025-12-21 17:05:24.990745: Current learning rate: 0.00593 
2025-12-21 17:07:43.047531: train_loss -0.8328 
2025-12-21 17:07:43.049534: val_loss -0.8292 
2025-12-21 17:07:43.051275: Pseudo dice [0.9094, 0.941, 0.9173] 
2025-12-21 17:07:43.051275: Epoch time: 138.06 s 
2025-12-21 17:07:43.698964:  
2025-12-21 17:07:43.698964: Epoch 441 
2025-12-21 17:07:43.698964: Current learning rate: 0.00592 
2025-12-21 17:10:01.945314: train_loss -0.8272 
2025-12-21 17:10:01.945314: val_loss -0.8444 
2025-12-21 17:10:01.951060: Pseudo dice [0.9158, 0.9435, 0.9152] 
2025-12-21 17:10:01.957067: Epoch time: 138.25 s 
2025-12-21 17:10:02.692215:  
2025-12-21 17:10:02.692215: Epoch 442 
2025-12-21 17:10:02.692215: Current learning rate: 0.00592 
2025-12-21 17:12:20.579865: train_loss -0.8381 
2025-12-21 17:12:20.579865: val_loss -0.8547 
2025-12-21 17:12:20.587878: Pseudo dice [0.9186, 0.9501, 0.9295] 
2025-12-21 17:12:20.591885: Epoch time: 137.89 s 
2025-12-21 17:12:21.213911:  
2025-12-21 17:12:21.213911: Epoch 443 
2025-12-21 17:12:21.228014: Current learning rate: 0.00591 
2025-12-21 17:14:39.295206: train_loss -0.8444 
2025-12-21 17:14:39.295206: val_loss -0.8316 
2025-12-21 17:14:39.299210: Pseudo dice [0.8978, 0.9339, 0.9334] 
2025-12-21 17:14:39.303214: Epoch time: 138.08 s 
2025-12-21 17:14:39.918160:  
2025-12-21 17:14:39.918160: Epoch 444 
2025-12-21 17:14:39.918160: Current learning rate: 0.0059 
2025-12-21 17:16:57.980472: train_loss -0.8416 
2025-12-21 17:16:57.982474: val_loss -0.8433 
2025-12-21 17:16:57.986217: Pseudo dice [0.9116, 0.9436, 0.9294] 
2025-12-21 17:16:57.986217: Epoch time: 138.06 s 
2025-12-21 17:16:58.712103:  
2025-12-21 17:16:58.712103: Epoch 445 
2025-12-21 17:16:58.712103: Current learning rate: 0.00589 
2025-12-21 17:19:16.520526: train_loss -0.8389 
2025-12-21 17:19:16.522528: val_loss -0.8458 
2025-12-21 17:19:16.526533: Pseudo dice [0.9112, 0.9416, 0.9296] 
2025-12-21 17:19:16.532280: Epoch time: 137.81 s 
2025-12-21 17:19:17.327348:  
2025-12-21 17:19:17.327348: Epoch 446 
2025-12-21 17:19:17.327348: Current learning rate: 0.00588 
2025-12-21 17:21:35.213169: train_loss -0.8415 
2025-12-21 17:21:35.215171: val_loss -0.8703 
2025-12-21 17:21:35.218676: Pseudo dice [0.9259, 0.9583, 0.9361] 
2025-12-21 17:21:35.218676: Epoch time: 137.89 s 
2025-12-21 17:21:35.833565:  
2025-12-21 17:21:35.833565: Epoch 447 
2025-12-21 17:21:35.849505: Current learning rate: 0.00587 
2025-12-21 17:23:53.792251: train_loss -0.8453 
2025-12-21 17:23:53.794253: val_loss -0.8707 
2025-12-21 17:23:53.795254: Pseudo dice [0.9264, 0.9517, 0.94] 
2025-12-21 17:23:53.795254: Epoch time: 137.96 s 
2025-12-21 17:23:54.537977:  
2025-12-21 17:23:54.537977: Epoch 448 
2025-12-21 17:23:54.537977: Current learning rate: 0.00586 
2025-12-21 17:26:12.478262: train_loss -0.8378 
2025-12-21 17:26:12.478262: val_loss -0.8525 
2025-12-21 17:26:12.478262: Pseudo dice [0.9191, 0.947, 0.9271] 
2025-12-21 17:26:12.478262: Epoch time: 137.94 s 
2025-12-21 17:26:13.096400:  
2025-12-21 17:26:13.096400: Epoch 449 
2025-12-21 17:26:13.096400: Current learning rate: 0.00585 
2025-12-21 17:28:30.962226: train_loss -0.8403 
2025-12-21 17:28:30.962226: val_loss -0.8671 
2025-12-21 17:28:30.977965: Pseudo dice [0.9262, 0.9553, 0.9314] 
2025-12-21 17:28:30.979968: Epoch time: 137.87 s 
2025-12-21 17:28:31.832421:  
2025-12-21 17:28:31.832421: Epoch 450 
2025-12-21 17:28:31.848136: Current learning rate: 0.00584 
2025-12-21 17:30:49.759735: train_loss -0.8417 
2025-12-21 17:30:49.759735: val_loss -0.8623 
2025-12-21 17:30:49.765742: Pseudo dice [0.9224, 0.9539, 0.9284] 
2025-12-21 17:30:49.771748: Epoch time: 137.93 s 
2025-12-21 17:30:50.422149:  
2025-12-21 17:30:50.422149: Epoch 451 
2025-12-21 17:30:50.422149: Current learning rate: 0.00583 
2025-12-21 17:33:08.583190: train_loss -0.8433 
2025-12-21 17:33:08.585193: val_loss -0.8563 
2025-12-21 17:33:08.585193: Pseudo dice [0.9141, 0.9481, 0.9341] 
2025-12-21 17:33:08.585193: Epoch time: 138.16 s 
2025-12-21 17:33:09.434560:  
2025-12-21 17:33:09.436563: Epoch 452 
2025-12-21 17:33:09.436563: Current learning rate: 0.00582 
2025-12-21 17:35:27.472801: train_loss -0.8404 
2025-12-21 17:35:27.474803: val_loss -0.8528 
2025-12-21 17:35:27.478545: Pseudo dice [0.9117, 0.9435, 0.9412] 
2025-12-21 17:35:27.480547: Epoch time: 138.04 s 
2025-12-21 17:35:28.128006:  
2025-12-21 17:35:28.128006: Epoch 453 
2025-12-21 17:35:28.143899: Current learning rate: 0.00581 
2025-12-21 17:37:45.925364: train_loss -0.8435 
2025-12-21 17:37:45.941359: val_loss -0.8672 
2025-12-21 17:37:45.941359: Pseudo dice [0.9226, 0.9527, 0.9397] 
2025-12-21 17:37:45.941359: Epoch time: 137.8 s 
2025-12-21 17:37:46.558682:  
2025-12-21 17:37:46.558682: Epoch 454 
2025-12-21 17:37:46.558682: Current learning rate: 0.0058 
2025-12-21 17:40:04.556309: train_loss -0.8471 
2025-12-21 17:40:04.556309: val_loss -0.8657 
2025-12-21 17:40:04.572120: Pseudo dice [0.9245, 0.9543, 0.937] 
2025-12-21 17:40:04.574122: Epoch time: 138.0 s 
2025-12-21 17:40:05.187382:  
2025-12-21 17:40:05.187382: Epoch 455 
2025-12-21 17:40:05.187382: Current learning rate: 0.00579 
2025-12-21 17:42:23.168500: train_loss -0.8476 
2025-12-21 17:42:23.168500: val_loss -0.8752 
2025-12-21 17:42:23.168500: Pseudo dice [0.928, 0.9562, 0.9406] 
2025-12-21 17:42:23.184234: Epoch time: 137.98 s 
2025-12-21 17:42:23.788372:  
2025-12-21 17:42:23.804317: Epoch 456 
2025-12-21 17:42:23.804317: Current learning rate: 0.00578 
2025-12-21 17:44:41.810499: train_loss -0.8406 
2025-12-21 17:44:41.821528: val_loss -0.8657 
2025-12-21 17:44:41.824477: Pseudo dice [0.9282, 0.9523, 0.9331] 
2025-12-21 17:44:41.824477: Epoch time: 138.02 s 
2025-12-21 17:44:42.444052:  
2025-12-21 17:44:42.444052: Epoch 457 
2025-12-21 17:44:42.444052: Current learning rate: 0.00577 
2025-12-21 17:47:00.380553: train_loss -0.8453 
2025-12-21 17:47:00.382556: val_loss -0.8758 
2025-12-21 17:47:00.384559: Pseudo dice [0.9272, 0.955, 0.9455] 
2025-12-21 17:47:00.384559: Epoch time: 137.94 s 
2025-12-21 17:47:01.012000:  
2025-12-21 17:47:01.012000: Epoch 458 
2025-12-21 17:47:01.012000: Current learning rate: 0.00576 
2025-12-21 17:49:19.010282: train_loss -0.8468 
2025-12-21 17:49:19.010282: val_loss -0.8683 
2025-12-21 17:49:19.026108: Pseudo dice [0.9233, 0.9536, 0.9394] 
2025-12-21 17:49:19.026108: Epoch time: 138.0 s 
2025-12-21 17:49:19.866271:  
2025-12-21 17:49:19.866271: Epoch 459 
2025-12-21 17:49:19.882055: Current learning rate: 0.00575 
2025-12-21 17:51:37.808821: train_loss -0.8479 
2025-12-21 17:51:37.810824: val_loss -0.8547 
2025-12-21 17:51:37.814828: Pseudo dice [0.9183, 0.9517, 0.9329] 
2025-12-21 17:51:37.820837: Epoch time: 137.94 s 
2025-12-21 17:51:38.444862:  
2025-12-21 17:51:38.444862: Epoch 460 
2025-12-21 17:51:38.444862: Current learning rate: 0.00574 
2025-12-21 17:53:56.344759: train_loss -0.8461 
2025-12-21 17:53:56.344759: val_loss -0.8653 
2025-12-21 17:53:56.344759: Pseudo dice [0.9242, 0.9502, 0.9368] 
2025-12-21 17:53:56.360559: Epoch time: 137.9 s 
2025-12-21 17:53:56.964010:  
2025-12-21 17:53:56.964010: Epoch 461 
2025-12-21 17:53:56.964010: Current learning rate: 0.00573 
2025-12-21 17:56:14.976835: train_loss -0.841 
2025-12-21 17:56:14.976835: val_loss -0.8643 
2025-12-21 17:56:14.982842: Pseudo dice [0.9289, 0.9535, 0.9204] 
2025-12-21 17:56:14.986847: Epoch time: 138.01 s 
2025-12-21 17:56:15.754397:  
2025-12-21 17:56:15.754397: Epoch 462 
2025-12-21 17:56:15.756399: Current learning rate: 0.00572 
2025-12-21 17:58:33.713530: train_loss -0.8399 
2025-12-21 17:58:33.713530: val_loss -0.8635 
2025-12-21 17:58:33.713530: Pseudo dice [0.9237, 0.9569, 0.9366] 
2025-12-21 17:58:33.713530: Epoch time: 137.96 s 
2025-12-21 17:58:34.348802:  
2025-12-21 17:58:34.348802: Epoch 463 
2025-12-21 17:58:34.358692: Current learning rate: 0.00571 
2025-12-21 18:00:52.187365: train_loss -0.8371 
2025-12-21 18:00:52.187365: val_loss -0.8491 
2025-12-21 18:00:52.194997: Pseudo dice [0.915, 0.9452, 0.9324] 
2025-12-21 18:00:52.194997: Epoch time: 137.84 s 
2025-12-21 18:00:52.823951:  
2025-12-21 18:00:52.823951: Epoch 464 
2025-12-21 18:00:52.823951: Current learning rate: 0.0057 
2025-12-21 18:03:10.608262: train_loss -0.8436 
2025-12-21 18:03:10.608262: val_loss -0.8665 
2025-12-21 18:03:10.610264: Pseudo dice [0.9228, 0.9499, 0.9402] 
2025-12-21 18:03:10.616846: Epoch time: 137.78 s 
2025-12-21 18:03:11.565795:  
2025-12-21 18:03:11.567700: Epoch 465 
2025-12-21 18:03:11.567700: Current learning rate: 0.0057 
2025-12-21 18:05:29.466781: train_loss -0.8452 
2025-12-21 18:05:29.466781: val_loss -0.8581 
2025-12-21 18:05:29.470524: Pseudo dice [0.9197, 0.9464, 0.9341] 
2025-12-21 18:05:29.475809: Epoch time: 137.9 s 
2025-12-21 18:05:30.090944:  
2025-12-21 18:05:30.090944: Epoch 466 
2025-12-21 18:05:30.104807: Current learning rate: 0.00569 
2025-12-21 18:07:48.043084: train_loss -0.8432 
2025-12-21 18:07:48.043084: val_loss -0.8717 
2025-12-21 18:07:48.054040: Pseudo dice [0.9256, 0.9495, 0.9431] 
2025-12-21 18:07:48.058948: Epoch time: 137.95 s 
2025-12-21 18:07:48.680265:  
2025-12-21 18:07:48.680265: Epoch 467 
2025-12-21 18:07:48.680265: Current learning rate: 0.00568 
2025-12-21 18:10:06.892935: train_loss -0.8404 
2025-12-21 18:10:06.892935: val_loss -0.8716 
2025-12-21 18:10:06.898181: Pseudo dice [0.9301, 0.9601, 0.929] 
2025-12-21 18:10:06.898181: Epoch time: 138.21 s 
2025-12-21 18:10:07.590682:  
2025-12-21 18:10:07.590682: Epoch 468 
2025-12-21 18:10:07.600730: Current learning rate: 0.00567 
2025-12-21 18:12:25.491661: train_loss -0.839 
2025-12-21 18:12:25.491661: val_loss -0.8471 
2025-12-21 18:12:25.509406: Pseudo dice [0.9161, 0.9457, 0.9322] 
2025-12-21 18:12:25.511408: Epoch time: 137.9 s 
2025-12-21 18:12:26.140476:  
2025-12-21 18:12:26.140476: Epoch 469 
2025-12-21 18:12:26.140476: Current learning rate: 0.00566 
2025-12-21 18:14:43.996490: train_loss -0.8461 
2025-12-21 18:14:44.003994: val_loss -0.8597 
2025-12-21 18:14:44.005996: Pseudo dice [0.9178, 0.9497, 0.9394] 
2025-12-21 18:14:44.005996: Epoch time: 137.86 s 
2025-12-21 18:14:44.644870:  
2025-12-21 18:14:44.644870: Epoch 470 
2025-12-21 18:14:44.654569: Current learning rate: 0.00565 
2025-12-21 18:17:02.446092: train_loss -0.8451 
2025-12-21 18:17:02.446092: val_loss -0.8706 
2025-12-21 18:17:02.446092: Pseudo dice [0.9262, 0.9562, 0.9353] 
2025-12-21 18:17:02.459973: Epoch time: 137.8 s 
2025-12-21 18:17:03.063231:  
2025-12-21 18:17:03.063231: Epoch 471 
2025-12-21 18:17:03.078947: Current learning rate: 0.00564 
2025-12-21 18:19:21.028422: train_loss -0.8372 
2025-12-21 18:19:21.028422: val_loss -0.8599 
2025-12-21 18:19:21.030424: Pseudo dice [0.9179, 0.9492, 0.9386] 
2025-12-21 18:19:21.030424: Epoch time: 137.97 s 
2025-12-21 18:19:21.838402:  
2025-12-21 18:19:21.838402: Epoch 472 
2025-12-21 18:19:21.838402: Current learning rate: 0.00563 
2025-12-21 18:21:39.714804: train_loss -0.846 
2025-12-21 18:21:39.714804: val_loss -0.8783 
2025-12-21 18:21:39.730665: Pseudo dice [0.9315, 0.9561, 0.9421] 
2025-12-21 18:21:39.730665: Epoch time: 137.88 s 
2025-12-21 18:21:40.349216:  
2025-12-21 18:21:40.349216: Epoch 473 
2025-12-21 18:21:40.349216: Current learning rate: 0.00562 
2025-12-21 18:23:58.550512: train_loss -0.8414 
2025-12-21 18:23:58.550512: val_loss -0.874 
2025-12-21 18:23:58.556395: Pseudo dice [0.9281, 0.9598, 0.9409] 
2025-12-21 18:23:58.561812: Epoch time: 138.2 s 
2025-12-21 18:23:59.185949:  
2025-12-21 18:23:59.185949: Epoch 474 
2025-12-21 18:23:59.185949: Current learning rate: 0.00561 
2025-12-21 18:26:17.149112: train_loss -0.8437 
2025-12-21 18:26:17.149112: val_loss -0.8793 
2025-12-21 18:26:17.149112: Pseudo dice [0.9338, 0.959, 0.9388] 
2025-12-21 18:26:17.160421: Epoch time: 137.98 s 
2025-12-21 18:26:17.783610:  
2025-12-21 18:26:17.783610: Epoch 475 
2025-12-21 18:26:17.783610: Current learning rate: 0.0056 
2025-12-21 18:28:35.535673: train_loss -0.8495 
2025-12-21 18:28:35.535673: val_loss -0.8594 
2025-12-21 18:28:35.535673: Pseudo dice [0.9186, 0.9504, 0.9353] 
2025-12-21 18:28:35.535673: Epoch time: 137.75 s 
2025-12-21 18:28:36.263492:  
2025-12-21 18:28:36.263492: Epoch 476 
2025-12-21 18:28:36.269510: Current learning rate: 0.00559 
2025-12-21 18:30:54.209459: train_loss -0.842 
2025-12-21 18:30:54.225122: val_loss -0.8586 
2025-12-21 18:30:54.225122: Pseudo dice [0.9182, 0.9482, 0.9399] 
2025-12-21 18:30:54.225122: Epoch time: 137.95 s 
2025-12-21 18:30:54.875868:  
2025-12-21 18:30:54.875868: Epoch 477 
2025-12-21 18:30:54.875868: Current learning rate: 0.00558 
2025-12-21 18:33:12.876846: train_loss -0.8435 
2025-12-21 18:33:12.876846: val_loss -0.8631 
2025-12-21 18:33:12.886588: Pseudo dice [0.9246, 0.9478, 0.9276] 
2025-12-21 18:33:12.888847: Epoch time: 138.0 s 
2025-12-21 18:33:13.672573:  
2025-12-21 18:33:13.672573: Epoch 478 
2025-12-21 18:33:13.688595: Current learning rate: 0.00557 
2025-12-21 18:35:31.652564: train_loss -0.8452 
2025-12-21 18:35:31.652564: val_loss -0.8663 
2025-12-21 18:35:31.654305: Pseudo dice [0.9222, 0.9512, 0.9396] 
2025-12-21 18:35:31.654305: Epoch time: 137.98 s 
2025-12-21 18:35:32.420847:  
2025-12-21 18:35:32.420847: Epoch 479 
2025-12-21 18:35:32.420847: Current learning rate: 0.00556 
2025-12-21 18:37:50.327494: train_loss -0.8485 
2025-12-21 18:37:50.327494: val_loss -0.8632 
2025-12-21 18:37:50.327494: Pseudo dice [0.9208, 0.9513, 0.9311] 
2025-12-21 18:37:50.327494: Epoch time: 137.92 s 
2025-12-21 18:37:50.960160:  
2025-12-21 18:37:50.960160: Epoch 480 
2025-12-21 18:37:50.960160: Current learning rate: 0.00555 
2025-12-21 18:40:08.899325: train_loss -0.8449 
2025-12-21 18:40:08.899325: val_loss -0.8621 
2025-12-21 18:40:08.910656: Pseudo dice [0.9194, 0.9477, 0.9425] 
2025-12-21 18:40:08.912745: Epoch time: 137.94 s 
2025-12-21 18:40:09.532169:  
2025-12-21 18:40:09.532169: Epoch 481 
2025-12-21 18:40:09.548145: Current learning rate: 0.00554 
2025-12-21 18:42:27.587736: train_loss -0.8486 
2025-12-21 18:42:27.587736: val_loss -0.8612 
2025-12-21 18:42:27.587736: Pseudo dice [0.9219, 0.9475, 0.9411] 
2025-12-21 18:42:27.587736: Epoch time: 138.06 s 
2025-12-21 18:42:28.326010:  
2025-12-21 18:42:28.326010: Epoch 482 
2025-12-21 18:42:28.341783: Current learning rate: 0.00553 
2025-12-21 18:44:46.310994: train_loss -0.8498 
2025-12-21 18:44:46.310994: val_loss -0.862 
2025-12-21 18:44:46.310994: Pseudo dice [0.9218, 0.9518, 0.9377] 
2025-12-21 18:44:46.326885: Epoch time: 137.98 s 
2025-12-21 18:44:46.945850:  
2025-12-21 18:44:46.945850: Epoch 483 
2025-12-21 18:44:46.961544: Current learning rate: 0.00552 
2025-12-21 18:47:04.999736: train_loss -0.8495 
2025-12-21 18:47:04.999736: val_loss -0.8847 
2025-12-21 18:47:05.004126: Pseudo dice [0.9319, 0.9637, 0.9446] 
2025-12-21 18:47:05.008130: Epoch time: 138.05 s 
2025-12-21 18:47:05.629202:  
2025-12-21 18:47:05.629202: Epoch 484 
2025-12-21 18:47:05.629202: Current learning rate: 0.00551 
2025-12-21 18:49:23.605129: train_loss -0.8468 
2025-12-21 18:49:23.605129: val_loss -0.863 
2025-12-21 18:49:23.609133: Pseudo dice [0.9229, 0.9507, 0.9413] 
2025-12-21 18:49:23.611136: Epoch time: 137.98 s 
2025-12-21 18:49:24.422494:  
2025-12-21 18:49:24.422494: Epoch 485 
2025-12-21 18:49:24.435110: Current learning rate: 0.0055 
2025-12-21 18:51:42.195941: train_loss -0.8431 
2025-12-21 18:51:42.195941: val_loss -0.8724 
2025-12-21 18:51:42.201685: Pseudo dice [0.9266, 0.955, 0.9402] 
2025-12-21 18:51:42.205691: Epoch time: 137.77 s 
2025-12-21 18:51:42.834655:  
2025-12-21 18:51:42.834655: Epoch 486 
2025-12-21 18:51:42.834655: Current learning rate: 0.00549 
2025-12-21 18:54:00.810832: train_loss -0.8498 
2025-12-21 18:54:00.810832: val_loss -0.8535 
2025-12-21 18:54:00.823138: Pseudo dice [0.9172, 0.9488, 0.9319] 
2025-12-21 18:54:00.827024: Epoch time: 137.98 s 
2025-12-21 18:54:01.440313:  
2025-12-21 18:54:01.440313: Epoch 487 
2025-12-21 18:54:01.459121: Current learning rate: 0.00548 
2025-12-21 18:56:19.259943: train_loss -0.8431 
2025-12-21 18:56:19.259943: val_loss -0.8677 
2025-12-21 18:56:19.265744: Pseudo dice [0.924, 0.9543, 0.9367] 
2025-12-21 18:56:19.269720: Epoch time: 137.82 s 
2025-12-21 18:56:19.901832:  
2025-12-21 18:56:19.901832: Epoch 488 
2025-12-21 18:56:19.910823: Current learning rate: 0.00547 
2025-12-21 18:58:38.055633: train_loss -0.8452 
2025-12-21 18:58:38.057636: val_loss -0.8777 
2025-12-21 18:58:38.061378: Pseudo dice [0.932, 0.9557, 0.9379] 
2025-12-21 18:58:38.064177: Epoch time: 138.15 s 
2025-12-21 18:58:38.696863:  
2025-12-21 18:58:38.696863: Epoch 489 
2025-12-21 18:58:38.703851: Current learning rate: 0.00546 
2025-12-21 19:00:56.706471: train_loss -0.8454 
2025-12-21 19:00:56.706471: val_loss -0.8601 
2025-12-21 19:00:56.708473: Pseudo dice [0.9202, 0.9482, 0.9313] 
2025-12-21 19:00:56.708473: Epoch time: 138.01 s 
2025-12-21 19:00:57.352653:  
2025-12-21 19:00:57.352653: Epoch 490 
2025-12-21 19:00:57.360843: Current learning rate: 0.00546 
2025-12-21 19:03:15.116842: train_loss -0.8459 
2025-12-21 19:03:15.116842: val_loss -0.8642 
2025-12-21 19:03:15.134555: Pseudo dice [0.9199, 0.9476, 0.9438] 
2025-12-21 19:03:15.134555: Epoch time: 137.76 s 
2025-12-21 19:03:15.828331:  
2025-12-21 19:03:15.828331: Epoch 491 
2025-12-21 19:03:15.828331: Current learning rate: 0.00545 
2025-12-21 19:05:33.786060: train_loss -0.8482 
2025-12-21 19:05:33.786060: val_loss -0.8734 
2025-12-21 19:05:33.786060: Pseudo dice [0.9271, 0.9535, 0.9473] 
2025-12-21 19:05:33.801781: Epoch time: 137.96 s 
2025-12-21 19:05:34.595025:  
2025-12-21 19:05:34.595025: Epoch 492 
2025-12-21 19:05:34.611090: Current learning rate: 0.00544 
2025-12-21 19:07:52.538801: train_loss -0.8499 
2025-12-21 19:07:52.538801: val_loss -0.8775 
2025-12-21 19:07:52.538801: Pseudo dice [0.9312, 0.9586, 0.938] 
2025-12-21 19:07:52.556839: Epoch time: 137.94 s 
2025-12-21 19:07:53.239245:  
2025-12-21 19:07:53.239245: Epoch 493 
2025-12-21 19:07:53.244276: Current learning rate: 0.00543 
2025-12-21 19:10:11.697570: train_loss -0.8511 
2025-12-21 19:10:11.697570: val_loss -0.865 
2025-12-21 19:10:11.704795: Pseudo dice [0.9206, 0.9514, 0.9357] 
2025-12-21 19:10:11.704795: Epoch time: 138.46 s 
2025-12-21 19:10:12.347598:  
2025-12-21 19:10:12.347598: Epoch 494 
2025-12-21 19:10:12.350790: Current learning rate: 0.00542 
2025-12-21 19:12:30.370530: train_loss -0.8436 
2025-12-21 19:12:30.370530: val_loss -0.8633 
2025-12-21 19:12:30.389870: Pseudo dice [0.922, 0.9517, 0.9328] 
2025-12-21 19:12:30.389870: Epoch time: 138.04 s 
2025-12-21 19:12:31.035158:  
2025-12-21 19:12:31.035158: Epoch 495 
2025-12-21 19:12:31.035158: Current learning rate: 0.00541 
2025-12-21 19:14:49.187761: train_loss -0.8444 
2025-12-21 19:14:49.187761: val_loss -0.87 
2025-12-21 19:14:49.193508: Pseudo dice [0.9304, 0.9538, 0.9251] 
2025-12-21 19:14:49.201535: Epoch time: 138.15 s 
2025-12-21 19:14:49.917659:  
2025-12-21 19:14:49.917659: Epoch 496 
2025-12-21 19:14:49.924165: Current learning rate: 0.0054 
2025-12-21 19:17:07.976200: train_loss -0.8471 
2025-12-21 19:17:07.976200: val_loss -0.8651 
2025-12-21 19:17:07.980204: Pseudo dice [0.9257, 0.9518, 0.9367] 
2025-12-21 19:17:07.985246: Epoch time: 138.06 s 
2025-12-21 19:17:08.604195:  
2025-12-21 19:17:08.604195: Epoch 497 
2025-12-21 19:17:08.604195: Current learning rate: 0.00539 
2025-12-21 19:19:26.602060: train_loss -0.849 
2025-12-21 19:19:26.602060: val_loss -0.8654 
2025-12-21 19:19:26.609817: Pseudo dice [0.924, 0.9515, 0.9291] 
2025-12-21 19:19:26.613822: Epoch time: 138.0 s 
2025-12-21 19:19:27.404233:  
2025-12-21 19:19:27.404233: Epoch 498 
2025-12-21 19:19:27.420227: Current learning rate: 0.00538 
2025-12-21 19:21:45.307192: train_loss -0.8455 
2025-12-21 19:21:45.307192: val_loss -0.8694 
2025-12-21 19:21:45.317070: Pseudo dice [0.9238, 0.9541, 0.9413] 
2025-12-21 19:21:45.317070: Epoch time: 137.9 s 
2025-12-21 19:21:46.110558:  
2025-12-21 19:21:46.110558: Epoch 499 
2025-12-21 19:21:46.112980: Current learning rate: 0.00537 
2025-12-21 19:24:04.002120: train_loss -0.8484 
2025-12-21 19:24:04.002120: val_loss -0.8735 
2025-12-21 19:24:04.015824: Pseudo dice [0.9254, 0.9566, 0.9456] 
2025-12-21 19:24:04.020849: Epoch time: 137.89 s 
2025-12-21 19:24:04.902832:  
2025-12-21 19:24:04.902832: Epoch 500 
2025-12-21 19:24:04.909556: Current learning rate: 0.00536 
2025-12-21 19:26:22.917700: train_loss -0.8466 
2025-12-21 19:26:22.917700: val_loss -0.8735 
2025-12-21 19:26:22.923408: Pseudo dice [0.9301, 0.9553, 0.9382] 
2025-12-21 19:26:22.923408: Epoch time: 138.01 s 
2025-12-21 19:26:23.536784:  
2025-12-21 19:26:23.552716: Epoch 501 
2025-12-21 19:26:23.554719: Current learning rate: 0.00535 
2025-12-21 19:28:41.295825: train_loss -0.8479 
2025-12-21 19:28:41.295825: val_loss -0.8726 
2025-12-21 19:28:41.311088: Pseudo dice [0.9265, 0.9506, 0.9451] 
2025-12-21 19:28:41.313092: Epoch time: 137.76 s 
2025-12-21 19:28:42.043206:  
2025-12-21 19:28:42.045209: Epoch 502 
2025-12-21 19:28:42.049216: Current learning rate: 0.00534 
2025-12-21 19:31:00.218142: train_loss -0.846 
2025-12-21 19:31:00.220143: val_loss -0.8835 
2025-12-21 19:31:00.224147: Pseudo dice [0.934, 0.9603, 0.9432] 
2025-12-21 19:31:00.227890: Epoch time: 138.17 s 
2025-12-21 19:31:00.861997:  
2025-12-21 19:31:00.861997: Epoch 503 
2025-12-21 19:31:00.861997: Current learning rate: 0.00533 
2025-12-21 19:33:18.853796: train_loss -0.8438 
2025-12-21 19:33:18.853796: val_loss -0.8724 
2025-12-21 19:33:18.858843: Pseudo dice [0.9278, 0.9556, 0.9348] 
2025-12-21 19:33:18.858843: Epoch time: 137.99 s 
2025-12-21 19:33:19.631265:  
2025-12-21 19:33:19.631265: Epoch 504 
2025-12-21 19:33:19.647347: Current learning rate: 0.00532 
2025-12-21 19:35:37.519110: train_loss -0.8498 
2025-12-21 19:35:37.519110: val_loss -0.8694 
2025-12-21 19:35:37.525119: Pseudo dice [0.9229, 0.9504, 0.9413] 
2025-12-21 19:35:37.527122: Epoch time: 137.89 s 
2025-12-21 19:35:38.257518:  
2025-12-21 19:35:38.257518: Epoch 505 
2025-12-21 19:35:38.257518: Current learning rate: 0.00531 
2025-12-21 19:37:56.119464: train_loss -0.8421 
2025-12-21 19:37:56.119464: val_loss -0.8672 
2025-12-21 19:37:56.135250: Pseudo dice [0.9234, 0.9524, 0.9378] 
2025-12-21 19:37:56.135250: Epoch time: 137.86 s 
2025-12-21 19:37:56.769526:  
2025-12-21 19:37:56.769526: Epoch 506 
2025-12-21 19:37:56.769526: Current learning rate: 0.0053 
2025-12-21 19:40:14.735069: train_loss -0.8502 
2025-12-21 19:40:14.737071: val_loss -0.8766 
2025-12-21 19:40:14.740075: Pseudo dice [0.9311, 0.9584, 0.9402] 
2025-12-21 19:40:14.740075: Epoch time: 137.97 s 
2025-12-21 19:40:15.373381:  
2025-12-21 19:40:15.373381: Epoch 507 
2025-12-21 19:40:15.373381: Current learning rate: 0.00529 
2025-12-21 19:42:33.603330: train_loss -0.8434 
2025-12-21 19:42:33.605333: val_loss -0.8588 
2025-12-21 19:42:33.611340: Pseudo dice [0.917, 0.9478, 0.9359] 
2025-12-21 19:42:33.615344: Epoch time: 138.25 s 
2025-12-21 19:42:34.299100:  
2025-12-21 19:42:34.300842: Epoch 508 
2025-12-21 19:42:34.302845: Current learning rate: 0.00528 
2025-12-21 19:44:52.295666: train_loss -0.8482 
2025-12-21 19:44:52.297668: val_loss -0.8768 
2025-12-21 19:44:52.301677: Pseudo dice [0.9328, 0.9586, 0.9371] 
2025-12-21 19:44:52.303679: Epoch time: 138.0 s 
2025-12-21 19:44:52.981806:  
2025-12-21 19:44:52.981806: Epoch 509 
2025-12-21 19:44:52.996292: Current learning rate: 0.00527 
2025-12-21 19:47:10.812122: train_loss -0.8517 
2025-12-21 19:47:10.812122: val_loss -0.8694 
2025-12-21 19:47:10.812122: Pseudo dice [0.9256, 0.9503, 0.94] 
2025-12-21 19:47:10.812122: Epoch time: 137.83 s 
2025-12-21 19:47:11.619761:  
2025-12-21 19:47:11.619761: Epoch 510 
2025-12-21 19:47:11.635600: Current learning rate: 0.00526 
2025-12-21 19:49:29.494465: train_loss -0.8525 
2025-12-21 19:49:29.494465: val_loss -0.8735 
2025-12-21 19:49:29.510290: Pseudo dice [0.9275, 0.9559, 0.94] 
2025-12-21 19:49:29.514294: Epoch time: 137.87 s 
2025-12-21 19:49:30.190650:  
2025-12-21 19:49:30.190650: Epoch 511 
2025-12-21 19:49:30.204733: Current learning rate: 0.00525 
2025-12-21 19:51:48.345147: train_loss -0.846 
2025-12-21 19:51:48.345147: val_loss -0.8727 
2025-12-21 19:51:48.345147: Pseudo dice [0.9265, 0.9552, 0.9432] 
2025-12-21 19:51:48.345147: Epoch time: 138.15 s 
2025-12-21 19:51:49.009405:  
2025-12-21 19:51:49.009405: Epoch 512 
2025-12-21 19:51:49.009405: Current learning rate: 0.00524 
2025-12-21 19:54:06.880843: train_loss -0.8502 
2025-12-21 19:54:06.880843: val_loss -0.8637 
2025-12-21 19:54:06.886196: Pseudo dice [0.9245, 0.9504, 0.9316] 
2025-12-21 19:54:06.890882: Epoch time: 137.87 s 
2025-12-21 19:54:07.522665:  
2025-12-21 19:54:07.522665: Epoch 513 
2025-12-21 19:54:07.538751: Current learning rate: 0.00523 
2025-12-21 19:56:25.397543: train_loss -0.8504 
2025-12-21 19:56:25.397543: val_loss -0.8718 
2025-12-21 19:56:25.399546: Pseudo dice [0.9275, 0.9559, 0.9395] 
2025-12-21 19:56:25.405559: Epoch time: 137.87 s 
2025-12-21 19:56:26.036894:  
2025-12-21 19:56:26.036894: Epoch 514 
2025-12-21 19:56:26.036894: Current learning rate: 0.00522 
2025-12-21 19:58:43.943009: train_loss -0.8467 
2025-12-21 19:58:43.943009: val_loss -0.8564 
2025-12-21 19:58:43.943009: Pseudo dice [0.9173, 0.9468, 0.9447] 
2025-12-21 19:58:43.954525: Epoch time: 137.91 s 
2025-12-21 19:58:44.596233:  
2025-12-21 19:58:44.596233: Epoch 515 
2025-12-21 19:58:44.596233: Current learning rate: 0.00521 
2025-12-21 20:01:02.710811: train_loss -0.8478 
2025-12-21 20:01:02.712814: val_loss -0.8768 
2025-12-21 20:01:02.716820: Pseudo dice [0.9286, 0.9555, 0.9392] 
2025-12-21 20:01:02.720564: Epoch time: 138.11 s 
2025-12-21 20:01:03.547452:  
2025-12-21 20:01:03.547452: Epoch 516 
2025-12-21 20:01:03.561425: Current learning rate: 0.0052 
2025-12-21 20:03:21.340612: train_loss -0.8441 
2025-12-21 20:03:21.340612: val_loss -0.865 
2025-12-21 20:03:21.347842: Pseudo dice [0.919, 0.9513, 0.9386] 
2025-12-21 20:03:21.351069: Epoch time: 137.79 s 
2025-12-21 20:03:21.979260:  
2025-12-21 20:03:21.979260: Epoch 517 
2025-12-21 20:03:21.979260: Current learning rate: 0.00519 
2025-12-21 20:05:39.965264: train_loss -0.8484 
2025-12-21 20:05:39.965264: val_loss -0.8743 
2025-12-21 20:05:39.983076: Pseudo dice [0.9279, 0.9574, 0.9434] 
2025-12-21 20:05:39.983076: Epoch time: 137.99 s 
2025-12-21 20:05:40.616415:  
2025-12-21 20:05:40.616415: Epoch 518 
2025-12-21 20:05:40.616415: Current learning rate: 0.00518 
2025-12-21 20:07:58.566864: train_loss -0.8485 
2025-12-21 20:07:58.568866: val_loss -0.8678 
2025-12-21 20:07:58.569869: Pseudo dice [0.9231, 0.9538, 0.9379] 
2025-12-21 20:07:58.569869: Epoch time: 137.95 s 
2025-12-21 20:07:59.360729:  
2025-12-21 20:07:59.360729: Epoch 519 
2025-12-21 20:07:59.360729: Current learning rate: 0.00518 
2025-12-21 20:10:17.668943: train_loss -0.8553 
2025-12-21 20:10:17.668943: val_loss -0.8561 
2025-12-21 20:10:17.687065: Pseudo dice [0.9164, 0.946, 0.9357] 
2025-12-21 20:10:17.691069: Epoch time: 138.32 s 
2025-12-21 20:10:18.335953:  
2025-12-21 20:10:18.335953: Epoch 520 
2025-12-21 20:10:18.335953: Current learning rate: 0.00517 
2025-12-21 20:12:36.415351: train_loss -0.8524 
2025-12-21 20:12:36.417354: val_loss -0.8563 
2025-12-21 20:12:36.421097: Pseudo dice [0.9161, 0.9459, 0.9401] 
2025-12-21 20:12:36.421097: Epoch time: 138.08 s 
2025-12-21 20:12:37.055733:  
2025-12-21 20:12:37.055733: Epoch 521 
2025-12-21 20:12:37.066449: Current learning rate: 0.00516 
2025-12-21 20:14:55.070854: train_loss -0.8495 
2025-12-21 20:14:55.070854: val_loss -0.8703 
2025-12-21 20:14:55.070854: Pseudo dice [0.9258, 0.9512, 0.9416] 
2025-12-21 20:14:55.080219: Epoch time: 138.02 s 
2025-12-21 20:14:55.870238:  
2025-12-21 20:14:55.872241: Epoch 522 
2025-12-21 20:14:55.874243: Current learning rate: 0.00515 
2025-12-21 20:17:13.928667: train_loss -0.8453 
2025-12-21 20:17:13.930670: val_loss -0.8602 
2025-12-21 20:17:13.936678: Pseudo dice [0.9201, 0.9515, 0.9345] 
2025-12-21 20:17:13.940611: Epoch time: 138.06 s 
2025-12-21 20:17:14.753087:  
2025-12-21 20:17:14.753087: Epoch 523 
2025-12-21 20:17:14.753087: Current learning rate: 0.00514 
2025-12-21 20:19:32.521169: train_loss -0.8497 
2025-12-21 20:19:32.521169: val_loss -0.8627 
2025-12-21 20:19:32.525173: Pseudo dice [0.9189, 0.9528, 0.9353] 
2025-12-21 20:19:32.525173: Epoch time: 137.77 s 
2025-12-21 20:19:33.154100:  
2025-12-21 20:19:33.154100: Epoch 524 
2025-12-21 20:19:33.154100: Current learning rate: 0.00513 
2025-12-21 20:21:51.099535: train_loss -0.8443 
2025-12-21 20:21:51.099535: val_loss -0.8687 
2025-12-21 20:21:51.103539: Pseudo dice [0.9296, 0.9519, 0.9356] 
2025-12-21 20:21:51.107281: Epoch time: 137.95 s 
2025-12-21 20:21:51.831023:  
2025-12-21 20:21:51.831023: Epoch 525 
2025-12-21 20:21:51.833536: Current learning rate: 0.00512 
2025-12-21 20:24:09.958301: train_loss -0.8489 
2025-12-21 20:24:09.958301: val_loss -0.8707 
2025-12-21 20:24:09.958301: Pseudo dice [0.9253, 0.9578, 0.9379] 
2025-12-21 20:24:09.958301: Epoch time: 138.13 s 
2025-12-21 20:24:10.621032:  
2025-12-21 20:24:10.623034: Epoch 526 
2025-12-21 20:24:10.623034: Current learning rate: 0.00511 
2025-12-21 20:26:28.577146: train_loss -0.8463 
2025-12-21 20:26:28.578887: val_loss -0.8637 
2025-12-21 20:26:28.578887: Pseudo dice [0.9237, 0.9513, 0.9353] 
2025-12-21 20:26:28.588529: Epoch time: 137.96 s 
2025-12-21 20:26:29.228552:  
2025-12-21 20:26:29.228552: Epoch 527 
2025-12-21 20:26:29.228552: Current learning rate: 0.0051 
2025-12-21 20:28:47.328184: train_loss -0.8443 
2025-12-21 20:28:47.329925: val_loss -0.8595 
2025-12-21 20:28:47.335931: Pseudo dice [0.9175, 0.9485, 0.94] 
2025-12-21 20:28:47.339935: Epoch time: 138.1 s 
2025-12-21 20:28:48.071698:  
2025-12-21 20:28:48.071698: Epoch 528 
2025-12-21 20:28:48.073442: Current learning rate: 0.00509 
2025-12-21 20:31:06.185351: train_loss -0.8427 
2025-12-21 20:31:06.185351: val_loss -0.8609 
2025-12-21 20:31:06.197235: Pseudo dice [0.926, 0.9486, 0.9338] 
2025-12-21 20:31:06.203242: Epoch time: 138.12 s 
2025-12-21 20:31:06.996201:  
2025-12-21 20:31:06.996201: Epoch 529 
2025-12-21 20:31:07.012291: Current learning rate: 0.00508 
2025-12-21 20:33:25.014418: train_loss -0.8425 
2025-12-21 20:33:25.014418: val_loss -0.8707 
2025-12-21 20:33:25.019429: Pseudo dice [0.9266, 0.9538, 0.9375] 
2025-12-21 20:33:25.024133: Epoch time: 138.02 s 
2025-12-21 20:33:25.654975:  
2025-12-21 20:33:25.654975: Epoch 530 
2025-12-21 20:33:25.672845: Current learning rate: 0.00507 
2025-12-21 20:35:43.571288: train_loss -0.8514 
2025-12-21 20:35:43.571288: val_loss -0.8587 
2025-12-21 20:35:43.571288: Pseudo dice [0.9186, 0.9521, 0.9284] 
2025-12-21 20:35:43.581763: Epoch time: 137.92 s 
2025-12-21 20:35:44.204473:  
2025-12-21 20:35:44.204473: Epoch 531 
2025-12-21 20:35:44.215289: Current learning rate: 0.00506 
2025-12-21 20:38:02.089998: train_loss -0.8471 
2025-12-21 20:38:02.089998: val_loss -0.8652 
2025-12-21 20:38:02.105917: Pseudo dice [0.9223, 0.9519, 0.9426] 
2025-12-21 20:38:02.105917: Epoch time: 137.89 s 
2025-12-21 20:38:02.739623:  
2025-12-21 20:38:02.739623: Epoch 532 
2025-12-21 20:38:02.750457: Current learning rate: 0.00505 
2025-12-21 20:40:20.589997: train_loss -0.8483 
2025-12-21 20:40:20.592000: val_loss -0.875 
2025-12-21 20:40:20.596005: Pseudo dice [0.9317, 0.9589, 0.9352] 
2025-12-21 20:40:20.600835: Epoch time: 137.85 s 
2025-12-21 20:40:21.215432:  
2025-12-21 20:40:21.215432: Epoch 533 
2025-12-21 20:40:21.231215: Current learning rate: 0.00504 
2025-12-21 20:42:39.002256: train_loss -0.845 
2025-12-21 20:42:39.002256: val_loss -0.8755 
2025-12-21 20:42:39.008084: Pseudo dice [0.929, 0.9578, 0.9419] 
2025-12-21 20:42:39.008084: Epoch time: 137.79 s 
2025-12-21 20:42:39.643233:  
2025-12-21 20:42:39.643233: Epoch 534 
2025-12-21 20:42:39.643233: Current learning rate: 0.00503 
2025-12-21 20:44:57.641513: train_loss -0.8427 
2025-12-21 20:44:57.641513: val_loss -0.8709 
2025-12-21 20:44:57.657324: Pseudo dice [0.9242, 0.9517, 0.9427] 
2025-12-21 20:44:57.657324: Epoch time: 138.0 s 
2025-12-21 20:44:58.448621:  
2025-12-21 20:44:58.448621: Epoch 535 
2025-12-21 20:44:58.464263: Current learning rate: 0.00502 
2025-12-21 20:47:16.296263: train_loss -0.85 
2025-12-21 20:47:16.296263: val_loss -0.8666 
2025-12-21 20:47:16.302270: Pseudo dice [0.9237, 0.9526, 0.9403] 
2025-12-21 20:47:16.306274: Epoch time: 137.85 s 
2025-12-21 20:47:17.055880:  
2025-12-21 20:47:17.055880: Epoch 536 
2025-12-21 20:47:17.055880: Current learning rate: 0.00501 
2025-12-21 20:49:34.822687: train_loss -0.8505 
2025-12-21 20:49:34.822687: val_loss -0.8738 
2025-12-21 20:49:34.838762: Pseudo dice [0.9289, 0.9591, 0.9356] 
2025-12-21 20:49:34.838762: Epoch time: 137.77 s 
2025-12-21 20:49:35.459290:  
2025-12-21 20:49:35.459290: Epoch 537 
2025-12-21 20:49:35.475387: Current learning rate: 0.005 
2025-12-21 20:51:53.609541: train_loss -0.8465 
2025-12-21 20:51:53.609541: val_loss -0.8735 
2025-12-21 20:51:53.613990: Pseudo dice [0.9258, 0.9563, 0.9349] 
2025-12-21 20:51:53.613990: Epoch time: 138.15 s 
2025-12-21 20:51:54.228967:  
2025-12-21 20:51:54.228967: Epoch 538 
2025-12-21 20:51:54.244939: Current learning rate: 0.00499 
2025-12-21 20:54:12.193887: train_loss -0.8419 
2025-12-21 20:54:12.193887: val_loss -0.8621 
2025-12-21 20:54:12.209624: Pseudo dice [0.9208, 0.9518, 0.9367] 
2025-12-21 20:54:12.213630: Epoch time: 137.96 s 
2025-12-21 20:54:12.984100:  
2025-12-21 20:54:12.984100: Epoch 539 
2025-12-21 20:54:12.984100: Current learning rate: 0.00498 
2025-12-21 20:56:30.760816: train_loss -0.8532 
2025-12-21 20:56:30.760816: val_loss -0.8582 
2025-12-21 20:56:30.770108: Pseudo dice [0.9159, 0.9487, 0.9354] 
2025-12-21 20:56:30.770108: Epoch time: 137.79 s 
2025-12-21 20:56:31.413767:  
2025-12-21 20:56:31.413767: Epoch 540 
2025-12-21 20:56:31.413767: Current learning rate: 0.00497 
2025-12-21 20:58:49.345990: train_loss -0.8497 
2025-12-21 20:58:49.361954: val_loss -0.8704 
2025-12-21 20:58:49.365960: Pseudo dice [0.9249, 0.9521, 0.938] 
2025-12-21 20:58:49.369964: Epoch time: 137.93 s 
2025-12-21 20:58:50.168633:  
2025-12-21 20:58:50.168633: Epoch 541 
2025-12-21 20:58:50.168633: Current learning rate: 0.00496 
2025-12-21 21:01:08.193594: train_loss -0.8518 
2025-12-21 21:01:08.193594: val_loss -0.8569 
2025-12-21 21:01:08.199010: Pseudo dice [0.9174, 0.9462, 0.9314] 
2025-12-21 21:01:08.203016: Epoch time: 138.02 s 
2025-12-21 21:01:08.942215:  
2025-12-21 21:01:08.942215: Epoch 542 
2025-12-21 21:01:08.944681: Current learning rate: 0.00495 
2025-12-21 21:03:26.951297: train_loss -0.8518 
2025-12-21 21:03:26.951297: val_loss -0.8749 
2025-12-21 21:03:26.957869: Pseudo dice [0.9255, 0.9525, 0.9481] 
2025-12-21 21:03:26.960975: Epoch time: 138.01 s 
2025-12-21 21:03:27.584915:  
2025-12-21 21:03:27.584915: Epoch 543 
2025-12-21 21:03:27.602921: Current learning rate: 0.00494 
2025-12-21 21:05:45.414918: train_loss -0.8482 
2025-12-21 21:05:45.414918: val_loss -0.8639 
2025-12-21 21:05:45.430914: Pseudo dice [0.9251, 0.9507, 0.9323] 
2025-12-21 21:05:45.434472: Epoch time: 137.83 s 
2025-12-21 21:05:46.049823:  
2025-12-21 21:05:46.049823: Epoch 544 
2025-12-21 21:05:46.062364: Current learning rate: 0.00493 
2025-12-21 21:08:03.959628: train_loss -0.8537 
2025-12-21 21:08:03.959628: val_loss -0.8534 
2025-12-21 21:08:03.965636: Pseudo dice [0.9144, 0.9454, 0.9392] 
2025-12-21 21:08:03.971643: Epoch time: 137.91 s 
2025-12-21 21:08:04.606823:  
2025-12-21 21:08:04.606823: Epoch 545 
2025-12-21 21:08:04.622922: Current learning rate: 0.00492 
2025-12-21 21:10:22.879071: train_loss -0.8488 
2025-12-21 21:10:22.879071: val_loss -0.8752 
2025-12-21 21:10:22.879071: Pseudo dice [0.9274, 0.9576, 0.9384] 
2025-12-21 21:10:22.895110: Epoch time: 138.27 s 
2025-12-21 21:10:23.531291:  
2025-12-21 21:10:23.531291: Epoch 546 
2025-12-21 21:10:23.542674: Current learning rate: 0.00491 
2025-12-21 21:12:41.634819: train_loss -0.8493 
2025-12-21 21:12:41.634819: val_loss -0.8674 
2025-12-21 21:12:41.634819: Pseudo dice [0.9227, 0.9521, 0.9447] 
2025-12-21 21:12:41.650808: Epoch time: 138.1 s 
2025-12-21 21:12:42.446126:  
2025-12-21 21:12:42.446126: Epoch 547 
2025-12-21 21:12:42.449361: Current learning rate: 0.0049 
2025-12-21 21:15:00.524512: train_loss -0.8487 
2025-12-21 21:15:00.526252: val_loss -0.8811 
2025-12-21 21:15:00.526252: Pseudo dice [0.9305, 0.9646, 0.9401] 
2025-12-21 21:15:00.535000: Epoch time: 138.08 s 
2025-12-21 21:15:01.207430:  
2025-12-21 21:15:01.207430: Epoch 548 
2025-12-21 21:15:01.220481: Current learning rate: 0.00489 
2025-12-21 21:17:19.264665: train_loss -0.8473 
2025-12-21 21:17:19.264665: val_loss -0.8768 
2025-12-21 21:17:19.280351: Pseudo dice [0.9297, 0.9565, 0.9392] 
2025-12-21 21:17:19.283939: Epoch time: 138.06 s 
2025-12-21 21:17:19.915437:  
2025-12-21 21:17:19.915437: Epoch 549 
2025-12-21 21:17:19.920557: Current learning rate: 0.00488 
2025-12-21 21:19:37.814982: train_loss -0.8467 
2025-12-21 21:19:37.814982: val_loss -0.8714 
2025-12-21 21:19:37.820730: Pseudo dice [0.9299, 0.9532, 0.939] 
2025-12-21 21:19:37.824735: Epoch time: 137.9 s 
2025-12-21 21:19:38.710516:  
2025-12-21 21:19:38.710516: Epoch 550 
2025-12-21 21:19:38.714953: Current learning rate: 0.00487 
2025-12-21 21:21:56.588192: train_loss -0.8497 
2025-12-21 21:21:56.590197: val_loss -0.8493 
2025-12-21 21:21:56.600223: Pseudo dice [0.9093, 0.94, 0.9414] 
2025-12-21 21:21:56.603967: Epoch time: 137.88 s 
2025-12-21 21:21:57.236357:  
2025-12-21 21:21:57.236357: Epoch 551 
2025-12-21 21:21:57.236357: Current learning rate: 0.00486 
2025-12-21 21:24:16.715372: train_loss -0.851 
2025-12-21 21:24:16.715372: val_loss -0.8882 
2025-12-21 21:24:16.715372: Pseudo dice [0.9383, 0.9629, 0.939] 
2025-12-21 21:24:16.729282: Epoch time: 139.48 s 
2025-12-21 21:24:17.387920:  
2025-12-21 21:24:17.387920: Epoch 552 
2025-12-21 21:24:17.387920: Current learning rate: 0.00485 
2025-12-21 21:26:35.790158: train_loss -0.8392 
2025-12-21 21:26:35.790158: val_loss -0.8656 
2025-12-21 21:26:35.796163: Pseudo dice [0.9249, 0.9559, 0.9351] 
2025-12-21 21:26:35.799906: Epoch time: 138.4 s 
2025-12-21 21:26:36.602530:  
2025-12-21 21:26:36.602530: Epoch 553 
2025-12-21 21:26:36.602530: Current learning rate: 0.00484 
2025-12-21 21:28:55.122247: train_loss -0.8449 
2025-12-21 21:28:55.122247: val_loss -0.8728 
2025-12-21 21:28:55.122247: Pseudo dice [0.9316, 0.9567, 0.929] 
2025-12-21 21:28:55.122247: Epoch time: 138.52 s 
2025-12-21 21:28:55.847997:  
2025-12-21 21:28:55.847997: Epoch 554 
2025-12-21 21:28:55.847997: Current learning rate: 0.00484 
2025-12-21 21:31:14.344447: train_loss -0.8535 
2025-12-21 21:31:14.344447: val_loss -0.8577 
2025-12-21 21:31:14.344447: Pseudo dice [0.9149, 0.9456, 0.938] 
2025-12-21 21:31:14.360414: Epoch time: 138.5 s 
2025-12-21 21:31:14.988052:  
2025-12-21 21:31:14.988052: Epoch 555 
2025-12-21 21:31:14.988052: Current learning rate: 0.00483 
2025-12-21 21:33:33.276003: train_loss -0.8523 
2025-12-21 21:33:33.276003: val_loss -0.884 
2025-12-21 21:33:33.280008: Pseudo dice [0.935, 0.9621, 0.9401] 
2025-12-21 21:33:33.284012: Epoch time: 138.29 s 
2025-12-21 21:33:33.910098:  
2025-12-21 21:33:33.910098: Epoch 556 
2025-12-21 21:33:33.924117: Current learning rate: 0.00482 
2025-12-21 21:35:51.822572: train_loss -0.853 
2025-12-21 21:35:51.822572: val_loss -0.8486 
2025-12-21 21:35:51.822572: Pseudo dice [0.9091, 0.9411, 0.9313] 
2025-12-21 21:35:51.822572: Epoch time: 137.91 s 
2025-12-21 21:35:52.577723:  
2025-12-21 21:35:52.577723: Epoch 557 
2025-12-21 21:35:52.577723: Current learning rate: 0.00481 
2025-12-21 21:38:10.426920: train_loss -0.8534 
2025-12-21 21:38:10.426920: val_loss -0.8685 
2025-12-21 21:38:10.428923: Pseudo dice [0.9213, 0.954, 0.9415] 
2025-12-21 21:38:10.428923: Epoch time: 137.85 s 
2025-12-21 21:38:11.074062:  
2025-12-21 21:38:11.074062: Epoch 558 
2025-12-21 21:38:11.074062: Current learning rate: 0.0048 
2025-12-21 21:40:28.964802: train_loss -0.852 
2025-12-21 21:40:28.964802: val_loss -0.8554 
2025-12-21 21:40:28.968806: Pseudo dice [0.9184, 0.9453, 0.9312] 
2025-12-21 21:40:28.968806: Epoch time: 137.89 s 
2025-12-21 21:40:29.817305:  
2025-12-21 21:40:29.817305: Epoch 559 
2025-12-21 21:40:29.817305: Current learning rate: 0.00479 
2025-12-21 21:42:47.705788: train_loss -0.8512 
2025-12-21 21:42:47.705788: val_loss -0.8697 
2025-12-21 21:42:47.709529: Pseudo dice [0.923, 0.9567, 0.9395] 
2025-12-21 21:42:47.709529: Epoch time: 137.89 s 
2025-12-21 21:42:48.406761:  
2025-12-21 21:42:48.406761: Epoch 560 
2025-12-21 21:42:48.406761: Current learning rate: 0.00478 
2025-12-21 21:45:06.395784: train_loss -0.8535 
2025-12-21 21:45:06.395784: val_loss -0.8846 
2025-12-21 21:45:06.411886: Pseudo dice [0.9345, 0.96, 0.9459] 
2025-12-21 21:45:06.415716: Epoch time: 137.99 s 
2025-12-21 21:45:07.059797:  
2025-12-21 21:45:07.059797: Epoch 561 
2025-12-21 21:45:07.059797: Current learning rate: 0.00477 
2025-12-21 21:47:25.041074: train_loss -0.8524 
2025-12-21 21:47:25.043076: val_loss -0.8659 
2025-12-21 21:47:25.045082: Pseudo dice [0.919, 0.9507, 0.9407] 
2025-12-21 21:47:25.045082: Epoch time: 137.98 s 
2025-12-21 21:47:25.692043:  
2025-12-21 21:47:25.692043: Epoch 562 
2025-12-21 21:47:25.692043: Current learning rate: 0.00476 
2025-12-21 21:49:43.715281: train_loss -0.8448 
2025-12-21 21:49:43.715281: val_loss -0.8785 
2025-12-21 21:49:43.723028: Pseudo dice [0.931, 0.9583, 0.9374] 
2025-12-21 21:49:43.727032: Epoch time: 138.02 s 
2025-12-21 21:49:44.352322:  
2025-12-21 21:49:44.352322: Epoch 563 
2025-12-21 21:49:44.352322: Current learning rate: 0.00475 
2025-12-21 21:52:02.206766: train_loss -0.8524 
2025-12-21 21:52:02.208769: val_loss -0.8662 
2025-12-21 21:52:02.214276: Pseudo dice [0.9226, 0.9526, 0.9408] 
2025-12-21 21:52:02.214276: Epoch time: 137.85 s 
2025-12-21 21:52:02.845132:  
2025-12-21 21:52:02.845132: Epoch 564 
2025-12-21 21:52:02.845132: Current learning rate: 0.00474 
2025-12-21 21:54:20.961734: train_loss -0.8527 
2025-12-21 21:54:20.961734: val_loss -0.8627 
2025-12-21 21:54:20.968713: Pseudo dice [0.9169, 0.9517, 0.9415] 
2025-12-21 21:54:20.972717: Epoch time: 138.12 s 
2025-12-21 21:54:21.610301:  
2025-12-21 21:54:21.610301: Epoch 565 
2025-12-21 21:54:21.610301: Current learning rate: 0.00473 
2025-12-21 21:56:39.432834: train_loss -0.8579 
2025-12-21 21:56:39.432834: val_loss -0.8402 
2025-12-21 21:56:39.438842: Pseudo dice [0.9095, 0.9414, 0.925] 
2025-12-21 21:56:39.440844: Epoch time: 137.82 s 
2025-12-21 21:56:40.299476:  
2025-12-21 21:56:40.299476: Epoch 566 
2025-12-21 21:56:40.299476: Current learning rate: 0.00472 
2025-12-21 21:58:58.287178: train_loss -0.8516 
2025-12-21 21:58:58.289179: val_loss -0.8739 
2025-12-21 21:58:58.292921: Pseudo dice [0.928, 0.9544, 0.9416] 
2025-12-21 21:58:58.296925: Epoch time: 137.99 s 
2025-12-21 21:58:58.937608:  
2025-12-21 21:58:58.937608: Epoch 567 
2025-12-21 21:58:58.937608: Current learning rate: 0.00471 
2025-12-21 22:01:17.122481: train_loss -0.8471 
2025-12-21 22:01:17.122481: val_loss -0.8796 
2025-12-21 22:01:17.122481: Pseudo dice [0.9303, 0.9579, 0.9432] 
2025-12-21 22:01:17.122481: Epoch time: 138.18 s 
2025-12-21 22:01:17.757240:  
2025-12-21 22:01:17.757240: Epoch 568 
2025-12-21 22:01:17.773128: Current learning rate: 0.0047 
2025-12-21 22:03:35.720850: train_loss -0.8537 
2025-12-21 22:03:35.722852: val_loss -0.8857 
2025-12-21 22:03:35.728596: Pseudo dice [0.9372, 0.963, 0.9438] 
2025-12-21 22:03:35.732601: Epoch time: 137.96 s 
2025-12-21 22:03:36.357991:  
2025-12-21 22:03:36.357991: Epoch 569 
2025-12-21 22:03:36.357991: Current learning rate: 0.00469 
2025-12-21 22:05:54.253614: train_loss -0.8497 
2025-12-21 22:05:54.253614: val_loss -0.8635 
2025-12-21 22:05:54.253614: Pseudo dice [0.9251, 0.9514, 0.9292] 
2025-12-21 22:05:54.271556: Epoch time: 137.9 s 
2025-12-21 22:05:54.902629:  
2025-12-21 22:05:54.902629: Epoch 570 
2025-12-21 22:05:54.902629: Current learning rate: 0.00468 
2025-12-21 22:08:12.874455: train_loss -0.8522 
2025-12-21 22:08:12.874455: val_loss -0.8807 
2025-12-21 22:08:12.878458: Pseudo dice [0.9315, 0.9603, 0.9396] 
2025-12-21 22:08:12.882200: Epoch time: 137.97 s 
2025-12-21 22:08:13.694672:  
2025-12-21 22:08:13.694672: Epoch 571 
2025-12-21 22:08:13.694672: Current learning rate: 0.00467 
2025-12-21 22:10:32.217488: train_loss -0.8525 
2025-12-21 22:10:32.217488: val_loss -0.8624 
2025-12-21 22:10:32.217488: Pseudo dice [0.9157, 0.9524, 0.9358] 
2025-12-21 22:10:32.233314: Epoch time: 138.52 s 
2025-12-21 22:10:33.037305:  
2025-12-21 22:10:33.037305: Epoch 572 
2025-12-21 22:10:33.037305: Current learning rate: 0.00466 
2025-12-21 22:12:50.927425: train_loss -0.8535 
2025-12-21 22:12:50.927425: val_loss -0.8856 
2025-12-21 22:12:50.927425: Pseudo dice [0.9348, 0.9622, 0.9411] 
2025-12-21 22:12:50.927425: Epoch time: 137.89 s 
2025-12-21 22:12:51.624269:  
2025-12-21 22:12:51.624269: Epoch 573 
2025-12-21 22:12:51.624269: Current learning rate: 0.00465 
2025-12-21 22:15:09.608680: train_loss -0.856 
2025-12-21 22:15:09.608680: val_loss -0.8463 
2025-12-21 22:15:09.614688: Pseudo dice [0.9111, 0.9429, 0.9245] 
2025-12-21 22:15:09.618692: Epoch time: 137.98 s 
2025-12-21 22:15:10.401536:  
2025-12-21 22:15:10.401536: Epoch 574 
2025-12-21 22:15:10.401536: Current learning rate: 0.00464 
2025-12-21 22:17:28.394682: train_loss -0.8504 
2025-12-21 22:17:28.394682: val_loss -0.8741 
2025-12-21 22:17:28.410440: Pseudo dice [0.926, 0.9536, 0.9432] 
2025-12-21 22:17:28.410440: Epoch time: 137.99 s 
2025-12-21 22:17:29.076231:  
2025-12-21 22:17:29.076231: Epoch 575 
2025-12-21 22:17:29.076231: Current learning rate: 0.00463 
2025-12-21 22:19:46.963966: train_loss -0.8547 
2025-12-21 22:19:46.963966: val_loss -0.8686 
2025-12-21 22:19:46.979674: Pseudo dice [0.9239, 0.9545, 0.9351] 
2025-12-21 22:19:46.981985: Epoch time: 137.89 s 
2025-12-21 22:19:47.610470:  
2025-12-21 22:19:47.610470: Epoch 576 
2025-12-21 22:19:47.626293: Current learning rate: 0.00462 
2025-12-21 22:22:05.586119: train_loss -0.8469 
2025-12-21 22:22:05.588121: val_loss -0.87 
2025-12-21 22:22:05.592125: Pseudo dice [0.9268, 0.9532, 0.933] 
2025-12-21 22:22:05.593865: Epoch time: 137.98 s 
2025-12-21 22:22:06.344269:  
2025-12-21 22:22:06.344269: Epoch 577 
2025-12-21 22:22:06.358281: Current learning rate: 0.00461 
2025-12-21 22:24:24.458627: train_loss -0.8544 
2025-12-21 22:24:24.460630: val_loss -0.8654 
2025-12-21 22:24:24.468380: Pseudo dice [0.9174, 0.95, 0.942] 
2025-12-21 22:24:24.472384: Epoch time: 138.11 s 
2025-12-21 22:24:25.270778:  
2025-12-21 22:24:25.270778: Epoch 578 
2025-12-21 22:24:25.286697: Current learning rate: 0.0046 
2025-12-21 22:26:43.143774: train_loss -0.8527 
2025-12-21 22:26:43.143774: val_loss -0.8632 
2025-12-21 22:26:43.149534: Pseudo dice [0.9203, 0.9507, 0.9324] 
2025-12-21 22:26:43.155541: Epoch time: 137.87 s 
2025-12-21 22:26:43.781801:  
2025-12-21 22:26:43.781801: Epoch 579 
2025-12-21 22:26:43.797702: Current learning rate: 0.00459 
2025-12-21 22:29:01.693473: train_loss -0.8461 
2025-12-21 22:29:01.693473: val_loss -0.8714 
2025-12-21 22:29:01.699479: Pseudo dice [0.9267, 0.953, 0.9407] 
2025-12-21 22:29:01.703483: Epoch time: 137.91 s 
2025-12-21 22:29:02.429766:  
2025-12-21 22:29:02.429766: Epoch 580 
2025-12-21 22:29:02.429766: Current learning rate: 0.00458 
2025-12-21 22:31:20.402569: train_loss -0.8447 
2025-12-21 22:31:20.402569: val_loss -0.862 
2025-12-21 22:31:20.418482: Pseudo dice [0.9213, 0.9485, 0.9356] 
2025-12-21 22:31:20.420484: Epoch time: 137.97 s 
2025-12-21 22:31:21.066219:  
2025-12-21 22:31:21.066219: Epoch 581 
2025-12-21 22:31:21.066219: Current learning rate: 0.00457 
2025-12-21 22:33:39.219863: train_loss -0.8471 
2025-12-21 22:33:39.221865: val_loss -0.8692 
2025-12-21 22:33:39.231884: Pseudo dice [0.9229, 0.9539, 0.9371] 
2025-12-21 22:33:39.235531: Epoch time: 138.15 s 
2025-12-21 22:33:39.914549:  
2025-12-21 22:33:39.914549: Epoch 582 
2025-12-21 22:33:39.914549: Current learning rate: 0.00456 
2025-12-21 22:35:58.146109: train_loss -0.8469 
2025-12-21 22:35:58.146109: val_loss -0.857 
2025-12-21 22:35:58.152116: Pseudo dice [0.9223, 0.955, 0.9236] 
2025-12-21 22:35:58.158122: Epoch time: 138.23 s 
2025-12-21 22:35:58.840559:  
2025-12-21 22:35:58.840559: Epoch 583 
2025-12-21 22:35:58.840559: Current learning rate: 0.00455 
2025-12-21 22:38:16.786911: train_loss -0.8446 
2025-12-21 22:38:16.786911: val_loss -0.8763 
2025-12-21 22:38:16.792655: Pseudo dice [0.9276, 0.9546, 0.945] 
2025-12-21 22:38:16.796397: Epoch time: 137.95 s 
2025-12-21 22:38:17.590168:  
2025-12-21 22:38:17.605979: Epoch 584 
2025-12-21 22:38:17.605979: Current learning rate: 0.00454 
2025-12-21 22:40:35.695489: train_loss -0.8505 
2025-12-21 22:40:35.695489: val_loss -0.8877 
2025-12-21 22:40:35.700494: Pseudo dice [0.9359, 0.9617, 0.9408] 
2025-12-21 22:40:35.706302: Epoch time: 138.11 s 
2025-12-21 22:40:36.351284:  
2025-12-21 22:40:36.351284: Epoch 585 
2025-12-21 22:40:36.351284: Current learning rate: 0.00453 
2025-12-21 22:42:54.098349: train_loss -0.8571 
2025-12-21 22:42:54.100352: val_loss -0.8672 
2025-12-21 22:42:54.104359: Pseudo dice [0.9243, 0.951, 0.9401] 
2025-12-21 22:42:54.104359: Epoch time: 137.75 s 
2025-12-21 22:42:54.750718:  
2025-12-21 22:42:54.750718: Epoch 586 
2025-12-21 22:42:54.766516: Current learning rate: 0.00452 
2025-12-21 22:45:12.976638: train_loss -0.8448 
2025-12-21 22:45:12.976638: val_loss -0.8879 
2025-12-21 22:45:12.976638: Pseudo dice [0.9359, 0.9623, 0.9479] 
2025-12-21 22:45:12.976638: Epoch time: 138.23 s 
2025-12-21 22:45:13.624954:  
2025-12-21 22:45:13.624954: Epoch 587 
2025-12-21 22:45:13.624954: Current learning rate: 0.00451 
2025-12-21 22:47:31.545012: train_loss -0.8508 
2025-12-21 22:47:31.545012: val_loss -0.8609 
2025-12-21 22:47:31.560790: Pseudo dice [0.9164, 0.9442, 0.9473] 
2025-12-21 22:47:31.560790: Epoch time: 137.92 s 
2025-12-21 22:47:32.209847:  
2025-12-21 22:47:32.209847: Epoch 588 
2025-12-21 22:47:32.209847: Current learning rate: 0.0045 
2025-12-21 22:49:50.175599: train_loss -0.851 
2025-12-21 22:49:50.175599: val_loss -0.872 
2025-12-21 22:49:50.191334: Pseudo dice [0.9304, 0.9576, 0.9316] 
2025-12-21 22:49:50.191334: Epoch time: 137.97 s 
2025-12-21 22:49:50.886894:  
2025-12-21 22:49:50.886894: Epoch 589 
2025-12-21 22:49:50.891621: Current learning rate: 0.00449 
2025-12-21 22:52:08.969062: train_loss -0.8529 
2025-12-21 22:52:08.971065: val_loss -0.8898 
2025-12-21 22:52:08.977075: Pseudo dice [0.9385, 0.9615, 0.9444] 
2025-12-21 22:52:08.981084: Epoch time: 138.1 s 
2025-12-21 22:52:08.985089: Yayy! New best EMA pseudo Dice: 0.9402 
2025-12-21 22:52:10.069064:  
2025-12-21 22:52:10.069064: Epoch 590 
2025-12-21 22:52:10.069064: Current learning rate: 0.00448 
2025-12-21 22:54:28.232607: train_loss -0.8473 
2025-12-21 22:54:28.234609: val_loss -0.8766 
2025-12-21 22:54:28.238615: Pseudo dice [0.9283, 0.9574, 0.9423] 
2025-12-21 22:54:28.242619: Epoch time: 138.17 s 
2025-12-21 22:54:28.246361: Yayy! New best EMA pseudo Dice: 0.9405 
2025-12-21 22:54:29.213981:  
2025-12-21 22:54:29.213981: Epoch 591 
2025-12-21 22:54:29.213981: Current learning rate: 0.00447 
2025-12-21 22:56:47.181273: train_loss -0.8562 
2025-12-21 22:56:47.189854: val_loss -0.8613 
2025-12-21 22:56:47.194515: Pseudo dice [0.9204, 0.9485, 0.9396] 
2025-12-21 22:56:47.200098: Epoch time: 137.97 s 
2025-12-21 22:56:47.841745:  
2025-12-21 22:56:47.841745: Epoch 592 
2025-12-21 22:56:47.841745: Current learning rate: 0.00446 
2025-12-21 22:59:05.744145: train_loss -0.8449 
2025-12-21 22:59:05.744145: val_loss -0.8614 
2025-12-21 22:59:05.744145: Pseudo dice [0.918, 0.9527, 0.9309] 
2025-12-21 22:59:05.760034: Epoch time: 137.9 s 
2025-12-21 22:59:06.377620:  
2025-12-21 22:59:06.377620: Epoch 593 
2025-12-21 22:59:06.393537: Current learning rate: 0.00445 
2025-12-21 23:01:24.392865: train_loss -0.8504 
2025-12-21 23:01:24.392865: val_loss -0.8638 
2025-12-21 23:01:24.398610: Pseudo dice [0.922, 0.9455, 0.9439] 
2025-12-21 23:01:24.404617: Epoch time: 138.02 s 
2025-12-21 23:01:25.061818:  
2025-12-21 23:01:25.061818: Epoch 594 
2025-12-21 23:01:25.061818: Current learning rate: 0.00444 
2025-12-21 23:03:42.797209: train_loss -0.8566 
2025-12-21 23:03:42.799211: val_loss -0.8738 
2025-12-21 23:03:42.805217: Pseudo dice [0.9283, 0.9563, 0.9397] 
2025-12-21 23:03:42.810224: Epoch time: 137.74 s 
2025-12-21 23:03:43.601839:  
2025-12-21 23:03:43.601839: Epoch 595 
2025-12-21 23:03:43.617709: Current learning rate: 0.00443 
2025-12-21 23:06:01.628841: train_loss -0.8512 
2025-12-21 23:06:01.630843: val_loss -0.8591 
2025-12-21 23:06:01.634847: Pseudo dice [0.9146, 0.9482, 0.9376] 
2025-12-21 23:06:01.634847: Epoch time: 138.03 s 
2025-12-21 23:06:02.267718:  
2025-12-21 23:06:02.267718: Epoch 596 
2025-12-21 23:06:02.283405: Current learning rate: 0.00442 
2025-12-21 23:08:20.046977: train_loss -0.8527 
2025-12-21 23:08:20.046977: val_loss -0.873 
2025-12-21 23:08:20.056236: Pseudo dice [0.9258, 0.9534, 0.9416] 
2025-12-21 23:08:20.060242: Epoch time: 137.78 s 
2025-12-21 23:08:20.865720:  
2025-12-21 23:08:20.865720: Epoch 597 
2025-12-21 23:08:20.877923: Current learning rate: 0.00441 
2025-12-21 23:10:39.188118: train_loss -0.8541 
2025-12-21 23:10:39.188118: val_loss -0.8766 
2025-12-21 23:10:39.193124: Pseudo dice [0.926, 0.9558, 0.9438] 
2025-12-21 23:10:39.197504: Epoch time: 138.32 s 
2025-12-21 23:10:39.851227:  
2025-12-21 23:10:39.851227: Epoch 598 
2025-12-21 23:10:39.853230: Current learning rate: 0.0044 
2025-12-21 23:12:57.960452: train_loss -0.8535 
2025-12-21 23:12:57.960452: val_loss -0.8758 
2025-12-21 23:12:57.966458: Pseudo dice [0.9273, 0.9542, 0.946] 
2025-12-21 23:12:57.970463: Epoch time: 138.11 s 
2025-12-21 23:12:58.619008:  
2025-12-21 23:12:58.619008: Epoch 599 
2025-12-21 23:12:58.621793: Current learning rate: 0.00439 
2025-12-21 23:15:16.480674: train_loss -0.8521 
2025-12-21 23:15:16.482676: val_loss -0.8879 
2025-12-21 23:15:16.486680: Pseudo dice [0.9373, 0.9631, 0.9405] 
2025-12-21 23:15:16.492335: Epoch time: 137.86 s 
2025-12-21 23:15:17.548673:  
2025-12-21 23:15:17.548673: Epoch 600 
2025-12-21 23:15:17.548673: Current learning rate: 0.00438 
2025-12-21 23:17:35.592357: train_loss -0.8507 
2025-12-21 23:17:35.592357: val_loss -0.8482 
2025-12-21 23:17:35.597363: Pseudo dice [0.9095, 0.9415, 0.9398] 
2025-12-21 23:17:35.603370: Epoch time: 138.04 s 
2025-12-21 23:17:36.425077:  
2025-12-21 23:17:36.426817: Epoch 601 
2025-12-21 23:17:36.426817: Current learning rate: 0.00437 
2025-12-21 23:19:54.298667: train_loss -0.8532 
2025-12-21 23:19:54.298667: val_loss -0.8644 
2025-12-21 23:19:54.298667: Pseudo dice [0.9199, 0.9517, 0.9395] 
2025-12-21 23:19:54.314737: Epoch time: 137.87 s 
2025-12-21 23:19:54.943568:  
2025-12-21 23:19:54.943568: Epoch 602 
2025-12-21 23:19:54.943568: Current learning rate: 0.00436 
2025-12-21 23:22:12.978637: train_loss -0.8515 
2025-12-21 23:22:12.978637: val_loss -0.8755 
2025-12-21 23:22:12.984946: Pseudo dice [0.9294, 0.954, 0.9401] 
2025-12-21 23:22:12.988953: Epoch time: 138.04 s 
2025-12-21 23:22:13.802471:  
2025-12-21 23:22:13.802471: Epoch 603 
2025-12-21 23:22:13.807977: Current learning rate: 0.00435 
2025-12-21 23:24:31.835455: train_loss -0.8512 
2025-12-21 23:24:31.837459: val_loss -0.8568 
2025-12-21 23:24:31.841020: Pseudo dice [0.919, 0.9495, 0.9303] 
2025-12-21 23:24:31.845025: Epoch time: 138.05 s 
2025-12-21 23:24:32.483381:  
2025-12-21 23:24:32.483381: Epoch 604 
2025-12-21 23:24:32.489319: Current learning rate: 0.00434 
2025-12-21 23:26:50.354169: train_loss -0.8493 
2025-12-21 23:26:50.354169: val_loss -0.8708 
2025-12-21 23:26:50.362176: Pseudo dice [0.9262, 0.9544, 0.9347] 
2025-12-21 23:26:50.365919: Epoch time: 137.87 s 
2025-12-21 23:26:50.999802:  
2025-12-21 23:26:50.999802: Epoch 605 
2025-12-21 23:26:51.015907: Current learning rate: 0.00433 
2025-12-21 23:29:08.970231: train_loss -0.8597 
2025-12-21 23:29:08.970231: val_loss -0.868 
2025-12-21 23:29:08.978239: Pseudo dice [0.9288, 0.9521, 0.9314] 
2025-12-21 23:29:08.983984: Epoch time: 137.97 s 
2025-12-21 23:29:09.787384:  
2025-12-21 23:29:09.787384: Epoch 606 
2025-12-21 23:29:09.794592: Current learning rate: 0.00432 
2025-12-21 23:31:27.771431: train_loss -0.8496 
2025-12-21 23:31:27.771431: val_loss -0.8676 
2025-12-21 23:31:27.782415: Pseudo dice [0.9225, 0.9484, 0.9357] 
2025-12-21 23:31:27.787422: Epoch time: 137.98 s 
2025-12-21 23:31:28.426098:  
2025-12-21 23:31:28.426098: Epoch 607 
2025-12-21 23:31:28.429694: Current learning rate: 0.00431 
2025-12-21 23:33:46.461154: train_loss -0.8311 
2025-12-21 23:33:46.463157: val_loss -0.8288 
2025-12-21 23:33:46.465685: Pseudo dice [0.9087, 0.9398, 0.917] 
2025-12-21 23:33:46.465685: Epoch time: 138.04 s 
2025-12-21 23:33:47.299014:  
2025-12-21 23:33:47.299014: Epoch 608 
2025-12-21 23:33:47.314773: Current learning rate: 0.0043 
2025-12-21 23:36:05.285922: train_loss -0.8236 
2025-12-21 23:36:05.285922: val_loss -0.8612 
2025-12-21 23:36:05.285922: Pseudo dice [0.9236, 0.9555, 0.9279] 
2025-12-21 23:36:05.297530: Epoch time: 137.99 s 
2025-12-21 23:36:05.994189:  
2025-12-21 23:36:05.994189: Epoch 609 
2025-12-21 23:36:06.012498: Current learning rate: 0.00429 
2025-12-21 23:38:23.971449: train_loss -0.8287 
2025-12-21 23:38:23.973452: val_loss -0.8505 
2025-12-21 23:38:23.973452: Pseudo dice [0.9166, 0.945, 0.9335] 
2025-12-21 23:38:23.979141: Epoch time: 137.98 s 
2025-12-21 23:38:24.656105:  
2025-12-21 23:38:24.656105: Epoch 610 
2025-12-21 23:38:24.656105: Current learning rate: 0.00429 
2025-12-21 23:40:42.641584: train_loss -0.8389 
2025-12-21 23:40:42.643587: val_loss -0.86 
2025-12-21 23:40:42.645589: Pseudo dice [0.9213, 0.9499, 0.9353] 
2025-12-21 23:40:42.652487: Epoch time: 137.99 s 
2025-12-21 23:40:43.297920:  
2025-12-21 23:40:43.299923: Epoch 611 
2025-12-21 23:40:43.299923: Current learning rate: 0.00428 
2025-12-21 23:43:01.205904: train_loss -0.8458 
2025-12-21 23:43:01.207906: val_loss -0.871 
2025-12-21 23:43:01.213650: Pseudo dice [0.9328, 0.9547, 0.9291] 
2025-12-21 23:43:01.219656: Epoch time: 137.91 s 
2025-12-21 23:43:01.971716:  
2025-12-21 23:43:01.971716: Epoch 612 
2025-12-21 23:43:01.977899: Current learning rate: 0.00427 
2025-12-21 23:45:19.890964: train_loss -0.8379 
2025-12-21 23:45:19.890964: val_loss -0.8735 
2025-12-21 23:45:19.896970: Pseudo dice [0.9308, 0.9561, 0.9373] 
2025-12-21 23:45:19.902976: Epoch time: 137.92 s 
2025-12-21 23:45:20.589212:  
2025-12-21 23:45:20.589212: Epoch 613 
2025-12-21 23:45:20.589212: Current learning rate: 0.00426 
2025-12-21 23:47:38.436436: train_loss -0.8337 
2025-12-21 23:47:38.436436: val_loss -0.8651 
2025-12-21 23:47:38.444445: Pseudo dice [0.9256, 0.9545, 0.9353] 
2025-12-21 23:47:38.448448: Epoch time: 137.85 s 
2025-12-21 23:47:39.085239:  
2025-12-21 23:47:39.085239: Epoch 614 
2025-12-21 23:47:39.101187: Current learning rate: 0.00425 
2025-12-21 23:49:57.139794: train_loss -0.8419 
2025-12-21 23:49:57.139794: val_loss -0.864 
2025-12-21 23:49:57.147541: Pseudo dice [0.9222, 0.9541, 0.9305] 
2025-12-21 23:49:57.151545: Epoch time: 138.05 s 
2025-12-21 23:49:57.841863:  
2025-12-21 23:49:57.841863: Epoch 615 
2025-12-21 23:49:57.841863: Current learning rate: 0.00424 
2025-12-21 23:52:16.017584: train_loss -0.8424 
2025-12-21 23:52:16.017584: val_loss -0.8712 
2025-12-21 23:52:16.022927: Pseudo dice [0.9275, 0.9576, 0.928] 
2025-12-21 23:52:16.026932: Epoch time: 138.17 s 
2025-12-21 23:52:16.676574:  
2025-12-21 23:52:16.676574: Epoch 616 
2025-12-21 23:52:16.676574: Current learning rate: 0.00423 
2025-12-21 23:54:34.554220: train_loss -0.844 
2025-12-21 23:54:34.556222: val_loss -0.8632 
2025-12-21 23:54:34.560226: Pseudo dice [0.9195, 0.9465, 0.9422] 
2025-12-21 23:54:34.564230: Epoch time: 137.88 s 
2025-12-21 23:54:35.204910:  
2025-12-21 23:54:35.204910: Epoch 617 
2025-12-21 23:54:35.204910: Current learning rate: 0.00422 
2025-12-21 23:56:53.236970: train_loss -0.8452 
2025-12-21 23:56:53.236970: val_loss -0.8658 
2025-12-21 23:56:53.245193: Pseudo dice [0.9244, 0.9515, 0.9327] 
2025-12-21 23:56:53.249197: Epoch time: 138.03 s 
2025-12-21 23:56:53.894566:  
2025-12-21 23:56:53.896569: Epoch 618 
2025-12-21 23:56:53.899604: Current learning rate: 0.00421 
2025-12-21 23:59:11.792309: train_loss -0.8472 
2025-12-21 23:59:11.794050: val_loss -0.8866 
2025-12-21 23:59:11.794050: Pseudo dice [0.9378, 0.9616, 0.9409] 
2025-12-21 23:59:11.794050: Epoch time: 137.9 s 
2025-12-21 23:59:12.603105:  
2025-12-21 23:59:12.603105: Epoch 619 
2025-12-21 23:59:12.618882: Current learning rate: 0.0042 
2025-12-22 00:01:30.527371: train_loss -0.847 
2025-12-22 00:01:30.527371: val_loss -0.8801 
2025-12-22 00:01:30.543088: Pseudo dice [0.9331, 0.9595, 0.9414] 
2025-12-22 00:01:30.543088: Epoch time: 137.92 s 
2025-12-22 00:01:31.177625:  
2025-12-22 00:01:31.177625: Epoch 620 
2025-12-22 00:01:31.177625: Current learning rate: 0.00419 
2025-12-22 00:03:49.110970: train_loss -0.8562 
2025-12-22 00:03:49.110970: val_loss -0.8596 
2025-12-22 00:03:49.110970: Pseudo dice [0.9176, 0.9484, 0.9404] 
2025-12-22 00:03:49.110970: Epoch time: 137.93 s 
2025-12-22 00:03:49.764163:  
2025-12-22 00:03:49.764163: Epoch 621 
2025-12-22 00:03:49.764163: Current learning rate: 0.00418 
2025-12-22 00:06:07.604903: train_loss -0.8476 
2025-12-22 00:06:07.604903: val_loss -0.8766 
2025-12-22 00:06:07.612652: Pseudo dice [0.9264, 0.9564, 0.943] 
2025-12-22 00:06:07.616394: Epoch time: 137.84 s 
2025-12-22 00:06:08.308259:  
2025-12-22 00:06:08.308259: Epoch 622 
2025-12-22 00:06:08.308259: Current learning rate: 0.00417 
2025-12-22 00:08:26.225407: train_loss -0.8516 
2025-12-22 00:08:26.225407: val_loss -0.8809 
2025-12-22 00:08:26.232219: Pseudo dice [0.931, 0.9562, 0.9452] 
2025-12-22 00:08:26.236226: Epoch time: 137.92 s 
2025-12-22 00:08:27.049422:  
2025-12-22 00:08:27.049422: Epoch 623 
2025-12-22 00:08:27.065305: Current learning rate: 0.00416 
2025-12-22 00:10:45.353837: train_loss -0.8495 
2025-12-22 00:10:45.353837: val_loss -0.8663 
2025-12-22 00:10:45.353837: Pseudo dice [0.9238, 0.9497, 0.9324] 
2025-12-22 00:10:45.369625: Epoch time: 138.3 s 
2025-12-22 00:10:46.002098:  
2025-12-22 00:10:46.002098: Epoch 624 
2025-12-22 00:10:46.002098: Current learning rate: 0.00415 
2025-12-22 00:13:03.761261: train_loss -0.8537 
2025-12-22 00:13:03.761261: val_loss -0.8777 
2025-12-22 00:13:03.765265: Pseudo dice [0.9322, 0.9559, 0.9403] 
2025-12-22 00:13:03.765265: Epoch time: 137.76 s 
2025-12-22 00:13:04.408172:  
2025-12-22 00:13:04.408172: Epoch 625 
2025-12-22 00:13:04.408172: Current learning rate: 0.00414 
2025-12-22 00:15:22.497521: train_loss -0.8475 
2025-12-22 00:15:22.497521: val_loss -0.8707 
2025-12-22 00:15:22.504528: Pseudo dice [0.9244, 0.9529, 0.9386] 
2025-12-22 00:15:22.508533: Epoch time: 138.09 s 
2025-12-22 00:15:23.474338:  
2025-12-22 00:15:23.474338: Epoch 626 
2025-12-22 00:15:23.476341: Current learning rate: 0.00413 
2025-12-22 00:17:41.419582: train_loss -0.8471 
2025-12-22 00:17:41.419582: val_loss -0.8767 
2025-12-22 00:17:41.419582: Pseudo dice [0.9314, 0.9585, 0.9369] 
2025-12-22 00:17:41.419582: Epoch time: 137.95 s 
2025-12-22 00:17:42.068901:  
2025-12-22 00:17:42.068901: Epoch 627 
2025-12-22 00:17:42.084588: Current learning rate: 0.00412 
2025-12-22 00:20:00.097589: train_loss -0.8493 
2025-12-22 00:20:00.097589: val_loss -0.852 
2025-12-22 00:20:00.103333: Pseudo dice [0.9106, 0.9437, 0.9428] 
2025-12-22 00:20:00.105335: Epoch time: 138.03 s 
2025-12-22 00:20:00.739634:  
2025-12-22 00:20:00.739634: Epoch 628 
2025-12-22 00:20:00.739634: Current learning rate: 0.00411 
2025-12-22 00:22:18.580738: train_loss -0.8441 
2025-12-22 00:22:18.596458: val_loss -0.8731 
2025-12-22 00:22:18.596458: Pseudo dice [0.9264, 0.9522, 0.9352] 
2025-12-22 00:22:18.596458: Epoch time: 137.84 s 
2025-12-22 00:22:19.342026:  
2025-12-22 00:22:19.342026: Epoch 629 
2025-12-22 00:22:19.357831: Current learning rate: 0.0041 
2025-12-22 00:24:37.448271: train_loss -0.8496 
2025-12-22 00:24:37.448271: val_loss -0.8822 
2025-12-22 00:24:37.453277: Pseudo dice [0.9282, 0.9621, 0.9448] 
2025-12-22 00:24:37.457280: Epoch time: 138.11 s 
2025-12-22 00:24:38.094280:  
2025-12-22 00:24:38.094280: Epoch 630 
2025-12-22 00:24:38.094280: Current learning rate: 0.00409 
2025-12-22 00:26:56.040912: train_loss -0.8481 
2025-12-22 00:26:56.040912: val_loss -0.8765 
2025-12-22 00:26:56.046917: Pseudo dice [0.9268, 0.9572, 0.9425] 
2025-12-22 00:26:56.049922: Epoch time: 137.95 s 
2025-12-22 00:26:56.683184:  
2025-12-22 00:26:56.683184: Epoch 631 
2025-12-22 00:26:56.699095: Current learning rate: 0.00408 
2025-12-22 00:29:14.745888: train_loss -0.8522 
2025-12-22 00:29:14.745888: val_loss -0.8751 
2025-12-22 00:29:14.745888: Pseudo dice [0.9255, 0.9558, 0.9447] 
2025-12-22 00:29:14.761722: Epoch time: 138.06 s 
2025-12-22 00:29:15.647236:  
2025-12-22 00:29:15.647236: Epoch 632 
2025-12-22 00:29:15.663125: Current learning rate: 0.00407 
2025-12-22 00:31:33.642545: train_loss -0.8527 
2025-12-22 00:31:33.642545: val_loss -0.8702 
2025-12-22 00:31:33.650544: Pseudo dice [0.9228, 0.9544, 0.9373] 
2025-12-22 00:31:33.654548: Epoch time: 138.0 s 
2025-12-22 00:31:34.296431:  
2025-12-22 00:31:34.296431: Epoch 633 
2025-12-22 00:31:34.296431: Current learning rate: 0.00406 
2025-12-22 00:33:52.292734: train_loss -0.8518 
2025-12-22 00:33:52.292734: val_loss -0.8779 
2025-12-22 00:33:52.308502: Pseudo dice [0.9302, 0.9617, 0.9407] 
2025-12-22 00:33:52.308502: Epoch time: 138.0 s 
2025-12-22 00:33:52.958699:  
2025-12-22 00:33:52.958699: Epoch 634 
2025-12-22 00:33:52.958699: Current learning rate: 0.00405 
2025-12-22 00:36:11.012021: train_loss -0.8508 
2025-12-22 00:36:11.027751: val_loss -0.8772 
2025-12-22 00:36:11.027751: Pseudo dice [0.9308, 0.9549, 0.9392] 
2025-12-22 00:36:11.027751: Epoch time: 138.07 s 
2025-12-22 00:36:11.699985:  
2025-12-22 00:36:11.699985: Epoch 635 
2025-12-22 00:36:11.699985: Current learning rate: 0.00404 
2025-12-22 00:38:29.714067: train_loss -0.8521 
2025-12-22 00:38:29.716069: val_loss -0.8857 
2025-12-22 00:38:29.722076: Pseudo dice [0.9398, 0.9589, 0.9368] 
2025-12-22 00:38:29.728084: Epoch time: 138.02 s 
2025-12-22 00:38:29.731826: Yayy! New best EMA pseudo Dice: 0.9407 
2025-12-22 00:38:30.679440:  
2025-12-22 00:38:30.679440: Epoch 636 
2025-12-22 00:38:30.679440: Current learning rate: 0.00403 
2025-12-22 00:40:48.673887: train_loss -0.8533 
2025-12-22 00:40:48.673887: val_loss -0.8719 
2025-12-22 00:40:48.683097: Pseudo dice [0.9258, 0.952, 0.9347] 
2025-12-22 00:40:48.689103: Epoch time: 137.99 s 
2025-12-22 00:40:49.491175:  
2025-12-22 00:40:49.491175: Epoch 637 
2025-12-22 00:40:49.491175: Current learning rate: 0.00402 
2025-12-22 00:43:07.389519: train_loss -0.853 
2025-12-22 00:43:07.389519: val_loss -0.878 
2025-12-22 00:43:07.397026: Pseudo dice [0.9299, 0.9591, 0.9384] 
2025-12-22 00:43:07.401030: Epoch time: 137.9 s 
2025-12-22 00:43:08.054157:  
2025-12-22 00:43:08.054157: Epoch 638 
2025-12-22 00:43:08.070079: Current learning rate: 0.00401 
2025-12-22 00:45:26.130820: train_loss -0.8541 
2025-12-22 00:45:26.130820: val_loss -0.8664 
2025-12-22 00:45:26.136825: Pseudo dice [0.9241, 0.9529, 0.9374] 
2025-12-22 00:45:26.140829: Epoch time: 138.08 s 
2025-12-22 00:45:26.842404:  
2025-12-22 00:45:26.842404: Epoch 639 
2025-12-22 00:45:26.842404: Current learning rate: 0.004 
2025-12-22 00:47:44.770080: train_loss -0.8528 
2025-12-22 00:47:44.770080: val_loss -0.8673 
2025-12-22 00:47:44.770080: Pseudo dice [0.9249, 0.9541, 0.9372] 
2025-12-22 00:47:44.770080: Epoch time: 137.93 s 
2025-12-22 00:47:45.419432:  
2025-12-22 00:47:45.419432: Epoch 640 
2025-12-22 00:47:45.419432: Current learning rate: 0.00399 
2025-12-22 00:50:03.189957: train_loss -0.8532 
2025-12-22 00:50:03.189957: val_loss -0.879 
2025-12-22 00:50:03.189957: Pseudo dice [0.9317, 0.9576, 0.94] 
2025-12-22 00:50:03.207837: Epoch time: 137.77 s 
2025-12-22 00:50:03.855048:  
2025-12-22 00:50:03.855048: Epoch 641 
2025-12-22 00:50:03.855048: Current learning rate: 0.00398 
2025-12-22 00:52:21.614201: train_loss -0.8594 
2025-12-22 00:52:21.614201: val_loss -0.8676 
2025-12-22 00:52:21.631900: Pseudo dice [0.923, 0.9529, 0.9377] 
2025-12-22 00:52:21.631900: Epoch time: 137.76 s 
2025-12-22 00:52:22.279191:  
2025-12-22 00:52:22.279191: Epoch 642 
2025-12-22 00:52:22.279191: Current learning rate: 0.00397 
2025-12-22 00:54:40.244226: train_loss -0.8558 
2025-12-22 00:54:40.244226: val_loss -0.8863 
2025-12-22 00:54:40.246228: Pseudo dice [0.9345, 0.9616, 0.9455] 
2025-12-22 00:54:40.254086: Epoch time: 137.97 s 
2025-12-22 00:54:40.259487: Yayy! New best EMA pseudo Dice: 0.9409 
2025-12-22 00:54:41.185595:  
2025-12-22 00:54:41.185595: Epoch 643 
2025-12-22 00:54:41.185595: Current learning rate: 0.00396 
2025-12-22 00:56:59.025584: train_loss -0.8559 
2025-12-22 00:56:59.025584: val_loss -0.8815 
2025-12-22 00:56:59.029588: Pseudo dice [0.9319, 0.9583, 0.9412] 
2025-12-22 00:56:59.033592: Epoch time: 137.84 s 
2025-12-22 00:56:59.039336: Yayy! New best EMA pseudo Dice: 0.9412 
2025-12-22 00:57:00.173004:  
2025-12-22 00:57:00.173004: Epoch 644 
2025-12-22 00:57:00.188993: Current learning rate: 0.00395 
2025-12-22 00:59:18.110029: train_loss -0.8524 
2025-12-22 00:59:18.110029: val_loss -0.875 
2025-12-22 00:59:18.118387: Pseudo dice [0.9272, 0.9551, 0.943] 
2025-12-22 00:59:18.126399: Epoch time: 137.94 s 
2025-12-22 00:59:18.132149: Yayy! New best EMA pseudo Dice: 0.9413 
2025-12-22 00:59:19.068963:  
2025-12-22 00:59:19.068963: Epoch 645 
2025-12-22 00:59:19.075168: Current learning rate: 0.00394 
2025-12-22 01:01:36.949436: train_loss -0.8548 
2025-12-22 01:01:36.949436: val_loss -0.8879 
2025-12-22 01:01:36.949436: Pseudo dice [0.9381, 0.9619, 0.9451] 
2025-12-22 01:01:36.964698: Epoch time: 137.88 s 
2025-12-22 01:01:36.967611: Yayy! New best EMA pseudo Dice: 0.942 
2025-12-22 01:01:37.897147:  
2025-12-22 01:01:37.897147: Epoch 646 
2025-12-22 01:01:37.897147: Current learning rate: 0.00393 
2025-12-22 01:03:55.988930: train_loss -0.8503 
2025-12-22 01:03:55.988930: val_loss -0.8755 
2025-12-22 01:03:55.994427: Pseudo dice [0.9278, 0.9554, 0.94] 
2025-12-22 01:03:55.998431: Epoch time: 138.1 s 
2025-12-22 01:03:56.645748:  
2025-12-22 01:03:56.645748: Epoch 647 
2025-12-22 01:03:56.650462: Current learning rate: 0.00392 
2025-12-22 01:06:14.783987: train_loss -0.8566 
2025-12-22 01:06:14.785989: val_loss -0.8757 
2025-12-22 01:06:14.792173: Pseudo dice [0.928, 0.9561, 0.941] 
2025-12-22 01:06:14.798179: Epoch time: 138.14 s 
2025-12-22 01:06:15.434215:  
2025-12-22 01:06:15.449980: Epoch 648 
2025-12-22 01:06:15.449980: Current learning rate: 0.00391 
2025-12-22 01:08:33.404295: train_loss -0.8558 
2025-12-22 01:08:33.404295: val_loss -0.8841 
2025-12-22 01:08:33.411803: Pseudo dice [0.9345, 0.9612, 0.9422] 
2025-12-22 01:08:33.415806: Epoch time: 137.97 s 
2025-12-22 01:08:33.419810: Yayy! New best EMA pseudo Dice: 0.9423 
2025-12-22 01:08:34.563265:  
2025-12-22 01:08:34.563265: Epoch 649 
2025-12-22 01:08:34.563265: Current learning rate: 0.0039 
2025-12-22 01:10:52.937339: train_loss -0.8537 
2025-12-22 01:10:52.937339: val_loss -0.8841 
2025-12-22 01:10:52.941344: Pseudo dice [0.9335, 0.9584, 0.9444] 
2025-12-22 01:10:52.947350: Epoch time: 138.37 s 
2025-12-22 01:10:53.216866: Yayy! New best EMA pseudo Dice: 0.9426 
2025-12-22 01:10:54.155871:  
2025-12-22 01:10:54.155871: Epoch 650 
2025-12-22 01:10:54.157875: Current learning rate: 0.00389 
2025-12-22 01:13:12.213471: train_loss -0.8491 
2025-12-22 01:13:12.213471: val_loss -0.8748 
2025-12-22 01:13:12.221481: Pseudo dice [0.928, 0.9568, 0.9416] 
2025-12-22 01:13:12.225486: Epoch time: 138.06 s 
2025-12-22 01:13:12.918700:  
2025-12-22 01:13:12.918700: Epoch 651 
2025-12-22 01:13:12.923413: Current learning rate: 0.00388 
2025-12-22 01:15:31.072450: train_loss -0.8467 
2025-12-22 01:15:31.072450: val_loss -0.8681 
2025-12-22 01:15:31.072450: Pseudo dice [0.9279, 0.9544, 0.9303] 
2025-12-22 01:15:31.091624: Epoch time: 138.17 s 
2025-12-22 01:15:31.736824:  
2025-12-22 01:15:31.736824: Epoch 652 
2025-12-22 01:15:31.744268: Current learning rate: 0.00387 
2025-12-22 01:17:49.765259: train_loss -0.8398 
2025-12-22 01:17:49.767262: val_loss -0.8605 
2025-12-22 01:17:49.773008: Pseudo dice [0.9206, 0.9526, 0.9384] 
2025-12-22 01:17:49.779014: Epoch time: 138.03 s 
2025-12-22 01:17:50.420517:  
2025-12-22 01:17:50.420517: Epoch 653 
2025-12-22 01:17:50.432381: Current learning rate: 0.00386 
2025-12-22 01:20:08.470048: train_loss -0.84 
2025-12-22 01:20:08.470048: val_loss -0.8564 
2025-12-22 01:20:08.489588: Pseudo dice [0.9235, 0.9481, 0.9336] 
2025-12-22 01:20:08.494686: Epoch time: 138.05 s 
2025-12-22 01:20:09.153012:  
2025-12-22 01:20:09.153012: Epoch 654 
2025-12-22 01:20:09.169035: Current learning rate: 0.00385 
2025-12-22 01:22:26.965451: train_loss -0.8417 
2025-12-22 01:22:26.965451: val_loss -0.8547 
2025-12-22 01:22:26.981488: Pseudo dice [0.9197, 0.9452, 0.9379] 
2025-12-22 01:22:26.981488: Epoch time: 137.81 s 
2025-12-22 01:22:27.847070:  
2025-12-22 01:22:27.847070: Epoch 655 
2025-12-22 01:22:27.853427: Current learning rate: 0.00384 
2025-12-22 01:24:45.782434: train_loss -0.8439 
2025-12-22 01:24:45.782434: val_loss -0.8705 
2025-12-22 01:24:45.798138: Pseudo dice [0.9279, 0.9553, 0.9376] 
2025-12-22 01:24:45.807019: Epoch time: 137.94 s 
2025-12-22 01:24:46.498997:  
2025-12-22 01:24:46.498997: Epoch 656 
2025-12-22 01:24:46.498997: Current learning rate: 0.00383 
2025-12-22 01:27:04.449296: train_loss -0.8414 
2025-12-22 01:27:04.449296: val_loss -0.8648 
2025-12-22 01:27:04.463745: Pseudo dice [0.9255, 0.9526, 0.935] 
2025-12-22 01:27:04.467095: Epoch time: 137.95 s 
2025-12-22 01:27:05.114453:  
2025-12-22 01:27:05.114453: Epoch 657 
2025-12-22 01:27:05.114453: Current learning rate: 0.00382 
2025-12-22 01:29:22.881408: train_loss -0.8462 
2025-12-22 01:29:22.881408: val_loss -0.8645 
2025-12-22 01:29:22.886913: Pseudo dice [0.9227, 0.9519, 0.9308] 
2025-12-22 01:29:22.890920: Epoch time: 137.77 s 
2025-12-22 01:29:23.728678:  
2025-12-22 01:29:23.728678: Epoch 658 
2025-12-22 01:29:23.738187: Current learning rate: 0.00381 
2025-12-22 01:31:41.486641: train_loss -0.8449 
2025-12-22 01:31:41.486641: val_loss -0.8695 
2025-12-22 01:31:41.492647: Pseudo dice [0.9264, 0.954, 0.9394] 
2025-12-22 01:31:41.498393: Epoch time: 137.76 s 
2025-12-22 01:31:42.127048:  
2025-12-22 01:31:42.127048: Epoch 659 
2025-12-22 01:31:42.143099: Current learning rate: 0.0038 
2025-12-22 01:34:00.037049: train_loss -0.8535 
2025-12-22 01:34:00.037049: val_loss -0.8638 
2025-12-22 01:34:00.037049: Pseudo dice [0.9208, 0.9496, 0.9372] 
2025-12-22 01:34:00.037049: Epoch time: 137.91 s 
2025-12-22 01:34:00.682864:  
2025-12-22 01:34:00.682864: Epoch 660 
2025-12-22 01:34:00.686894: Current learning rate: 0.00379 
2025-12-22 01:36:18.562509: train_loss -0.847 
2025-12-22 01:36:18.562509: val_loss -0.8786 
2025-12-22 01:36:18.567703: Pseudo dice [0.9315, 0.9601, 0.9392] 
2025-12-22 01:36:18.571445: Epoch time: 137.88 s 
2025-12-22 01:36:19.515524:  
2025-12-22 01:36:19.517527: Epoch 661 
2025-12-22 01:36:19.521534: Current learning rate: 0.00378 
2025-12-22 01:38:37.322269: train_loss -0.8508 
2025-12-22 01:38:37.322269: val_loss -0.8792 
2025-12-22 01:38:37.328201: Pseudo dice [0.9329, 0.9571, 0.9374] 
2025-12-22 01:38:37.331751: Epoch time: 137.81 s 
2025-12-22 01:38:37.977601:  
2025-12-22 01:38:37.977601: Epoch 662 
2025-12-22 01:38:37.977601: Current learning rate: 0.00377 
2025-12-22 01:40:56.033101: train_loss -0.8481 
2025-12-22 01:40:56.033101: val_loss -0.8702 
2025-12-22 01:40:56.048309: Pseudo dice [0.9252, 0.9567, 0.9416] 
2025-12-22 01:40:56.048309: Epoch time: 138.06 s 
2025-12-22 01:40:56.698267:  
2025-12-22 01:40:56.698267: Epoch 663 
2025-12-22 01:40:56.698267: Current learning rate: 0.00376 
2025-12-22 01:43:14.741373: train_loss -0.8479 
2025-12-22 01:43:14.741373: val_loss -0.872 
2025-12-22 01:43:14.741373: Pseudo dice [0.9255, 0.9567, 0.9418] 
2025-12-22 01:43:14.750607: Epoch time: 138.05 s 
2025-12-22 01:43:15.576918:  
2025-12-22 01:43:15.576918: Epoch 664 
2025-12-22 01:43:15.576918: Current learning rate: 0.00375 
2025-12-22 01:45:33.540583: train_loss -0.8503 
2025-12-22 01:45:33.540583: val_loss -0.872 
2025-12-22 01:45:33.546589: Pseudo dice [0.9243, 0.9565, 0.9404] 
2025-12-22 01:45:33.549593: Epoch time: 137.96 s 
2025-12-22 01:45:34.199438:  
2025-12-22 01:45:34.199438: Epoch 665 
2025-12-22 01:45:34.199438: Current learning rate: 0.00374 
2025-12-22 01:47:52.158336: train_loss -0.8516 
2025-12-22 01:47:52.158336: val_loss -0.8829 
2025-12-22 01:47:52.166619: Pseudo dice [0.9361, 0.9586, 0.9392] 
2025-12-22 01:47:52.170623: Epoch time: 137.96 s 
2025-12-22 01:47:52.821842:  
2025-12-22 01:47:52.823582: Epoch 666 
2025-12-22 01:47:52.823582: Current learning rate: 0.00373 
2025-12-22 01:50:10.642043: train_loss -0.8548 
2025-12-22 01:50:10.642043: val_loss -0.8826 
2025-12-22 01:50:10.642043: Pseudo dice [0.9321, 0.9588, 0.9482] 
2025-12-22 01:50:10.642043: Epoch time: 137.82 s 
2025-12-22 01:50:11.461840:  
2025-12-22 01:50:11.461840: Epoch 667 
2025-12-22 01:50:11.465584: Current learning rate: 0.00372 
2025-12-22 01:52:29.280492: train_loss -0.8513 
2025-12-22 01:52:29.282232: val_loss -0.8533 
2025-12-22 01:52:29.288239: Pseudo dice [0.9135, 0.9437, 0.9406] 
2025-12-22 01:52:29.293983: Epoch time: 137.82 s 
2025-12-22 01:52:29.932043:  
2025-12-22 01:52:29.932043: Epoch 668 
2025-12-22 01:52:29.932043: Current learning rate: 0.00371 
2025-12-22 01:54:48.070639: train_loss -0.8511 
2025-12-22 01:54:48.070639: val_loss -0.8732 
2025-12-22 01:54:48.076383: Pseudo dice [0.926, 0.955, 0.939] 
2025-12-22 01:54:48.080502: Epoch time: 138.14 s 
2025-12-22 01:54:48.729387:  
2025-12-22 01:54:48.729387: Epoch 669 
2025-12-22 01:54:48.729387: Current learning rate: 0.0037 
2025-12-22 01:57:06.609147: train_loss -0.8547 
2025-12-22 01:57:06.609147: val_loss -0.8675 
2025-12-22 01:57:06.616655: Pseudo dice [0.926, 0.9534, 0.9347] 
2025-12-22 01:57:06.620659: Epoch time: 137.88 s 
2025-12-22 01:57:07.276175:  
2025-12-22 01:57:07.276175: Epoch 670 
2025-12-22 01:57:07.276175: Current learning rate: 0.00369 
2025-12-22 01:59:25.167491: train_loss -0.8492 
2025-12-22 01:59:25.167491: val_loss -0.8619 
2025-12-22 01:59:25.173497: Pseudo dice [0.9203, 0.9508, 0.9404] 
2025-12-22 01:59:25.177501: Epoch time: 137.89 s 
2025-12-22 01:59:25.832327:  
2025-12-22 01:59:25.832327: Epoch 671 
2025-12-22 01:59:25.832327: Current learning rate: 0.00368 
2025-12-22 02:01:43.955209: train_loss -0.8463 
2025-12-22 02:01:43.955209: val_loss -0.8771 
2025-12-22 02:01:43.970881: Pseudo dice [0.9292, 0.9595, 0.9368] 
2025-12-22 02:01:43.970881: Epoch time: 138.12 s 
2025-12-22 02:01:44.764149:  
2025-12-22 02:01:44.764149: Epoch 672 
2025-12-22 02:01:44.780056: Current learning rate: 0.00367 
2025-12-22 02:04:02.693042: train_loss -0.8524 
2025-12-22 02:04:02.693042: val_loss -0.8701 
2025-12-22 02:04:02.699049: Pseudo dice [0.9257, 0.9521, 0.9406] 
2025-12-22 02:04:02.703053: Epoch time: 137.93 s 
2025-12-22 02:04:03.357351:  
2025-12-22 02:04:03.357351: Epoch 673 
2025-12-22 02:04:03.357351: Current learning rate: 0.00366 
2025-12-22 02:06:21.252969: train_loss -0.8515 
2025-12-22 02:06:21.252969: val_loss -0.8839 
2025-12-22 02:06:21.262044: Pseudo dice [0.9325, 0.9541, 0.9437] 
2025-12-22 02:06:21.266788: Epoch time: 137.9 s 
2025-12-22 02:06:21.914562:  
2025-12-22 02:06:21.914562: Epoch 674 
2025-12-22 02:06:21.914562: Current learning rate: 0.00365 
2025-12-22 02:08:40.034693: train_loss -0.8554 
2025-12-22 02:08:40.036695: val_loss -0.8467 
2025-12-22 02:08:40.044441: Pseudo dice [0.9088, 0.9423, 0.9344] 
2025-12-22 02:08:40.048446: Epoch time: 138.12 s 
2025-12-22 02:08:40.830337:  
2025-12-22 02:08:40.830337: Epoch 675 
2025-12-22 02:08:40.830337: Current learning rate: 0.00364 
2025-12-22 02:10:59.149126: train_loss -0.85 
2025-12-22 02:10:59.149126: val_loss -0.8727 
2025-12-22 02:10:59.153130: Pseudo dice [0.9267, 0.9587, 0.9402] 
2025-12-22 02:10:59.162231: Epoch time: 138.32 s 
2025-12-22 02:10:59.798774:  
2025-12-22 02:10:59.798774: Epoch 676 
2025-12-22 02:10:59.814688: Current learning rate: 0.00363 
2025-12-22 02:13:17.828670: train_loss -0.8546 
2025-12-22 02:13:17.830673: val_loss -0.8775 
2025-12-22 02:13:17.838680: Pseudo dice [0.9304, 0.9564, 0.9396] 
2025-12-22 02:13:17.846431: Epoch time: 138.03 s 
2025-12-22 02:13:18.521738:  
2025-12-22 02:13:18.521738: Epoch 677 
2025-12-22 02:13:18.521738: Current learning rate: 0.00362 
2025-12-22 02:15:36.469383: train_loss -0.8532 
2025-12-22 02:15:36.471387: val_loss -0.8758 
2025-12-22 02:15:36.476640: Pseudo dice [0.9303, 0.9548, 0.9397] 
2025-12-22 02:15:36.476640: Epoch time: 137.95 s 
2025-12-22 02:15:37.218224:  
2025-12-22 02:15:37.218224: Epoch 678 
2025-12-22 02:15:37.234091: Current learning rate: 0.00361 
2025-12-22 02:17:55.304005: train_loss -0.8545 
2025-12-22 02:17:55.304005: val_loss -0.8785 
2025-12-22 02:17:55.304005: Pseudo dice [0.9313, 0.9569, 0.9423] 
2025-12-22 02:17:55.304005: Epoch time: 138.09 s 
2025-12-22 02:17:55.954843:  
2025-12-22 02:17:55.954843: Epoch 679 
2025-12-22 02:17:55.954843: Current learning rate: 0.0036 
2025-12-22 02:20:13.717736: train_loss -0.8595 
2025-12-22 02:20:13.717736: val_loss -0.8586 
2025-12-22 02:20:13.717736: Pseudo dice [0.9157, 0.949, 0.9393] 
2025-12-22 02:20:13.733543: Epoch time: 137.76 s 
2025-12-22 02:20:14.370083:  
2025-12-22 02:20:14.370083: Epoch 680 
2025-12-22 02:20:14.370083: Current learning rate: 0.00359 
2025-12-22 02:22:32.234276: train_loss -0.8542 
2025-12-22 02:22:32.236279: val_loss -0.8764 
2025-12-22 02:22:32.241523: Pseudo dice [0.9259, 0.9552, 0.9482] 
2025-12-22 02:22:32.245527: Epoch time: 137.86 s 
2025-12-22 02:22:32.973195:  
2025-12-22 02:22:32.973195: Epoch 681 
2025-12-22 02:22:32.973195: Current learning rate: 0.00358 
2025-12-22 02:24:51.229970: train_loss -0.8579 
2025-12-22 02:24:51.229970: val_loss -0.8625 
2025-12-22 02:24:51.233712: Pseudo dice [0.9212, 0.9535, 0.9323] 
2025-12-22 02:24:51.233712: Epoch time: 138.25 s 
2025-12-22 02:24:51.882830:  
2025-12-22 02:24:51.882830: Epoch 682 
2025-12-22 02:24:51.898611: Current learning rate: 0.00357 
2025-12-22 02:27:09.956164: train_loss -0.8548 
2025-12-22 02:27:09.956164: val_loss -0.8717 
2025-12-22 02:27:09.962169: Pseudo dice [0.9247, 0.9543, 0.9441] 
2025-12-22 02:27:09.967913: Epoch time: 138.07 s 
2025-12-22 02:27:10.622712:  
2025-12-22 02:27:10.622712: Epoch 683 
2025-12-22 02:27:10.622712: Current learning rate: 0.00356 
2025-12-22 02:29:28.594120: train_loss -0.8551 
2025-12-22 02:29:28.594120: val_loss -0.8645 
2025-12-22 02:29:28.596122: Pseudo dice [0.9218, 0.9477, 0.9461] 
2025-12-22 02:29:28.603924: Epoch time: 137.97 s 
2025-12-22 02:29:29.554317:  
2025-12-22 02:29:29.554317: Epoch 684 
2025-12-22 02:29:29.554317: Current learning rate: 0.00355 
2025-12-22 02:31:47.541542: train_loss -0.852 
2025-12-22 02:31:47.543544: val_loss -0.8722 
2025-12-22 02:31:47.545547: Pseudo dice [0.9274, 0.9533, 0.9409] 
2025-12-22 02:31:47.553714: Epoch time: 138.0 s 
2025-12-22 02:31:48.202958:  
2025-12-22 02:31:48.202958: Epoch 685 
2025-12-22 02:31:48.202958: Current learning rate: 0.00354 
2025-12-22 02:34:06.131332: train_loss -0.8563 
2025-12-22 02:34:06.131332: val_loss -0.87 
2025-12-22 02:34:06.139827: Pseudo dice [0.921, 0.9532, 0.9455] 
2025-12-22 02:34:06.147115: Epoch time: 137.93 s 
2025-12-22 02:34:06.794333:  
2025-12-22 02:34:06.794333: Epoch 686 
2025-12-22 02:34:06.810205: Current learning rate: 0.00353 
2025-12-22 02:36:24.751802: train_loss -0.8555 
2025-12-22 02:36:24.751802: val_loss -0.8757 
2025-12-22 02:36:24.767532: Pseudo dice [0.9268, 0.9543, 0.9454] 
2025-12-22 02:36:24.767532: Epoch time: 137.96 s 
2025-12-22 02:36:25.463464:  
2025-12-22 02:36:25.463464: Epoch 687 
2025-12-22 02:36:25.463464: Current learning rate: 0.00352 
2025-12-22 02:38:43.389579: train_loss -0.8546 
2025-12-22 02:38:43.391581: val_loss -0.8869 
2025-12-22 02:38:43.403368: Pseudo dice [0.9348, 0.9606, 0.9396] 
2025-12-22 02:38:43.407775: Epoch time: 137.93 s 
2025-12-22 02:38:44.067321:  
2025-12-22 02:38:44.067321: Epoch 688 
2025-12-22 02:38:44.067321: Current learning rate: 0.00351 
2025-12-22 02:41:02.096036: train_loss -0.8551 
2025-12-22 02:41:02.096036: val_loss -0.8705 
2025-12-22 02:41:02.102043: Pseudo dice [0.9225, 0.9556, 0.9395] 
2025-12-22 02:41:02.107650: Epoch time: 138.04 s 
2025-12-22 02:41:02.808928:  
2025-12-22 02:41:02.808928: Epoch 689 
2025-12-22 02:41:02.808928: Current learning rate: 0.0035 
2025-12-22 02:43:20.886425: train_loss -0.852 
2025-12-22 02:43:20.886425: val_loss -0.8611 
2025-12-22 02:43:20.892431: Pseudo dice [0.919, 0.949, 0.9343] 
2025-12-22 02:43:20.898438: Epoch time: 138.09 s 
2025-12-22 02:43:21.713375:  
2025-12-22 02:43:21.713375: Epoch 690 
2025-12-22 02:43:21.713375: Current learning rate: 0.00349 
2025-12-22 02:45:39.548953: train_loss -0.8525 
2025-12-22 02:45:39.548953: val_loss -0.8617 
2025-12-22 02:45:39.564702: Pseudo dice [0.9174, 0.9498, 0.9377] 
2025-12-22 02:45:39.564702: Epoch time: 137.84 s 
2025-12-22 02:45:40.230623:  
2025-12-22 02:45:40.230623: Epoch 691 
2025-12-22 02:45:40.230623: Current learning rate: 0.00348 
2025-12-22 02:47:57.925928: train_loss -0.8599 
2025-12-22 02:47:57.925928: val_loss -0.8795 
2025-12-22 02:47:57.925928: Pseudo dice [0.9305, 0.9605, 0.9407] 
2025-12-22 02:47:57.941649: Epoch time: 137.71 s 
2025-12-22 02:47:58.575801:  
2025-12-22 02:47:58.575801: Epoch 692 
2025-12-22 02:47:58.586810: Current learning rate: 0.00346 
2025-12-22 02:50:16.447983: train_loss -0.8531 
2025-12-22 02:50:16.447983: val_loss -0.8673 
2025-12-22 02:50:16.447983: Pseudo dice [0.9236, 0.9501, 0.9371] 
2025-12-22 02:50:16.465778: Epoch time: 137.87 s 
2025-12-22 02:50:17.112059:  
2025-12-22 02:50:17.112059: Epoch 693 
2025-12-22 02:50:17.112059: Current learning rate: 0.00345 
2025-12-22 02:52:34.985271: train_loss -0.8507 
2025-12-22 02:52:34.985271: val_loss -0.8809 
2025-12-22 02:52:34.985271: Pseudo dice [0.9319, 0.9555, 0.941] 
2025-12-22 02:52:34.985271: Epoch time: 137.87 s 
2025-12-22 02:52:35.634682:  
2025-12-22 02:52:35.634682: Epoch 694 
2025-12-22 02:52:35.634682: Current learning rate: 0.00344 
2025-12-22 02:54:53.565586: train_loss -0.8517 
2025-12-22 02:54:53.565586: val_loss -0.8775 
2025-12-22 02:54:53.565586: Pseudo dice [0.9299, 0.9617, 0.9336] 
2025-12-22 02:54:53.581423: Epoch time: 137.93 s 
2025-12-22 02:54:54.371119:  
2025-12-22 02:54:54.371119: Epoch 695 
2025-12-22 02:54:54.371119: Current learning rate: 0.00343 
2025-12-22 02:57:12.223473: train_loss -0.8534 
2025-12-22 02:57:12.223473: val_loss -0.8804 
2025-12-22 02:57:12.228406: Pseudo dice [0.9299, 0.9606, 0.94] 
2025-12-22 02:57:12.234412: Epoch time: 137.85 s 
2025-12-22 02:57:13.062403:  
2025-12-22 02:57:13.062403: Epoch 696 
2025-12-22 02:57:13.073807: Current learning rate: 0.00342 
2025-12-22 02:59:30.900673: train_loss -0.8522 
2025-12-22 02:59:30.900673: val_loss -0.8807 
2025-12-22 02:59:30.906418: Pseudo dice [0.9299, 0.9537, 0.9462] 
2025-12-22 02:59:30.910583: Epoch time: 137.84 s 
2025-12-22 02:59:31.552975:  
2025-12-22 02:59:31.552975: Epoch 697 
2025-12-22 02:59:31.568737: Current learning rate: 0.00341 
2025-12-22 03:01:49.458650: train_loss -0.8557 
2025-12-22 03:01:49.458650: val_loss -0.8686 
2025-12-22 03:01:49.466397: Pseudo dice [0.9235, 0.9562, 0.9374] 
2025-12-22 03:01:49.474149: Epoch time: 137.91 s 
2025-12-22 03:01:50.284595:  
2025-12-22 03:01:50.284595: Epoch 698 
2025-12-22 03:01:50.284595: Current learning rate: 0.0034 
2025-12-22 03:04:08.169424: train_loss -0.8565 
2025-12-22 03:04:08.169424: val_loss -0.8742 
2025-12-22 03:04:08.177432: Pseudo dice [0.9254, 0.9512, 0.941] 
2025-12-22 03:04:08.183378: Epoch time: 137.88 s 
2025-12-22 03:04:08.832474:  
2025-12-22 03:04:08.832474: Epoch 699 
2025-12-22 03:04:08.832474: Current learning rate: 0.00339 
2025-12-22 03:06:26.889152: train_loss -0.8532 
2025-12-22 03:06:26.889152: val_loss -0.8702 
2025-12-22 03:06:26.894896: Pseudo dice [0.9256, 0.9515, 0.939] 
2025-12-22 03:06:26.900394: Epoch time: 138.06 s 
2025-12-22 03:06:27.812209:  
2025-12-22 03:06:27.812209: Epoch 700 
2025-12-22 03:06:27.819671: Current learning rate: 0.00338 
2025-12-22 03:08:45.905268: train_loss -0.8542 
2025-12-22 03:08:45.907270: val_loss -0.8807 
2025-12-22 03:08:45.913014: Pseudo dice [0.9312, 0.9566, 0.9414] 
2025-12-22 03:08:45.917018: Epoch time: 138.09 s 
2025-12-22 03:08:46.677697:  
2025-12-22 03:08:46.677697: Epoch 701 
2025-12-22 03:08:46.677697: Current learning rate: 0.00337 
2025-12-22 03:11:04.889113: train_loss -0.85 
2025-12-22 03:11:04.890910: val_loss -0.8928 
2025-12-22 03:11:04.896917: Pseudo dice [0.9421, 0.9635, 0.9423] 
2025-12-22 03:11:04.900922: Epoch time: 138.21 s 
2025-12-22 03:11:05.602534:  
2025-12-22 03:11:05.602534: Epoch 702 
2025-12-22 03:11:05.611452: Current learning rate: 0.00336 
2025-12-22 03:13:23.746785: train_loss -0.8548 
2025-12-22 03:13:23.748787: val_loss -0.8482 
2025-12-22 03:13:23.754793: Pseudo dice [0.9064, 0.9406, 0.9412] 
2025-12-22 03:13:23.762542: Epoch time: 138.14 s 
2025-12-22 03:13:24.408852:  
2025-12-22 03:13:24.408852: Epoch 703 
2025-12-22 03:13:24.424790: Current learning rate: 0.00335 
2025-12-22 03:15:42.422636: train_loss -0.8543 
2025-12-22 03:15:42.422636: val_loss -0.8751 
2025-12-22 03:15:42.440721: Pseudo dice [0.9281, 0.9568, 0.9402] 
2025-12-22 03:15:42.444725: Epoch time: 138.01 s 
2025-12-22 03:15:43.199191:  
2025-12-22 03:15:43.199191: Epoch 704 
2025-12-22 03:15:43.214890: Current learning rate: 0.00334 
2025-12-22 03:18:01.249511: train_loss -0.8557 
2025-12-22 03:18:01.249511: val_loss -0.8651 
2025-12-22 03:18:01.253515: Pseudo dice [0.9185, 0.948, 0.9419] 
2025-12-22 03:18:01.259456: Epoch time: 138.05 s 
2025-12-22 03:18:01.940958:  
2025-12-22 03:18:01.940958: Epoch 705 
2025-12-22 03:18:01.940958: Current learning rate: 0.00333 
2025-12-22 03:20:19.704291: train_loss -0.8609 
2025-12-22 03:20:19.704291: val_loss -0.8789 
2025-12-22 03:20:19.713302: Pseudo dice [0.9298, 0.9541, 0.947] 
2025-12-22 03:20:19.721052: Epoch time: 137.76 s 
2025-12-22 03:20:20.372752:  
2025-12-22 03:20:20.372752: Epoch 706 
2025-12-22 03:20:20.372752: Current learning rate: 0.00332 
2025-12-22 03:22:38.401258: train_loss -0.8544 
2025-12-22 03:22:38.401258: val_loss -0.8815 
2025-12-22 03:22:38.411051: Pseudo dice [0.9299, 0.9562, 0.9463] 
2025-12-22 03:22:38.417062: Epoch time: 138.03 s 
2025-12-22 03:22:39.184130:  
2025-12-22 03:22:39.184130: Epoch 707 
2025-12-22 03:22:39.184130: Current learning rate: 0.00331 
2025-12-22 03:24:56.995249: train_loss -0.8559 
2025-12-22 03:24:56.995249: val_loss -0.8831 
2025-12-22 03:24:57.002229: Pseudo dice [0.9341, 0.9563, 0.9424] 
2025-12-22 03:24:57.007235: Epoch time: 137.81 s 
2025-12-22 03:24:57.812435:  
2025-12-22 03:24:57.812435: Epoch 708 
2025-12-22 03:24:57.828265: Current learning rate: 0.0033 
2025-12-22 03:27:15.701309: train_loss -0.8547 
2025-12-22 03:27:15.703311: val_loss -0.8788 
2025-12-22 03:27:15.711059: Pseudo dice [0.932, 0.9574, 0.9373] 
2025-12-22 03:27:15.717066: Epoch time: 137.89 s 
2025-12-22 03:27:16.417654:  
2025-12-22 03:27:16.417654: Epoch 709 
2025-12-22 03:27:16.433775: Current learning rate: 0.00329 
2025-12-22 03:29:34.404319: train_loss -0.8513 
2025-12-22 03:29:34.406320: val_loss -0.8781 
2025-12-22 03:29:34.412326: Pseudo dice [0.9314, 0.9544, 0.9434] 
2025-12-22 03:29:34.416331: Epoch time: 137.99 s 
2025-12-22 03:29:35.069429:  
2025-12-22 03:29:35.069429: Epoch 710 
2025-12-22 03:29:35.078073: Current learning rate: 0.00328 
2025-12-22 03:31:52.940218: train_loss -0.8517 
2025-12-22 03:31:52.940218: val_loss -0.8753 
2025-12-22 03:31:52.948226: Pseudo dice [0.9261, 0.9593, 0.9422] 
2025-12-22 03:31:52.953970: Epoch time: 137.87 s 
2025-12-22 03:31:53.601627:  
2025-12-22 03:31:53.601627: Epoch 711 
2025-12-22 03:31:53.617409: Current learning rate: 0.00327 
2025-12-22 03:34:11.565405: train_loss -0.8501 
2025-12-22 03:34:11.565405: val_loss -0.874 
2025-12-22 03:34:11.571411: Pseudo dice [0.9259, 0.9548, 0.944] 
2025-12-22 03:34:11.576893: Epoch time: 137.96 s 
2025-12-22 03:34:12.303762:  
2025-12-22 03:34:12.303762: Epoch 712 
2025-12-22 03:34:12.308688: Current learning rate: 0.00326 
2025-12-22 03:36:30.317484: train_loss -0.8567 
2025-12-22 03:36:30.319486: val_loss -0.8765 
2025-12-22 03:36:30.325491: Pseudo dice [0.9262, 0.9557, 0.9422] 
2025-12-22 03:36:30.329233: Epoch time: 138.01 s 
2025-12-22 03:36:31.015341:  
2025-12-22 03:36:31.015341: Epoch 713 
2025-12-22 03:36:31.015341: Current learning rate: 0.00325 
2025-12-22 03:38:49.012972: train_loss -0.8562 
2025-12-22 03:38:49.012972: val_loss -0.8776 
2025-12-22 03:38:49.030438: Pseudo dice [0.9248, 0.9557, 0.9422] 
2025-12-22 03:38:49.030438: Epoch time: 138.0 s 
2025-12-22 03:38:49.853793:  
2025-12-22 03:38:49.853793: Epoch 714 
2025-12-22 03:38:49.865425: Current learning rate: 0.00324 
2025-12-22 03:41:07.857295: train_loss -0.855 
2025-12-22 03:41:07.857295: val_loss -0.8686 
2025-12-22 03:41:07.865042: Pseudo dice [0.9228, 0.9478, 0.9456] 
2025-12-22 03:41:07.871049: Epoch time: 138.0 s 
2025-12-22 03:41:08.517257:  
2025-12-22 03:41:08.517257: Epoch 715 
2025-12-22 03:41:08.517257: Current learning rate: 0.00323 
2025-12-22 03:43:26.451504: train_loss -0.8548 
2025-12-22 03:43:26.451504: val_loss -0.8701 
2025-12-22 03:43:26.467318: Pseudo dice [0.9257, 0.9574, 0.9302] 
2025-12-22 03:43:26.469486: Epoch time: 137.93 s 
2025-12-22 03:43:27.102762:  
2025-12-22 03:43:27.102762: Epoch 716 
2025-12-22 03:43:27.117361: Current learning rate: 0.00322 
2025-12-22 03:45:45.138753: train_loss -0.853 
2025-12-22 03:45:45.138753: val_loss -0.8629 
2025-12-22 03:45:45.147268: Pseudo dice [0.9226, 0.9514, 0.9371] 
2025-12-22 03:45:45.153274: Epoch time: 138.04 s 
2025-12-22 03:45:45.841764:  
2025-12-22 03:45:45.841764: Epoch 717 
2025-12-22 03:45:45.841764: Current learning rate: 0.00321 
2025-12-22 03:48:03.770503: train_loss -0.8566 
2025-12-22 03:48:03.770503: val_loss -0.8654 
2025-12-22 03:48:03.776510: Pseudo dice [0.9225, 0.9525, 0.9381] 
2025-12-22 03:48:03.780514: Epoch time: 137.93 s 
2025-12-22 03:48:04.512967:  
2025-12-22 03:48:04.512967: Epoch 718 
2025-12-22 03:48:04.518313: Current learning rate: 0.0032 
2025-12-22 03:50:22.373031: train_loss -0.8565 
2025-12-22 03:50:22.373031: val_loss -0.8861 
2025-12-22 03:50:22.373031: Pseudo dice [0.9343, 0.9609, 0.9431] 
2025-12-22 03:50:22.373031: Epoch time: 137.86 s 
2025-12-22 03:50:23.098006:  
2025-12-22 03:50:23.098006: Epoch 719 
2025-12-22 03:50:23.100864: Current learning rate: 0.00319 
2025-12-22 03:52:41.108930: train_loss -0.8526 
2025-12-22 03:52:41.108930: val_loss -0.8836 
2025-12-22 03:52:41.124783: Pseudo dice [0.9342, 0.9583, 0.9418] 
2025-12-22 03:52:41.124783: Epoch time: 138.03 s 
2025-12-22 03:52:41.934446:  
2025-12-22 03:52:41.934446: Epoch 720 
2025-12-22 03:52:41.951736: Current learning rate: 0.00318 
2025-12-22 03:54:59.882560: train_loss -0.8491 
2025-12-22 03:54:59.882560: val_loss -0.8722 
2025-12-22 03:54:59.898452: Pseudo dice [0.9257, 0.9533, 0.9428] 
2025-12-22 03:54:59.898452: Epoch time: 137.95 s 
2025-12-22 03:55:00.707142:  
2025-12-22 03:55:00.707142: Epoch 721 
2025-12-22 03:55:00.716424: Current learning rate: 0.00317 
2025-12-22 03:57:18.570202: train_loss -0.86 
2025-12-22 03:57:18.570202: val_loss -0.8879 
2025-12-22 03:57:18.585904: Pseudo dice [0.9339, 0.9624, 0.942] 
2025-12-22 03:57:18.585904: Epoch time: 137.86 s 
2025-12-22 03:57:19.234333:  
2025-12-22 03:57:19.234333: Epoch 722 
2025-12-22 03:57:19.234333: Current learning rate: 0.00316 
2025-12-22 03:59:37.099791: train_loss -0.8552 
2025-12-22 03:59:37.101794: val_loss -0.8732 
2025-12-22 03:59:37.107538: Pseudo dice [0.9243, 0.9555, 0.9401] 
2025-12-22 03:59:37.113544: Epoch time: 137.87 s 
2025-12-22 03:59:37.770129:  
2025-12-22 03:59:37.770129: Epoch 723 
2025-12-22 03:59:37.770129: Current learning rate: 0.00315 
2025-12-22 04:01:55.689904: train_loss -0.8517 
2025-12-22 04:01:55.689904: val_loss -0.8774 
2025-12-22 04:01:55.697635: Pseudo dice [0.9278, 0.9557, 0.9425] 
2025-12-22 04:01:55.701640: Epoch time: 137.92 s 
2025-12-22 04:01:56.455043:  
2025-12-22 04:01:56.455043: Epoch 724 
2025-12-22 04:01:56.470798: Current learning rate: 0.00314 
2025-12-22 04:04:14.410331: train_loss -0.8579 
2025-12-22 04:04:14.410331: val_loss -0.8708 
2025-12-22 04:04:14.416337: Pseudo dice [0.9266, 0.9546, 0.9399] 
2025-12-22 04:04:14.422344: Epoch time: 137.96 s 
2025-12-22 04:04:15.069208:  
2025-12-22 04:04:15.085182: Epoch 725 
2025-12-22 04:04:15.087075: Current learning rate: 0.00313 
2025-12-22 04:06:33.242154: train_loss -0.851 
2025-12-22 04:06:33.252174: val_loss -0.8694 
2025-12-22 04:06:33.252174: Pseudo dice [0.9259, 0.9524, 0.9424] 
2025-12-22 04:06:33.252174: Epoch time: 138.17 s 
2025-12-22 04:06:33.903325:  
2025-12-22 04:06:33.903325: Epoch 726 
2025-12-22 04:06:33.903325: Current learning rate: 0.00312 
2025-12-22 04:08:52.205573: train_loss -0.8536 
2025-12-22 04:08:52.205573: val_loss -0.8704 
2025-12-22 04:08:52.211272: Pseudo dice [0.9237, 0.9553, 0.9467] 
2025-12-22 04:08:52.218771: Epoch time: 138.3 s 
2025-12-22 04:08:52.966732:  
2025-12-22 04:08:52.966732: Epoch 727 
2025-12-22 04:08:52.970815: Current learning rate: 0.00311 
2025-12-22 04:11:11.185755: train_loss -0.853 
2025-12-22 04:11:11.185755: val_loss -0.8791 
2025-12-22 04:11:11.199851: Pseudo dice [0.9309, 0.9556, 0.9441] 
2025-12-22 04:11:11.199851: Epoch time: 138.22 s 
2025-12-22 04:11:11.864891:  
2025-12-22 04:11:11.864891: Epoch 728 
2025-12-22 04:11:11.864891: Current learning rate: 0.0031 
2025-12-22 04:13:29.827852: train_loss -0.8591 
2025-12-22 04:13:29.827852: val_loss -0.8762 
2025-12-22 04:13:29.833858: Pseudo dice [0.9272, 0.956, 0.9426] 
2025-12-22 04:13:29.837600: Epoch time: 137.96 s 
2025-12-22 04:13:30.491096:  
2025-12-22 04:13:30.491096: Epoch 729 
2025-12-22 04:13:30.491096: Current learning rate: 0.00309 
2025-12-22 04:15:48.498650: train_loss -0.8504 
2025-12-22 04:15:48.498650: val_loss -0.869 
2025-12-22 04:15:48.506135: Pseudo dice [0.9209, 0.952, 0.9343] 
2025-12-22 04:15:48.512738: Epoch time: 138.02 s 
2025-12-22 04:15:49.157201:  
2025-12-22 04:15:49.157201: Epoch 730 
2025-12-22 04:15:49.157201: Current learning rate: 0.00308 
2025-12-22 04:18:07.079018: train_loss -0.8523 
2025-12-22 04:18:07.079018: val_loss -0.8878 
2025-12-22 04:18:07.081021: Pseudo dice [0.9352, 0.962, 0.9407] 
2025-12-22 04:18:07.090884: Epoch time: 137.92 s 
2025-12-22 04:18:07.743232:  
2025-12-22 04:18:07.743232: Epoch 731 
2025-12-22 04:18:07.758997: Current learning rate: 0.00307 
2025-12-22 04:20:25.667367: train_loss -0.8569 
2025-12-22 04:20:25.667367: val_loss -0.8694 
2025-12-22 04:20:25.674460: Pseudo dice [0.9228, 0.9519, 0.9385] 
2025-12-22 04:20:25.674460: Epoch time: 137.92 s 
2025-12-22 04:20:26.556020:  
2025-12-22 04:20:26.556020: Epoch 732 
2025-12-22 04:20:26.571762: Current learning rate: 0.00306 
2025-12-22 04:22:44.522094: train_loss -0.8529 
2025-12-22 04:22:44.522094: val_loss -0.8816 
2025-12-22 04:22:44.522094: Pseudo dice [0.9341, 0.96, 0.9423] 
2025-12-22 04:22:44.522094: Epoch time: 137.97 s 
2025-12-22 04:22:45.173545:  
2025-12-22 04:22:45.173545: Epoch 733 
2025-12-22 04:22:45.189307: Current learning rate: 0.00305 
2025-12-22 04:25:03.388798: train_loss -0.8492 
2025-12-22 04:25:03.390800: val_loss -0.8821 
2025-12-22 04:25:03.396545: Pseudo dice [0.9292, 0.9552, 0.9539] 
2025-12-22 04:25:03.402552: Epoch time: 138.22 s 
2025-12-22 04:25:04.138227:  
2025-12-22 04:25:04.138227: Epoch 734 
2025-12-22 04:25:04.154136: Current learning rate: 0.00304 
2025-12-22 04:27:22.141192: train_loss -0.8587 
2025-12-22 04:27:22.141192: val_loss -0.8768 
2025-12-22 04:27:22.158901: Pseudo dice [0.9288, 0.9572, 0.9437] 
2025-12-22 04:27:22.164907: Epoch time: 138.0 s 
2025-12-22 04:27:22.822396:  
2025-12-22 04:27:22.822396: Epoch 735 
2025-12-22 04:27:22.838365: Current learning rate: 0.00303 
2025-12-22 04:29:40.695619: train_loss -0.854 
2025-12-22 04:29:40.695619: val_loss -0.8921 
2025-12-22 04:29:40.695619: Pseudo dice [0.9375, 0.964, 0.9463] 
2025-12-22 04:29:40.711297: Epoch time: 137.87 s 
2025-12-22 04:29:40.711297: Yayy! New best EMA pseudo Dice: 0.9428 
2025-12-22 04:29:41.644639:  
2025-12-22 04:29:41.644639: Epoch 736 
2025-12-22 04:29:41.644639: Current learning rate: 0.00302 
2025-12-22 04:31:59.608574: train_loss -0.8531 
2025-12-22 04:31:59.608574: val_loss -0.8887 
2025-12-22 04:31:59.624430: Pseudo dice [0.9376, 0.9645, 0.9441] 
2025-12-22 04:31:59.624430: Epoch time: 137.98 s 
2025-12-22 04:31:59.624430: Yayy! New best EMA pseudo Dice: 0.9434 
2025-12-22 04:32:00.560676:  
2025-12-22 04:32:00.560676: Epoch 737 
2025-12-22 04:32:00.576521: Current learning rate: 0.00301 
2025-12-22 04:34:18.456606: train_loss -0.8568 
2025-12-22 04:34:18.456606: val_loss -0.8825 
2025-12-22 04:34:18.456606: Pseudo dice [0.9297, 0.9579, 0.9455] 
2025-12-22 04:34:18.464928: Epoch time: 137.9 s 
2025-12-22 04:34:18.464928: Yayy! New best EMA pseudo Dice: 0.9435 
2025-12-22 04:34:19.594061:  
2025-12-22 04:34:19.594061: Epoch 738 
2025-12-22 04:34:19.596063: Current learning rate: 0.003 
2025-12-22 04:36:37.754931: train_loss -0.8538 
2025-12-22 04:36:37.754931: val_loss -0.8849 
2025-12-22 04:36:37.756935: Pseudo dice [0.9367, 0.9621, 0.9381] 
2025-12-22 04:36:37.756935: Epoch time: 138.16 s 
2025-12-22 04:36:37.756935: Yayy! New best EMA pseudo Dice: 0.9437 
2025-12-22 04:36:38.745351:  
2025-12-22 04:36:38.745351: Epoch 739 
2025-12-22 04:36:38.747093: Current learning rate: 0.00299 
2025-12-22 04:38:56.805083: train_loss -0.8575 
2025-12-22 04:38:56.807085: val_loss -0.8646 
2025-12-22 04:38:56.814326: Pseudo dice [0.9187, 0.9523, 0.9456] 
2025-12-22 04:38:56.818330: Epoch time: 138.06 s 
2025-12-22 04:38:57.481443:  
2025-12-22 04:38:57.481443: Epoch 740 
2025-12-22 04:38:57.486726: Current learning rate: 0.00297 
2025-12-22 04:41:15.572710: train_loss -0.8564 
2025-12-22 04:41:15.572710: val_loss -0.8719 
2025-12-22 04:41:15.580719: Pseudo dice [0.9241, 0.9522, 0.9454] 
2025-12-22 04:41:15.586463: Epoch time: 138.09 s 
2025-12-22 04:41:16.295465:  
2025-12-22 04:41:16.295465: Epoch 741 
2025-12-22 04:41:16.295465: Current learning rate: 0.00296 
2025-12-22 04:43:34.268062: train_loss -0.8581 
2025-12-22 04:43:34.268062: val_loss -0.8732 
2025-12-22 04:43:34.287640: Pseudo dice [0.9255, 0.9538, 0.9472] 
2025-12-22 04:43:34.291644: Epoch time: 137.97 s 
2025-12-22 04:43:34.996113:  
2025-12-22 04:43:34.996113: Epoch 742 
2025-12-22 04:43:34.998116: Current learning rate: 0.00295 
2025-12-22 04:45:53.134762: train_loss -0.854 
2025-12-22 04:45:53.134762: val_loss -0.8709 
2025-12-22 04:45:53.142419: Pseudo dice [0.9258, 0.9524, 0.9497] 
2025-12-22 04:45:53.148425: Epoch time: 138.14 s 
2025-12-22 04:45:53.958216:  
2025-12-22 04:45:53.958216: Epoch 743 
2025-12-22 04:45:53.958216: Current learning rate: 0.00294 
2025-12-22 04:48:11.847335: train_loss -0.8563 
2025-12-22 04:48:11.847335: val_loss -0.8769 
2025-12-22 04:48:11.863086: Pseudo dice [0.9279, 0.9549, 0.9464] 
2025-12-22 04:48:11.863086: Epoch time: 137.89 s 
2025-12-22 04:48:12.514644:  
2025-12-22 04:48:12.514644: Epoch 744 
2025-12-22 04:48:12.514644: Current learning rate: 0.00293 
2025-12-22 04:50:30.371578: train_loss -0.8534 
2025-12-22 04:50:30.371578: val_loss -0.866 
2025-12-22 04:50:30.387634: Pseudo dice [0.9156, 0.9538, 0.9468] 
2025-12-22 04:50:30.395187: Epoch time: 137.86 s 
2025-12-22 04:50:31.052876:  
2025-12-22 04:50:31.052876: Epoch 745 
2025-12-22 04:50:31.052876: Current learning rate: 0.00292 
2025-12-22 04:52:48.878254: train_loss -0.8575 
2025-12-22 04:52:48.878254: val_loss -0.8874 
2025-12-22 04:52:48.888004: Pseudo dice [0.935, 0.9622, 0.9481] 
2025-12-22 04:52:48.895752: Epoch time: 137.83 s 
2025-12-22 04:52:49.548977:  
2025-12-22 04:52:49.548977: Epoch 746 
2025-12-22 04:52:49.548977: Current learning rate: 0.00291 
2025-12-22 04:55:07.506163: train_loss -0.8529 
2025-12-22 04:55:07.506163: val_loss -0.8913 
2025-12-22 04:55:07.512171: Pseudo dice [0.9406, 0.9644, 0.939] 
2025-12-22 04:55:07.516176: Epoch time: 137.96 s 
2025-12-22 04:55:08.283026:  
2025-12-22 04:55:08.283026: Epoch 747 
2025-12-22 04:55:08.283026: Current learning rate: 0.0029 
2025-12-22 04:57:26.215366: train_loss -0.859 
2025-12-22 04:57:26.217369: val_loss -0.8795 
2025-12-22 04:57:26.227386: Pseudo dice [0.9307, 0.9581, 0.9441] 
2025-12-22 04:57:26.233130: Epoch time: 137.93 s 
2025-12-22 04:57:26.889094:  
2025-12-22 04:57:26.889094: Epoch 748 
2025-12-22 04:57:26.889094: Current learning rate: 0.00289 
2025-12-22 04:59:44.854905: train_loss -0.8503 
2025-12-22 04:59:44.856908: val_loss -0.8805 
2025-12-22 04:59:44.861379: Pseudo dice [0.9321, 0.9579, 0.9389] 
2025-12-22 04:59:44.861379: Epoch time: 137.97 s 
2025-12-22 04:59:45.684533:  
2025-12-22 04:59:45.684533: Epoch 749 
2025-12-22 04:59:45.684533: Current learning rate: 0.00288 
2025-12-22 05:02:03.559279: train_loss -0.86 
2025-12-22 05:02:03.559279: val_loss -0.8804 
2025-12-22 05:02:03.575028: Pseudo dice [0.9297, 0.9583, 0.9399] 
2025-12-22 05:02:03.575028: Epoch time: 137.88 s 
2025-12-22 05:02:04.678001:  
2025-12-22 05:02:04.678001: Epoch 750 
2025-12-22 05:02:04.681396: Current learning rate: 0.00287 
2025-12-22 05:04:22.641504: train_loss -0.8571 
2025-12-22 05:04:22.641504: val_loss -0.8719 
2025-12-22 05:04:22.650664: Pseudo dice [0.9235, 0.9557, 0.9434] 
2025-12-22 05:04:22.656671: Epoch time: 137.98 s 
2025-12-22 05:04:23.312343:  
2025-12-22 05:04:23.314345: Epoch 751 
2025-12-22 05:04:23.316553: Current learning rate: 0.00286 
2025-12-22 05:06:41.174544: train_loss -0.8595 
2025-12-22 05:06:41.174544: val_loss -0.8677 
2025-12-22 05:06:41.182164: Pseudo dice [0.9204, 0.954, 0.9416] 
2025-12-22 05:06:41.186168: Epoch time: 137.86 s 
2025-12-22 05:06:41.843044:  
2025-12-22 05:06:41.843044: Epoch 752 
2025-12-22 05:06:41.843044: Current learning rate: 0.00285 
2025-12-22 05:08:59.909691: train_loss -0.8594 
2025-12-22 05:08:59.911693: val_loss -0.8869 
2025-12-22 05:08:59.919702: Pseudo dice [0.9349, 0.96, 0.9428] 
2025-12-22 05:08:59.925709: Epoch time: 138.07 s 
2025-12-22 05:09:00.724816:  
2025-12-22 05:09:00.724816: Epoch 753 
2025-12-22 05:09:00.724816: Current learning rate: 0.00284 
2025-12-22 05:11:19.052457: train_loss -0.8611 
2025-12-22 05:11:19.052457: val_loss -0.877 
2025-12-22 05:11:19.058463: Pseudo dice [0.9268, 0.9554, 0.9437] 
2025-12-22 05:11:19.062468: Epoch time: 138.33 s 
2025-12-22 05:11:19.716049:  
2025-12-22 05:11:19.716049: Epoch 754 
2025-12-22 05:11:19.716049: Current learning rate: 0.00283 
2025-12-22 05:13:37.840485: train_loss -0.8578 
2025-12-22 05:13:37.840485: val_loss -0.885 
2025-12-22 05:13:37.848405: Pseudo dice [0.9335, 0.9597, 0.9431] 
2025-12-22 05:13:37.854411: Epoch time: 138.12 s 
2025-12-22 05:13:38.664168:  
2025-12-22 05:13:38.664168: Epoch 755 
2025-12-22 05:13:38.680138: Current learning rate: 0.00282 
2025-12-22 05:15:56.540751: train_loss -0.8643 
2025-12-22 05:15:56.540751: val_loss -0.8938 
2025-12-22 05:15:56.540751: Pseudo dice [0.9359, 0.9636, 0.9502] 
2025-12-22 05:15:56.540751: Epoch time: 137.88 s 
2025-12-22 05:15:56.556519: Yayy! New best EMA pseudo Dice: 0.9439 
2025-12-22 05:15:57.655391:  
2025-12-22 05:15:57.657394: Epoch 756 
2025-12-22 05:15:57.663193: Current learning rate: 0.00281 
2025-12-22 05:18:15.364626: train_loss -0.861 
2025-12-22 05:18:15.365628: val_loss -0.8765 
2025-12-22 05:18:15.373573: Pseudo dice [0.9296, 0.9576, 0.9389] 
2025-12-22 05:18:15.377578: Epoch time: 137.71 s 
2025-12-22 05:18:16.041732:  
2025-12-22 05:18:16.041732: Epoch 757 
2025-12-22 05:18:16.041732: Current learning rate: 0.0028 
2025-12-22 05:20:34.075479: train_loss -0.8531 
2025-12-22 05:20:34.075479: val_loss -0.8905 
2025-12-22 05:20:34.095152: Pseudo dice [0.9379, 0.964, 0.9456] 
2025-12-22 05:20:34.099157: Epoch time: 138.04 s 
2025-12-22 05:20:34.104901: Yayy! New best EMA pseudo Dice: 0.9442 
2025-12-22 05:20:35.024275:  
2025-12-22 05:20:35.024275: Epoch 758 
2025-12-22 05:20:35.044348: Current learning rate: 0.00279 
2025-12-22 05:22:52.951247: train_loss -0.8574 
2025-12-22 05:22:52.951247: val_loss -0.8785 
2025-12-22 05:22:52.963186: Pseudo dice [0.9315, 0.9592, 0.939] 
2025-12-22 05:22:52.967190: Epoch time: 137.93 s 
2025-12-22 05:22:53.734592:  
2025-12-22 05:22:53.734592: Epoch 759 
2025-12-22 05:22:53.750674: Current learning rate: 0.00278 
2025-12-22 05:25:11.745105: train_loss -0.8563 
2025-12-22 05:25:11.745105: val_loss -0.8836 
2025-12-22 05:25:11.751110: Pseudo dice [0.9315, 0.9608, 0.9425] 
2025-12-22 05:25:11.757237: Epoch time: 138.01 s 
2025-12-22 05:25:12.407234:  
2025-12-22 05:25:12.407234: Epoch 760 
2025-12-22 05:25:12.407234: Current learning rate: 0.00277 
2025-12-22 05:27:30.388370: train_loss -0.8585 
2025-12-22 05:27:30.390373: val_loss -0.8857 
2025-12-22 05:27:30.400392: Pseudo dice [0.9319, 0.9579, 0.9486] 
2025-12-22 05:27:30.406139: Epoch time: 137.98 s 
2025-12-22 05:27:30.414153: Yayy! New best EMA pseudo Dice: 0.9444 
2025-12-22 05:27:31.526138:  
2025-12-22 05:27:31.526138: Epoch 761 
2025-12-22 05:27:31.537838: Current learning rate: 0.00276 
2025-12-22 05:29:49.377275: train_loss -0.8594 
2025-12-22 05:29:49.377275: val_loss -0.8809 
2025-12-22 05:29:49.389074: Pseudo dice [0.9299, 0.9598, 0.942] 
2025-12-22 05:29:49.389074: Epoch time: 137.85 s 
2025-12-22 05:29:50.187867:  
2025-12-22 05:29:50.187867: Epoch 762 
2025-12-22 05:29:50.189871: Current learning rate: 0.00275 
2025-12-22 05:32:07.990030: train_loss -0.859 
2025-12-22 05:32:07.992037: val_loss -0.8786 
2025-12-22 05:32:08.001791: Pseudo dice [0.9312, 0.9559, 0.9394] 
2025-12-22 05:32:08.005795: Epoch time: 137.8 s 
2025-12-22 05:32:08.678184:  
2025-12-22 05:32:08.678184: Epoch 763 
2025-12-22 05:32:08.678184: Current learning rate: 0.00274 
2025-12-22 05:34:26.528809: train_loss -0.8558 
2025-12-22 05:34:26.528809: val_loss -0.8767 
2025-12-22 05:34:26.548286: Pseudo dice [0.9298, 0.954, 0.943] 
2025-12-22 05:34:26.552291: Epoch time: 137.85 s 
2025-12-22 05:34:27.209230:  
2025-12-22 05:34:27.209230: Epoch 764 
2025-12-22 05:34:27.225327: Current learning rate: 0.00273 
2025-12-22 05:36:45.140338: train_loss -0.8562 
2025-12-22 05:36:45.140338: val_loss -0.8811 
2025-12-22 05:36:45.140338: Pseudo dice [0.9298, 0.9573, 0.9466] 
2025-12-22 05:36:45.156044: Epoch time: 137.93 s 
2025-12-22 05:36:45.807284:  
2025-12-22 05:36:45.807284: Epoch 765 
2025-12-22 05:36:45.807284: Current learning rate: 0.00272 
2025-12-22 05:39:03.741243: train_loss -0.8568 
2025-12-22 05:39:03.741243: val_loss -0.8762 
2025-12-22 05:39:03.741243: Pseudo dice [0.9285, 0.9562, 0.9418] 
2025-12-22 05:39:03.757174: Epoch time: 137.93 s 
2025-12-22 05:39:04.568699:  
2025-12-22 05:39:04.568699: Epoch 766 
2025-12-22 05:39:04.584780: Current learning rate: 0.00271 
2025-12-22 05:41:22.708686: train_loss -0.8577 
2025-12-22 05:41:22.708686: val_loss -0.8734 
2025-12-22 05:41:22.724731: Pseudo dice [0.9231, 0.9517, 0.9442] 
2025-12-22 05:41:22.724731: Epoch time: 138.14 s 
2025-12-22 05:41:23.377875:  
2025-12-22 05:41:23.377875: Epoch 767 
2025-12-22 05:41:23.391565: Current learning rate: 0.0027 
2025-12-22 05:43:41.232213: train_loss -0.8596 
2025-12-22 05:43:41.234215: val_loss -0.8698 
2025-12-22 05:43:41.239774: Pseudo dice [0.9224, 0.9515, 0.943] 
2025-12-22 05:43:41.239774: Epoch time: 137.85 s 
2025-12-22 05:43:41.896152:  
2025-12-22 05:43:41.896152: Epoch 768 
2025-12-22 05:43:41.911782: Current learning rate: 0.00268 
2025-12-22 05:45:59.642117: train_loss -0.8618 
2025-12-22 05:45:59.642117: val_loss -0.8988 
2025-12-22 05:45:59.657886: Pseudo dice [0.9424, 0.9662, 0.947] 
2025-12-22 05:45:59.657886: Epoch time: 137.75 s 
2025-12-22 05:46:00.309427:  
2025-12-22 05:46:00.309427: Epoch 769 
2025-12-22 05:46:00.325119: Current learning rate: 0.00267 
2025-12-22 05:48:18.060037: train_loss -0.8579 
2025-12-22 05:48:18.060037: val_loss -0.8802 
2025-12-22 05:48:18.066040: Pseudo dice [0.9325, 0.9579, 0.9405] 
2025-12-22 05:48:18.066040: Epoch time: 137.75 s 
2025-12-22 05:48:18.769289:  
2025-12-22 05:48:18.769289: Epoch 770 
2025-12-22 05:48:18.784956: Current learning rate: 0.00266 
2025-12-22 05:50:36.766386: train_loss -0.8592 
2025-12-22 05:50:36.766386: val_loss -0.8651 
2025-12-22 05:50:36.774135: Pseudo dice [0.9199, 0.951, 0.9395] 
2025-12-22 05:50:36.780143: Epoch time: 138.0 s 
2025-12-22 05:50:37.448971:  
2025-12-22 05:50:37.448971: Epoch 771 
2025-12-22 05:50:37.448971: Current learning rate: 0.00265 
2025-12-22 05:52:55.455119: train_loss -0.857 
2025-12-22 05:52:55.455119: val_loss -0.8906 
2025-12-22 05:52:55.470782: Pseudo dice [0.9388, 0.9621, 0.9424] 
2025-12-22 05:52:55.474604: Epoch time: 138.01 s 
2025-12-22 05:52:56.340276:  
2025-12-22 05:52:56.356062: Epoch 772 
2025-12-22 05:52:56.356062: Current learning rate: 0.00264 
2025-12-22 05:55:14.307402: train_loss -0.8564 
2025-12-22 05:55:14.307402: val_loss -0.8732 
2025-12-22 05:55:14.323517: Pseudo dice [0.9254, 0.9501, 0.9443] 
2025-12-22 05:55:14.323517: Epoch time: 137.97 s 
2025-12-22 05:55:15.134061:  
2025-12-22 05:55:15.134061: Epoch 773 
2025-12-22 05:55:15.134061: Current learning rate: 0.00263 
2025-12-22 05:57:33.101418: train_loss -0.8568 
2025-12-22 05:57:33.101418: val_loss -0.8935 
2025-12-22 05:57:33.111166: Pseudo dice [0.9404, 0.9629, 0.9434] 
2025-12-22 05:57:33.117172: Epoch time: 137.97 s 
2025-12-22 05:57:33.776093:  
2025-12-22 05:57:33.776093: Epoch 774 
2025-12-22 05:57:33.776093: Current learning rate: 0.00262 
2025-12-22 05:59:51.869177: train_loss -0.8558 
2025-12-22 05:59:51.869177: val_loss -0.8921 
2025-12-22 05:59:51.884836: Pseudo dice [0.9399, 0.9616, 0.9421] 
2025-12-22 05:59:51.884836: Epoch time: 138.09 s 
2025-12-22 05:59:52.551645:  
2025-12-22 05:59:52.551645: Epoch 775 
2025-12-22 05:59:52.551645: Current learning rate: 0.00261 
2025-12-22 06:02:10.410004: train_loss -0.8585 
2025-12-22 06:02:10.410004: val_loss -0.8608 
2025-12-22 06:02:10.419754: Pseudo dice [0.9114, 0.9486, 0.9417] 
2025-12-22 06:02:10.425760: Epoch time: 137.86 s 
2025-12-22 06:02:11.210625:  
2025-12-22 06:02:11.210625: Epoch 776 
2025-12-22 06:02:11.210625: Current learning rate: 0.0026 
2025-12-22 06:04:29.335406: train_loss -0.8558 
2025-12-22 06:04:29.335406: val_loss -0.8702 
2025-12-22 06:04:29.335406: Pseudo dice [0.9263, 0.9516, 0.9377] 
2025-12-22 06:04:29.335406: Epoch time: 138.12 s 
2025-12-22 06:04:30.002516:  
2025-12-22 06:04:30.002516: Epoch 777 
2025-12-22 06:04:30.002516: Current learning rate: 0.00259 
2025-12-22 06:06:47.961687: train_loss -0.8597 
2025-12-22 06:06:47.961687: val_loss -0.8843 
2025-12-22 06:06:47.969694: Pseudo dice [0.9324, 0.9595, 0.9428] 
2025-12-22 06:06:47.973438: Epoch time: 137.96 s 
2025-12-22 06:06:48.800284:  
2025-12-22 06:06:48.800284: Epoch 778 
2025-12-22 06:06:48.814204: Current learning rate: 0.00258 
2025-12-22 06:09:07.150464: train_loss -0.8552 
2025-12-22 06:09:07.150464: val_loss -0.8772 
2025-12-22 06:09:07.156471: Pseudo dice [0.9279, 0.9543, 0.9462] 
2025-12-22 06:09:07.162214: Epoch time: 138.35 s 
2025-12-22 06:09:07.971235:  
2025-12-22 06:09:07.971235: Epoch 779 
2025-12-22 06:09:07.986884: Current learning rate: 0.00257 
2025-12-22 06:11:26.141641: train_loss -0.8579 
2025-12-22 06:11:26.141641: val_loss -0.8758 
2025-12-22 06:11:26.143382: Pseudo dice [0.925, 0.9512, 0.9491] 
2025-12-22 06:11:26.143382: Epoch time: 138.17 s 
2025-12-22 06:11:26.809535:  
2025-12-22 06:11:26.809535: Epoch 780 
2025-12-22 06:11:26.823550: Current learning rate: 0.00256 
2025-12-22 06:13:44.658343: train_loss -0.8608 
2025-12-22 06:13:44.658343: val_loss -0.8831 
2025-12-22 06:13:44.666089: Pseudo dice [0.9304, 0.9563, 0.9439] 
2025-12-22 06:13:44.668091: Epoch time: 137.85 s 
2025-12-22 06:13:45.328240:  
2025-12-22 06:13:45.328240: Epoch 781 
2025-12-22 06:13:45.344087: Current learning rate: 0.00255 
2025-12-22 06:16:03.139479: train_loss -0.8638 
2025-12-22 06:16:03.141481: val_loss -0.8728 
2025-12-22 06:16:03.149228: Pseudo dice [0.9249, 0.9546, 0.9429] 
2025-12-22 06:16:03.157236: Epoch time: 137.81 s 
2025-12-22 06:16:03.934850:  
2025-12-22 06:16:03.934850: Epoch 782 
2025-12-22 06:16:03.950670: Current learning rate: 0.00254 
2025-12-22 06:18:21.916819: train_loss -0.8567 
2025-12-22 06:18:21.916819: val_loss -0.8789 
2025-12-22 06:18:21.916819: Pseudo dice [0.9316, 0.9587, 0.936] 
2025-12-22 06:18:21.932717: Epoch time: 137.98 s 
2025-12-22 06:18:22.584273:  
2025-12-22 06:18:22.584273: Epoch 783 
2025-12-22 06:18:22.598292: Current learning rate: 0.00253 
2025-12-22 06:20:40.542322: train_loss -0.8591 
2025-12-22 06:20:40.542322: val_loss -0.8765 
2025-12-22 06:20:40.552334: Pseudo dice [0.9289, 0.9538, 0.9392] 
2025-12-22 06:20:40.558078: Epoch time: 137.96 s 
2025-12-22 06:20:41.380320:  
2025-12-22 06:20:41.380320: Epoch 784 
2025-12-22 06:20:41.396393: Current learning rate: 0.00252 
2025-12-22 06:22:59.389866: train_loss -0.8612 
2025-12-22 06:22:59.389866: val_loss -0.8801 
2025-12-22 06:22:59.397876: Pseudo dice [0.9309, 0.9566, 0.9429] 
2025-12-22 06:22:59.401618: Epoch time: 138.01 s 
2025-12-22 06:23:00.141880:  
2025-12-22 06:23:00.141880: Epoch 785 
2025-12-22 06:23:00.141880: Current learning rate: 0.00251 
2025-12-22 06:25:18.064107: train_loss -0.8613 
2025-12-22 06:25:18.064107: val_loss -0.8853 
2025-12-22 06:25:18.064107: Pseudo dice [0.936, 0.9577, 0.949] 
2025-12-22 06:25:18.082127: Epoch time: 137.92 s 
2025-12-22 06:25:18.730330:  
2025-12-22 06:25:18.730330: Epoch 786 
2025-12-22 06:25:18.746380: Current learning rate: 0.0025 
2025-12-22 06:27:36.517255: train_loss -0.8621 
2025-12-22 06:27:36.517255: val_loss -0.8918 
2025-12-22 06:27:36.517255: Pseudo dice [0.9361, 0.9641, 0.9504] 
2025-12-22 06:27:36.517255: Epoch time: 137.79 s 
2025-12-22 06:27:37.200779:  
2025-12-22 06:27:37.216764: Epoch 787 
2025-12-22 06:27:37.220742: Current learning rate: 0.00249 
2025-12-22 06:29:55.268990: train_loss -0.8558 
2025-12-22 06:29:55.268990: val_loss -0.8673 
2025-12-22 06:29:55.268990: Pseudo dice [0.9234, 0.9529, 0.9374] 
2025-12-22 06:29:55.284728: Epoch time: 138.07 s 
2025-12-22 06:29:56.028655:  
2025-12-22 06:29:56.028655: Epoch 788 
2025-12-22 06:29:56.028655: Current learning rate: 0.00248 
2025-12-22 06:32:13.848489: train_loss -0.858 
2025-12-22 06:32:13.848489: val_loss -0.8681 
2025-12-22 06:32:13.854233: Pseudo dice [0.9195, 0.9548, 0.9404] 
2025-12-22 06:32:13.859977: Epoch time: 137.82 s 
2025-12-22 06:32:14.502635:  
2025-12-22 06:32:14.502635: Epoch 789 
2025-12-22 06:32:14.518759: Current learning rate: 0.00247 
2025-12-22 06:34:32.478941: train_loss -0.8579 
2025-12-22 06:34:32.478941: val_loss -0.8821 
2025-12-22 06:34:32.494963: Pseudo dice [0.9286, 0.9573, 0.9478] 
2025-12-22 06:34:32.494963: Epoch time: 137.98 s 
2025-12-22 06:34:33.383771:  
2025-12-22 06:34:33.383771: Epoch 790 
2025-12-22 06:34:33.383771: Current learning rate: 0.00245 
2025-12-22 06:36:51.192839: train_loss -0.8604 
2025-12-22 06:36:51.192839: val_loss -0.8757 
2025-12-22 06:36:51.204624: Pseudo dice [0.926, 0.9532, 0.9457] 
2025-12-22 06:36:51.204624: Epoch time: 137.81 s 
2025-12-22 06:36:51.916280:  
2025-12-22 06:36:51.916280: Epoch 791 
2025-12-22 06:36:51.916280: Current learning rate: 0.00244 
2025-12-22 06:39:09.751312: train_loss -0.8623 
2025-12-22 06:39:09.751312: val_loss -0.8654 
2025-12-22 06:39:09.751312: Pseudo dice [0.9137, 0.9465, 0.9535] 
2025-12-22 06:39:09.762926: Epoch time: 137.84 s 
2025-12-22 06:39:10.426251:  
2025-12-22 06:39:10.426251: Epoch 792 
2025-12-22 06:39:10.441953: Current learning rate: 0.00243 
2025-12-22 06:41:28.426996: train_loss -0.8598 
2025-12-22 06:41:28.426996: val_loss -0.8583 
2025-12-22 06:41:28.432747: Pseudo dice [0.9158, 0.9475, 0.9371] 
2025-12-22 06:41:28.438757: Epoch time: 138.0 s 
2025-12-22 06:41:29.236118:  
2025-12-22 06:41:29.236118: Epoch 793 
2025-12-22 06:41:29.251844: Current learning rate: 0.00242 
2025-12-22 06:43:47.233563: train_loss -0.8577 
2025-12-22 06:43:47.235566: val_loss -0.8761 
2025-12-22 06:43:47.239570: Pseudo dice [0.9267, 0.9536, 0.952] 
2025-12-22 06:43:47.245575: Epoch time: 138.0 s 
2025-12-22 06:43:47.914461:  
2025-12-22 06:43:47.914461: Epoch 794 
2025-12-22 06:43:47.914461: Current learning rate: 0.00241 
2025-12-22 06:46:05.774909: train_loss -0.8606 
2025-12-22 06:46:05.774909: val_loss -0.8855 
2025-12-22 06:46:05.782917: Pseudo dice [0.9327, 0.9599, 0.9446] 
2025-12-22 06:46:05.790665: Epoch time: 137.86 s 
2025-12-22 06:46:06.450628:  
2025-12-22 06:46:06.450628: Epoch 795 
2025-12-22 06:46:06.450628: Current learning rate: 0.0024 
2025-12-22 06:48:24.434414: train_loss -0.8577 
2025-12-22 06:48:24.436154: val_loss -0.8754 
2025-12-22 06:48:24.446169: Pseudo dice [0.9288, 0.9506, 0.9438] 
2025-12-22 06:48:24.455923: Epoch time: 137.98 s 
2025-12-22 06:48:25.498317:  
2025-12-22 06:48:25.498317: Epoch 796 
2025-12-22 06:48:25.498317: Current learning rate: 0.00239 
2025-12-22 06:50:43.366136: train_loss -0.8583 
2025-12-22 06:50:43.366136: val_loss -0.874 
2025-12-22 06:50:43.380137: Pseudo dice [0.9248, 0.9517, 0.9435] 
2025-12-22 06:50:43.380137: Epoch time: 137.87 s 
2025-12-22 06:50:44.047715:  
2025-12-22 06:50:44.047715: Epoch 797 
2025-12-22 06:50:44.061762: Current learning rate: 0.00238 
2025-12-22 06:53:01.881540: train_loss -0.8604 
2025-12-22 06:53:01.881540: val_loss -0.8824 
2025-12-22 06:53:01.886292: Pseudo dice [0.93, 0.9552, 0.9476] 
2025-12-22 06:53:01.892298: Epoch time: 137.83 s 
2025-12-22 06:53:02.548578:  
2025-12-22 06:53:02.548578: Epoch 798 
2025-12-22 06:53:02.548578: Current learning rate: 0.00237 
2025-12-22 06:55:20.378083: train_loss -0.8578 
2025-12-22 06:55:20.378083: val_loss -0.8846 
2025-12-22 06:55:20.394169: Pseudo dice [0.9321, 0.9606, 0.9411] 
2025-12-22 06:55:20.394169: Epoch time: 137.83 s 
2025-12-22 06:55:21.215801:  
2025-12-22 06:55:21.215801: Epoch 799 
2025-12-22 06:55:21.215801: Current learning rate: 0.00236 
2025-12-22 06:57:39.017294: train_loss -0.859 
2025-12-22 06:57:39.017294: val_loss -0.8826 
2025-12-22 06:57:39.017294: Pseudo dice [0.931, 0.9567, 0.9467] 
2025-12-22 06:57:39.017294: Epoch time: 137.8 s 
2025-12-22 06:57:39.947645:  
2025-12-22 06:57:39.947645: Epoch 800 
2025-12-22 06:57:39.963469: Current learning rate: 0.00235 
2025-12-22 06:59:57.863880: train_loss -0.8565 
2025-12-22 06:59:57.863880: val_loss -0.8886 
2025-12-22 06:59:57.863880: Pseudo dice [0.937, 0.961, 0.9454] 
2025-12-22 06:59:57.872146: Epoch time: 137.92 s 
2025-12-22 06:59:58.595566:  
2025-12-22 06:59:58.595566: Epoch 801 
2025-12-22 06:59:58.595566: Current learning rate: 0.00234 
2025-12-22 07:02:16.385267: train_loss -0.8559 
2025-12-22 07:02:16.385267: val_loss -0.8707 
2025-12-22 07:02:16.393280: Pseudo dice [0.9245, 0.9513, 0.9364] 
2025-12-22 07:02:16.401026: Epoch time: 137.79 s 
2025-12-22 07:02:17.262094:  
2025-12-22 07:02:17.262094: Epoch 802 
2025-12-22 07:02:17.275790: Current learning rate: 0.00233 
2025-12-22 07:04:35.183285: train_loss -0.8613 
2025-12-22 07:04:35.183285: val_loss -0.8679 
2025-12-22 07:04:35.188128: Pseudo dice [0.9194, 0.9527, 0.9381] 
2025-12-22 07:04:35.194007: Epoch time: 137.92 s 
2025-12-22 07:04:35.865772:  
2025-12-22 07:04:35.865772: Epoch 803 
2025-12-22 07:04:35.865772: Current learning rate: 0.00232 
2025-12-22 07:06:53.699028: train_loss -0.8596 
2025-12-22 07:06:53.699028: val_loss -0.8847 
2025-12-22 07:06:53.707037: Pseudo dice [0.9326, 0.9573, 0.9467] 
2025-12-22 07:06:53.713892: Epoch time: 137.83 s 
2025-12-22 07:06:54.379019:  
2025-12-22 07:06:54.379019: Epoch 804 
2025-12-22 07:06:54.379019: Current learning rate: 0.00231 
2025-12-22 07:09:12.318235: train_loss -0.8573 
2025-12-22 07:09:12.318235: val_loss -0.8754 
2025-12-22 07:09:12.340460: Pseudo dice [0.9282, 0.9555, 0.9442] 
2025-12-22 07:09:12.344464: Epoch time: 137.94 s 
2025-12-22 07:09:13.014360:  
2025-12-22 07:09:13.014360: Epoch 805 
2025-12-22 07:09:13.030259: Current learning rate: 0.0023 
2025-12-22 07:11:31.080812: train_loss -0.8587 
2025-12-22 07:11:31.080812: val_loss -0.875 
2025-12-22 07:11:31.090317: Pseudo dice [0.9267, 0.953, 0.9427] 
2025-12-22 07:11:31.094322: Epoch time: 138.07 s 
2025-12-22 07:11:31.760356:  
2025-12-22 07:11:31.760356: Epoch 806 
2025-12-22 07:11:31.760356: Current learning rate: 0.00229 
2025-12-22 07:13:49.488621: train_loss -0.8661 
2025-12-22 07:13:49.488621: val_loss -0.8766 
2025-12-22 07:13:49.498637: Pseudo dice [0.931, 0.9541, 0.9425] 
2025-12-22 07:13:49.504653: Epoch time: 137.73 s 
2025-12-22 07:13:50.364573:  
2025-12-22 07:13:50.364573: Epoch 807 
2025-12-22 07:13:50.380388: Current learning rate: 0.00228 
2025-12-22 07:16:08.509593: train_loss -0.8606 
2025-12-22 07:16:08.509593: val_loss -0.8906 
2025-12-22 07:16:08.509593: Pseudo dice [0.9351, 0.9627, 0.9466] 
2025-12-22 07:16:08.525586: Epoch time: 138.15 s 
2025-12-22 07:16:09.191755:  
2025-12-22 07:16:09.191755: Epoch 808 
2025-12-22 07:16:09.191755: Current learning rate: 0.00226 
2025-12-22 07:18:26.939220: train_loss -0.8606 
2025-12-22 07:18:26.939220: val_loss -0.8751 
2025-12-22 07:18:26.939220: Pseudo dice [0.9317, 0.9554, 0.9332] 
2025-12-22 07:18:26.939220: Epoch time: 137.75 s 
2025-12-22 07:18:27.607477:  
2025-12-22 07:18:27.607477: Epoch 809 
2025-12-22 07:18:27.607477: Current learning rate: 0.00225 
2025-12-22 07:20:45.438909: train_loss -0.8582 
2025-12-22 07:20:45.438909: val_loss -0.8691 
2025-12-22 07:20:45.447726: Pseudo dice [0.9214, 0.9496, 0.9417] 
2025-12-22 07:20:45.448727: Epoch time: 137.83 s 
2025-12-22 07:20:46.162246:  
2025-12-22 07:20:46.162246: Epoch 810 
2025-12-22 07:20:46.162246: Current learning rate: 0.00224 
2025-12-22 07:23:04.059863: train_loss -0.8604 
2025-12-22 07:23:04.061865: val_loss -0.8936 
2025-12-22 07:23:04.067872: Pseudo dice [0.9386, 0.9628, 0.9448] 
2025-12-22 07:23:04.071876: Epoch time: 137.9 s 
2025-12-22 07:23:04.745722:  
2025-12-22 07:23:04.745722: Epoch 811 
2025-12-22 07:23:04.750135: Current learning rate: 0.00223 
2025-12-22 07:25:22.831534: train_loss -0.8522 
2025-12-22 07:25:22.831534: val_loss -0.8755 
2025-12-22 07:25:22.847407: Pseudo dice [0.9232, 0.9509, 0.9463] 
2025-12-22 07:25:22.856658: Epoch time: 138.09 s 
2025-12-22 07:25:23.518538:  
2025-12-22 07:25:23.518538: Epoch 812 
2025-12-22 07:25:23.534200: Current learning rate: 0.00222 
2025-12-22 07:27:41.312077: train_loss -0.8556 
2025-12-22 07:27:41.314671: val_loss -0.8536 
2025-12-22 07:27:41.318676: Pseudo dice [0.9111, 0.9493, 0.9351] 
2025-12-22 07:27:41.324682: Epoch time: 137.79 s 
2025-12-22 07:27:42.326397:  
2025-12-22 07:27:42.326397: Epoch 813 
2025-12-22 07:27:42.334966: Current learning rate: 0.00221 
2025-12-22 07:30:00.052508: train_loss -0.8602 
2025-12-22 07:30:00.052508: val_loss -0.8821 
2025-12-22 07:30:00.060516: Pseudo dice [0.9282, 0.956, 0.9501] 
2025-12-22 07:30:00.064520: Epoch time: 137.73 s 
2025-12-22 07:30:00.737934:  
2025-12-22 07:30:00.739936: Epoch 814 
2025-12-22 07:30:00.739936: Current learning rate: 0.0022 
2025-12-22 07:32:18.789417: train_loss -0.8569 
2025-12-22 07:32:18.789417: val_loss -0.8714 
2025-12-22 07:32:18.808922: Pseudo dice [0.9265, 0.9512, 0.9411] 
2025-12-22 07:32:18.814928: Epoch time: 138.05 s 
2025-12-22 07:32:19.485265:  
2025-12-22 07:32:19.485265: Epoch 815 
2025-12-22 07:32:19.485265: Current learning rate: 0.00219 
2025-12-22 07:34:37.335125: train_loss -0.8563 
2025-12-22 07:34:37.335125: val_loss -0.8811 
2025-12-22 07:34:37.341131: Pseudo dice [0.9307, 0.9565, 0.9447] 
2025-12-22 07:34:37.345136: Epoch time: 137.87 s 
2025-12-22 07:34:38.138575:  
2025-12-22 07:34:38.138575: Epoch 816 
2025-12-22 07:34:38.149122: Current learning rate: 0.00218 
2025-12-22 07:36:56.005769: train_loss -0.8585 
2025-12-22 07:36:56.005769: val_loss -0.8917 
2025-12-22 07:36:56.005769: Pseudo dice [0.9417, 0.9656, 0.9358] 
2025-12-22 07:36:56.014610: Epoch time: 137.87 s 
2025-12-22 07:36:56.673159:  
2025-12-22 07:36:56.676666: Epoch 817 
2025-12-22 07:36:56.676666: Current learning rate: 0.00217 
2025-12-22 07:39:14.623063: train_loss -0.8575 
2025-12-22 07:39:14.623063: val_loss -0.8743 
2025-12-22 07:39:14.629068: Pseudo dice [0.9268, 0.9568, 0.9378] 
2025-12-22 07:39:14.634573: Epoch time: 137.95 s 
2025-12-22 07:39:15.308204:  
2025-12-22 07:39:15.308204: Epoch 818 
2025-12-22 07:39:15.308204: Current learning rate: 0.00216 
2025-12-22 07:41:33.336002: train_loss -0.8568 
2025-12-22 07:41:33.338005: val_loss -0.8783 
2025-12-22 07:41:33.343762: Pseudo dice [0.9248, 0.9583, 0.948] 
2025-12-22 07:41:33.349771: Epoch time: 138.03 s 
2025-12-22 07:41:34.318309:  
2025-12-22 07:41:34.318309: Epoch 819 
2025-12-22 07:41:34.336052: Current learning rate: 0.00215 
2025-12-22 07:43:52.153049: train_loss -0.857 
2025-12-22 07:43:52.153049: val_loss -0.8882 
2025-12-22 07:43:52.161058: Pseudo dice [0.9333, 0.9588, 0.9517] 
2025-12-22 07:43:52.168798: Epoch time: 137.83 s 
2025-12-22 07:43:52.812573:  
2025-12-22 07:43:52.812573: Epoch 820 
2025-12-22 07:43:52.812573: Current learning rate: 0.00214 
2025-12-22 07:46:10.626189: train_loss -0.8575 
2025-12-22 07:46:10.626189: val_loss -0.87 
2025-12-22 07:46:10.645607: Pseudo dice [0.9243, 0.9513, 0.9393] 
2025-12-22 07:46:10.651613: Epoch time: 137.82 s 
2025-12-22 07:46:11.289327:  
2025-12-22 07:46:11.291067: Epoch 821 
2025-12-22 07:46:11.292070: Current learning rate: 0.00213 
2025-12-22 07:48:29.243127: train_loss -0.8583 
2025-12-22 07:48:29.245130: val_loss -0.8781 
2025-12-22 07:48:29.251137: Pseudo dice [0.9278, 0.9568, 0.9432] 
2025-12-22 07:48:29.256642: Epoch time: 137.95 s 
2025-12-22 07:48:30.024406:  
2025-12-22 07:48:30.024406: Epoch 822 
2025-12-22 07:48:30.028413: Current learning rate: 0.00212 
2025-12-22 07:50:47.887023: train_loss -0.8598 
2025-12-22 07:50:47.887023: val_loss -0.8706 
2025-12-22 07:50:47.906669: Pseudo dice [0.9239, 0.9492, 0.9492] 
2025-12-22 07:50:47.912675: Epoch time: 137.87 s 
2025-12-22 07:50:48.568259:  
2025-12-22 07:50:48.568259: Epoch 823 
2025-12-22 07:50:48.586823: Current learning rate: 0.0021 
2025-12-22 07:53:06.466476: train_loss -0.8612 
2025-12-22 07:53:06.466476: val_loss -0.8815 
2025-12-22 07:53:06.479011: Pseudo dice [0.9252, 0.9563, 0.9494] 
2025-12-22 07:53:06.482516: Epoch time: 137.9 s 
2025-12-22 07:53:07.177584:  
2025-12-22 07:53:07.177584: Epoch 824 
2025-12-22 07:53:07.177584: Current learning rate: 0.00209 
2025-12-22 07:55:25.188069: train_loss -0.8589 
2025-12-22 07:55:25.188069: val_loss -0.8635 
2025-12-22 07:55:25.204076: Pseudo dice [0.9191, 0.9459, 0.9438] 
2025-12-22 07:55:25.204076: Epoch time: 138.01 s 
2025-12-22 07:55:26.042799:  
2025-12-22 07:55:26.042799: Epoch 825 
2025-12-22 07:55:26.042799: Current learning rate: 0.00208 
2025-12-22 07:57:43.850818: train_loss -0.8608 
2025-12-22 07:57:43.852612: val_loss -0.8751 
2025-12-22 07:57:43.856616: Pseudo dice [0.9238, 0.9535, 0.9487] 
2025-12-22 07:57:43.862360: Epoch time: 137.81 s 
2025-12-22 07:57:44.495705:  
2025-12-22 07:57:44.497707: Epoch 826 
2025-12-22 07:57:44.497707: Current learning rate: 0.00207 
2025-12-22 08:00:02.438935: train_loss -0.859 
2025-12-22 08:00:02.440937: val_loss -0.8789 
2025-12-22 08:00:02.448684: Pseudo dice [0.9287, 0.9582, 0.9452] 
2025-12-22 08:00:02.454029: Epoch time: 137.94 s 
2025-12-22 08:00:03.098588:  
2025-12-22 08:00:03.098588: Epoch 827 
2025-12-22 08:00:03.100329: Current learning rate: 0.00206 
2025-12-22 08:02:20.994948: train_loss -0.8646 
2025-12-22 08:02:20.994948: val_loss -0.8745 
2025-12-22 08:02:21.000954: Pseudo dice [0.9271, 0.9549, 0.9424] 
2025-12-22 08:02:21.006697: Epoch time: 137.9 s 
2025-12-22 08:02:21.636974:  
2025-12-22 08:02:21.652893: Epoch 828 
2025-12-22 08:02:21.652893: Current learning rate: 0.00205 
2025-12-22 08:04:39.731093: train_loss -0.8601 
2025-12-22 08:04:39.733095: val_loss -0.8882 
2025-12-22 08:04:39.740842: Pseudo dice [0.9357, 0.9614, 0.9408] 
2025-12-22 08:04:39.746848: Epoch time: 138.09 s 
2025-12-22 08:04:40.449214:  
2025-12-22 08:04:40.451216: Epoch 829 
2025-12-22 08:04:40.451216: Current learning rate: 0.00204 
2025-12-22 08:06:58.343635: train_loss -0.8652 
2025-12-22 08:06:58.343635: val_loss -0.8608 
2025-12-22 08:06:58.353394: Pseudo dice [0.9156, 0.9481, 0.9462] 
2025-12-22 08:06:58.361402: Epoch time: 137.89 s 
2025-12-22 08:06:59.079183:  
2025-12-22 08:06:59.079183: Epoch 830 
2025-12-22 08:06:59.079183: Current learning rate: 0.00203 
2025-12-22 08:09:17.202122: train_loss -0.8635 
2025-12-22 08:09:17.202122: val_loss -0.8829 
2025-12-22 08:09:17.218235: Pseudo dice [0.9328, 0.9637, 0.9399] 
2025-12-22 08:09:17.218235: Epoch time: 138.12 s 
2025-12-22 08:09:17.864143:  
2025-12-22 08:09:17.864143: Epoch 831 
2025-12-22 08:09:17.868175: Current learning rate: 0.00202 
2025-12-22 08:11:35.980361: train_loss -0.8602 
2025-12-22 08:11:35.980361: val_loss -0.8753 
2025-12-22 08:11:35.980361: Pseudo dice [0.9284, 0.9551, 0.9379] 
2025-12-22 08:11:35.980361: Epoch time: 138.12 s 
2025-12-22 08:11:36.852009:  
2025-12-22 08:11:36.852009: Epoch 832 
2025-12-22 08:11:36.868121: Current learning rate: 0.00201 
2025-12-22 08:13:54.803708: train_loss -0.8555 
2025-12-22 08:13:54.803708: val_loss -0.8901 
2025-12-22 08:13:54.803708: Pseudo dice [0.932, 0.9606, 0.9506] 
2025-12-22 08:13:54.812091: Epoch time: 137.95 s 
2025-12-22 08:13:55.476395:  
2025-12-22 08:13:55.476395: Epoch 833 
2025-12-22 08:13:55.492485: Current learning rate: 0.002 
2025-12-22 08:16:13.383896: train_loss -0.8653 
2025-12-22 08:16:13.383896: val_loss -0.8748 
2025-12-22 08:16:13.399757: Pseudo dice [0.925, 0.9516, 0.9444] 
2025-12-22 08:16:13.399757: Epoch time: 137.91 s 
2025-12-22 08:16:14.031551:  
2025-12-22 08:16:14.031551: Epoch 834 
2025-12-22 08:16:14.047492: Current learning rate: 0.00199 
2025-12-22 08:18:31.957349: train_loss -0.8604 
2025-12-22 08:18:31.966280: val_loss -0.8957 
2025-12-22 08:18:31.972594: Pseudo dice [0.9424, 0.963, 0.9434] 
2025-12-22 08:18:31.978097: Epoch time: 137.93 s 
2025-12-22 08:18:32.613929:  
2025-12-22 08:18:32.614934: Epoch 835 
2025-12-22 08:18:32.619855: Current learning rate: 0.00198 
2025-12-22 08:20:51.181790: train_loss -0.8605 
2025-12-22 08:20:51.181790: val_loss -0.8841 
2025-12-22 08:20:51.187537: Pseudo dice [0.9303, 0.9567, 0.9513] 
2025-12-22 08:20:51.191394: Epoch time: 138.57 s 
2025-12-22 08:20:51.846957:  
2025-12-22 08:20:51.846957: Epoch 836 
2025-12-22 08:20:51.853300: Current learning rate: 0.00196 
2025-12-22 08:23:09.880911: train_loss -0.8577 
2025-12-22 08:23:09.880911: val_loss -0.8838 
2025-12-22 08:23:09.888658: Pseudo dice [0.9314, 0.959, 0.9455] 
2025-12-22 08:23:09.896404: Epoch time: 138.04 s 
2025-12-22 08:23:10.534555:  
2025-12-22 08:23:10.534555: Epoch 837 
2025-12-22 08:23:10.534555: Current learning rate: 0.00195 
2025-12-22 08:25:28.584388: train_loss -0.8596 
2025-12-22 08:25:28.584388: val_loss -0.8697 
2025-12-22 08:25:28.600220: Pseudo dice [0.9211, 0.9527, 0.943] 
2025-12-22 08:25:28.604343: Epoch time: 138.05 s 
2025-12-22 08:25:29.404242:  
2025-12-22 08:25:29.404242: Epoch 838 
2025-12-22 08:25:29.404242: Current learning rate: 0.00194 
2025-12-22 08:27:47.279467: train_loss -0.8661 
2025-12-22 08:27:47.279467: val_loss -0.8838 
2025-12-22 08:27:47.285211: Pseudo dice [0.9327, 0.9591, 0.9445] 
2025-12-22 08:27:47.285211: Epoch time: 137.88 s 
2025-12-22 08:27:47.939932:  
2025-12-22 08:27:47.939932: Epoch 839 
2025-12-22 08:27:47.939932: Current learning rate: 0.00193 
2025-12-22 08:30:05.827425: train_loss -0.8593 
2025-12-22 08:30:05.827425: val_loss -0.8799 
2025-12-22 08:30:05.827425: Pseudo dice [0.9261, 0.9588, 0.9448] 
2025-12-22 08:30:05.827425: Epoch time: 137.89 s 
2025-12-22 08:30:06.507776:  
2025-12-22 08:30:06.507776: Epoch 840 
2025-12-22 08:30:06.507776: Current learning rate: 0.00192 
2025-12-22 08:32:24.393453: train_loss -0.8629 
2025-12-22 08:32:24.409165: val_loss -0.8896 
2025-12-22 08:32:24.409165: Pseudo dice [0.9327, 0.9612, 0.9521] 
2025-12-22 08:32:24.409165: Epoch time: 137.89 s 
2025-12-22 08:32:25.058927:  
2025-12-22 08:32:25.058927: Epoch 841 
2025-12-22 08:32:25.058927: Current learning rate: 0.00191 
2025-12-22 08:34:43.014620: train_loss -0.8616 
2025-12-22 08:34:43.014620: val_loss -0.8783 
2025-12-22 08:34:43.014620: Pseudo dice [0.9278, 0.9575, 0.9462] 
2025-12-22 08:34:43.014620: Epoch time: 137.96 s 
2025-12-22 08:34:43.743092:  
2025-12-22 08:34:43.743092: Epoch 842 
2025-12-22 08:34:43.758859: Current learning rate: 0.0019 
2025-12-22 08:37:01.578072: train_loss -0.8633 
2025-12-22 08:37:01.578072: val_loss -0.8814 
2025-12-22 08:37:01.580075: Pseudo dice [0.9295, 0.9595, 0.9448] 
2025-12-22 08:37:01.593919: Epoch time: 137.83 s 
2025-12-22 08:37:02.211619:  
2025-12-22 08:37:02.211619: Epoch 843 
2025-12-22 08:37:02.227625: Current learning rate: 0.00189 
2025-12-22 08:39:20.149318: train_loss -0.8599 
2025-12-22 08:39:20.151320: val_loss -0.8696 
2025-12-22 08:39:20.157328: Pseudo dice [0.9219, 0.9535, 0.938] 
2025-12-22 08:39:20.157328: Epoch time: 137.94 s 
2025-12-22 08:39:20.966929:  
2025-12-22 08:39:20.966929: Epoch 844 
2025-12-22 08:39:20.966929: Current learning rate: 0.00188 
2025-12-22 08:41:38.722310: train_loss -0.8646 
2025-12-22 08:41:38.722310: val_loss -0.84 
2025-12-22 08:41:38.730317: Pseudo dice [0.9011, 0.9344, 0.9429] 
2025-12-22 08:41:38.733797: Epoch time: 137.76 s 
2025-12-22 08:41:39.369149:  
2025-12-22 08:41:39.369149: Epoch 845 
2025-12-22 08:41:39.385082: Current learning rate: 0.00187 
2025-12-22 08:43:57.495560: train_loss -0.8562 
2025-12-22 08:43:57.495560: val_loss -0.8776 
2025-12-22 08:43:57.511306: Pseudo dice [0.9249, 0.9546, 0.9459] 
2025-12-22 08:43:57.511306: Epoch time: 138.13 s 
2025-12-22 08:43:58.144860:  
2025-12-22 08:43:58.144860: Epoch 846 
2025-12-22 08:43:58.144860: Current learning rate: 0.00186 
2025-12-22 08:46:16.015881: train_loss -0.8598 
2025-12-22 08:46:16.015881: val_loss -0.8692 
2025-12-22 08:46:16.021888: Pseudo dice [0.9206, 0.952, 0.9422] 
2025-12-22 08:46:16.027894: Epoch time: 137.87 s 
2025-12-22 08:46:16.665683:  
2025-12-22 08:46:16.665683: Epoch 847 
2025-12-22 08:46:16.665683: Current learning rate: 0.00185 
2025-12-22 08:48:34.576946: train_loss -0.8588 
2025-12-22 08:48:34.576946: val_loss -0.8827 
2025-12-22 08:48:34.576946: Pseudo dice [0.9323, 0.9583, 0.9436] 
2025-12-22 08:48:34.576946: Epoch time: 137.91 s 
2025-12-22 08:48:35.226261:  
2025-12-22 08:48:35.226261: Epoch 848 
2025-12-22 08:48:35.226261: Current learning rate: 0.00184 
2025-12-22 08:50:53.347166: train_loss -0.8631 
2025-12-22 08:50:53.347166: val_loss -0.8747 
2025-12-22 08:50:53.350908: Pseudo dice [0.927, 0.9552, 0.9418] 
2025-12-22 08:50:53.350908: Epoch time: 138.12 s 
2025-12-22 08:50:53.996608:  
2025-12-22 08:50:53.996608: Epoch 849 
2025-12-22 08:50:53.996608: Current learning rate: 0.00182 
2025-12-22 08:53:11.777123: train_loss -0.8598 
2025-12-22 08:53:11.777123: val_loss -0.8799 
2025-12-22 08:53:11.784869: Pseudo dice [0.9305, 0.9581, 0.9422] 
2025-12-22 08:53:11.788873: Epoch time: 137.8 s 
2025-12-22 08:53:12.924760:  
2025-12-22 08:53:12.924760: Epoch 850 
2025-12-22 08:53:12.924760: Current learning rate: 0.00181 
2025-12-22 08:55:31.021726: train_loss -0.8606 
2025-12-22 08:55:31.021726: val_loss -0.875 
2025-12-22 08:55:31.021726: Pseudo dice [0.9262, 0.9525, 0.9462] 
2025-12-22 08:55:31.021726: Epoch time: 138.1 s 
2025-12-22 08:55:31.641981:  
2025-12-22 08:55:31.641981: Epoch 851 
2025-12-22 08:55:31.659446: Current learning rate: 0.0018 
2025-12-22 08:57:49.381356: train_loss -0.8612 
2025-12-22 08:57:49.381356: val_loss -0.8867 
2025-12-22 08:57:49.389363: Pseudo dice [0.9361, 0.9613, 0.9402] 
2025-12-22 08:57:49.394598: Epoch time: 137.74 s 
2025-12-22 08:57:50.023493:  
2025-12-22 08:57:50.023493: Epoch 852 
2025-12-22 08:57:50.023493: Current learning rate: 0.00179 
2025-12-22 09:00:07.987538: train_loss -0.856 
2025-12-22 09:00:07.987538: val_loss -0.8858 
2025-12-22 09:00:07.994262: Pseudo dice [0.9327, 0.9608, 0.9415] 
2025-12-22 09:00:08.000268: Epoch time: 137.98 s 
2025-12-22 09:00:08.661752:  
2025-12-22 09:00:08.661752: Epoch 853 
2025-12-22 09:00:08.661752: Current learning rate: 0.00178 
2025-12-22 09:02:26.983343: train_loss -0.8587 
2025-12-22 09:02:26.983343: val_loss -0.892 
2025-12-22 09:02:26.990411: Pseudo dice [0.938, 0.9626, 0.9481] 
2025-12-22 09:02:26.996417: Epoch time: 138.32 s 
2025-12-22 09:02:27.633207:  
2025-12-22 09:02:27.635209: Epoch 854 
2025-12-22 09:02:27.635209: Current learning rate: 0.00177 
2025-12-22 09:04:45.602196: train_loss -0.8626 
2025-12-22 09:04:45.602196: val_loss -0.8681 
2025-12-22 09:04:45.615955: Pseudo dice [0.9207, 0.9493, 0.9448] 
2025-12-22 09:04:45.619872: Epoch time: 137.97 s 
2025-12-22 09:04:46.258737:  
2025-12-22 09:04:46.258737: Epoch 855 
2025-12-22 09:04:46.260741: Current learning rate: 0.00176 
2025-12-22 09:07:04.049012: train_loss -0.861 
2025-12-22 09:07:04.049012: val_loss -0.8828 
2025-12-22 09:07:04.064943: Pseudo dice [0.9298, 0.9595, 0.9398] 
2025-12-22 09:07:04.070953: Epoch time: 137.79 s 
2025-12-22 09:07:04.829953:  
2025-12-22 09:07:04.829953: Epoch 856 
2025-12-22 09:07:04.829953: Current learning rate: 0.00175 
2025-12-22 09:09:23.080045: train_loss -0.8615 
2025-12-22 09:09:23.080045: val_loss -0.8908 
2025-12-22 09:09:23.085789: Pseudo dice [0.9364, 0.9625, 0.9472] 
2025-12-22 09:09:23.089793: Epoch time: 138.25 s 
2025-12-22 09:09:23.961469:  
2025-12-22 09:09:23.961469: Epoch 857 
2025-12-22 09:09:23.967712: Current learning rate: 0.00174 
2025-12-22 09:11:41.775815: train_loss -0.8586 
2025-12-22 09:11:41.775815: val_loss -0.8839 
2025-12-22 09:11:41.791583: Pseudo dice [0.9314, 0.9588, 0.9476] 
2025-12-22 09:11:41.791583: Epoch time: 137.81 s 
2025-12-22 09:11:42.410599:  
2025-12-22 09:11:42.410599: Epoch 858 
2025-12-22 09:11:42.426273: Current learning rate: 0.00173 
2025-12-22 09:14:00.440221: train_loss -0.8654 
2025-12-22 09:14:00.442223: val_loss -0.8778 
2025-12-22 09:14:00.448228: Pseudo dice [0.9283, 0.9551, 0.9449] 
2025-12-22 09:14:00.453782: Epoch time: 138.03 s 
2025-12-22 09:14:01.192161:  
2025-12-22 09:14:01.192161: Epoch 859 
2025-12-22 09:14:01.192161: Current learning rate: 0.00172 
2025-12-22 09:16:19.140736: train_loss -0.8651 
2025-12-22 09:16:19.142738: val_loss -0.8799 
2025-12-22 09:16:19.148746: Pseudo dice [0.9298, 0.9547, 0.9451] 
2025-12-22 09:16:19.154490: Epoch time: 137.96 s 
2025-12-22 09:16:19.781982:  
2025-12-22 09:16:19.783984: Epoch 860 
2025-12-22 09:16:19.785727: Current learning rate: 0.0017 
2025-12-22 09:18:37.471238: train_loss -0.8645 
2025-12-22 09:18:37.473240: val_loss -0.8745 
2025-12-22 09:18:37.479028: Pseudo dice [0.9301, 0.9549, 0.9355] 
2025-12-22 09:18:37.485034: Epoch time: 137.69 s 
2025-12-22 09:18:38.093082:  
2025-12-22 09:18:38.093082: Epoch 861 
2025-12-22 09:18:38.108910: Current learning rate: 0.00169 
2025-12-22 09:20:55.922387: train_loss -0.8558 
2025-12-22 09:20:55.922387: val_loss -0.8819 
2025-12-22 09:20:55.927891: Pseudo dice [0.9305, 0.96, 0.9451] 
2025-12-22 09:20:55.933899: Epoch time: 137.83 s 
2025-12-22 09:20:56.646804:  
2025-12-22 09:20:56.646804: Epoch 862 
2025-12-22 09:20:56.646804: Current learning rate: 0.00168 
2025-12-22 09:23:14.649064: train_loss -0.8619 
2025-12-22 09:23:14.651066: val_loss -0.8765 
2025-12-22 09:23:14.657072: Pseudo dice [0.926, 0.9548, 0.949] 
2025-12-22 09:23:14.661077: Epoch time: 138.0 s 
2025-12-22 09:23:15.534715:  
2025-12-22 09:23:15.534715: Epoch 863 
2025-12-22 09:23:15.539016: Current learning rate: 0.00167 
2025-12-22 09:25:33.258098: train_loss -0.8633 
2025-12-22 09:25:33.258098: val_loss -0.8634 
2025-12-22 09:25:33.266938: Pseudo dice [0.9199, 0.9514, 0.9367] 
2025-12-22 09:25:33.270942: Epoch time: 137.72 s 
2025-12-22 09:25:33.986837:  
2025-12-22 09:25:33.986837: Epoch 864 
2025-12-22 09:25:33.988840: Current learning rate: 0.00166 
2025-12-22 09:27:51.788672: train_loss -0.8586 
2025-12-22 09:27:51.788672: val_loss -0.8864 
2025-12-22 09:27:51.794679: Pseudo dice [0.9335, 0.9575, 0.948] 
2025-12-22 09:27:51.802182: Epoch time: 137.8 s 
2025-12-22 09:27:52.590415:  
2025-12-22 09:27:52.590415: Epoch 865 
2025-12-22 09:27:52.599262: Current learning rate: 0.00165 
2025-12-22 09:30:10.414006: train_loss -0.866 
2025-12-22 09:30:10.414006: val_loss -0.8613 
2025-12-22 09:30:10.423513: Pseudo dice [0.9138, 0.948, 0.9391] 
2025-12-22 09:30:10.429519: Epoch time: 137.82 s 
2025-12-22 09:30:11.046664:  
2025-12-22 09:30:11.046664: Epoch 866 
2025-12-22 09:30:11.062406: Current learning rate: 0.00164 
2025-12-22 09:32:29.060141: train_loss -0.8541 
2025-12-22 09:32:29.060141: val_loss -0.8922 
2025-12-22 09:32:29.069651: Pseudo dice [0.9385, 0.9634, 0.9415] 
2025-12-22 09:32:29.073655: Epoch time: 138.01 s 
2025-12-22 09:32:29.745426:  
2025-12-22 09:32:29.745426: Epoch 867 
2025-12-22 09:32:29.761321: Current learning rate: 0.00163 
2025-12-22 09:34:47.730822: train_loss -0.8584 
2025-12-22 09:34:47.730822: val_loss -0.8807 
2025-12-22 09:34:47.738570: Pseudo dice [0.9293, 0.9595, 0.9427] 
2025-12-22 09:34:47.746579: Epoch time: 137.99 s 
2025-12-22 09:34:48.368087:  
2025-12-22 09:34:48.368087: Epoch 868 
2025-12-22 09:34:48.383800: Current learning rate: 0.00162 
2025-12-22 09:37:06.232759: train_loss -0.8648 
2025-12-22 09:37:06.232759: val_loss -0.8651 
2025-12-22 09:37:06.250792: Pseudo dice [0.9197, 0.9492, 0.9443] 
2025-12-22 09:37:06.256373: Epoch time: 137.86 s 
2025-12-22 09:37:06.868227:  
2025-12-22 09:37:06.868227: Epoch 869 
2025-12-22 09:37:06.886320: Current learning rate: 0.00161 
2025-12-22 09:39:24.826097: train_loss -0.8627 
2025-12-22 09:39:24.827837: val_loss -0.8822 
2025-12-22 09:39:24.836343: Pseudo dice [0.9311, 0.9552, 0.9443] 
2025-12-22 09:39:24.842428: Epoch time: 137.96 s 
2025-12-22 09:39:25.699316:  
2025-12-22 09:39:25.699316: Epoch 870 
2025-12-22 09:39:25.717099: Current learning rate: 0.00159 
2025-12-22 09:41:43.624029: train_loss -0.8592 
2025-12-22 09:41:43.624029: val_loss -0.8804 
2025-12-22 09:41:43.629214: Pseudo dice [0.9343, 0.9561, 0.9375] 
2025-12-22 09:41:43.635724: Epoch time: 137.92 s 
2025-12-22 09:41:44.268689:  
2025-12-22 09:41:44.268689: Epoch 871 
2025-12-22 09:41:44.268689: Current learning rate: 0.00158 
2025-12-22 09:44:02.149193: train_loss -0.8651 
2025-12-22 09:44:02.151195: val_loss -0.8978 
2025-12-22 09:44:02.160716: Pseudo dice [0.9433, 0.9655, 0.9432] 
2025-12-22 09:44:02.166723: Epoch time: 137.88 s 
2025-12-22 09:44:02.789164:  
2025-12-22 09:44:02.789164: Epoch 872 
2025-12-22 09:44:02.805170: Current learning rate: 0.00157 
2025-12-22 09:46:20.636817: train_loss -0.8644 
2025-12-22 09:46:20.636817: val_loss -0.895 
2025-12-22 09:46:20.642825: Pseudo dice [0.939, 0.9632, 0.9481] 
2025-12-22 09:46:20.648831: Epoch time: 137.85 s 
2025-12-22 09:46:21.368814:  
2025-12-22 09:46:21.368814: Epoch 873 
2025-12-22 09:46:21.368814: Current learning rate: 0.00156 
2025-12-22 09:48:39.205363: train_loss -0.8548 
2025-12-22 09:48:39.205363: val_loss -0.8693 
2025-12-22 09:48:39.210869: Pseudo dice [0.9249, 0.954, 0.9392] 
2025-12-22 09:48:39.210869: Epoch time: 137.84 s 
2025-12-22 09:48:39.844475:  
2025-12-22 09:48:39.844475: Epoch 874 
2025-12-22 09:48:39.844475: Current learning rate: 0.00155 
2025-12-22 09:50:57.622627: train_loss -0.8595 
2025-12-22 09:50:57.624629: val_loss -0.8865 
2025-12-22 09:50:57.630635: Pseudo dice [0.9366, 0.9601, 0.937] 
2025-12-22 09:50:57.638038: Epoch time: 137.78 s 
2025-12-22 09:50:58.252263:  
2025-12-22 09:50:58.252263: Epoch 875 
2025-12-22 09:50:58.269001: Current learning rate: 0.00154 
2025-12-22 09:53:16.164147: train_loss -0.8628 
2025-12-22 09:53:16.166149: val_loss -0.8865 
2025-12-22 09:53:16.177910: Pseudo dice [0.933, 0.9602, 0.9494] 
2025-12-22 09:53:16.187405: Epoch time: 137.91 s 
2025-12-22 09:53:17.120829:  
2025-12-22 09:53:17.120829: Epoch 876 
2025-12-22 09:53:17.136616: Current learning rate: 0.00153 
2025-12-22 09:55:35.270168: train_loss -0.8637 
2025-12-22 09:55:35.270168: val_loss -0.8809 
2025-12-22 09:55:35.272171: Pseudo dice [0.9291, 0.9538, 0.9492] 
2025-12-22 09:55:35.272171: Epoch time: 138.15 s 
2025-12-22 09:55:35.904432:  
2025-12-22 09:55:35.904432: Epoch 877 
2025-12-22 09:55:35.904432: Current learning rate: 0.00152 
2025-12-22 09:57:53.732839: train_loss -0.8603 
2025-12-22 09:57:53.732839: val_loss -0.892 
2025-12-22 09:57:53.732839: Pseudo dice [0.937, 0.9645, 0.9457] 
2025-12-22 09:57:53.748803: Epoch time: 137.84 s 
2025-12-22 09:57:53.757393: Yayy! New best EMA pseudo Dice: 0.9445 
2025-12-22 09:57:54.659646:  
2025-12-22 09:57:54.659646: Epoch 878 
2025-12-22 09:57:54.661387: Current learning rate: 0.00151 
2025-12-22 10:00:12.422456: train_loss -0.8601 
2025-12-22 10:00:12.422456: val_loss -0.8744 
2025-12-22 10:00:12.431159: Pseudo dice [0.9267, 0.9525, 0.9386] 
2025-12-22 10:00:12.435164: Epoch time: 137.76 s 
2025-12-22 10:00:13.185829:  
2025-12-22 10:00:13.185829: Epoch 879 
2025-12-22 10:00:13.185829: Current learning rate: 0.00149 
2025-12-22 10:02:31.129750: train_loss -0.8645 
2025-12-22 10:02:31.131752: val_loss -0.8778 
2025-12-22 10:02:31.139336: Pseudo dice [0.9229, 0.9568, 0.952] 
2025-12-22 10:02:31.143340: Epoch time: 137.95 s 
2025-12-22 10:02:31.851432:  
2025-12-22 10:02:31.851432: Epoch 880 
2025-12-22 10:02:31.853434: Current learning rate: 0.00148 
2025-12-22 10:04:49.864416: train_loss -0.8598 
2025-12-22 10:04:49.864416: val_loss -0.8796 
2025-12-22 10:04:49.874166: Pseudo dice [0.9312, 0.9541, 0.9442] 
2025-12-22 10:04:49.879911: Epoch time: 138.01 s 
2025-12-22 10:04:50.567720:  
2025-12-22 10:04:50.567720: Epoch 881 
2025-12-22 10:04:50.567720: Current learning rate: 0.00147 
2025-12-22 10:07:08.378225: train_loss -0.8635 
2025-12-22 10:07:08.380227: val_loss -0.8758 
2025-12-22 10:07:08.386233: Pseudo dice [0.9298, 0.9546, 0.9425] 
2025-12-22 10:07:08.393216: Epoch time: 137.81 s 
2025-12-22 10:07:09.196802:  
2025-12-22 10:07:09.196802: Epoch 882 
2025-12-22 10:07:09.212860: Current learning rate: 0.00146 
2025-12-22 10:09:27.337934: train_loss -0.8637 
2025-12-22 10:09:27.337934: val_loss -0.8939 
2025-12-22 10:09:27.343678: Pseudo dice [0.9374, 0.9616, 0.9488] 
2025-12-22 10:09:27.351274: Epoch time: 138.14 s 
2025-12-22 10:09:28.213221:  
2025-12-22 10:09:28.213221: Epoch 883 
2025-12-22 10:09:28.229050: Current learning rate: 0.00145 
2025-12-22 10:11:46.084639: train_loss -0.8634 
2025-12-22 10:11:46.084639: val_loss -0.8866 
2025-12-22 10:11:46.090645: Pseudo dice [0.9354, 0.9591, 0.9374] 
2025-12-22 10:11:46.096651: Epoch time: 137.87 s 
2025-12-22 10:11:46.727219:  
2025-12-22 10:11:46.727219: Epoch 884 
2025-12-22 10:11:46.728961: Current learning rate: 0.00144 
2025-12-22 10:14:04.766331: train_loss -0.8666 
2025-12-22 10:14:04.766331: val_loss -0.875 
2025-12-22 10:14:04.779275: Pseudo dice [0.9246, 0.9509, 0.9467] 
2025-12-22 10:14:04.786546: Epoch time: 138.04 s 
2025-12-22 10:14:05.512424:  
2025-12-22 10:14:05.512424: Epoch 885 
2025-12-22 10:14:05.512424: Current learning rate: 0.00143 
2025-12-22 10:16:23.416654: train_loss -0.8636 
2025-12-22 10:16:23.416654: val_loss -0.8739 
2025-12-22 10:16:23.432670: Pseudo dice [0.9234, 0.9522, 0.9442] 
2025-12-22 10:16:23.432670: Epoch time: 137.91 s 
2025-12-22 10:16:24.062229:  
2025-12-22 10:16:24.064231: Epoch 886 
2025-12-22 10:16:24.064231: Current learning rate: 0.00142 
2025-12-22 10:18:41.876976: train_loss -0.8623 
2025-12-22 10:18:41.876976: val_loss -0.8769 
2025-12-22 10:18:41.883985: Pseudo dice [0.9271, 0.9563, 0.9434] 
2025-12-22 10:18:41.889729: Epoch time: 137.81 s 
2025-12-22 10:18:42.512120:  
2025-12-22 10:18:42.512120: Epoch 887 
2025-12-22 10:18:42.512120: Current learning rate: 0.00141 
2025-12-22 10:21:00.486575: train_loss -0.8631 
2025-12-22 10:21:00.490072: val_loss -0.8656 
2025-12-22 10:21:00.496078: Pseudo dice [0.9202, 0.9487, 0.9397] 
2025-12-22 10:21:00.502084: Epoch time: 137.98 s 
2025-12-22 10:21:01.119708:  
2025-12-22 10:21:01.119708: Epoch 888 
2025-12-22 10:21:01.135631: Current learning rate: 0.00139 
2025-12-22 10:23:19.011152: train_loss -0.8658 
2025-12-22 10:23:19.011152: val_loss -0.8812 
2025-12-22 10:23:19.026960: Pseudo dice [0.9319, 0.9563, 0.9396] 
2025-12-22 10:23:19.026960: Epoch time: 137.89 s 
2025-12-22 10:23:19.847908:  
2025-12-22 10:23:19.847908: Epoch 889 
2025-12-22 10:23:19.853921: Current learning rate: 0.00138 
2025-12-22 10:25:37.694591: train_loss -0.8599 
2025-12-22 10:25:37.694591: val_loss -0.8746 
2025-12-22 10:25:37.706344: Pseudo dice [0.9244, 0.9538, 0.9487] 
2025-12-22 10:25:37.712350: Epoch time: 137.85 s 
2025-12-22 10:25:38.351972:  
2025-12-22 10:25:38.351972: Epoch 890 
2025-12-22 10:25:38.351972: Current learning rate: 0.00137 
2025-12-22 10:27:56.286879: train_loss -0.8633 
2025-12-22 10:27:56.288620: val_loss -0.8765 
2025-12-22 10:27:56.296629: Pseudo dice [0.9299, 0.9555, 0.9442] 
2025-12-22 10:27:56.304436: Epoch time: 137.93 s 
2025-12-22 10:27:56.939589:  
2025-12-22 10:27:56.939589: Epoch 891 
2025-12-22 10:27:56.939589: Current learning rate: 0.00136 
2025-12-22 10:30:14.971488: train_loss -0.8614 
2025-12-22 10:30:14.973490: val_loss -0.8856 
2025-12-22 10:30:14.981338: Pseudo dice [0.9342, 0.9583, 0.9451] 
2025-12-22 10:30:14.989174: Epoch time: 138.03 s 
2025-12-22 10:30:15.623641:  
2025-12-22 10:30:15.623641: Epoch 892 
2025-12-22 10:30:15.629702: Current learning rate: 0.00135 
2025-12-22 10:32:33.509281: train_loss -0.8635 
2025-12-22 10:32:33.509281: val_loss -0.8717 
2025-12-22 10:32:33.517291: Pseudo dice [0.9199, 0.9509, 0.9426] 
2025-12-22 10:32:33.525132: Epoch time: 137.89 s 
2025-12-22 10:32:34.165112:  
2025-12-22 10:32:34.165112: Epoch 893 
2025-12-22 10:32:34.169410: Current learning rate: 0.00134 
2025-12-22 10:34:52.259030: train_loss -0.8579 
2025-12-22 10:34:52.262576: val_loss -0.8808 
2025-12-22 10:34:52.269078: Pseudo dice [0.9293, 0.9578, 0.9438] 
2025-12-22 10:34:52.274822: Epoch time: 138.09 s 
2025-12-22 10:34:52.907628:  
2025-12-22 10:34:52.907628: Epoch 894 
2025-12-22 10:34:52.907628: Current learning rate: 0.00133 
2025-12-22 10:37:11.039912: train_loss -0.8611 
2025-12-22 10:37:11.039912: val_loss -0.8733 
2025-12-22 10:37:11.047208: Pseudo dice [0.9266, 0.9535, 0.9375] 
2025-12-22 10:37:11.053214: Epoch time: 138.13 s 
2025-12-22 10:37:11.676252:  
2025-12-22 10:37:11.676252: Epoch 895 
2025-12-22 10:37:11.682243: Current learning rate: 0.00132 
2025-12-22 10:39:29.622567: train_loss -0.8597 
2025-12-22 10:39:29.622567: val_loss -0.8742 
2025-12-22 10:39:29.638593: Pseudo dice [0.9254, 0.9526, 0.94] 
2025-12-22 10:39:29.638593: Epoch time: 137.95 s 
2025-12-22 10:39:30.495646:  
2025-12-22 10:39:30.495646: Epoch 896 
2025-12-22 10:39:30.495646: Current learning rate: 0.0013 
2025-12-22 10:41:48.452803: train_loss -0.8607 
2025-12-22 10:41:48.452803: val_loss -0.8694 
2025-12-22 10:41:48.462408: Pseudo dice [0.9227, 0.9521, 0.9461] 
2025-12-22 10:41:48.468414: Epoch time: 137.96 s 
2025-12-22 10:41:49.104404:  
2025-12-22 10:41:49.104404: Epoch 897 
2025-12-22 10:41:49.104404: Current learning rate: 0.00129 
2025-12-22 10:44:07.008424: train_loss -0.8622 
2025-12-22 10:44:07.008424: val_loss -0.8908 
2025-12-22 10:44:07.018437: Pseudo dice [0.9365, 0.9621, 0.9414] 
2025-12-22 10:44:07.026187: Epoch time: 137.9 s 
2025-12-22 10:44:07.653412:  
2025-12-22 10:44:07.653412: Epoch 898 
2025-12-22 10:44:07.669342: Current learning rate: 0.00128 
2025-12-22 10:46:25.719336: train_loss -0.8643 
2025-12-22 10:46:25.719336: val_loss -0.8738 
2025-12-22 10:46:25.730453: Pseudo dice [0.9265, 0.9517, 0.9451] 
2025-12-22 10:46:25.734683: Epoch time: 138.07 s 
2025-12-22 10:46:26.495292:  
2025-12-22 10:46:26.511050: Epoch 899 
2025-12-22 10:46:26.517207: Current learning rate: 0.00127 
2025-12-22 10:48:44.404581: train_loss -0.8658 
2025-12-22 10:48:44.404581: val_loss -0.877 
2025-12-22 10:48:44.404581: Pseudo dice [0.9239, 0.9543, 0.9473] 
2025-12-22 10:48:44.424015: Epoch time: 137.91 s 
2025-12-22 10:48:45.307891:  
2025-12-22 10:48:45.307891: Epoch 900 
2025-12-22 10:48:45.307891: Current learning rate: 0.00126 
2025-12-22 10:51:03.123864: train_loss -0.8632 
2025-12-22 10:51:03.125609: val_loss -0.8819 
2025-12-22 10:51:03.137623: Pseudo dice [0.9302, 0.957, 0.9518] 
2025-12-22 10:51:03.143368: Epoch time: 137.82 s 
2025-12-22 10:51:03.776702:  
2025-12-22 10:51:03.776702: Epoch 901 
2025-12-22 10:51:03.776702: Current learning rate: 0.00125 
2025-12-22 10:53:21.685697: train_loss -0.8649 
2025-12-22 10:53:21.687700: val_loss -0.8882 
2025-12-22 10:53:21.696712: Pseudo dice [0.9342, 0.9596, 0.9505] 
2025-12-22 10:53:21.704459: Epoch time: 137.91 s 
2025-12-22 10:53:22.636829:  
2025-12-22 10:53:22.636829: Epoch 902 
2025-12-22 10:53:22.636829: Current learning rate: 0.00124 
2025-12-22 10:55:40.695425: train_loss -0.8632 
2025-12-22 10:55:40.695425: val_loss -0.8839 
2025-12-22 10:55:40.705436: Pseudo dice [0.9352, 0.9575, 0.946] 
2025-12-22 10:55:40.713185: Epoch time: 138.06 s 
2025-12-22 10:55:41.414716:  
2025-12-22 10:55:41.414716: Epoch 903 
2025-12-22 10:55:41.414716: Current learning rate: 0.00122 
2025-12-22 10:57:59.318177: train_loss -0.8609 
2025-12-22 10:57:59.318177: val_loss -0.8922 
2025-12-22 10:57:59.325690: Pseudo dice [0.9383, 0.9634, 0.9476] 
2025-12-22 10:57:59.331696: Epoch time: 137.9 s 
2025-12-22 10:57:59.961990:  
2025-12-22 10:57:59.961990: Epoch 904 
2025-12-22 10:57:59.961990: Current learning rate: 0.00121 
2025-12-22 11:00:17.992548: train_loss -0.8635 
2025-12-22 11:00:17.992548: val_loss -0.8726 
2025-12-22 11:00:18.000556: Pseudo dice [0.9278, 0.9528, 0.939] 
2025-12-22 11:00:18.006423: Epoch time: 138.03 s 
2025-12-22 11:00:18.729879:  
2025-12-22 11:00:18.729879: Epoch 905 
2025-12-22 11:00:18.729879: Current learning rate: 0.0012 
2025-12-22 11:02:36.735091: train_loss -0.8648 
2025-12-22 11:02:36.735091: val_loss -0.8774 
2025-12-22 11:02:36.738833: Pseudo dice [0.9259, 0.9521, 0.9432] 
2025-12-22 11:02:36.748384: Epoch time: 138.01 s 
2025-12-22 11:02:37.372746:  
2025-12-22 11:02:37.372746: Epoch 906 
2025-12-22 11:02:37.372746: Current learning rate: 0.00119 
2025-12-22 11:04:55.474852: train_loss -0.8657 
2025-12-22 11:04:55.474852: val_loss -0.878 
2025-12-22 11:04:55.487670: Pseudo dice [0.9249, 0.9521, 0.9532] 
2025-12-22 11:04:55.490674: Epoch time: 138.1 s 
2025-12-22 11:04:56.122167:  
2025-12-22 11:04:56.122167: Epoch 907 
2025-12-22 11:04:56.122167: Current learning rate: 0.00118 
2025-12-22 11:07:14.209427: train_loss -0.8641 
2025-12-22 11:07:14.211429: val_loss -0.8803 
2025-12-22 11:07:14.217261: Pseudo dice [0.9278, 0.9549, 0.9507] 
2025-12-22 11:07:14.221265: Epoch time: 138.09 s 
2025-12-22 11:07:15.031990:  
2025-12-22 11:07:15.042226: Epoch 908 
2025-12-22 11:07:15.047785: Current learning rate: 0.00117 
2025-12-22 11:09:33.177063: train_loss -0.8633 
2025-12-22 11:09:33.177063: val_loss -0.872 
2025-12-22 11:09:33.190336: Pseudo dice [0.9227, 0.9498, 0.9501] 
2025-12-22 11:09:33.192338: Epoch time: 138.15 s 
2025-12-22 11:09:34.028558:  
2025-12-22 11:09:34.028558: Epoch 909 
2025-12-22 11:09:34.028558: Current learning rate: 0.00116 
2025-12-22 11:11:52.004702: train_loss -0.8595 
2025-12-22 11:11:52.004702: val_loss -0.8857 
2025-12-22 11:11:52.020656: Pseudo dice [0.934, 0.9589, 0.9423] 
2025-12-22 11:11:52.024523: Epoch time: 137.98 s 
2025-12-22 11:11:52.652179:  
2025-12-22 11:11:52.654182: Epoch 910 
2025-12-22 11:11:52.654182: Current learning rate: 0.00115 
2025-12-22 11:14:10.629416: train_loss -0.8619 
2025-12-22 11:14:10.629416: val_loss -0.8764 
2025-12-22 11:14:10.639374: Pseudo dice [0.9255, 0.9552, 0.9451] 
2025-12-22 11:14:10.645511: Epoch time: 137.98 s 
2025-12-22 11:14:11.388807:  
2025-12-22 11:14:11.388807: Epoch 911 
2025-12-22 11:14:11.388807: Current learning rate: 0.00113 
2025-12-22 11:16:29.848597: train_loss -0.8637 
2025-12-22 11:16:29.848597: val_loss -0.8859 
2025-12-22 11:16:29.856048: Pseudo dice [0.9334, 0.9587, 0.9487] 
2025-12-22 11:16:29.861833: Epoch time: 138.46 s 
2025-12-22 11:16:30.559253:  
2025-12-22 11:16:30.574392: Epoch 912 
2025-12-22 11:16:30.580927: Current learning rate: 0.00112 
2025-12-22 11:18:48.664574: train_loss -0.8589 
2025-12-22 11:18:48.664574: val_loss -0.877 
2025-12-22 11:18:48.673306: Pseudo dice [0.9254, 0.9572, 0.9436] 
2025-12-22 11:18:48.677310: Epoch time: 138.11 s 
2025-12-22 11:18:49.296468:  
2025-12-22 11:18:49.296468: Epoch 913 
2025-12-22 11:18:49.312285: Current learning rate: 0.00111 
2025-12-22 11:21:07.517057: train_loss -0.8595 
2025-12-22 11:21:07.518057: val_loss -0.8915 
2025-12-22 11:21:07.525164: Pseudo dice [0.9376, 0.9626, 0.9469] 
2025-12-22 11:21:07.530164: Epoch time: 138.22 s 
2025-12-22 11:21:08.285797:  
2025-12-22 11:21:08.285797: Epoch 914 
2025-12-22 11:21:08.293312: Current learning rate: 0.0011 
2025-12-22 11:23:26.293665: train_loss -0.8612 
2025-12-22 11:23:26.293665: val_loss -0.8929 
2025-12-22 11:23:26.303414: Pseudo dice [0.9408, 0.9636, 0.9457] 
2025-12-22 11:23:26.308909: Epoch time: 138.01 s 
2025-12-22 11:23:26.315362: Yayy! New best EMA pseudo Dice: 0.9446 
2025-12-22 11:23:27.214592:  
2025-12-22 11:23:27.218097: Epoch 915 
2025-12-22 11:23:27.218097: Current learning rate: 0.00109 
2025-12-22 11:25:45.104016: train_loss -0.8641 
2025-12-22 11:25:45.104016: val_loss -0.8838 
2025-12-22 11:25:45.116044: Pseudo dice [0.9333, 0.9544, 0.9419] 
2025-12-22 11:25:45.121791: Epoch time: 137.89 s 
2025-12-22 11:25:45.977381:  
2025-12-22 11:25:45.977381: Epoch 916 
2025-12-22 11:25:45.977381: Current learning rate: 0.00108 
2025-12-22 11:28:03.711467: train_loss -0.8633 
2025-12-22 11:28:03.711467: val_loss -0.881 
2025-12-22 11:28:03.725083: Pseudo dice [0.9322, 0.9554, 0.9401] 
2025-12-22 11:28:03.731431: Epoch time: 137.73 s 
2025-12-22 11:28:04.483582:  
2025-12-22 11:28:04.483582: Epoch 917 
2025-12-22 11:28:04.493589: Current learning rate: 0.00106 
2025-12-22 11:30:22.413954: train_loss -0.8599 
2025-12-22 11:30:22.413954: val_loss -0.8863 
2025-12-22 11:30:22.415956: Pseudo dice [0.9334, 0.9601, 0.9425] 
2025-12-22 11:30:22.428006: Epoch time: 137.93 s 
2025-12-22 11:30:23.054746:  
2025-12-22 11:30:23.054746: Epoch 918 
2025-12-22 11:30:23.057221: Current learning rate: 0.00105 
2025-12-22 11:32:40.967548: train_loss -0.8654 
2025-12-22 11:32:40.967548: val_loss -0.8825 
2025-12-22 11:32:40.982877: Pseudo dice [0.9305, 0.9573, 0.9475] 
2025-12-22 11:32:40.990635: Epoch time: 137.91 s 
2025-12-22 11:32:41.694549:  
2025-12-22 11:32:41.694549: Epoch 919 
2025-12-22 11:32:41.694549: Current learning rate: 0.00104 
2025-12-22 11:34:59.737281: train_loss -0.8612 
2025-12-22 11:34:59.737281: val_loss -0.8864 
2025-12-22 11:34:59.744829: Pseudo dice [0.9358, 0.9601, 0.9418] 
2025-12-22 11:34:59.750836: Epoch time: 138.04 s 
2025-12-22 11:35:00.369999:  
2025-12-22 11:35:00.369999: Epoch 920 
2025-12-22 11:35:00.369999: Current learning rate: 0.00103 
2025-12-22 11:37:18.351891: train_loss -0.8645 
2025-12-22 11:37:18.353893: val_loss -0.881 
2025-12-22 11:37:18.364913: Pseudo dice [0.9278, 0.9566, 0.9478] 
2025-12-22 11:37:18.368918: Epoch time: 137.98 s 
2025-12-22 11:37:18.988699:  
2025-12-22 11:37:19.002216: Epoch 921 
2025-12-22 11:37:19.006223: Current learning rate: 0.00102 
2025-12-22 11:39:36.811407: train_loss -0.8612 
2025-12-22 11:39:36.813410: val_loss -0.8752 
2025-12-22 11:39:36.819571: Pseudo dice [0.9271, 0.9543, 0.9434] 
2025-12-22 11:39:36.819571: Epoch time: 137.82 s 
2025-12-22 11:39:37.660706:  
2025-12-22 11:39:37.660706: Epoch 922 
2025-12-22 11:39:37.660706: Current learning rate: 0.00101 
2025-12-22 11:41:55.448290: train_loss -0.865 
2025-12-22 11:41:55.448290: val_loss -0.8906 
2025-12-22 11:41:55.456357: Pseudo dice [0.9377, 0.9623, 0.9457] 
2025-12-22 11:41:55.462364: Epoch time: 137.79 s 
2025-12-22 11:41:55.468108: Yayy! New best EMA pseudo Dice: 0.9447 
2025-12-22 11:41:56.417685:  
2025-12-22 11:41:56.417685: Epoch 923 
2025-12-22 11:41:56.417685: Current learning rate: 0.001 
2025-12-22 11:44:14.301144: train_loss -0.8653 
2025-12-22 11:44:14.301144: val_loss -0.8878 
2025-12-22 11:44:14.301144: Pseudo dice [0.9339, 0.9587, 0.9446] 
2025-12-22 11:44:14.316925: Epoch time: 137.88 s 
2025-12-22 11:44:14.316925: Yayy! New best EMA pseudo Dice: 0.9448 
2025-12-22 11:44:15.279531:  
2025-12-22 11:44:15.279531: Epoch 924 
2025-12-22 11:44:15.295597: Current learning rate: 0.00098 
2025-12-22 11:46:33.221920: train_loss -0.8625 
2025-12-22 11:46:33.221920: val_loss -0.884 
2025-12-22 11:46:33.229165: Pseudo dice [0.9313, 0.9587, 0.9454] 
2025-12-22 11:46:33.235171: Epoch time: 137.94 s 
2025-12-22 11:46:33.239175: Yayy! New best EMA pseudo Dice: 0.9448 
2025-12-22 11:46:34.221844:  
2025-12-22 11:46:34.223847: Epoch 925 
2025-12-22 11:46:34.230207: Current learning rate: 0.00097 
2025-12-22 11:48:52.099466: train_loss -0.8618 
2025-12-22 11:48:52.099466: val_loss -0.8756 
2025-12-22 11:48:52.107312: Pseudo dice [0.9235, 0.9557, 0.95] 
2025-12-22 11:48:52.113319: Epoch time: 137.88 s 
2025-12-22 11:48:52.732183:  
2025-12-22 11:48:52.732183: Epoch 926 
2025-12-22 11:48:52.747968: Current learning rate: 0.00096 
2025-12-22 11:51:10.548391: train_loss -0.8605 
2025-12-22 11:51:10.548391: val_loss -0.8821 
2025-12-22 11:51:10.566202: Pseudo dice [0.929, 0.9569, 0.9485] 
2025-12-22 11:51:10.573706: Epoch time: 137.82 s 
2025-12-22 11:51:11.207510:  
2025-12-22 11:51:11.207510: Epoch 927 
2025-12-22 11:51:11.213829: Current learning rate: 0.00095 
2025-12-22 11:53:28.818222: train_loss -0.8659 
2025-12-22 11:53:28.818222: val_loss -0.8936 
2025-12-22 11:53:28.825973: Pseudo dice [0.9407, 0.9629, 0.9455] 
2025-12-22 11:53:28.829979: Epoch time: 137.61 s 
2025-12-22 11:53:28.835988: Yayy! New best EMA pseudo Dice: 0.9452 
2025-12-22 11:53:30.110327:  
2025-12-22 11:53:30.110327: Epoch 928 
2025-12-22 11:53:30.131206: Current learning rate: 0.00094 
2025-12-22 11:55:47.853731: train_loss -0.8629 
2025-12-22 11:55:47.855473: val_loss -0.8759 
2025-12-22 11:55:47.859941: Pseudo dice [0.9264, 0.9535, 0.9448] 
2025-12-22 11:55:47.859941: Epoch time: 137.74 s 
2025-12-22 11:55:48.488600:  
2025-12-22 11:55:48.488600: Epoch 929 
2025-12-22 11:55:48.506396: Current learning rate: 0.00092 
2025-12-22 11:58:06.341980: train_loss -0.8615 
2025-12-22 11:58:06.343983: val_loss -0.8867 
2025-12-22 11:58:06.351903: Pseudo dice [0.9353, 0.959, 0.9424] 
2025-12-22 11:58:06.359914: Epoch time: 137.85 s 
2025-12-22 11:58:06.982687:  
2025-12-22 11:58:06.982687: Epoch 930 
2025-12-22 11:58:06.998380: Current learning rate: 0.00091 
2025-12-22 12:00:24.834393: train_loss -0.8652 
2025-12-22 12:00:24.834393: val_loss -0.8854 
2025-12-22 12:00:24.841904: Pseudo dice [0.9325, 0.9572, 0.9516] 
2025-12-22 12:00:24.841904: Epoch time: 137.85 s 
2025-12-22 12:00:25.550134:  
2025-12-22 12:00:25.550134: Epoch 931 
2025-12-22 12:00:25.550134: Current learning rate: 0.0009 
2025-12-22 12:02:43.498595: train_loss -0.8611 
2025-12-22 12:02:43.498595: val_loss -0.8884 
2025-12-22 12:02:43.504340: Pseudo dice [0.932, 0.9614, 0.9491] 
2025-12-22 12:02:43.504340: Epoch time: 137.95 s 
2025-12-22 12:02:43.518181: Yayy! New best EMA pseudo Dice: 0.9453 
2025-12-22 12:02:44.421759:  
2025-12-22 12:02:44.421759: Epoch 932 
2025-12-22 12:02:44.421759: Current learning rate: 0.00089 
2025-12-22 12:05:02.253435: train_loss -0.8638 
2025-12-22 12:05:02.255438: val_loss -0.8821 
2025-12-22 12:05:02.261445: Pseudo dice [0.9289, 0.9553, 0.948] 
2025-12-22 12:05:02.267451: Epoch time: 137.83 s 
2025-12-22 12:05:02.895387:  
2025-12-22 12:05:02.895387: Epoch 933 
2025-12-22 12:05:02.895387: Current learning rate: 0.00088 
2025-12-22 12:07:20.717290: train_loss -0.8695 
2025-12-22 12:07:20.719292: val_loss -0.8739 
2025-12-22 12:07:20.721294: Pseudo dice [0.9232, 0.9522, 0.9458] 
2025-12-22 12:07:20.730797: Epoch time: 137.82 s 
2025-12-22 12:07:21.654193:  
2025-12-22 12:07:21.670115: Epoch 934 
2025-12-22 12:07:21.676387: Current learning rate: 0.00087 
2025-12-22 12:09:39.812705: train_loss -0.8665 
2025-12-22 12:09:39.812705: val_loss -0.9017 
2025-12-22 12:09:39.820284: Pseudo dice [0.9442, 0.969, 0.9418] 
2025-12-22 12:09:39.826290: Epoch time: 138.16 s 
2025-12-22 12:09:39.832296: Yayy! New best EMA pseudo Dice: 0.9454 
2025-12-22 12:09:40.778757:  
2025-12-22 12:09:40.778757: Epoch 935 
2025-12-22 12:09:40.778757: Current learning rate: 0.00085 
2025-12-22 12:11:58.700069: train_loss -0.8649 
2025-12-22 12:11:58.701071: val_loss -0.8851 
2025-12-22 12:11:58.706910: Pseudo dice [0.9334, 0.9594, 0.9515] 
2025-12-22 12:11:58.712916: Epoch time: 137.92 s 
2025-12-22 12:11:58.716919: Yayy! New best EMA pseudo Dice: 0.9457 
2025-12-22 12:11:59.646506:  
2025-12-22 12:11:59.646506: Epoch 936 
2025-12-22 12:11:59.646506: Current learning rate: 0.00084 
2025-12-22 12:14:17.513627: train_loss -0.8675 
2025-12-22 12:14:17.513627: val_loss -0.8812 
2025-12-22 12:14:17.521377: Pseudo dice [0.927, 0.9565, 0.9474] 
2025-12-22 12:14:17.529385: Epoch time: 137.87 s 
2025-12-22 12:14:18.260326:  
2025-12-22 12:14:18.260326: Epoch 937 
2025-12-22 12:14:18.262329: Current learning rate: 0.00083 
2025-12-22 12:16:36.122338: train_loss -0.8663 
2025-12-22 12:16:36.122338: val_loss -0.8687 
2025-12-22 12:16:36.143791: Pseudo dice [0.9196, 0.9521, 0.9451] 
2025-12-22 12:16:36.147796: Epoch time: 137.86 s 
2025-12-22 12:16:36.803311:  
2025-12-22 12:16:36.803311: Epoch 938 
2025-12-22 12:16:36.803311: Current learning rate: 0.00082 
2025-12-22 12:18:54.842666: train_loss -0.8654 
2025-12-22 12:18:54.842666: val_loss -0.8684 
2025-12-22 12:18:54.850500: Pseudo dice [0.9194, 0.9533, 0.9424] 
2025-12-22 12:18:54.854504: Epoch time: 138.04 s 
2025-12-22 12:18:55.553470:  
2025-12-22 12:18:55.553470: Epoch 939 
2025-12-22 12:18:55.553470: Current learning rate: 0.00081 
2025-12-22 12:21:13.238447: train_loss -0.8664 
2025-12-22 12:21:13.238447: val_loss -0.88 
2025-12-22 12:21:13.248458: Pseudo dice [0.9291, 0.9557, 0.9423] 
2025-12-22 12:21:13.256374: Epoch time: 137.68 s 
2025-12-22 12:21:13.918401:  
2025-12-22 12:21:13.918401: Epoch 940 
2025-12-22 12:21:13.934106: Current learning rate: 0.00079 
2025-12-22 12:23:31.779044: train_loss -0.8636 
2025-12-22 12:23:31.779044: val_loss -0.8797 
2025-12-22 12:23:31.785051: Pseudo dice [0.9313, 0.96, 0.9423] 
2025-12-22 12:23:31.791057: Epoch time: 137.86 s 
2025-12-22 12:23:32.458781:  
2025-12-22 12:23:32.458781: Epoch 941 
2025-12-22 12:23:32.474583: Current learning rate: 0.00078 
2025-12-22 12:25:50.193522: train_loss -0.8677 
2025-12-22 12:25:50.193522: val_loss -0.8846 
2025-12-22 12:25:50.197264: Pseudo dice [0.9321, 0.9576, 0.9466] 
2025-12-22 12:25:50.206507: Epoch time: 137.73 s 
2025-12-22 12:25:50.928034:  
2025-12-22 12:25:50.930036: Epoch 942 
2025-12-22 12:25:50.930036: Current learning rate: 0.00077 
2025-12-22 12:28:08.748343: train_loss -0.8656 
2025-12-22 12:28:08.750345: val_loss -0.881 
2025-12-22 12:28:08.756846: Pseudo dice [0.9266, 0.9563, 0.9489] 
2025-12-22 12:28:08.762851: Epoch time: 137.82 s 
2025-12-22 12:28:09.475412:  
2025-12-22 12:28:09.475412: Epoch 943 
2025-12-22 12:28:09.480062: Current learning rate: 0.00076 
2025-12-22 12:30:27.337078: train_loss -0.8629 
2025-12-22 12:30:27.337078: val_loss -0.8794 
2025-12-22 12:30:27.343990: Pseudo dice [0.9267, 0.9556, 0.9468] 
2025-12-22 12:30:27.343990: Epoch time: 137.86 s 
2025-12-22 12:30:28.028182:  
2025-12-22 12:30:28.028182: Epoch 944 
2025-12-22 12:30:28.028182: Current learning rate: 0.00075 
2025-12-22 12:32:45.825244: train_loss -0.8634 
2025-12-22 12:32:45.825244: val_loss -0.8736 
2025-12-22 12:32:45.831250: Pseudo dice [0.924, 0.952, 0.9461] 
2025-12-22 12:32:45.834254: Epoch time: 137.8 s 
2025-12-22 12:32:46.606212:  
2025-12-22 12:32:46.606212: Epoch 945 
2025-12-22 12:32:46.606212: Current learning rate: 0.00074 
2025-12-22 12:35:04.405692: train_loss -0.8718 
2025-12-22 12:35:04.405692: val_loss -0.879 
2025-12-22 12:35:04.405692: Pseudo dice [0.9277, 0.9564, 0.9464] 
2025-12-22 12:35:04.421690: Epoch time: 137.8 s 
2025-12-22 12:35:05.040814:  
2025-12-22 12:35:05.040814: Epoch 946 
2025-12-22 12:35:05.056582: Current learning rate: 0.00072 
2025-12-22 12:37:22.907859: train_loss -0.8669 
2025-12-22 12:37:22.908862: val_loss -0.8828 
2025-12-22 12:37:22.914424: Pseudo dice [0.9315, 0.9578, 0.9478] 
2025-12-22 12:37:22.920430: Epoch time: 137.87 s 
2025-12-22 12:37:23.701844:  
2025-12-22 12:37:23.701844: Epoch 947 
2025-12-22 12:37:23.717689: Current learning rate: 0.00071 
2025-12-22 12:39:41.522835: train_loss -0.8626 
2025-12-22 12:39:41.522835: val_loss -0.8694 
2025-12-22 12:39:41.528840: Pseudo dice [0.9187, 0.9492, 0.9487] 
2025-12-22 12:39:41.536268: Epoch time: 137.82 s 
2025-12-22 12:39:42.320286:  
2025-12-22 12:39:42.320286: Epoch 948 
2025-12-22 12:39:42.328296: Current learning rate: 0.0007 
2025-12-22 12:42:00.181080: train_loss -0.8625 
2025-12-22 12:42:00.181080: val_loss -0.8797 
2025-12-22 12:42:00.188652: Pseudo dice [0.9272, 0.9546, 0.9506] 
2025-12-22 12:42:00.194658: Epoch time: 137.86 s 
2025-12-22 12:42:00.846325:  
2025-12-22 12:42:00.846325: Epoch 949 
2025-12-22 12:42:00.851860: Current learning rate: 0.00069 
2025-12-22 12:44:18.539746: train_loss -0.8665 
2025-12-22 12:44:18.539746: val_loss -0.8972 
2025-12-22 12:44:18.547492: Pseudo dice [0.9386, 0.9652, 0.9491] 
2025-12-22 12:44:18.553498: Epoch time: 137.7 s 
2025-12-22 12:44:19.438853:  
2025-12-22 12:44:19.438853: Epoch 950 
2025-12-22 12:44:19.454890: Current learning rate: 0.00067 
2025-12-22 12:46:37.220404: train_loss -0.8662 
2025-12-22 12:46:37.220404: val_loss -0.8834 
2025-12-22 12:46:37.228280: Pseudo dice [0.9266, 0.9568, 0.9467] 
2025-12-22 12:46:37.232284: Epoch time: 137.78 s 
2025-12-22 12:46:37.968798:  
2025-12-22 12:46:37.968798: Epoch 951 
2025-12-22 12:46:37.977250: Current learning rate: 0.00066 
2025-12-22 12:48:55.814580: train_loss -0.8663 
2025-12-22 12:48:55.816583: val_loss -0.8683 
2025-12-22 12:48:55.816583: Pseudo dice [0.9198, 0.948, 0.945] 
2025-12-22 12:48:55.824258: Epoch time: 137.85 s 
2025-12-22 12:48:56.474036:  
2025-12-22 12:48:56.474036: Epoch 952 
2025-12-22 12:48:56.491830: Current learning rate: 0.00065 
2025-12-22 12:51:14.425612: train_loss -0.8647 
2025-12-22 12:51:14.425612: val_loss -0.8826 
2025-12-22 12:51:14.430854: Pseudo dice [0.9293, 0.9601, 0.9421] 
2025-12-22 12:51:14.430854: Epoch time: 137.95 s 
2025-12-22 12:51:15.310738:  
2025-12-22 12:51:15.310738: Epoch 953 
2025-12-22 12:51:15.310738: Current learning rate: 0.00064 
2025-12-22 12:53:33.290846: train_loss -0.8655 
2025-12-22 12:53:33.290846: val_loss -0.8762 
2025-12-22 12:53:33.290846: Pseudo dice [0.9239, 0.9531, 0.9417] 
2025-12-22 12:53:33.308802: Epoch time: 137.98 s 
2025-12-22 12:53:34.082306:  
2025-12-22 12:53:34.082306: Epoch 954 
2025-12-22 12:53:34.082306: Current learning rate: 0.00063 
2025-12-22 12:55:51.813989: train_loss -0.8618 
2025-12-22 12:55:51.813989: val_loss -0.8661 
2025-12-22 12:55:51.831708: Pseudo dice [0.9227, 0.949, 0.9422] 
2025-12-22 12:55:51.831708: Epoch time: 137.73 s 
2025-12-22 12:55:52.466164:  
2025-12-22 12:55:52.466164: Epoch 955 
2025-12-22 12:55:52.466164: Current learning rate: 0.00061 
2025-12-22 12:58:10.353802: train_loss -0.8667 
2025-12-22 12:58:10.353802: val_loss -0.8565 
2025-12-22 12:58:10.353802: Pseudo dice [0.9127, 0.9468, 0.9429] 
2025-12-22 12:58:10.367535: Epoch time: 137.9 s 
2025-12-22 12:58:11.000102:  
2025-12-22 12:58:11.000102: Epoch 956 
2025-12-22 12:58:11.016226: Current learning rate: 0.0006 
2025-12-22 13:00:29.043654: train_loss -0.8622 
2025-12-22 13:00:29.045657: val_loss -0.8825 
2025-12-22 13:00:29.055666: Pseudo dice [0.9346, 0.9564, 0.9391] 
2025-12-22 13:00:29.061301: Epoch time: 138.04 s 
2025-12-22 13:00:29.695061:  
2025-12-22 13:00:29.695061: Epoch 957 
2025-12-22 13:00:29.709059: Current learning rate: 0.00059 
2025-12-22 13:02:47.456319: train_loss -0.8673 
2025-12-22 13:02:47.458060: val_loss -0.8836 
2025-12-22 13:02:47.467306: Pseudo dice [0.9315, 0.9568, 0.949] 
2025-12-22 13:02:47.473808: Epoch time: 137.76 s 
2025-12-22 13:02:48.092392:  
2025-12-22 13:02:48.108301: Epoch 958 
2025-12-22 13:02:48.110081: Current learning rate: 0.00058 
2025-12-22 13:05:06.118757: train_loss -0.8677 
2025-12-22 13:05:06.118757: val_loss -0.8843 
2025-12-22 13:05:06.134592: Pseudo dice [0.9308, 0.9571, 0.948] 
2025-12-22 13:05:06.134592: Epoch time: 138.03 s 
2025-12-22 13:05:06.768662:  
2025-12-22 13:05:06.768662: Epoch 959 
2025-12-22 13:05:06.784636: Current learning rate: 0.00056 
2025-12-22 13:07:24.791106: train_loss -0.8647 
2025-12-22 13:07:24.791106: val_loss -0.8844 
2025-12-22 13:07:24.795112: Pseudo dice [0.9314, 0.9558, 0.9485] 
2025-12-22 13:07:24.795112: Epoch time: 138.02 s 
2025-12-22 13:07:25.648983:  
2025-12-22 13:07:25.648983: Epoch 960 
2025-12-22 13:07:25.664913: Current learning rate: 0.00055 
2025-12-22 13:09:43.900657: train_loss -0.8669 
2025-12-22 13:09:43.900657: val_loss -0.8819 
2025-12-22 13:09:43.916559: Pseudo dice [0.9311, 0.9581, 0.938] 
2025-12-22 13:09:43.916559: Epoch time: 138.25 s 
2025-12-22 13:09:44.597755:  
2025-12-22 13:09:44.597755: Epoch 961 
2025-12-22 13:09:44.597755: Current learning rate: 0.00054 
2025-12-22 13:12:02.356848: train_loss -0.8652 
2025-12-22 13:12:02.356848: val_loss -0.8827 
2025-12-22 13:12:02.368649: Pseudo dice [0.93, 0.9582, 0.9444] 
2025-12-22 13:12:02.368649: Epoch time: 137.76 s 
2025-12-22 13:12:03.017315:  
2025-12-22 13:12:03.017315: Epoch 962 
2025-12-22 13:12:03.017315: Current learning rate: 0.00053 
2025-12-22 13:14:20.904479: train_loss -0.8667 
2025-12-22 13:14:20.904479: val_loss -0.8818 
2025-12-22 13:14:20.912247: Pseudo dice [0.9285, 0.9567, 0.9443] 
2025-12-22 13:14:20.912247: Epoch time: 137.89 s 
2025-12-22 13:14:21.543638:  
2025-12-22 13:14:21.543638: Epoch 963 
2025-12-22 13:14:21.543638: Current learning rate: 0.00051 
2025-12-22 13:16:39.362556: train_loss -0.8646 
2025-12-22 13:16:39.362556: val_loss -0.8826 
2025-12-22 13:16:39.362556: Pseudo dice [0.9336, 0.9578, 0.943] 
2025-12-22 13:16:39.380084: Epoch time: 137.82 s 
2025-12-22 13:16:40.015296:  
2025-12-22 13:16:40.015296: Epoch 964 
2025-12-22 13:16:40.015296: Current learning rate: 0.0005 
2025-12-22 13:18:57.747010: train_loss -0.8634 
2025-12-22 13:18:57.747010: val_loss -0.8773 
2025-12-22 13:18:57.762940: Pseudo dice [0.9293, 0.9565, 0.9381] 
2025-12-22 13:18:57.769304: Epoch time: 137.73 s 
2025-12-22 13:18:58.508727:  
2025-12-22 13:18:58.508727: Epoch 965 
2025-12-22 13:18:58.524352: Current learning rate: 0.00049 
2025-12-22 13:21:16.445064: train_loss -0.8653 
2025-12-22 13:21:16.445064: val_loss -0.8903 
2025-12-22 13:21:16.454843: Pseudo dice [0.9354, 0.9592, 0.9538] 
2025-12-22 13:21:16.466445: Epoch time: 137.94 s 
2025-12-22 13:21:17.265109:  
2025-12-22 13:21:17.265109: Epoch 966 
2025-12-22 13:21:17.281075: Current learning rate: 0.00048 
2025-12-22 13:23:35.103041: train_loss -0.8638 
2025-12-22 13:23:35.103041: val_loss -0.9026 
2025-12-22 13:23:35.113053: Pseudo dice [0.9425, 0.9668, 0.9518] 
2025-12-22 13:23:35.118736: Epoch time: 137.84 s 
2025-12-22 13:23:35.797873:  
2025-12-22 13:23:35.797873: Epoch 967 
2025-12-22 13:23:35.805201: Current learning rate: 0.00046 
2025-12-22 13:25:53.746734: train_loss -0.8615 
2025-12-22 13:25:53.746734: val_loss -0.878 
2025-12-22 13:25:53.756485: Pseudo dice [0.9224, 0.9532, 0.9512] 
2025-12-22 13:25:53.766509: Epoch time: 137.95 s 
2025-12-22 13:25:54.512628:  
2025-12-22 13:25:54.514440: Epoch 968 
2025-12-22 13:25:54.514440: Current learning rate: 0.00045 
2025-12-22 13:28:12.293613: train_loss -0.8635 
2025-12-22 13:28:12.293613: val_loss -0.8835 
2025-12-22 13:28:12.293613: Pseudo dice [0.93, 0.9594, 0.9423] 
2025-12-22 13:28:12.309353: Epoch time: 137.8 s 
2025-12-22 13:28:12.931072:  
2025-12-22 13:28:12.945091: Epoch 969 
2025-12-22 13:28:12.950971: Current learning rate: 0.00044 
2025-12-22 13:30:30.638098: train_loss -0.8655 
2025-12-22 13:30:30.638098: val_loss -0.893 
2025-12-22 13:30:30.649114: Pseudo dice [0.938, 0.9634, 0.9509] 
2025-12-22 13:30:30.655121: Epoch time: 137.71 s 
2025-12-22 13:30:31.294858:  
2025-12-22 13:30:31.294858: Epoch 970 
2025-12-22 13:30:31.294858: Current learning rate: 0.00043 
2025-12-22 13:32:48.975547: train_loss -0.8693 
2025-12-22 13:32:48.975547: val_loss -0.8826 
2025-12-22 13:32:48.991320: Pseudo dice [0.9279, 0.9552, 0.9527] 
2025-12-22 13:32:49.000825: Epoch time: 137.68 s 
2025-12-22 13:32:49.626588:  
2025-12-22 13:32:49.626588: Epoch 971 
2025-12-22 13:32:49.640563: Current learning rate: 0.00041 
2025-12-22 13:35:07.318259: train_loss -0.8659 
2025-12-22 13:35:07.318259: val_loss -0.8855 
2025-12-22 13:35:07.333999: Pseudo dice [0.9336, 0.9585, 0.9457] 
2025-12-22 13:35:07.333999: Epoch time: 137.69 s 
2025-12-22 13:35:08.144284:  
2025-12-22 13:35:08.144284: Epoch 972 
2025-12-22 13:35:08.144284: Current learning rate: 0.0004 
2025-12-22 13:37:26.097316: train_loss -0.8633 
2025-12-22 13:37:26.097316: val_loss -0.8736 
2025-12-22 13:37:26.105289: Pseudo dice [0.9249, 0.9554, 0.9422] 
2025-12-22 13:37:26.105289: Epoch time: 137.95 s 
2025-12-22 13:37:26.741235:  
2025-12-22 13:37:26.741235: Epoch 973 
2025-12-22 13:37:26.755205: Current learning rate: 0.00039 
2025-12-22 13:39:44.424290: train_loss -0.8618 
2025-12-22 13:39:44.424290: val_loss -0.868 
2025-12-22 13:39:44.440192: Pseudo dice [0.9171, 0.9497, 0.951] 
2025-12-22 13:39:44.440192: Epoch time: 137.68 s 
2025-12-22 13:39:45.074953:  
2025-12-22 13:39:45.074953: Epoch 974 
2025-12-22 13:39:45.074953: Current learning rate: 0.00037 
2025-12-22 13:42:02.889152: train_loss -0.8614 
2025-12-22 13:42:02.889152: val_loss -0.8855 
2025-12-22 13:42:02.899163: Pseudo dice [0.9333, 0.9601, 0.9469] 
2025-12-22 13:42:02.906910: Epoch time: 137.81 s 
2025-12-22 13:42:03.535829:  
2025-12-22 13:42:03.535829: Epoch 975 
2025-12-22 13:42:03.551744: Current learning rate: 0.00036 
2025-12-22 13:44:21.392026: train_loss -0.8655 
2025-12-22 13:44:21.392026: val_loss -0.8865 
2025-12-22 13:44:21.403786: Pseudo dice [0.9311, 0.96, 0.9472] 
2025-12-22 13:44:21.411287: Epoch time: 137.86 s 
2025-12-22 13:44:22.177020:  
2025-12-22 13:44:22.177020: Epoch 976 
2025-12-22 13:44:22.177020: Current learning rate: 0.00035 
2025-12-22 13:46:39.872353: train_loss -0.8668 
2025-12-22 13:46:39.872353: val_loss -0.8821 
2025-12-22 13:46:39.884194: Pseudo dice [0.9277, 0.9547, 0.9459] 
2025-12-22 13:46:39.890200: Epoch time: 137.7 s 
2025-12-22 13:46:40.593047:  
2025-12-22 13:46:40.593047: Epoch 977 
2025-12-22 13:46:40.593047: Current learning rate: 0.00034 
2025-12-22 13:48:58.226204: train_loss -0.8638 
2025-12-22 13:48:58.228205: val_loss -0.8829 
2025-12-22 13:48:58.234210: Pseudo dice [0.9328, 0.9595, 0.9406] 
2025-12-22 13:48:58.237770: Epoch time: 137.63 s 
2025-12-22 13:48:58.868611:  
2025-12-22 13:48:58.868611: Epoch 978 
2025-12-22 13:48:58.886513: Current learning rate: 0.00032 
2025-12-22 13:51:16.598686: train_loss -0.8691 
2025-12-22 13:51:16.598686: val_loss -0.8878 
2025-12-22 13:51:16.605926: Pseudo dice [0.9361, 0.9598, 0.9426] 
2025-12-22 13:51:16.605926: Epoch time: 137.73 s 
2025-12-22 13:51:17.462154:  
2025-12-22 13:51:17.462154: Epoch 979 
2025-12-22 13:51:17.462154: Current learning rate: 0.00031 
2025-12-22 13:53:35.194525: train_loss -0.8671 
2025-12-22 13:53:35.194525: val_loss -0.8809 
2025-12-22 13:53:35.208544: Pseudo dice [0.9285, 0.9554, 0.9496] 
2025-12-22 13:53:35.216292: Epoch time: 137.73 s 
2025-12-22 13:53:35.842880:  
2025-12-22 13:53:35.842880: Epoch 980 
2025-12-22 13:53:35.858549: Current learning rate: 0.0003 
2025-12-22 13:55:53.665803: train_loss -0.8642 
2025-12-22 13:55:53.681455: val_loss -0.899 
2025-12-22 13:55:53.687461: Pseudo dice [0.9437, 0.964, 0.9444] 
2025-12-22 13:55:53.691465: Epoch time: 137.82 s 
2025-12-22 13:55:54.329812:  
2025-12-22 13:55:54.329812: Epoch 981 
2025-12-22 13:55:54.329812: Current learning rate: 0.00028 
2025-12-22 13:58:12.151977: train_loss -0.8643 
2025-12-22 13:58:12.151977: val_loss -0.882 
2025-12-22 13:58:12.151977: Pseudo dice [0.9333, 0.9563, 0.9406] 
2025-12-22 13:58:12.151977: Epoch time: 137.82 s 
2025-12-22 13:58:12.785918:  
2025-12-22 13:58:12.801765: Epoch 982 
2025-12-22 13:58:12.801765: Current learning rate: 0.00027 
2025-12-22 14:00:30.478902: train_loss -0.8633 
2025-12-22 14:00:30.478902: val_loss -0.8884 
2025-12-22 14:00:30.486648: Pseudo dice [0.9331, 0.9586, 0.9495] 
2025-12-22 14:00:30.488650: Epoch time: 137.69 s 
2025-12-22 14:00:31.119989:  
2025-12-22 14:00:31.119989: Epoch 983 
2025-12-22 14:00:31.135815: Current learning rate: 0.00026 
2025-12-22 14:02:49.452609: train_loss -0.8656 
2025-12-22 14:02:49.452609: val_loss -0.8733 
2025-12-22 14:02:49.462369: Pseudo dice [0.9211, 0.9543, 0.9439] 
2025-12-22 14:02:49.470380: Epoch time: 138.33 s 
2025-12-22 14:02:50.205011:  
2025-12-22 14:02:50.205011: Epoch 984 
2025-12-22 14:02:50.220968: Current learning rate: 0.00024 
2025-12-22 14:05:08.627758: train_loss -0.8664 
2025-12-22 14:05:08.627758: val_loss -0.8719 
2025-12-22 14:05:08.631600: Pseudo dice [0.9215, 0.9505, 0.9543] 
2025-12-22 14:05:08.631600: Epoch time: 138.42 s 
2025-12-22 14:05:09.449492:  
2025-12-22 14:05:09.449492: Epoch 985 
2025-12-22 14:05:09.449492: Current learning rate: 0.00023 
2025-12-22 14:07:27.721973: train_loss -0.8683 
2025-12-22 14:07:27.721973: val_loss -0.9018 
2025-12-22 14:07:27.735821: Pseudo dice [0.9431, 0.9671, 0.9516] 
2025-12-22 14:07:27.735821: Epoch time: 138.27 s 
2025-12-22 14:07:28.384240:  
2025-12-22 14:07:28.384240: Epoch 986 
2025-12-22 14:07:28.384240: Current learning rate: 0.00021 
2025-12-22 14:09:46.975533: train_loss -0.8637 
2025-12-22 14:09:46.975533: val_loss -0.8964 
2025-12-22 14:09:46.985282: Pseudo dice [0.9401, 0.9648, 0.9504] 
2025-12-22 14:09:46.994541: Epoch time: 138.59 s 
2025-12-22 14:09:47.000548: Yayy! New best EMA pseudo Dice: 0.946 
2025-12-22 14:09:47.914744:  
2025-12-22 14:09:47.914744: Epoch 987 
2025-12-22 14:09:47.930758: Current learning rate: 0.0002 
2025-12-22 14:12:06.201102: train_loss -0.8645 
2025-12-22 14:12:06.201102: val_loss -0.8704 
2025-12-22 14:12:06.201102: Pseudo dice [0.9175, 0.9525, 0.9485] 
2025-12-22 14:12:06.201102: Epoch time: 138.29 s 
2025-12-22 14:12:06.862996:  
2025-12-22 14:12:06.862996: Epoch 988 
2025-12-22 14:12:06.862996: Current learning rate: 0.00019 
2025-12-22 14:14:24.861650: train_loss -0.8646 
2025-12-22 14:14:24.861650: val_loss -0.8803 
2025-12-22 14:14:24.871399: Pseudo dice [0.9295, 0.9577, 0.9467] 
2025-12-22 14:14:24.879146: Epoch time: 138.0 s 
2025-12-22 14:14:25.511923:  
2025-12-22 14:14:25.511923: Epoch 989 
2025-12-22 14:14:25.511923: Current learning rate: 0.00017 
2025-12-22 14:16:43.296999: train_loss -0.8649 
2025-12-22 14:16:43.296999: val_loss -0.8791 
2025-12-22 14:16:43.305006: Pseudo dice [0.9279, 0.9597, 0.9407] 
2025-12-22 14:16:43.309750: Epoch time: 137.79 s 
2025-12-22 14:16:43.940325:  
2025-12-22 14:16:43.940325: Epoch 990 
2025-12-22 14:16:43.940325: Current learning rate: 0.00016 
2025-12-22 14:19:01.685904: train_loss -0.8651 
2025-12-22 14:19:01.685904: val_loss -0.8862 
2025-12-22 14:19:01.693912: Pseudo dice [0.9323, 0.9585, 0.9489] 
2025-12-22 14:19:01.695652: Epoch time: 137.75 s 
2025-12-22 14:19:02.502652:  
2025-12-22 14:19:02.502652: Epoch 991 
2025-12-22 14:19:02.518608: Current learning rate: 0.00014 
2025-12-22 14:21:20.228263: train_loss -0.8666 
2025-12-22 14:21:20.228263: val_loss -0.875 
2025-12-22 14:21:20.248114: Pseudo dice [0.9235, 0.9542, 0.9469] 
2025-12-22 14:21:20.254121: Epoch time: 137.73 s 
2025-12-22 14:21:20.939986:  
2025-12-22 14:21:20.939986: Epoch 992 
2025-12-22 14:21:20.939986: Current learning rate: 0.00013 
2025-12-22 14:23:38.779339: train_loss -0.8653 
2025-12-22 14:23:38.781342: val_loss -0.891 
2025-12-22 14:23:38.787056: Pseudo dice [0.9328, 0.9601, 0.9509] 
2025-12-22 14:23:38.794155: Epoch time: 137.84 s 
2025-12-22 14:23:39.541124:  
2025-12-22 14:23:39.541124: Epoch 993 
2025-12-22 14:23:39.557148: Current learning rate: 0.00011 
2025-12-22 14:25:57.202301: train_loss -0.8704 
2025-12-22 14:25:57.204303: val_loss -0.8874 
2025-12-22 14:25:57.212049: Pseudo dice [0.9347, 0.9629, 0.9452] 
2025-12-22 14:25:57.218055: Epoch time: 137.66 s 
2025-12-22 14:25:57.861353:  
2025-12-22 14:25:57.861353: Epoch 994 
2025-12-22 14:25:57.861353: Current learning rate: 0.0001 
2025-12-22 14:28:15.602134: train_loss -0.8639 
2025-12-22 14:28:15.618134: val_loss -0.8826 
2025-12-22 14:28:15.620137: Pseudo dice [0.9305, 0.9575, 0.9489] 
2025-12-22 14:28:15.631543: Epoch time: 137.74 s 
2025-12-22 14:28:16.268336:  
2025-12-22 14:28:16.270079: Epoch 995 
2025-12-22 14:28:16.276147: Current learning rate: 8e-05 
2025-12-22 14:30:33.911439: train_loss -0.8733 
2025-12-22 14:30:33.911439: val_loss -0.882 
2025-12-22 14:30:33.920916: Pseudo dice [0.926, 0.9546, 0.9529] 
2025-12-22 14:30:33.927260: Epoch time: 137.66 s 
2025-12-22 14:30:34.687521:  
2025-12-22 14:30:34.689524: Epoch 996 
2025-12-22 14:30:34.689524: Current learning rate: 7e-05 
2025-12-22 14:32:52.576103: train_loss -0.8637 
2025-12-22 14:32:52.576103: val_loss -0.8789 
2025-12-22 14:32:52.583849: Pseudo dice [0.9271, 0.9555, 0.9437] 
2025-12-22 14:32:52.583849: Epoch time: 137.89 s 
2025-12-22 14:32:53.391068:  
2025-12-22 14:32:53.391068: Epoch 997 
2025-12-22 14:32:53.408792: Current learning rate: 5e-05 
2025-12-22 14:35:11.253652: train_loss -0.8652 
2025-12-22 14:35:11.253652: val_loss -0.8927 
2025-12-22 14:35:11.255910: Pseudo dice [0.936, 0.9632, 0.9482] 
2025-12-22 14:35:11.268223: Epoch time: 137.86 s 
2025-12-22 14:35:11.970302:  
2025-12-22 14:35:11.970302: Epoch 998 
2025-12-22 14:35:11.970302: Current learning rate: 4e-05 
2025-12-22 14:37:29.867473: train_loss -0.8633 
2025-12-22 14:37:29.867473: val_loss -0.8831 
2025-12-22 14:37:29.874912: Pseudo dice [0.9293, 0.9586, 0.9479] 
2025-12-22 14:37:29.880041: Epoch time: 137.9 s 
2025-12-22 14:37:30.515674:  
2025-12-22 14:37:30.515674: Epoch 999 
2025-12-22 14:37:30.535290: Current learning rate: 2e-05 
2025-12-22 14:39:48.321467: train_loss -0.8647 
2025-12-22 14:39:48.321467: val_loss -0.8909 
2025-12-22 14:39:48.337349: Pseudo dice [0.935, 0.9601, 0.9468] 
2025-12-22 14:39:48.337349: Epoch time: 137.81 s 
2025-12-22 14:39:49.402870: Training done. 
2025-12-22 14:39:49.481074: Using splits from existing split file: C:\Users\Anna\Documents\TFM\nnUNet_preprocessed\Dataset500_MRI\splits_final.json 
2025-12-22 14:39:49.484225: The split file contains 5 splits. 
2025-12-22 14:39:49.493895: Desired fold for training: 4 
2025-12-22 14:39:49.493895: This split has 400 training and 100 validation cases. 
2025-12-22 14:39:49.509643: predicting OAS30014_MR_d0196_1 
2025-12-22 14:39:49.667350: OAS30014_MR_d0196_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:40:09.716271: predicting OAS30014_MR_d0196_5 
2025-12-22 14:40:09.732485: OAS30014_MR_d0196_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:40:26.381360: predicting OAS30017_MR_d0054_2 
2025-12-22 14:40:26.397046: OAS30017_MR_d0054_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:40:43.136339: predicting OAS30025_MR_d0210_3 
2025-12-22 14:40:43.138341: OAS30025_MR_d0210_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:40:59.891798: predicting OAS30025_MR_d0210_9 
2025-12-22 14:40:59.909732: OAS30025_MR_d0210_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:41:16.605964: predicting OAS30036_MR_d0059_4 
2025-12-22 14:41:16.628471: OAS30036_MR_d0059_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:41:33.336272: predicting OAS30036_MR_d0059_6 
2025-12-22 14:41:33.360141: OAS30036_MR_d0059_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:41:50.043370: predicting OAS30039_MR_d1203_3 
2025-12-22 14:41:50.055212: OAS30039_MR_d1203_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:42:06.744204: predicting OAS30052_MR_d0693_8 
2025-12-22 14:42:06.758809: OAS30052_MR_d0693_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:42:23.417730: predicting OAS30052_MR_d0693_9 
2025-12-22 14:42:23.435826: OAS30052_MR_d0693_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:42:40.114251: predicting OAS30078_MR_d0210_2 
2025-12-22 14:42:40.132235: OAS30078_MR_d0210_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:42:56.854941: predicting OAS30078_MR_d0210_3 
2025-12-22 14:42:56.866078: OAS30078_MR_d0210_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:43:13.585897: predicting OAS30078_MR_d0210_4 
2025-12-22 14:43:13.601564: OAS30078_MR_d0210_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:43:30.290226: predicting OAS30083_MR_d0465_2 
2025-12-22 14:43:30.300247: OAS30083_MR_d0465_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:43:46.973828: predicting OAS30083_MR_d0465_4 
2025-12-22 14:43:46.993556: OAS30083_MR_d0465_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:44:03.661756: predicting OAS30083_MR_d0465_6 
2025-12-22 14:44:03.677723: OAS30083_MR_d0465_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:44:20.374346: predicting OAS30083_MR_d0465_7 
2025-12-22 14:44:20.398025: OAS30083_MR_d0465_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:44:37.093187: predicting OAS30087_MR_d0260_1 
2025-12-22 14:44:37.103044: OAS30087_MR_d0260_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:44:53.815038: predicting OAS30087_MR_d0260_10 
2025-12-22 14:44:53.826684: OAS30087_MR_d0260_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:45:10.519905: predicting OAS30087_MR_d0260_2 
2025-12-22 14:45:10.529272: OAS30087_MR_d0260_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:45:27.214906: predicting OAS30087_MR_d0260_3 
2025-12-22 14:45:27.227958: OAS30087_MR_d0260_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:45:43.894430: predicting OAS30099_MR_d0032_10 
2025-12-22 14:45:43.917419: OAS30099_MR_d0032_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:46:00.593201: predicting OAS30102_MR_d0024_5 
2025-12-22 14:46:00.608994: OAS30102_MR_d0024_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:46:17.298918: predicting OAS30102_MR_d0024_7 
2025-12-22 14:46:17.310690: OAS30102_MR_d0024_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:46:34.019213: predicting OAS30102_MR_d0024_8 
2025-12-22 14:46:34.032792: OAS30102_MR_d0024_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:46:50.749479: predicting OAS30104_MR_d0328_8 
2025-12-22 14:46:50.759035: OAS30104_MR_d0328_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:47:07.439041: predicting OAS30104_MR_d0328_9 
2025-12-22 14:47:07.453118: OAS30104_MR_d0328_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:47:24.137558: predicting OAS30107_MR_d0387_4 
2025-12-22 14:47:24.155419: OAS30107_MR_d0387_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:47:40.876390: predicting OAS30107_MR_d0387_9 
2025-12-22 14:47:40.888414: OAS30107_MR_d0387_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:47:57.604997: predicting OAS30125_MR_d0201_3 
2025-12-22 14:47:57.615075: OAS30125_MR_d0201_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:48:14.338019: predicting OAS30125_MR_d0201_8 
2025-12-22 14:48:14.347235: OAS30125_MR_d0201_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:48:31.029907: predicting OAS30127_MR_d0098_2 
2025-12-22 14:48:31.038854: OAS30127_MR_d0098_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:48:47.735379: predicting OAS30127_MR_d0098_3 
2025-12-22 14:48:47.757903: OAS30127_MR_d0098_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:49:04.496110: predicting OAS30127_MR_d0098_6 
2025-12-22 14:49:04.506126: OAS30127_MR_d0098_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:49:21.239371: predicting OAS30134_MR_d0080_5 
2025-12-22 14:49:21.259157: OAS30134_MR_d0080_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:49:37.924852: predicting OAS30140_MR_d0172_6 
2025-12-22 14:49:37.940516: OAS30140_MR_d0172_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:49:54.630769: predicting OAS30147_MR_d0048_10 
2025-12-22 14:49:54.644123: OAS30147_MR_d0048_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:50:11.334312: predicting OAS30147_MR_d0048_2 
2025-12-22 14:50:11.346261: OAS30147_MR_d0048_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:50:28.052670: predicting OAS30147_MR_d0048_8 
2025-12-22 14:50:28.063851: OAS30147_MR_d0048_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:50:44.813647: predicting OAS30165_MR_d1763_5 
2025-12-22 14:50:44.829376: OAS30165_MR_d1763_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:51:01.532190: predicting OAS30165_MR_d1763_9 
2025-12-22 14:51:01.543668: OAS30165_MR_d1763_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:51:18.254567: predicting OAS30176_MR_d0000_10 
2025-12-22 14:51:18.279015: OAS30176_MR_d0000_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:51:34.967426: predicting OAS30176_MR_d0000_8 
2025-12-22 14:51:34.979514: OAS30176_MR_d0000_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:51:51.661648: predicting OAS30195_MR_d1596_1 
2025-12-22 14:51:51.671708: OAS30195_MR_d1596_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:52:08.360058: predicting OAS30195_MR_d1596_8 
2025-12-22 14:52:08.377499: OAS30195_MR_d1596_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:52:25.038704: predicting OAS30226_MR_d0183_6 
2025-12-22 14:52:25.056751: OAS30226_MR_d0183_6, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:52:41.758747: predicting OAS30226_MR_d0183_7 
2025-12-22 14:52:41.772969: OAS30226_MR_d0183_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:52:58.452410: predicting OAS30234_MR_d2098_10 
2025-12-22 14:52:58.472300: OAS30234_MR_d2098_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:53:15.180443: predicting OAS30234_MR_d2098_5 
2025-12-22 14:53:15.190840: OAS30234_MR_d2098_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:53:31.911132: predicting OAS30238_MR_d0037_7 
2025-12-22 14:53:31.920965: OAS30238_MR_d0037_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:53:48.609536: predicting OAS30238_MR_d0037_8 
2025-12-22 14:53:48.631171: OAS30238_MR_d0037_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:54:05.360716: predicting OAS30250_MR_d0389_10 
2025-12-22 14:54:05.368468: OAS30250_MR_d0389_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:54:22.081140: predicting OAS30250_MR_d0389_2 
2025-12-22 14:54:22.092364: OAS30250_MR_d0389_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:54:38.789834: predicting OAS30250_MR_d0389_7 
2025-12-22 14:54:38.798817: OAS30250_MR_d0389_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:54:55.519737: predicting OAS30250_MR_d0389_9 
2025-12-22 14:54:55.537575: OAS30250_MR_d0389_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:55:12.209631: predicting OAS30262_MR_d0037_10 
2025-12-22 14:55:12.230784: OAS30262_MR_d0037_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:55:28.931482: predicting OAS30262_MR_d0037_3 
2025-12-22 14:55:28.953171: OAS30262_MR_d0037_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:55:45.641903: predicting OAS30262_MR_d0037_7 
2025-12-22 14:55:45.655070: OAS30262_MR_d0037_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:56:02.368399: predicting OAS30274_MR_d3332_8 
2025-12-22 14:56:02.386464: OAS30274_MR_d3332_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:56:19.087112: predicting OAS30274_MR_d3332_9 
2025-12-22 14:56:19.104982: OAS30274_MR_d3332_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:56:35.782923: predicting OAS30292_MR_d0165_5 
2025-12-22 14:56:35.804602: OAS30292_MR_d0165_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:56:52.512400: predicting OAS30292_MR_d0165_7 
2025-12-22 14:56:52.532071: OAS30292_MR_d0165_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:57:09.257203: predicting OAS30292_MR_d0165_8 
2025-12-22 14:57:09.272453: OAS30292_MR_d0165_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:57:25.946822: predicting OAS30297_MR_d1712_4 
2025-12-22 14:57:25.956777: OAS30297_MR_d1712_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:57:42.652165: predicting OAS30297_MR_d1712_7 
2025-12-22 14:57:42.664532: OAS30297_MR_d1712_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:57:59.353750: predicting OAS30300_MR_d0100_2 
2025-12-22 14:57:59.363265: OAS30300_MR_d0100_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:58:16.058629: predicting OAS30300_MR_d0100_9 
2025-12-22 14:58:16.067755: OAS30300_MR_d0100_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:58:32.784796: predicting OAS30302_MR_d0262_5 
2025-12-22 14:58:32.800868: OAS30302_MR_d0262_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:58:49.485019: predicting OAS30321_MR_d3003_10 
2025-12-22 14:58:49.508759: OAS30321_MR_d3003_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:59:06.246440: predicting OAS30321_MR_d3003_7 
2025-12-22 14:59:06.262444: OAS30321_MR_d3003_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:59:23.000753: predicting OAS30325_MR_d0032_3 
2025-12-22 14:59:23.013815: OAS30325_MR_d0032_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:59:39.728926: predicting OAS30325_MR_d0032_4 
2025-12-22 14:59:39.754313: OAS30325_MR_d0032_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 14:59:56.413007: predicting OAS30325_MR_d0032_7 
2025-12-22 14:59:56.435364: OAS30325_MR_d0032_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:00:13.133623: predicting OAS30343_MR_d4178_3 
2025-12-22 15:00:13.144390: OAS30343_MR_d4178_3, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:00:29.866040: predicting OAS30343_MR_d4178_7 
2025-12-22 15:00:29.885836: OAS30343_MR_d4178_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:00:46.616010: predicting OAS30349_MR_d0699_9 
2025-12-22 15:00:46.630475: OAS30349_MR_d0699_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:01:03.316524: predicting OAS30350_MR_d0018_1 
2025-12-22 15:01:03.328438: OAS30350_MR_d0018_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:01:20.038378: predicting OAS30350_MR_d0018_10 
2025-12-22 15:01:20.038378: OAS30350_MR_d0018_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:01:36.743700: predicting OAS30350_MR_d0018_4 
2025-12-22 15:01:36.753583: OAS30350_MR_d0018_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:01:53.444924: predicting OAS30350_MR_d0018_9 
2025-12-22 15:01:53.455737: OAS30350_MR_d0018_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:02:10.163438: predicting OAS30352_MR_d0099_2 
2025-12-22 15:02:10.177790: OAS30352_MR_d0099_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:02:26.879320: predicting OAS30352_MR_d0099_7 
2025-12-22 15:02:26.891307: OAS30352_MR_d0099_7, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:02:43.597914: predicting OAS30352_MR_d0099_9 
2025-12-22 15:02:43.609600: OAS30352_MR_d0099_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:03:00.322513: predicting OAS30354_MR_d0056_8 
2025-12-22 15:03:00.340498: OAS30354_MR_d0056_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:03:17.025145: predicting OAS30355_MR_d0048_5 
2025-12-22 15:03:17.033155: OAS30355_MR_d0048_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:03:33.717803: predicting OAS30367_MR_d1540_1 
2025-12-22 15:03:33.733548: OAS30367_MR_d1540_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:03:50.414814: predicting OAS30367_MR_d1540_5 
2025-12-22 15:03:50.434684: OAS30367_MR_d1540_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:04:07.136345: predicting OAS30369_MR_d4058_4 
2025-12-22 15:04:07.156029: OAS30369_MR_d4058_4, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:04:23.838588: predicting OAS30369_MR_d4058_5 
2025-12-22 15:04:23.858477: OAS30369_MR_d4058_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:04:40.562621: predicting OAS30369_MR_d4058_9 
2025-12-22 15:04:40.582402: OAS30369_MR_d4058_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:04:57.251385: predicting OAS30371_MR_d0338_1 
2025-12-22 15:04:57.266731: OAS30371_MR_d0338_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:05:13.935996: predicting OAS30371_MR_d0338_10 
2025-12-22 15:05:13.954034: OAS30371_MR_d0338_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:05:30.641183: predicting OAS30371_MR_d0338_8 
2025-12-22 15:05:30.651418: OAS30371_MR_d0338_8, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:05:47.339211: predicting OAS30371_MR_d0338_9 
2025-12-22 15:05:47.346873: OAS30371_MR_d0338_9, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:06:04.079604: predicting OAS30373_MR_d1211_1 
2025-12-22 15:06:04.093123: OAS30373_MR_d1211_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:06:20.818209: predicting OAS30380_MR_d3446_10 
2025-12-22 15:06:20.827700: OAS30380_MR_d3446_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:06:37.536097: predicting OAS30383_MR_d0134_2 
2025-12-22 15:06:37.551996: OAS30383_MR_d0134_2, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:06:54.277583: predicting OAS30383_MR_d0134_5 
2025-12-22 15:06:54.287484: OAS30383_MR_d0134_5, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:07:11.231818: predicting OAS30388_MR_d0073_1 
2025-12-22 15:07:11.251713: OAS30388_MR_d0073_1, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:07:28.323700: predicting OAS30388_MR_d0073_10 
2025-12-22 15:07:28.341530: OAS30388_MR_d0073_10, shape torch.Size([1, 202, 202, 202]), rank 0 
2025-12-22 15:08:11.815394: Validation complete 
2025-12-22 15:08:11.815394: Mean Validation Dice:  0.933902076342387 
